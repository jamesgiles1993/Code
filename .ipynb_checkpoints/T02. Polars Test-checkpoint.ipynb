{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b0b771-8bc9-4f75-9daf-1316bd2b5f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if not hasattr(sys.modules['__main__'], '__file__'):\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U1. Imports.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U2. Utilities.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U3. Classes.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U4. Datasets.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U5. Models.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8ce0f6-2eb6-4ecd-841b-2e99fc13c281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28e8cff1-f59e-4a58-a766-4747509c0168",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplier_df = pd.read_csv(os.path.join(baseball_path, \"Multiplier Dataset.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02405859-9235-419d-bb06-52eb83ede249",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b979a91-7a59-4d4b-b126-73771a2536ca",
   "metadata": {},
   "source": [
    "Create Latest PA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "208611b0-2531-45b0-b7e7-ae2db5db9c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge_datasets took 0.19 seconds\n",
      "clean_weather took 1.65 seconds\n",
      "create_events took 0.00 seconds\n",
      "create_variables took 0.09 seconds\n",
      "park_adjustments took 0.07 seconds\n",
      "start_data took 21.02 seconds\n",
      "Short took 3.90 seconds\n",
      "Long took 3.91 seconds\n",
      "CPU times: total: 30.5 s\n",
      "Wall time: 30.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "complete_dataset_unadjusted_latest = create_pa_inputs(multiplier_df, start_year=2025, end_year=2025, short=50, long=300, adjust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d2e8b3d-20de-4811-9084-667cf64004db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_data(df):\n",
    "    original_index = df.index  # Save the original index\n",
    "    \n",
    "    pl_df = pl.from_pandas(df)\n",
    "\n",
    "    # Calculate hits, total bases, reached, and faced\n",
    "    pl_df = pl_df.with_columns([\n",
    "        (pl.col('b1').cast(pl.Float64) + pl.col('b2').cast(pl.Float64) + pl.col('b3').cast(pl.Float64) + pl.col('hr').cast(pl.Float64)).alias('h'),\n",
    "        (pl.col('b1') * 1 + pl.col('b2') * 2 + pl.col('b3') * 3 + pl.col('hr') * 4).alias('tb'),\n",
    "        (pl.col('b1').cast(pl.Float64) + pl.col('b2').cast(pl.Float64) + pl.col('b3').cast(pl.Float64) + pl.col('hr').cast(pl.Float64) + pl.col('bb').cast(pl.Float64) + pl.col('hbp').cast(pl.Float64)).alias('reached'),\n",
    "        pl.lit(1).alias('faced'),\n",
    "        (((pl.col('inning') - 1) * 3) + pl.col('outs')).alias('outs_total')\n",
    "    ])\n",
    "\n",
    "    # Outs per PA\n",
    "    pl_df = pl_df.sort(['gamePk', 'inning', 'halfInning', 'atBatIndex'])\n",
    "    pl_df = pl_df.with_columns([\n",
    "        (pl.col('outs_total') - pl.col('outs_total').shift(1)).over(['gamePk', 'inning', 'halfInning']).alias('outs_pa')\n",
    "    ]).with_columns([\n",
    "        pl.when(pl.col('outs_pa').is_null()).then(pl.col('outs')).otherwise(pl.col('outs_pa')).alias('outs_pa')\n",
    "    ])\n",
    "\n",
    "    # Sort before cumulative calculations\n",
    "    pl_df = pl_df.sort(['gamePk', 'pitcher', 'inning', 'atBatIndex'])\n",
    "    \n",
    "    # Rolling cumulative stats per inning\n",
    "    for stat in events_list + ['h', 'tb', 'reached', 'faced', 'rbi', 'outs_pa']:\n",
    "        pl_df = pl_df.with_columns([\n",
    "            pl.col(stat).cum_sum().over(['gamePk', 'pitcher', 'inning']).alias(f'{stat}_inning')\n",
    "        ])\n",
    "\n",
    "    # Rolling cumulative stats per game\n",
    "    for stat in events_list + ['h', 'tb', 'reached', 'faced', 'rbi', 'outs_pa']:\n",
    "        pl_df = pl_df.with_columns([\n",
    "            pl.col(stat).cum_sum().over(['gamePk', 'pitcher']).alias(f'{stat}_game')\n",
    "        ])\n",
    "\n",
    "    # Bottom of the inning flag\n",
    "    pl_df = pl_df.with_columns([\n",
    "        (pl.col('top') == 0).cast(pl.Int8).alias('bottom')\n",
    "    ])\n",
    "\n",
    "    # Sort to identify starting pitchers\n",
    "    pl_df = pl_df.sort(['date', 'gamePk', 'bottom', 'atBatIndex'])\n",
    "\n",
    "    # Identify first at-bat for each bottom\n",
    "    pl_df = pl_df.with_columns([\n",
    "        pl.col('atBatIndex').min().over(['gamePk', 'bottom']).alias('atBatIndex_min')\n",
    "    ]).with_columns([\n",
    "        (pl.col('atBatIndex') == pl.col('atBatIndex_min')).cast(pl.Int8).alias('first_ab')\n",
    "    ])\n",
    "\n",
    "    # Identify pulled pitcher\n",
    "    pl_df = pl_df.with_columns([\n",
    "        pl.col('atBatIndex').max().over(['gamePk', 'pitcher']).alias('atBatIndex_max')\n",
    "    ]).with_columns([\n",
    "        (pl.col('atBatIndex') == pl.col('atBatIndex_max')).cast(pl.Int8).alias('pulled')\n",
    "    ])\n",
    "\n",
    "    # Times faced in game (adjusted for total batters faced)\n",
    "    pl_df = pl_df.with_columns([\n",
    "        (pl.col('faced_game') / 9).floor().fill_null(0).alias('times_faced')\n",
    "    ])\n",
    "\n",
    "    result = pl_df.to_pandas()\n",
    "    result.index = original_index  # Restore the original index\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63b489a5-ec0d-4c00-9b76-2de12fe7f1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_pas(df, pa_num, adjust, events_list=events_list):\n",
    "    if adjust:\n",
    "        events_list_copy = [f\"{event}_copy\" for event in events_list]\n",
    "        df[events_list_copy] = df[events_list].copy()\n",
    "        df[events_list] = df[events_list_adj].copy()\n",
    "    \n",
    "\n",
    "    \n",
    "    # Renaming columns on df before conversion to Polars\n",
    "    df.rename(columns={'hit_distance_sc': 'totalDistance', 'launch_speed': 'launchSpeed'}, inplace=True)\n",
    "\n",
    "    # Convert to Polars after renaming\n",
    "    pl_df = pl.from_pandas(df)\n",
    "\n",
    "    # Ensure types are correctly set after converting to Polars\n",
    "    pl_df = pl_df.with_columns([\n",
    "        pl.col('date').cast(pl.Int32),\n",
    "        pl.col('gamePk').cast(pl.Int32),\n",
    "        pl.col('atBatIndex').cast(pl.Int32),\n",
    "        pl.col('batter').cast(pl.Int32),\n",
    "        pl.col('pitcher').cast(pl.Int32)\n",
    "    ])\n",
    "\n",
    "    # Sorting is done in Polars\n",
    "    pl_df = pl_df.sort(['date', 'gamePk', 'atBatIndex'])\n",
    "\n",
    "    # Create expressions for batter and pitcher stats\n",
    "    batter_avg_exprs = [\n",
    "        pl.col(col).rolling_mean(window_size=pa_num, min_periods=1).over(['batter', 'pitchHand']).alias(col + '_b')\n",
    "        for col in events_list + statcast_list\n",
    "    ]\n",
    "    batter_max_exprs = [\n",
    "        pl.col(col).rolling_max(window_size=pa_num, min_periods=1).over(['batter', 'pitchHand']).alias(col + '_b')\n",
    "        for col in max_list\n",
    "    ]\n",
    "    batter_sum_exprs = [\n",
    "        pl.col(col).rolling_sum(window_size=pa_num, min_periods=1).over(['batter', 'pitchHand']).alias(col + '_b')\n",
    "        for col in ['ab', 'pa']\n",
    "    ]\n",
    "\n",
    "    pitcher_avg_exprs = [\n",
    "        pl.col(col).rolling_mean(window_size=pa_num, min_periods=1).over(['pitcher', 'batSide']).alias(col + '_p')\n",
    "        for col in events_list + statcast_list\n",
    "    ]\n",
    "    pitcher_max_exprs = [\n",
    "        pl.col(col).rolling_max(window_size=pa_num, min_periods=1).over(['pitcher', 'batSide']).alias(col + '_p')\n",
    "        for col in max_list\n",
    "    ]\n",
    "    pitcher_sum_exprs = [\n",
    "        pl.col(col).rolling_sum(window_size=pa_num, min_periods=1).over(['pitcher', 'batSide']).alias(col + '_p')\n",
    "        for col in ['ab', 'pa']\n",
    "    ]\n",
    "\n",
    "    # Add the computed columns to pl_df\n",
    "    pl_df = pl_df.with_columns(\n",
    "        batter_avg_exprs + batter_max_exprs + batter_sum_exprs +\n",
    "        pitcher_avg_exprs + pitcher_max_exprs + pitcher_sum_exprs\n",
    "    )\n",
    "\n",
    "    # Create 'imp_b' and 'imp_p' directly in Polars\n",
    "    pl_df = pl_df.with_columns([\n",
    "        (pl.col('pa_b') < 40).cast(pl.Int32).alias('imp_b'),\n",
    "        (pl.col('pa_p') < 40).cast(pl.Int32).alias('imp_p')\n",
    "    ])\n",
    "\n",
    "    # Clean up date and other columns directly in Polars\n",
    "    pl_df = pl_df.with_columns([\n",
    "        pl.col('game_date').str.replace_all('-', '').cast(pl.Int32).alias('date'),\n",
    "        pl.col('gamePk').cast(pl.Int32),\n",
    "        pl.col('atBatIndex').cast(pl.Int32),\n",
    "        pl.col('batter').cast(pl.Int32),\n",
    "        pl.col('pitcher').cast(pl.Int32)\n",
    "    ])\n",
    "\n",
    "    # Sort the data as needed\n",
    "    pl_df = pl_df.sort(['date', 'gamePk', 'atBatIndex'])\n",
    "\n",
    "    # Calculating wOBA, SLG, OBP, and ISO directly in Polars\n",
    "    pl_df = pl_df.with_columns([\n",
    "        (0.690 * pl.col('bb_b') + 0.721 * pl.col('hbp_b') +\n",
    "         0.885 * pl.col('b1_b') + 1.262 * pl.col('b2_b') +\n",
    "         1.601 * pl.col('b3_b') + 2.070 * pl.col('hr_b')).alias('woba_b'),\n",
    "        (0.690 * pl.col('bb_p') + 0.721 * pl.col('hbp_p') +\n",
    "         0.885 * pl.col('b1_p') + 1.262 * pl.col('b2_p') +\n",
    "         1.601 * pl.col('b3_p') + 2.070 * pl.col('hr_p')).alias('woba_p'),\n",
    "\n",
    "        ((1 * pl.col('b1_b') + 2 * pl.col('b2_b') + 3 * pl.col('b3_b') + 4 * pl.col('hr_b')) *\n",
    "         (1 / (1 - (pl.col('bb_b') + pl.col('hbp_b'))))).alias('slg_b'),\n",
    "        ((1 * pl.col('b1_p') + 2 * pl.col('b2_p') + 3 * pl.col('b3_p') + 4 * pl.col('hr_p')) *\n",
    "         (1 / (1 - (pl.col('bb_p') + pl.col('hbp_p'))))).alias('slg_p'),\n",
    "\n",
    "        (pl.col('b1_b') + pl.col('b2_b') + pl.col('b3_b') + pl.col('hr_b') +\n",
    "         pl.col('bb_b') + pl.col('hbp_b')).alias('obp_b'),\n",
    "        (pl.col('b1_p') + pl.col('b2_p') + pl.col('b3_p') + pl.col('hr_p') +\n",
    "         pl.col('bb_p') + pl.col('hbp_p')).alias('obp_p'),\n",
    "\n",
    "        ((pl.col('b2_b') + 2 * pl.col('b3_b') + 3 * pl.col('hr_b')) *\n",
    "         (1 / (1 - (pl.col('bb_b') + pl.col('hbp_b'))))).alias('iso_b'),\n",
    "        ((pl.col('b2_p') + 2 * pl.col('b3_p') + 3 * pl.col('hr_p')) *\n",
    "         (1 / (1 - (pl.col('bb_p') + pl.col('hbp_p'))))).alias('iso_p')\n",
    "    ])\n",
    "\n",
    "    # Convert back to pandas for final operations\n",
    "    df_copy = pl_df.to_pandas()\n",
    "    \n",
    "    if adjust:\n",
    "        df[events_list] = df[events_list_copy].copy()\n",
    "        \n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68fb2766-19ae-419d-b64d-36fcf2c51bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_weather(df):\n",
    "    import numpy as np\n",
    "\n",
    "    # Split weather into temperature and weather type\n",
    "    weather_split = df['weather'].str.split(\", \", expand=True)\n",
    "    df['temperature'] = pd.to_numeric(weather_split[0].str.replace(\" degrees\", \"\"), errors='coerce')\n",
    "    df['weather'] = weather_split[1]\n",
    "\n",
    "    # Split wind into speed and direction\n",
    "    wind_split = df['wind'].str.split(\", \", expand=True)\n",
    "    df['windSpeed'] = pd.to_numeric(wind_split[0].str.replace(\" mph\", \"\"), errors='coerce').fillna(0)\n",
    "    df['windDirection'] = wind_split[1].fillna('L to R').str.replace(\".\", \"\", regex=False)\n",
    "\n",
    "    wind_speed = df['windSpeed'].to_numpy()\n",
    "    angled = wind_speed / 2 * np.sqrt(2)\n",
    "    direction = df['windDirection'].to_numpy()\n",
    "\n",
    "    # Create lookup tables\n",
    "    y_lookup = {\n",
    "        \"Out To CF\": wind_speed,\n",
    "        \"Out To RF\": angled,\n",
    "        \"L To R\": np.zeros_like(wind_speed),\n",
    "        \"In From LF\": -angled,\n",
    "        \"In From CF\": -wind_speed,\n",
    "        \"In From RF\": -angled,\n",
    "        \"R To L\": np.zeros_like(wind_speed),\n",
    "        \"Out To LF\": angled\n",
    "    }\n",
    "\n",
    "    x_lookup = {\n",
    "        \"L To R\": wind_speed,\n",
    "        \"In From LF\": angled,\n",
    "        \"In From CF\": np.zeros_like(wind_speed),\n",
    "        \"In From RF\": -angled,\n",
    "        \"R To L\": -wind_speed,\n",
    "        \"Out To LF\": -angled,\n",
    "        \"Out To CF\": np.zeros_like(wind_speed),\n",
    "        \"Out To RF\": angled\n",
    "    }\n",
    "\n",
    "    df['y_vect'] = np.zeros(len(df))\n",
    "    df['x_vect'] = np.zeros(len(df))\n",
    "\n",
    "    for key, values in y_lookup.items():\n",
    "        df.loc[direction == key, 'y_vect'] = values[direction == key]\n",
    "    for key, values in x_lookup.items():\n",
    "        df.loc[direction == key, 'x_vect'] = values[direction == key]\n",
    "\n",
    "    # Overwrite for domes/roofs\n",
    "    is_dome = df['weather'].str.contains('Roof|Dome', na=False)\n",
    "    df.loc[is_dome, 'temperature'] = 70\n",
    "    df.loc[is_dome, ['x_vect', 'y_vect']] = 0\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5b635c2-9888-4944-864d-7c61c8139550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge_datasets took 0.19 seconds\n",
      "clean_weather took 0.10 seconds\n",
      "create_events took 0.00 seconds\n",
      "create_variables took 0.08 seconds\n",
      "park_adjustments took 0.06 seconds\n",
      "start_data took 0.22 seconds\n",
      "Short took 0.13 seconds\n",
      "Long took 0.13 seconds\n",
      "CPU times: total: 2.73 s\n",
      "Wall time: 977 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "complete_dataset_unadjusted_latest_pl = create_pa_inputs(multiplier_df, start_year=2025, end_year=2025, short=50, long=300, adjust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b1163eb-e786-4a83-b105-b63dde111183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(complete_dataset_unadjusted_latest.columns) == list(complete_dataset_unadjusted_latest_pl.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0205d4f0-ceec-4bbe-894b-6e0f2070251a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15259</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15260</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15261</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15262</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15263</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15264</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15265</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15266</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15267</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15268</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15269</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15270</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15271</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15272</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15273</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15274</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15275</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15276</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15277</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15278</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15279</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15280</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15281</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15282</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15283</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15284</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15285</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15286</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15287</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15288</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15289</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15290</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15291</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15292</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15293</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15294</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15295</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15296</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15297</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15298</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15299</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15300</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15301</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15302</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15303</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15304</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15305</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15306</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15307</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15308</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15309</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15310</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15311</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15312</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15314</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15315</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15316</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15317</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15318</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15319</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15320</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15321</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15322</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15323</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15324</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15325</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15326</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15327</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15328</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15329</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15330</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15331</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15332</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15333</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15334</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15335</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15336</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15337</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15338</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15339</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15340</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15341</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15342</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15343</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15344</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15345</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15346</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15347</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15348</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15349</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15350</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15351</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15352</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15353</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15354</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15355</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15356</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15357</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15358</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15359</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       self  other\n",
       "15259   NaN    NaN\n",
       "15260   NaN    NaN\n",
       "15261   NaN    NaN\n",
       "15262   NaN    NaN\n",
       "15263   NaN    NaN\n",
       "15264   NaN    NaN\n",
       "15265   NaN    NaN\n",
       "15266   NaN    NaN\n",
       "15267   NaN    NaN\n",
       "15268   NaN    NaN\n",
       "15269   NaN    NaN\n",
       "15270   NaN    NaN\n",
       "15271   NaN    NaN\n",
       "15272   NaN    NaN\n",
       "15273   NaN    NaN\n",
       "15274   NaN    NaN\n",
       "15275   NaN    NaN\n",
       "15276   NaN    NaN\n",
       "15277   NaN    NaN\n",
       "15278   NaN    NaN\n",
       "15279   NaN    NaN\n",
       "15280   NaN    NaN\n",
       "15281   NaN    NaN\n",
       "15282   NaN    NaN\n",
       "15283   NaN    NaN\n",
       "15284   NaN    NaN\n",
       "15285   NaN    NaN\n",
       "15286   NaN    NaN\n",
       "15287   NaN    NaN\n",
       "15288   NaN    NaN\n",
       "15289   NaN    NaN\n",
       "15290   NaN    NaN\n",
       "15291   NaN    NaN\n",
       "15292   NaN    NaN\n",
       "15293   NaN    NaN\n",
       "15294   NaN    NaN\n",
       "15295   NaN    NaN\n",
       "15296   NaN    NaN\n",
       "15297   NaN    NaN\n",
       "15298   NaN    NaN\n",
       "15299   NaN    NaN\n",
       "15300   NaN    NaN\n",
       "15301   NaN    NaN\n",
       "15302   NaN    NaN\n",
       "15303   NaN    NaN\n",
       "15304   NaN    NaN\n",
       "15305   NaN    NaN\n",
       "15306   NaN    NaN\n",
       "15307   NaN    NaN\n",
       "15308   NaN    NaN\n",
       "15309   NaN    NaN\n",
       "15310   NaN    NaN\n",
       "15311   NaN    NaN\n",
       "15312   NaN    NaN\n",
       "15314   NaN    NaN\n",
       "15315   NaN    NaN\n",
       "15316   NaN    NaN\n",
       "15317   NaN    NaN\n",
       "15318   NaN    NaN\n",
       "15319   NaN    NaN\n",
       "15320   NaN    NaN\n",
       "15321   NaN    NaN\n",
       "15322   NaN    NaN\n",
       "15323   NaN    NaN\n",
       "15324   NaN    NaN\n",
       "15325   NaN    NaN\n",
       "15326   NaN    NaN\n",
       "15327   NaN    NaN\n",
       "15328   NaN    NaN\n",
       "15329   NaN    NaN\n",
       "15330   NaN    NaN\n",
       "15331   NaN    NaN\n",
       "15332   NaN    NaN\n",
       "15333   NaN    NaN\n",
       "15334   NaN    NaN\n",
       "15335   NaN    NaN\n",
       "15336   NaN    NaN\n",
       "15337   NaN    NaN\n",
       "15338   NaN    NaN\n",
       "15339   NaN    NaN\n",
       "15340   NaN    NaN\n",
       "15341   NaN    NaN\n",
       "15342   NaN    NaN\n",
       "15343   NaN    NaN\n",
       "15344   NaN    NaN\n",
       "15345   NaN    NaN\n",
       "15346   NaN    NaN\n",
       "15347   NaN    NaN\n",
       "15348   NaN    NaN\n",
       "15349   NaN    NaN\n",
       "15350   NaN    NaN\n",
       "15351   NaN    NaN\n",
       "15352   NaN    NaN\n",
       "15353   NaN    NaN\n",
       "15354   NaN    NaN\n",
       "15355   NaN    NaN\n",
       "15356   NaN    NaN\n",
       "15357   NaN    NaN\n",
       "15358   NaN    NaN\n",
       "15359   NaN    NaN"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Align both rows (index) and columns of both DataFrames\n",
    "aligned_a, aligned_b = complete_dataset_unadjusted_latest.align(complete_dataset_unadjusted_latest_pl, axis=1, join='inner')\n",
    "\n",
    "# Now compare the aligned DataFrames\n",
    "diff = aligned_a.compare(aligned_b)\n",
    "diff['b1_b'].tail(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bd649a-8a53-420a-b564-937baa05f5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e44f4cc-a77f-40c6-b086-0d7650105025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac868cd8-cf5f-4345-b1e9-5029a4625a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda-base)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
