{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9bfbed2-b92a-4943-8ed0-2c617f6e1ea9",
   "metadata": {},
   "source": [
    "### MLB Stats API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8d171e-fd22-43ab-9519-34da1365191a",
   "metadata": {},
   "source": [
    "##### Box Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b766ada4-3301-44da-afd5-93306c0c304e",
   "metadata": {},
   "source": [
    "Extract game information from boxscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e5d0f6-3979-4a21-a770-fbc7209992ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in boxscore for weather\n",
    "def create_box(gamePk):\n",
    "    # Read in boxscore as json\n",
    "    box = pd.json_normalize(statsapi.boxscore_data(gamePk, timecode=None), record_path='gameBoxInfo')\n",
    "    \n",
    "    # Define default values\n",
    "    default_weather = \"75 degrees, Clear.\"\n",
    "    default_wind = \"0 mph, L To R.\"\n",
    "    default_venue = \"Missing Park.\"\n",
    "    default_date = \"November 30, 1993\"\n",
    "    \n",
    "    # Extract weather, wind, venue, and date\n",
    "    weather = box.loc[box['label'] == \"Weather\", \"value\"].item() if 'Weather' in box['label'].values else default_weather\n",
    "    wind = box.loc[box['label'] == \"Wind\", \"value\"].item() if 'Wind' in box['label'].values else default_wind\n",
    "    venue = box.loc[box['label'] == \"Venue\", \"value\"].item() if 'Venue' in box['label'].values else default_venue\n",
    "    \n",
    "    try:\n",
    "        date = box.iloc[-1, box.columns.get_loc('label')]\n",
    "    except:\n",
    "        date = default_date\n",
    "\n",
    "    if \"Weather\" not in list(box['label']):\n",
    "        missing_weather = True\n",
    "    else:\n",
    "        missing_weather = False\n",
    "        \n",
    "    \n",
    "    \n",
    "    return weather, wind, venue, date, missing_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d2240c-4c45-4f91-abbd-2cbdebc50a6c",
   "metadata": {},
   "source": [
    "Extract relevant data or provide default (helper function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad9c8c-b213-4276-9af6-3f804ff65d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_field(data, field, default=None):\n",
    "    try:\n",
    "        return data[field]\n",
    "    except:\n",
    "        return default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4884162-5de2-4115-9a66-d787d2c1f3ca",
   "metadata": {},
   "source": [
    "Extract play-by-play data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18d08cd-f91f-4d8d-a08f-49de1c9154ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_play_by_play(gamePk):\n",
    "    game = statsapi.get('game_playByPlay', {'gamePk': gamePk})\n",
    "    \n",
    "    # Create list with relevant variables\n",
    "    game_data = []\n",
    "    for play in game['allPlays']:\n",
    "        about = play['about']\n",
    "        count = play['count']\n",
    "        result = play['result']\n",
    "        matchup = play['matchup']\n",
    "        runners = play['runners']\n",
    "        \n",
    "        atBatIndex = about['atBatIndex']\n",
    "        inning = about['inning']\n",
    "        halfInning = about['halfInning']\n",
    "        outs = count['outs']\n",
    "        \n",
    "        type = extract_field(result, 'type')\n",
    "        event = extract_field(result, 'event')\n",
    "        eventType = extract_field(result, 'eventType')\n",
    "        description = extract_field(result, 'description')\n",
    "        rbi = extract_field(result, 'rbi', 0)\n",
    "        awayScore = extract_field(result, 'awayScore', 0)\n",
    "        homeScore = extract_field(result, 'homeScore', 0)\n",
    "        \n",
    "        batter = extract_field(matchup['batter'], 'id', 999999)\n",
    "        batterName = extract_field(matchup['batter'], 'fullName', 'Missing Name')\n",
    "        batSide = extract_field(matchup['batSide'], 'code', 'R')\n",
    "        pitcher = extract_field(matchup['pitcher'], 'id', 999999)\n",
    "        pitcherName = extract_field(matchup['pitcher'], 'fullName', 'Missing Name')\n",
    "        pitchHand = extract_field(matchup['pitchHand'], 'code', 'R')\n",
    "        \n",
    "        # Baserunner on base at the end of the play\n",
    "        postOnFirst = extract_field(matchup, 'postOnFirst', None)\n",
    "        postOnSecond = extract_field(matchup, 'postOnSecond', None)\n",
    "        postOnThird = extract_field(matchup, 'postOnThird', None)\n",
    "        \n",
    "        # Extract base runner information\n",
    "        for runner in runners:\n",
    "            details = runner['details']\n",
    "            movement = runner['movement']\n",
    "            \n",
    "            runner_id = details['runner']['id']\n",
    "            start = movement['start']\n",
    "            end = movement['end']\n",
    "            movementReason = details['movementReason']\n",
    "            isScoringEvent = details['isScoringEvent']\n",
    "            earned = details['earned']\n",
    "            \n",
    "            game_data.append([atBatIndex, inning, halfInning, outs, type, runner_id, event, eventType, description, \n",
    "                              rbi, awayScore, homeScore, batter, batterName, batSide, pitcher, pitcherName, pitchHand, \n",
    "                              postOnFirst, postOnSecond, postOnThird, runner_id, start, end, movementReason, isScoringEvent, earned])\n",
    "    \n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame(game_data, columns=['atBatIndex', 'inning', 'halfInning', 'outs', 'type', 'id', 'event', 'eventType', 'description', \n",
    "                                          'rbi', 'awayScore', 'homeScore', 'batter', 'batterName', 'batSide', 'pitcher', \n",
    "                                          'pitcherName', 'pitchHand', 'postOnFirst', 'postOnSecond', 'postOnThird', 'runner_id', 'start', 'end', \n",
    "                                          'movementReason', 'isScoringEvent', 'earned'])\n",
    " \n",
    "    # Create weather variables\n",
    "    weather, wind, venue, date, missing_weather = create_box(gamePk)\n",
    "    df['gamePk'] = gamePk\n",
    "    df['weather'] = weather\n",
    "    df['wind'] = wind\n",
    "    df['venue'] = venue\n",
    "    df['date'] = date\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09693acf-2db5-4fe5-99f1-8234d9b067fc",
   "metadata": {},
   "source": [
    "Extract API data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51055352-47f8-48ad-bca3-0595030721c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plays_statsapi(start_date, end_date):\n",
    "    # Extract year\n",
    "    year = start_date[-4:]\n",
    "    \n",
    "    # Read in schedule\n",
    "    games = statsapi.schedule(start_date=start_date, end_date=end_date)\n",
    "\n",
    "    # Use a list comprehension to extract unique game_ids\n",
    "    game_ids = list(game['game_id'] for game in games)\n",
    "    away_names = list(game['away_name'] for game in games)\n",
    "    home_names = list(game['home_name'] for game in games)\n",
    "    game_dates = list(game['game_date'] for game in games)\n",
    "    game_types = list(game['game_type'] for game in games)\n",
    "    venue_ids = list(game['venue_id'] for game in games)\n",
    "\n",
    "    # Run all in parallel\n",
    "    df_list = Parallel(n_jobs=-1, verbose=0)(delayed(create_play_by_play)(gamePk=game_id) for game_id in game_ids)\n",
    "\n",
    "    # Add additional information from schedule\n",
    "    for i in range(len(df_list)):\n",
    "        df_list[i]['away_name'] = away_names[i]\n",
    "        df_list[i]['home_name'] = home_names[i]\n",
    "        df_list[i]['game_date'] = game_dates[i]\n",
    "        df_list[i]['game_type'] = game_types[i]\n",
    "        df_list[i]['venue_id'] = venue_ids[i]\n",
    "    \n",
    "    # Append all dataframes together\n",
    "    df = pd.concat(df_list, axis=0)\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc639de6-17a1-4987-adfe-7529ee94ec9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db95afff-9b70-4350-a91a-3f570f64513d",
   "metadata": {},
   "source": [
    "### Statcast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504af340-2339-4a3e-91cb-90ef158f0ea2",
   "metadata": {},
   "source": [
    "Extract Statcast data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66ad3fb-e744-4684-beb3-1d3d1ee60760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plays_statcast(start_date, end_date):\n",
    "    # Extract year\n",
    "    year = start_date[:4]\n",
    "    \n",
    "    # Use pybaseball to read in Statcast data\n",
    "    data = statcast(start_date, end_date)\n",
    "    \n",
    "    # Create atBatIndex compatible with Statsapi\n",
    "    data['atBatIndex'] = data['at_bat_number'] - 1 \n",
    "    \n",
    "    # Highest level during the at bat\n",
    "    data['maxSpeed'] = data.groupby(['game_pk', 'atBatIndex'])['effective_speed'].transform(max)\n",
    "    data['maxSpin'] = data.groupby(['game_pk', 'atBatIndex'])['release_spin_rate'].transform(max)\n",
    "    \n",
    "    # Convert to numeric for sorting\n",
    "    data['game_pk'] = data['game_pk'].astype('int')\n",
    "    data['atBatIndex'] = data['atBatIndex'].astype('int')\n",
    "    data['pitch_number'] = data['pitch_number'].astype('int')\n",
    "    \n",
    "    # Only want the deciding (last) pitch\n",
    "    data.sort_values(['game_pk', 'atBatIndex', 'pitch_number'], inplace=True)\n",
    "    data.drop_duplicates(['game_pk', 'atBatIndex'], keep='last', inplace=True)\n",
    "    \n",
    "    data.rename(columns={'game_pk':'gamePk'}, inplace=True)\n",
    "    \n",
    "    # Keep relevant variables\n",
    "    keep_list = ['gamePk', 'atBatIndex', 'pitch_number', 'pitch_name', 'game_type',\n",
    "                 'hc_x', 'hc_y', 'hit_location', 'hit_distance_sc', 'launch_speed', 'launch_angle', 'launch_speed_angle',\n",
    "                 'woba_value', 'woba_denom', 'estimated_ba_using_speedangle', 'estimated_woba_using_speedangle',\n",
    "                 'iso_value', 'babip_value',\n",
    "                 'maxSpeed', 'maxSpin']\n",
    "                \n",
    "    data = data[keep_list]\n",
    "\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a6432e-1dbd-484a-b635-51b4bbff974c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85c5d873-8d0e-4e02-9de3-de9217dad8c7",
   "metadata": {},
   "source": [
    "### Complete Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe547cf-a769-4a55-b045-3b64196406e4",
   "metadata": {},
   "source": [
    "##### 1. Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdab70b7-8146-4f62-be70-b6a400f26131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_year(year):\n",
    "    statsapi_df = pd.read_csv(os.path.join(baseball_path, \"A02. MLB API\", \"1. Stats API\", f\"Stats API {year}.csv\"), encoding='iso-8859-1')\n",
    "    statcast_df = pd.read_csv(os.path.join(baseball_path, \"A02. MLB API\", \"2. Statcast\", f\"Statcast {year}.csv\"), encoding='iso-8859-1')\n",
    "\n",
    "    merged_df = pd.merge(statsapi_df, statcast_df, on=['gamePk', 'atBatIndex'], how='left', suffixes=(\"\", \"_copy\"))\n",
    "    merged_df.drop_duplicates(['gamePk', 'atBatIndex'], keep='first', inplace=True)\n",
    "    merged_df.drop(columns={'game_type_copy'}, inplace=True)\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "def merge_datasets(start_year=2015, end_year=2025):\n",
    "    df_list = Parallel(n_jobs=-1)(delayed(process_year)(year) for year in range(start_year, end_year + 1))\n",
    "    df = pd.concat(df_list, axis=0)\n",
    "    df.sort_values(['game_date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "    df.drop_duplicates(['gamePk', 'atBatIndex'], keep='first', inplace=True)\n",
    "    # Only keep regular season games\n",
    "    df = df[df['game_type'] == \"R\"]\n",
    "    \n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ce5d5f-5e1e-4d14-9b39-9a73e2836397",
   "metadata": {},
   "source": [
    "##### 2. Clean Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b22c001-0943-4bcc-8330-d6df39580b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_weather(df):\n",
    "    import numpy as np\n",
    "\n",
    "    # Split weather into temperature and weather type\n",
    "    weather_split = df['weather'].str.split(\", \", expand=True)\n",
    "    df['temperature'] = pd.to_numeric(weather_split[0].str.replace(\" degrees\", \"\"), errors='coerce')\n",
    "    df['weather'] = weather_split[1]\n",
    "\n",
    "    # Split wind into speed and direction\n",
    "    wind_split = df['wind'].str.split(\", \", expand=True)\n",
    "    df['windSpeed'] = pd.to_numeric(wind_split[0].str.replace(\" mph\", \"\"), errors='coerce').fillna(0)\n",
    "    df['windDirection'] = wind_split[1].fillna('L to R').str.replace(\".\", \"\", regex=False)\n",
    "\n",
    "    wind_speed = df['windSpeed'].to_numpy()\n",
    "    angled = wind_speed / 2 * np.sqrt(2)\n",
    "    direction = df['windDirection'].to_numpy()\n",
    "\n",
    "    # Create lookup tables\n",
    "    y_lookup = {\n",
    "        \"Out To CF\": wind_speed,\n",
    "        \"Out To RF\": angled,\n",
    "        \"L To R\": np.zeros_like(wind_speed),\n",
    "        \"In From LF\": -angled,\n",
    "        \"In From CF\": -wind_speed,\n",
    "        \"In From RF\": -angled,\n",
    "        \"R To L\": np.zeros_like(wind_speed),\n",
    "        \"Out To LF\": angled\n",
    "    }\n",
    "\n",
    "    x_lookup = {\n",
    "        \"L To R\": wind_speed,\n",
    "        \"In From LF\": angled,\n",
    "        \"In From CF\": np.zeros_like(wind_speed),\n",
    "        \"In From RF\": -angled,\n",
    "        \"R To L\": -wind_speed,\n",
    "        \"Out To LF\": -angled,\n",
    "        \"Out To CF\": np.zeros_like(wind_speed),\n",
    "        \"Out To RF\": angled\n",
    "    }\n",
    "\n",
    "    df['y_vect'] = np.zeros(len(df))\n",
    "    df['x_vect'] = np.zeros(len(df))\n",
    "\n",
    "    for key, values in y_lookup.items():\n",
    "        df.loc[direction == key, 'y_vect'] = values[direction == key]\n",
    "    for key, values in x_lookup.items():\n",
    "        df.loc[direction == key, 'x_vect'] = values[direction == key]\n",
    "\n",
    "    # Overwrite for domes/roofs\n",
    "    is_dome = df['weather'].str.contains('Roof|Dome', na=False)\n",
    "    df.loc[is_dome, 'temperature'] = 70\n",
    "    df.loc[is_dome, ['x_vect', 'y_vect']] = 0\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c88c9b0-0cdd-4814-b2be-8ba2f3b3af3e",
   "metadata": {},
   "source": [
    "##### 3. Create PA Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0c0bed1-43d5-4976-8bbc-3d3743518e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign play categories to full descriptions\n",
    "def create_events(df):\n",
    "    event_mapping = {\n",
    "        'Strikeout': 'so',\n",
    "        'Strikeout Double Play': 'so',\n",
    "        'Groundout': 'go',\n",
    "        'Fielders Choice': 'go',\n",
    "        'Fielders Choice Out': 'go',\n",
    "        'Double Play': 'go',\n",
    "        'Grounded Into DP': 'go',\n",
    "        'Triple Play': 'go',\n",
    "        'Field Error': 'go',\n",
    "        'Forceout': 'go',\n",
    "        'Sac Bunt': 'go',\n",
    "        'Sac Bunt Double Play': 'go', \n",
    "        'Bunt Groundout': 'go',\n",
    "        'Lineout': 'lo',\n",
    "        'Bunt Lineout': 'lo',\n",
    "        'Flyout': 'fo',\n",
    "        'Sac Fly': 'fo',\n",
    "        'Sac Fly Double Play': 'fo',\n",
    "        'Pop Out': 'po',\n",
    "        'Bunt Pop Out': 'po',\n",
    "        'Hit By Pitch': 'hbp',\n",
    "        'Walk': 'bb',\n",
    "        'Intent Walk': 'bb',\n",
    "        'Single': 'b1',\n",
    "        'Double': 'b2',\n",
    "        'Triple': 'b3',\n",
    "        'Home Run': 'hr'\n",
    "    }\n",
    "\n",
    "    df['eventsModel'] = df['event'].map(event_mapping).fillna('Cut')\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7368a3-1ae2-4fe5-9bd2-bf265e46bc96",
   "metadata": {},
   "source": [
    "##### 4. Create Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b97c232-0f40-4761-93a9-6e9b7bf93f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This turns several variables, including events, venues, hands, and bases into dummies\n",
    "def create_variables(df):    \n",
    "    # Events\n",
    "    event_dummies = pd.get_dummies(df['eventsModel'])\n",
    "    \n",
    "    # Hands\n",
    "    pitcher_dummies = pd.get_dummies(df['pitchHand'], prefix='p')\n",
    "    batter_dummies = pd.get_dummies(df['batSide'], prefix='b')\n",
    "    \n",
    "    # Years\n",
    "    df['year'] = df['game_date'].str[:4]\n",
    "    \n",
    "    # Add dummies to dataframe\n",
    "    df = pd.concat([df, event_dummies, pitcher_dummies, batter_dummies], axis=1)\n",
    "\n",
    "    # Identify starting pitcher\n",
    "    df['startingPitcher'] = df.groupby(['gamePk', 'halfInning'])['pitcherName'].transform('first')\n",
    "    df['starter'] = (df['startingPitcher'] == df['pitcherName']).astype('int')\n",
    "    \n",
    "    # Determine outs coming into PA\n",
    "    df['outs_pre'] = df.groupby(['gamePk', 'inning', 'halfInning'])['outs'].shift(fill_value=0)\n",
    "    \n",
    "    # Determine if PA ended in an out \n",
    "    df['is_out'] = df[['so', 'go', 'lo', 'po', 'fo']].sum(axis=1)\n",
    "    \n",
    "    # Create compatible date variable\n",
    "    df['date'] = df['game_date'].str.replace('-', '')\n",
    "    \n",
    "    # Convert to numeric for sorting\n",
    "    df['date'] = df['date'].astype('int')\n",
    "    df['gamePk'] = df['gamePk'].astype('int')\n",
    "    df['atBatIndex'] = df['atBatIndex'].astype('int')\n",
    "    \n",
    "    # Sort\n",
    "    df.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "    \n",
    "    # Create dummy for runners on base\n",
    "    df['preOnFirst'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnFirst'].shift(1)\n",
    "    df['preOnSecond'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnSecond'].shift(1)\n",
    "    df['preOnThird'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnThird'].shift(1)\n",
    "    \n",
    "    df['onFirst'] = df['preOnFirst'].apply(lambda x: 1 if isinstance(x, str) and 'id' in x else 0)\n",
    "    df['onSecond'] = df['preOnSecond'].apply(lambda x: 1 if isinstance(x, str) and 'id' in x else 0)\n",
    "    df['onThird'] = df['preOnThird'].apply(lambda x: 1 if isinstance(x, str) and 'id' in x else 0)\n",
    "    \n",
    "    # Top of the inning dummy\n",
    "    df['top'] = np.where(df['halfInning'] == \"top\", 1, 0)\n",
    "    \n",
    "    # Convert to numeric\n",
    "    df['awayScore'] = df['awayScore'].astype('int')\n",
    "    df['homeScore'] = df['homeScore'].astype('int')\n",
    "    \n",
    "    # Determine score before PA\n",
    "    df['preAwayScore'] = df.groupby(['gamePk'])['awayScore'].shift(1)\n",
    "    df['preHomeScore'] = df.groupby(['gamePk'])['homeScore'].shift(1)\n",
    "    \n",
    "    # If it's the first PA, it'll be missing. \n",
    "    df['preAwayScore'] = df['preAwayScore'].fillna(0)\n",
    "    df['preHomeScore'] = df['preHomeScore'].fillna(0)\n",
    "    \n",
    "    # Calculate differential\n",
    "    df['score_diff'] = np.where(df['top'] == 1, df['preAwayScore'] - df['preHomeScore'], df['preHomeScore'] - df['preAwayScore'])\n",
    "    \n",
    "    # Determine hitter and pitcher scores\n",
    "    df['batterScore'] = np.where(df['halfInning'] == 'top', df['awayScore'], df['homeScore'])\n",
    "    df['pitcherScore'] = np.where(df['halfInning'] == 'top', df['homeScore'], df['awayScore'])\n",
    "    \n",
    "    # Determine score before PA\n",
    "    df['preBatterScore'] = np.where(df['halfInning'] == 'top', df['preAwayScore'], df['preHomeScore'])\n",
    "    df['prePitcherScore'] = np.where(df['halfInning'] == 'top', df['preHomeScore'], df['preAwayScore'])\n",
    "    \n",
    "    # Calculate PAs and ABs\n",
    "    df['pa'] = np.where(df['eventsModel'] != \"Cut\", 1, 0)\n",
    "    df['ab'] = df['pa'] - df['hbp'] - df['bb']           \n",
    "    \n",
    "    \n",
    "    # Fix Guardians name to make uniform\n",
    "    df['away_name'] = np.where(df['away_name'] == \"Cleveland Indians\", \"Cleveland Guardians\", df['away_name'])\n",
    "    df['home_name'] = np.where(df['home_name'] == \"Cleveland Indians\", \"Cleveland Guardians\", df['home_name'])\n",
    "\n",
    "    \n",
    "    ### Statcast\n",
    "    # Convert variables to numeric\n",
    "    df['launch_speed'] = pd.to_numeric(df['launch_speed'], errors='coerce')\n",
    "    df['launch_speed_angle'] = pd.to_numeric(df['launch_speed_angle'], errors='coerce')\n",
    "    df['hc_x'] = pd.to_numeric(df['hc_x'], errors='coerce')\n",
    "    df['hc_y'] = pd.to_numeric(df['hc_y'], errors='coerce')\n",
    "    \n",
    "    # Hard hit dummy\n",
    "    df['hard_hit'] = (df['launch_speed'] >= 95).astype('int')\n",
    "    \n",
    "    # Barrel dummy\n",
    "    df['barrel'] = (df['launch_speed_angle'] == 6).astype('int')\n",
    "\n",
    "    # Spray \n",
    "    df['spray_angle'] = np.arctan((df['hc_x'] - 125.42) / (198.27 - df['hc_y'])) * 180 / np.pi * 0.75\n",
    "    df['to_left'] = (df['spray_angle'] < -15).astype('int')\n",
    "    df['to_middle'] = ((df['spray_angle'] >= -15) & (df['spray_angle'] <= 15)).astype('int')\n",
    "    df['to_right'] = (df['spray_angle'] > 15).astype('int')\n",
    "\n",
    "    # Sort\n",
    "    df.sort_values(['date', 'gamePk', 'atBatIndex'], inplace=True)\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34750e0a-9132-403f-81f9-7577815ca00e",
   "metadata": {},
   "source": [
    "##### 5. Park Adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d6fd63-b9fe-43a4-addd-577ad84ed686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def park_adjustments(df, multiplier_df):       \n",
    "    # Merge with park factors\n",
    "    pfx_columns = [col for col in multiplier_df.columns if \"pfx\" in col]\n",
    "    wfx_columns = [col for col in multiplier_df.columns if \"wfx\" in col]\n",
    "    df = df.merge(multiplier_df[['gamePk'] + pfx_columns + wfx_columns], on=['gamePk'], how='left')\n",
    "\n",
    "    # If missing, set adjustment to 1\n",
    "    df[pfx_columns] = df[pfx_columns].fillna(1)\n",
    "    df[wfx_columns] = df[wfx_columns].fillna(1)\n",
    "\n",
    "    # Loop over events\n",
    "    for event in events_list:\n",
    "        # Adjust based on calculated multiplier\n",
    "        df[f'{event}_adj'] = np.where(df['batSide'] == \"L\", df[event].astype(float) / df[f'{event}_wfx_l'].astype(float), df[event].astype(float) / df[f'{event}_wfx_r'].astype(float))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069dbaa1-7085-41ca-a0a0-d0621601144c",
   "metadata": {},
   "source": [
    "##### 6. Starter Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e05d7f0-c0d5-485d-806c-5d5e10f9e86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This creates information about starts for use in pulling pitchers\n",
    "# def start_data(df):\n",
    "#     ### PA-level\n",
    "#     # Calculate hits\n",
    "#     df['h'] = df[['b1', 'b2', 'b3', 'hr']].astype('float').sum(axis=1)\n",
    "#     # Calculate total bases\n",
    "#     df['tb'] = df['b1'] * 1 + df['b2'] * 2 + df['b3'] * 3 + df['hr'] * 4\n",
    "#     # Calculate batters reached\n",
    "#     df['reached'] = df[['b1', 'b2', 'b3', 'hr', 'bb', 'hbp']].astype('float').sum(axis=1)\n",
    "#     # Calculate batters faced\n",
    "#     df['faced'] = 1    \n",
    "#     # Identify outs on play\n",
    "#     df['outs_total'] = ((df['inning'] - 1) * 3) + df['outs']\n",
    "#     df['outs_pa'] = (df.groupby(['gamePk', 'inning', 'halfInning'])['outs_total'].apply(lambda x: x - x.shift(1)).reset_index(level=[0, 1, 2], drop=True))\n",
    "#     df['outs_pa'].fillna(df['outs'], inplace=True)\n",
    "\n",
    "#     # Sort\n",
    "#     df = df.sort_values(by=['date', 'gamePk', 'atBatIndex'])\n",
    "    \n",
    "    \n",
    "#     ### Cumulative - Inning (Excludes current PA)\n",
    "#     for stat in events_list + ['h', 'tb', 'reached', 'faced', 'rbi', 'outs_pa']:\n",
    "#         df[f'{stat}_inning'] = df.groupby(['gamePk', 'pitcher', 'inning'])[stat].apply(lambda x: x.cumsum()).reset_index(level=[0, 1, 2], drop=True)\n",
    "#         df[f'{stat}_inning'].fillna(0, inplace=True)\n",
    "\n",
    "#     ### Cumulative - Game (Excludes current PA)\n",
    "#     for stat in events_list + ['h', 'tb', 'reached', 'faced', 'rbi', 'outs_pa']:\n",
    "#         df[f'{stat}_game'] = df.groupby(['gamePk', 'pitcher'])[stat].apply(lambda x: x.cumsum()).reset_index(level=[0, 1], drop=True)\n",
    "#         df[f'{stat}_game'].fillna(0, inplace=True)\n",
    "        \n",
    "#     # Identify if it's the bottom of the inning (a little more helpful than \"top\" as it's sortable)\n",
    "#     df['bottom'] = (df['top'] == 0).astype('int')\n",
    "    \n",
    "#     # Sort to identify starting pitchers\n",
    "#     df = df.sort_values(by=['date', 'gamePk', 'bottom', 'atBatIndex'])\n",
    "    \n",
    "#     # The starter has the lowest atBatIndex\n",
    "#     df['atBatIndex_min'] = df.groupby(['gamePk', 'bottom'])['atBatIndex'].transform('min')\n",
    "#     df['first_ab'] = (df['atBatIndex'] == df['atBatIndex_min']).astype('int')\n",
    "    \n",
    "#     # A pitcher is pulled at their highest atBatIndex\n",
    "#     df['atBatIndex_max'] = df.groupby(['gamePk', 'pitcher'])['atBatIndex'].transform('max')\n",
    "#     df['pulled'] = (df['atBatIndex'] == df['atBatIndex_max']).astype('int')\n",
    "        \n",
    "#     # Number of times a matchup has happened that game\n",
    "#     df['times_faced'] = (df['faced_game']) // 9\n",
    "#     df['times_faced'].fillna(0, inplace=True)\n",
    "    \n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbb145d-03d8-4ab5-b254-c11e59ab63ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_data(df):\n",
    "    original_index = df.index  # Save the original index\n",
    "    \n",
    "    pl_df = pl.from_pandas(df)\n",
    "\n",
    "    # Calculate hits, total bases, reached, and faced\n",
    "    pl_df = pl_df.with_columns([\n",
    "        (pl.col('b1').cast(pl.Float64) + pl.col('b2').cast(pl.Float64) + pl.col('b3').cast(pl.Float64) + pl.col('hr').cast(pl.Float64)).alias('h'),\n",
    "        (pl.col('b1') * 1 + pl.col('b2') * 2 + pl.col('b3') * 3 + pl.col('hr') * 4).alias('tb'),\n",
    "        (pl.col('b1').cast(pl.Float64) + pl.col('b2').cast(pl.Float64) + pl.col('b3').cast(pl.Float64) + pl.col('hr').cast(pl.Float64) + pl.col('bb').cast(pl.Float64) + pl.col('hbp').cast(pl.Float64)).alias('reached'),\n",
    "        pl.lit(1).alias('faced'),\n",
    "        (((pl.col('inning') - 1) * 3) + pl.col('outs')).alias('outs_total')\n",
    "    ])\n",
    "\n",
    "    # Outs per PA\n",
    "    pl_df = pl_df.sort(['gamePk', 'inning', 'halfInning', 'atBatIndex'])\n",
    "    pl_df = pl_df.with_columns([\n",
    "        (pl.col('outs_total') - pl.col('outs_total').shift(1)).over(['gamePk', 'inning', 'halfInning']).alias('outs_pa')\n",
    "    ]).with_columns([\n",
    "        pl.when(pl.col('outs_pa').is_null()).then(pl.col('outs')).otherwise(pl.col('outs_pa')).alias('outs_pa')\n",
    "    ])\n",
    "\n",
    "    # Sort before cumulative calculations\n",
    "    pl_df = pl_df.sort(['gamePk', 'pitcher', 'inning', 'atBatIndex'])\n",
    "    \n",
    "    # Rolling cumulative stats per inning\n",
    "    for stat in events_list + ['h', 'tb', 'reached', 'faced', 'rbi', 'outs_pa']:\n",
    "        pl_df = pl_df.with_columns([\n",
    "            pl.col(stat).cum_sum().over(['gamePk', 'pitcher', 'inning']).alias(f'{stat}_inning')\n",
    "        ])\n",
    "\n",
    "    # Rolling cumulative stats per game\n",
    "    for stat in events_list + ['h', 'tb', 'reached', 'faced', 'rbi', 'outs_pa']:\n",
    "        pl_df = pl_df.with_columns([\n",
    "            pl.col(stat).cum_sum().over(['gamePk', 'pitcher']).alias(f'{stat}_game')\n",
    "        ])\n",
    "\n",
    "    # Bottom of the inning flag\n",
    "    pl_df = pl_df.with_columns([\n",
    "        (pl.col('top') == 0).cast(pl.Int8).alias('bottom')\n",
    "    ])\n",
    "\n",
    "    # Sort to identify starting pitchers\n",
    "    pl_df = pl_df.sort(['date', 'gamePk', 'bottom', 'atBatIndex'])\n",
    "\n",
    "    # Identify first at-bat for each bottom\n",
    "    pl_df = pl_df.with_columns([\n",
    "        pl.col('atBatIndex').min().over(['gamePk', 'bottom']).alias('atBatIndex_min')\n",
    "    ]).with_columns([\n",
    "        (pl.col('atBatIndex') == pl.col('atBatIndex_min')).cast(pl.Int8).alias('first_ab')\n",
    "    ])\n",
    "\n",
    "    # Identify pulled pitcher\n",
    "    pl_df = pl_df.with_columns([\n",
    "        pl.col('atBatIndex').max().over(['gamePk', 'pitcher']).alias('atBatIndex_max')\n",
    "    ]).with_columns([\n",
    "        (pl.col('atBatIndex') == pl.col('atBatIndex_max')).cast(pl.Int8).alias('pulled')\n",
    "    ])\n",
    "\n",
    "    # Times faced in game (adjusted for total batters faced)\n",
    "    pl_df = pl_df.with_columns([\n",
    "        (pl.col('faced_game') / 9).floor().fill_null(0).alias('times_faced')\n",
    "    ])\n",
    "\n",
    "    result = pl_df.to_pandas()\n",
    "    result.index = original_index  # Restore the original index\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af98d36a-9485-4652-a334-4a2118a18d7a",
   "metadata": {},
   "source": [
    "##### 7. Rolling Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2f862055-9a96-49e2-8844-6fde8b4bb5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This will return a dataframe that can eventually be used as the model input. Has pitcher vs hitter stats, specific to hand\n",
    "# def rolling_pas(df, pa_num, adjust, events_list=events_list):\n",
    "#     # Determine correct events_list\n",
    "#     if adjust == True:\n",
    "#         events_list = events_list_adj\n",
    "#     else:\n",
    "#         events_list = events_list\n",
    "    \n",
    "#     # Copy dataframe\n",
    "#     df_copy = df.copy()\n",
    "    \n",
    "#     # Note: batter_avg_short will work even when pa_num refers to the \"long\" period. Suffix will be added in post.\n",
    "#     # Rename for compatibility purposes\n",
    "#     df_copy.rename(columns={'hit_distance_sc':'totalDistance', \n",
    "#                             'launch_speed':'launchSpeed'}, inplace=True)          \n",
    "            \n",
    "#     # Convert to numeric and fill with 0s\n",
    "#     combined_list = avg_list + max_list\n",
    "#     for col in combined_list:\n",
    "#         # Check if the column is not numeric\n",
    "#         if not pd.api.types.is_numeric_dtype(df_copy[col]):\n",
    "#             # Convert the non-numeric column to numeric and fill missing values with 0\n",
    "#             df_copy[col] = pd.to_numeric(df_copy[col], errors='coerce')\n",
    "#             df_copy[col] = df_copy[col].fillna(0)\n",
    "\n",
    "#     # Sort\n",
    "#     df_copy.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "            \n",
    "#     # Data types may vary. This makes grouping impossible. \n",
    "#     df_copy['batter'] = df_copy['batter'].astype('int')\n",
    "#     df_copy['pitcher'] = df_copy['pitcher'].astype('int')\n",
    "\n",
    "#     ### Batter stats \n",
    "#     # Stats for which you want the average \n",
    "#     df_copy[batter_avg_short] = df_copy.groupby(['batter', 'pitchHand'])[events_list + statcast_list].transform(lambda x: x.rolling(pa_num, min_periods=1).mean())\n",
    "#     # Stats for which you want the maximum\n",
    "#     df_copy[batter_max_short] = df_copy.groupby(['batter', 'pitchHand'])[max_list].transform(lambda x: x.rolling(pa_num, min_periods=1).max())\n",
    "#     # Stats for which you just want the sum \n",
    "#     df_copy[['ab_b', 'pa_b']] = df_copy.groupby(['batter', 'pitchHand'])[['ab', 'pa']].transform(lambda x: x.rolling(pa_num, min_periods=1).sum())\n",
    "                \n",
    "#     ### Pitcher stats\n",
    "#     # Stats for which you want the average\n",
    "#     df_copy[pitcher_avg_short] = df_copy.groupby(['pitcher', 'batSide'])[events_list + statcast_list].transform(lambda x: x.rolling(pa_num, min_periods=1).mean())\n",
    "#     # Stats for which you want the maximum\n",
    "#     df_copy[pitcher_max_short] = df_copy.groupby(['pitcher', 'batSide'])[max_list].transform(lambda x: x.rolling(pa_num, min_periods=1).max())\n",
    "#     # Stats for which you just want the sum \n",
    "#     df_copy[['ab_p', 'pa_p']] = df_copy.groupby(['pitcher', 'batSide'])[['ab', 'pa']].transform(lambda x: x.rolling(pa_num, min_periods=1).sum())\n",
    "                \n",
    "        \n",
    "#     # Create imputation flags (these observations will have imputed inputs)\n",
    "#     df_copy['imp_b'] = (df_copy['pa_b'] < 40).astype('int')\n",
    "#     df_copy['imp_p'] = (df_copy['pa_p'] < 40).astype('int')\n",
    "\n",
    "#     # Create compatible date variable\n",
    "#     df_copy['date'] = df_copy['game_date'].str.replace('-', '')\n",
    "    \n",
    "#     # Convert to numeric for sorting\n",
    "#     df_copy['date'] = df_copy['date'].astype('int')\n",
    "#     df_copy['gamePk'] = df_copy['gamePk'].astype('int')\n",
    "#     df_copy['atBatIndex'] = df_copy['atBatIndex'].astype('int')\n",
    "#     df_copy['batter'] = df_copy['batter'].astype('int')\n",
    "#     df_copy['pitcher'] = df_copy['pitcher'].astype('int')\n",
    "    \n",
    "#     # Sort\n",
    "#     df_copy.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "\n",
    "#     ### Advanced stats\n",
    "#     # wOBA - using 2022 values throughout - may use slightly different implied denominator\n",
    "#     df_copy['woba_b'] = (0.690 * df_copy['bb_b']) + (0.721 * df_copy['hbp_b']) + (0.885 * df_copy['b1_b']) + (1.262 * df_copy['b2_b']) + (1.601 * df_copy['b3_b']) + (2.070 * df_copy['hr_b'])\n",
    "#     df_copy['woba_p'] = (0.690 * df_copy['bb_p']) + (0.721 * df_copy['hbp_p']) + (0.885 * df_copy['b1_p']) + (1.262 * df_copy['b2_p']) + (1.601 * df_copy['b3_p']) + (2.070 * df_copy['hr_p'])\n",
    "    \n",
    "#     # Slugging\n",
    "#     df_copy['slg_b'] = ((1 * df_copy['b1_b']) + (2 * df_copy['b2_b']) + (3 * df_copy['b3_b']) + (4 * df_copy['hr_b'])) * (1 / (1-(df_copy['bb_b'] + df_copy['hbp_b'])))\n",
    "#     df_copy['slg_p'] = ((1 * df_copy['b1_p']) + (2 * df_copy['b2_p']) + (3 * df_copy['b3_p']) + (4 * df_copy['hr_p'])) * (1 / (1-(df_copy['bb_p'] + df_copy['hbp_p'])))\n",
    "    \n",
    "#     # OBP    \n",
    "#     df_copy['obp_b'] = df_copy[['b1_b', 'b2_b', 'b3_b', 'hr_b', 'bb_b', 'hbp_b']].sum(axis=1)\n",
    "#     df_copy['obp_p'] = df_copy[['b1_p', 'b2_p', 'b3_p', 'hr_p', 'bb_p', 'hbp_p']].sum(axis=1)\n",
    "    \n",
    "#     # ISO\n",
    "#     df_copy['iso_b'] = (df_copy['b2_b'] * 1 + df_copy['b3_b'] * 2 + df_copy['hr_b'] * 3) * (1 / (1-(df_copy['bb_b'] + df_copy['hbp_b'])))\n",
    "#     df_copy['iso_p'] = (df_copy['b2_p'] * 1 + df_copy['b3_p'] * 2 + df_copy['hr_p'] * 3) * (1 / (1-(df_copy['bb_p'] + df_copy['hbp_p'])))\n",
    "\n",
    "    \n",
    "#     return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876f993b-f98f-4ae9-a950-3557a96428db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_pas(df, pa_num, adjust, events_list=events_list):\n",
    "    if adjust:\n",
    "        events_list_copy = [f\"{event}_copy\" for event in events_list]\n",
    "        df[events_list_copy] = df[events_list].copy()\n",
    "        df[events_list] = df[events_list_adj].copy()\n",
    "\n",
    "    \n",
    "    # Renaming columns on df before conversion to Polars\n",
    "    df.rename(columns={'hit_distance_sc': 'totalDistance', 'launch_speed': 'launchSpeed'}, inplace=True)\n",
    "\n",
    "    # Convert to Polars after renaming\n",
    "    pl_df = pl.from_pandas(df)\n",
    "\n",
    "    # Ensure types are correctly set after converting to Polars\n",
    "    pl_df = pl_df.with_columns([\n",
    "        pl.col('date').cast(pl.Int32),\n",
    "        pl.col('gamePk').cast(pl.Int32),\n",
    "        pl.col('atBatIndex').cast(pl.Int32),\n",
    "        pl.col('batter').cast(pl.Int32),\n",
    "        pl.col('pitcher').cast(pl.Int32)\n",
    "    ])\n",
    "\n",
    "    # Sorting is done in Polars\n",
    "    pl_df = pl_df.sort(['date', 'gamePk', 'atBatIndex'])\n",
    "\n",
    "    # Create expressions for batter and pitcher stats\n",
    "    batter_avg_exprs = [\n",
    "        pl.col(col).rolling_mean(window_size=pa_num, min_periods=1).over(['batter', 'pitchHand']).alias(col + '_b')\n",
    "        for col in events_list + statcast_list\n",
    "    ]\n",
    "    batter_max_exprs = [\n",
    "        pl.col(col).rolling_max(window_size=pa_num, min_periods=1).over(['batter', 'pitchHand']).alias(col + '_b')\n",
    "        for col in max_list\n",
    "    ]\n",
    "    batter_sum_exprs = [\n",
    "        pl.col(col).rolling_sum(window_size=pa_num, min_periods=1).over(['batter', 'pitchHand']).alias(col + '_b')\n",
    "        for col in ['ab', 'pa']\n",
    "    ]\n",
    "\n",
    "    pitcher_avg_exprs = [\n",
    "        pl.col(col).rolling_mean(window_size=pa_num, min_periods=1).over(['pitcher', 'batSide']).alias(col + '_p')\n",
    "        for col in events_list + statcast_list\n",
    "    ]\n",
    "    pitcher_max_exprs = [\n",
    "        pl.col(col).rolling_max(window_size=pa_num, min_periods=1).over(['pitcher', 'batSide']).alias(col + '_p')\n",
    "        for col in max_list\n",
    "    ]\n",
    "    pitcher_sum_exprs = [\n",
    "        pl.col(col).rolling_sum(window_size=pa_num, min_periods=1).over(['pitcher', 'batSide']).alias(col + '_p')\n",
    "        for col in ['ab', 'pa']\n",
    "    ]\n",
    "\n",
    "    # Add the computed columns to pl_df\n",
    "    pl_df = pl_df.with_columns(\n",
    "        batter_avg_exprs + batter_max_exprs + batter_sum_exprs +\n",
    "        pitcher_avg_exprs + pitcher_max_exprs + pitcher_sum_exprs\n",
    "    )\n",
    "\n",
    "    # Create 'imp_b' and 'imp_p' directly in Polars\n",
    "    pl_df = pl_df.with_columns([\n",
    "        (pl.col('pa_b') < 40).cast(pl.Int32).alias('imp_b'),\n",
    "        (pl.col('pa_p') < 40).cast(pl.Int32).alias('imp_p')\n",
    "    ])\n",
    "\n",
    "    # Clean up date and other columns directly in Polars\n",
    "    pl_df = pl_df.with_columns([\n",
    "        pl.col('game_date').str.replace_all('-', '').cast(pl.Int32).alias('date'),\n",
    "        pl.col('gamePk').cast(pl.Int32),\n",
    "        pl.col('atBatIndex').cast(pl.Int32),\n",
    "        pl.col('batter').cast(pl.Int32),\n",
    "        pl.col('pitcher').cast(pl.Int32)\n",
    "    ])\n",
    "\n",
    "    # Sort the data as needed\n",
    "    pl_df = pl_df.sort(['date', 'gamePk', 'atBatIndex'])\n",
    "\n",
    "    # Calculating wOBA, SLG, OBP, and ISO directly in Polars\n",
    "    pl_df = pl_df.with_columns([\n",
    "        (0.690 * pl.col('bb_b') + 0.721 * pl.col('hbp_b') +\n",
    "         0.885 * pl.col('b1_b') + 1.262 * pl.col('b2_b') +\n",
    "         1.601 * pl.col('b3_b') + 2.070 * pl.col('hr_b')).alias('woba_b'),\n",
    "        (0.690 * pl.col('bb_p') + 0.721 * pl.col('hbp_p') +\n",
    "         0.885 * pl.col('b1_p') + 1.262 * pl.col('b2_p') +\n",
    "         1.601 * pl.col('b3_p') + 2.070 * pl.col('hr_p')).alias('woba_p'),\n",
    "\n",
    "        ((1 * pl.col('b1_b') + 2 * pl.col('b2_b') + 3 * pl.col('b3_b') + 4 * pl.col('hr_b')) *\n",
    "         (1 / (1 - (pl.col('bb_b') + pl.col('hbp_b'))))).alias('slg_b'),\n",
    "        ((1 * pl.col('b1_p') + 2 * pl.col('b2_p') + 3 * pl.col('b3_p') + 4 * pl.col('hr_p')) *\n",
    "         (1 / (1 - (pl.col('bb_p') + pl.col('hbp_p'))))).alias('slg_p'),\n",
    "\n",
    "        (pl.col('b1_b') + pl.col('b2_b') + pl.col('b3_b') + pl.col('hr_b') +\n",
    "         pl.col('bb_b') + pl.col('hbp_b')).alias('obp_b'),\n",
    "        (pl.col('b1_p') + pl.col('b2_p') + pl.col('b3_p') + pl.col('hr_p') +\n",
    "         pl.col('bb_p') + pl.col('hbp_p')).alias('obp_p'),\n",
    "\n",
    "        ((pl.col('b2_b') + 2 * pl.col('b3_b') + 3 * pl.col('hr_b')) *\n",
    "         (1 / (1 - (pl.col('bb_b') + pl.col('hbp_b'))))).alias('iso_b'),\n",
    "        ((pl.col('b2_p') + 2 * pl.col('b3_p') + 3 * pl.col('hr_p')) *\n",
    "         (1 / (1 - (pl.col('bb_p') + pl.col('hbp_p'))))).alias('iso_p')\n",
    "    ])\n",
    "\n",
    "    # Convert back to pandas for final operations\n",
    "    df_copy = pl_df.to_pandas()\n",
    "    \n",
    "    if adjust:\n",
    "        df_copy[events_list] = df_copy[events_list_copy].copy()\n",
    "\n",
    "        df_copy.drop(columns=events_list_copy, inplace=True)\n",
    "        \n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611ae87b-8d9d-4651-98f0-e8926b21d2ef",
   "metadata": {},
   "source": [
    "##### Model Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eba83b-563d-4dbf-85eb-081559c50ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pa_inputs(multiplier_df, start_year=2014, end_year=2024, short=50, long=300, adjust=True):\n",
    "    # If we're creating a new complete dataset\n",
    "    # if generate == True:\n",
    "    start_time = time.time()\n",
    "    df = merge_datasets(start_year, end_year)\n",
    "    print(f\"merge_datasets took {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    df2 = clean_weather(df)\n",
    "    print(f\"clean_weather took {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    df3 = create_events(df2)\n",
    "    print(f\"create_events took {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    df4 = create_variables(df3)\n",
    "    print(f\"create_variables took {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    if adjust:\n",
    "        start_time = time.time()\n",
    "        df5 = park_adjustments(df4, multiplier_df)\n",
    "        print(f\"park_adjustments took {time.time() - start_time:.2f} seconds\")\n",
    "    else:\n",
    "        df5 = df4.copy()\n",
    "\n",
    "    start_time = time.time()\n",
    "    df6 = start_data(df5)\n",
    "    print(f\"start_data took {time.time() - start_time:.2f} seconds\")\n",
    "    \n",
    "    ### Rolling stats\n",
    "    # Short\n",
    "    start_time = time.time()\n",
    "    df_short = rolling_pas(df6, short, adjust)\n",
    "    print(f\"Short took {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    # Long\n",
    "    start_time = time.time()\n",
    "    df_long = rolling_pas(df6, long, adjust)\n",
    "    df_long = df_long.add_suffix(\"_long\")\n",
    "    print(f\"Long took {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "        \n",
    "    # We only need the rolling stats \n",
    "    long_stats = batter_stats_long + pitcher_stats_long\n",
    "    df_long = df_long[long_stats]\n",
    "    \n",
    "    # Dataset\n",
    "    complete_dataset = pd.concat([df_short, df_long], axis=1)\n",
    "\n",
    "    # Normalize so stats add up to 1\n",
    "    complete_dataset['sum_b'] = complete_dataset[['b1_b', 'b2_b', 'b3_b', 'hr_b', 'bb_b', 'hbp_b', 'so_b', 'lo_b', 'fo_b', 'go_b', 'po_b']].sum(axis=1)\n",
    "    for stat in ['b1_b', 'b2_b', 'b3_b', 'hr_b', 'bb_b', 'hbp_b', 'so_b', 'lo_b', 'fo_b', 'go_b', 'po_b']:\n",
    "        complete_dataset[stat] = complete_dataset[stat] / complete_dataset['sum_b']\n",
    "    \n",
    "    complete_dataset['sum_b_long'] = complete_dataset[['b1_b_long', 'b2_b_long', 'b3_b_long', 'hr_b_long', 'bb_b_long', 'hbp_b_long', 'so_b_long', 'lo_b_long', 'fo_b_long', 'go_b_long', 'po_b_long']].sum(axis=1)\n",
    "    for stat in ['b1_b_long', 'b2_b_long', 'b3_b_long', 'hr_b_long', 'bb_b_long', 'hbp_b_long', 'so_b_long', 'lo_b_long', 'fo_b_long', 'go_b_long', 'po_b_long']:\n",
    "        complete_dataset[stat] = complete_dataset[stat] / complete_dataset['sum_b_long']\n",
    "        \n",
    "    complete_dataset['sum_p'] = complete_dataset[['b1_p', 'b2_p', 'b3_p', 'hr_p', 'bb_p', 'hbp_p', 'so_p', 'lo_p', 'fo_p', 'go_p', 'po_p']].sum(axis=1)\n",
    "    for stat in ['b1_p', 'b2_p', 'b3_p', 'hr_p', 'bb_p', 'hbp_p', 'so_p', 'lo_p', 'fo_p', 'go_p', 'po_p']:\n",
    "        complete_dataset[stat] = complete_dataset[stat] / complete_dataset['sum_p']\n",
    "        \n",
    "    complete_dataset['sum_p_long'] = complete_dataset[['b1_p_long', 'b2_p_long', 'b3_p_long', 'hr_p_long', 'bb_p_long', 'hbp_p_long', 'so_p_long', 'lo_p_long', 'fo_p_long', 'go_p_long', 'po_p_long']].sum(axis=1)\n",
    "    for stat in ['b1_p_long', 'b2_p_long', 'b3_p_long', 'hr_p_long', 'bb_p_long', 'hbp_p_long', 'so_p_long', 'lo_p_long', 'fo_p_long', 'go_p_long', 'po_p_long']:\n",
    "        complete_dataset[stat] = complete_dataset[stat] / complete_dataset['sum_p_long']\n",
    "\n",
    "    # Reset index\n",
    "    complete_dataset.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Sort\n",
    "    complete_dataset.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "\n",
    "    \n",
    "    return complete_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea23573f-49f6-4efe-919a-e4fda12d9344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1adce9d5-ed85-4c7d-8f1e-4f88f642116c",
   "metadata": {},
   "source": [
    "##### Pull Inputs (deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2444aff1-2aad-4513-b6b8-37cd5ca0e774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete soon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d20a6b9-f5d7-4f6b-a32a-f486cc295612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_dummies(df):    \n",
    "#     # Events\n",
    "#     event_dummies = pd.get_dummies(df['eventsModel'])\n",
    "    \n",
    "#     # Hands\n",
    "#     pitcher_dummies = pd.get_dummies(df['pitchHand'], prefix='p')\n",
    "#     batter_dummies = pd.get_dummies(df['batSide'], prefix='b')\n",
    "    \n",
    "#     # Years\n",
    "#     df['year'] = df['game_date'].str[:4].astype(int)\n",
    "    \n",
    "#     # Add dummies to dataframe\n",
    "#     df = pd.concat([df, event_dummies, pitcher_dummies, batter_dummies], axis=1)\n",
    "\n",
    "#     # Identify starting pitcher\n",
    "#     df['startingPitcher'] = df.groupby(['gamePk', 'halfInning'])['pitcherName'].transform('first')\n",
    "#     df['starter'] = (df['startingPitcher'] == df['pitcherName']).astype('int')\n",
    "    \n",
    "#     # Create compatible date variable\n",
    "#     df['date'] = df['game_date'].str.replace('-', '')\n",
    "    \n",
    "#     # Convert to numeric for sorting\n",
    "#     df['date'] = df['date'].astype('int')\n",
    "#     df['gamePk'] = df['gamePk'].astype('int')\n",
    "#     df['atBatIndex'] = df['atBatIndex'].astype('int')\n",
    "    \n",
    "#     # Sort\n",
    "#     df.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "    \n",
    "#     # Create dummy for runners on base\n",
    "#     df['preOnFirst'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnFirst'].shift(1)\n",
    "#     df['preOnSecond'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnSecond'].shift(1)\n",
    "#     df['preOnThird'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnThird'].shift(1)\n",
    "    \n",
    "#     df['onFirst'] = df['preOnFirst'].apply(lambda x: 1 if isinstance(x, str) and 'id' in x else 0)\n",
    "#     df['onSecond'] = df['preOnSecond'].apply(lambda x: 1 if isinstance(x, str) and 'id' in x else 0)\n",
    "#     df['onThird'] = df['preOnThird'].apply(lambda x: 1 if isinstance(x, str) and 'id' in x else 0)\n",
    "    \n",
    "#     # Top of the inning dummy\n",
    "#     df['top'] = np.where(df['halfInning'] == \"top\", 1, 0)\n",
    "    \n",
    "#     # Convert to numeric\n",
    "#     df['awayScore'] = df['awayScore'].astype('int')\n",
    "#     df['homeScore'] = df['homeScore'].astype('int')\n",
    "    \n",
    "#     # Determine score before PA\n",
    "#     df['preAwayScore'] = df.groupby(['gamePk'])['awayScore'].shift(1)\n",
    "#     df['preHomeScore'] = df.groupby(['gamePk'])['homeScore'].shift(1)\n",
    "    \n",
    "#     # If it's the first PA, it'll be missing. \n",
    "#     df['preAwayScore'] = df['preAwayScore'].fillna(0)\n",
    "#     df['preHomeScore'] = df['preHomeScore'].fillna(0)\n",
    "    \n",
    "#     # Calculate differential\n",
    "#     df['score_diff'] = np.where(df['top'] == 1, df['preAwayScore'] - df['preHomeScore'], df['preHomeScore'] - df['preAwayScore'])\n",
    "    \n",
    "#     # Determine hitter and pitcher scores\n",
    "#     df['batterScore'] = np.where(df['halfInning'] == 'top', df['awayScore'], df['homeScore'])\n",
    "#     df['pitcherScore'] = np.where(df['halfInning'] == 'top', df['homeScore'], df['awayScore'])\n",
    "    \n",
    "#     # Determine score before PA\n",
    "#     df['preBatterScore'] = np.where(df['halfInning'] == 'top', df['preAwayScore'], df['preHomeScore'])\n",
    "#     df['prePitcherScore'] = np.where(df['halfInning'] == 'top', df['preHomeScore'], df['preAwayScore'])\n",
    "    \n",
    "#     # Calculate PAs and ABs\n",
    "#     df['pa'] = np.where(df['eventsModel'] != \"Cut\", 1, 0)\n",
    "#     df['ab'] = df['pa'] - df['hbp'] - df['bb']           \n",
    "            \n",
    "#     # Sort\n",
    "#     df.sort_values(['date', 'gamePk', 'atBatIndex'], inplace=True)\n",
    "\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83d0425-f155-4455-8d51-464a5b5cb400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_statcast(df):\n",
    "#     # Convert variables to numeric\n",
    "#     df['launch_speed'] = pd.to_numeric(df['launch_speed'], errors='coerce')\n",
    "#     df['launch_speed_angle'] = pd.to_numeric(df['launch_speed_angle'], errors='coerce')\n",
    "#     df['hc_x'] = pd.to_numeric(df['hc_x'], errors='coerce')\n",
    "#     df['hc_y'] = pd.to_numeric(df['hc_y'], errors='coerce')\n",
    "    \n",
    "#     # Hard hit dummy\n",
    "#     df['hard_hit'] = (df['launch_speed'] >= 95).astype('int')\n",
    "    \n",
    "#     # Barrel dummy\n",
    "#     df['barrel'] = (df['launch_speed_angle'] == 6).astype('int')\n",
    "\n",
    "#     # Spray \n",
    "#     df['spray_angle'] = np.arctan((df['hc_x'] - 125.42) / (198.27 - df['hc_y'])) * 180 / np.pi * 0.75\n",
    "#     df['to_left'] = (df['spray_angle'] < -15).astype('int')\n",
    "#     df['to_middle'] = ((df['spray_angle'] >= -15) & (df['spray_angle'] <= 15)).astype('int')\n",
    "#     df['to_right'] = (df['spray_angle'] > 15).astype('int')\n",
    "\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30622142-684b-4bf9-bdea-78225a0a9ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creates model inputs\n",
    "# def create_pull_inputs(park_factors, team_map, start_year, end_year, short=50, long=300, adjust=True):\n",
    "#     # Merge together raw Stats API and Statcast data\n",
    "#     df = merge_datasets(start_year, end_year)\n",
    "#     # Clean weather\n",
    "#     df2 = clean_weather(df)\n",
    "#     # Create PA events \n",
    "#     df3 = create_events(df2)\n",
    "#     # Create dummy variables \n",
    "#     df4 = create_dummies(df3)\n",
    "#     # Create Statcast variables\n",
    "#     df5 = clean_statcast(df4)   \n",
    "#     # Adjust for park factors\n",
    "#     if adjust == True:\n",
    "#         df6 = park_adjustments(df5)\n",
    "#         df6.drop(columns={'_merge'}, inplace=True)\n",
    "#     else:\n",
    "#         df6 = df5.copy()\n",
    "#     # Add start data\n",
    "#     complete_dataset = start_data(df6)\n",
    "    \n",
    "#     # Clean up\n",
    "#     # complete_dataset.drop(columns={'_merge'}, inplace=True)\n",
    "#     complete_dataset.fillna(0, inplace=True)\n",
    "    \n",
    "#     # Sort\n",
    "#     complete_dataset.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "\n",
    "    \n",
    "#     return complete_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bed1bf-2e5b-4278-9ffd-1ed51f954cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1506c1fc-dd11-47ce-87e9-1d5f5f58cd98",
   "metadata": {},
   "source": [
    "### Steamer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06c0a65-8fa9-4fd1-9b72-d501c3361a7a",
   "metadata": {},
   "source": [
    "##### 1. Hitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2053516-8f29-4c3c-87e1-49f5fbc91361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_steamer_hitters(df):\n",
    "    # Basic stats\n",
    "    hit_list = ['1B', '2B', '3B', 'HR', 'BB', 'HBP', 'K']\n",
    "\n",
    "    # Advance stats\n",
    "    rate_list = ['OBP', 'SLG', 'wOBA']\n",
    "    for stat in hit_list:\n",
    "        rate = stat + \"_rate\"\n",
    "        rate_list.append(rate)\n",
    "        df[rate] = df[stat] / df['PA']\n",
    "\n",
    "    # Stolen base attempts\n",
    "    df['SBA'] = df['SB'] + df['CS']\n",
    "    # Stolen base opportunities (times on first)\n",
    "    df['SBO'] = df['1B'] + df['BB'] + df['HBP']\n",
    "    \n",
    "    # Date\n",
    "    df['date'] = df['proj_date'].str.replace(\"-\", \"\")\n",
    "    df['date'] = df['date'].astype('int')\n",
    "    \n",
    "    # Keep relevant variables\n",
    "    keep_list = ['date', 'firstname', 'lastname', 'mlbamid', 'steamerid'] + ['SB', 'SBA', 'SBO'] + rate_list\n",
    "    df = df[keep_list]\n",
    "    \n",
    "    # Clean up\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.rename(columns={'1b_rate': 'b1_rate', '2b_rate': 'b2_rate', '3b_rate': 'b3_rate', 'k_rate':'so_rate'}, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Drop duplicates\n",
    "    df.drop_duplicates(subset=['steamerid', 'date'], inplace=True)\n",
    "\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc95785-c051-452e-aa5a-f8b9fbdd6c4a",
   "metadata": {},
   "source": [
    "##### 2. Pitchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3876f6da-1d0d-461f-8ab3-b002df855e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_steamer_pitchers(df):\n",
    "    # Hits per 9 innings\n",
    "    df['H9'] = df['H'] / df['IP'] * 9\n",
    "    \n",
    "    # Calculate average innings per game started\n",
    "    df['IP_start'] = df['start_IP'] / df['GS']\n",
    "    df['IP_start'].fillna(0, inplace=True)\n",
    "    # Replace infinites\n",
    "    df['IP_start'].replace([np.inf, -np.inf], 3, inplace=True)\n",
    "\n",
    "    # Date\n",
    "    df['date'] = df['proj_date'].str.replace(\"-\", \"\")\n",
    "    df['date'] = df['date'].astype('int')\n",
    "    \n",
    "    # Keep relevant variables\n",
    "    keep_list = ['date', 'firstname', 'lastname', 'mlbamid', 'steamerid'] + pitcher_stats_fg2 \n",
    "    df = df[keep_list]\n",
    "    \n",
    "    # Drop duplicates\n",
    "    df.drop_duplicates(subset=['steamerid', 'date'], inplace=True)\n",
    "\n",
    "    \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda-base)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
