{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a4d9497-f84b-4dac-a065-5d0bd2ee1f57",
   "metadata": {},
   "source": [
    "# 11. Projections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e348e236-0a4b-4271-89ae-49ec14b44c11",
   "metadata": {},
   "source": [
    "1. Projections - Daily Fantasy Fuel\n",
    "2. Projections - RotoWire\n",
    "3. Odds - Fantasy Labs\n",
    "    \n",
    "Note: \n",
    "1. The best time to run this is probably about an hour or so before start time so the projections are reasonably updated and the correct slate is chosen\n",
    "2. You may want to check that projections are from the same slate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a907e344-0f99-48d8-9b22-f53746efa9dd",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a898b1f-5b4f-41c6-bdcf-30f9a1dfe896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import datetime\n",
    "# import pandas as pd\n",
    "# from openpyxl import load_workbook\n",
    "# import os\n",
    "# import time\n",
    "# import numpy as np\n",
    "# from datetime import date\n",
    "\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(r\"C:\\Users\\james\\Documents\\MLB\\Code\")\n",
    "# from Utilities import *\n",
    "\n",
    "# import import_ipynb\n",
    "# from Utilities import *\n",
    "\n",
    "# import shutil\n",
    "\n",
    "# import re\n",
    "\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# import warnings\n",
    "# warnings.simplefilter(action=\"ignore\")\n",
    "\n",
    "# baseball_path = r\"C:\\Users\\james\\Documents\\MLB\\Data2\"\n",
    "# download_path = r\"C:\\Users\\james\\Downloads\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "594b5bd8-806d-44c5-a81a-2bb377086fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Team Map\n",
    "# team_map = pd.read_csv(os.path.join(baseball_path, \"Utilities\", \"Team Map.csv\"))\n",
    "# # Full team name, Fantasypros abbreviation, Baseball Reference abbreviation, Rotowire abbreviation\n",
    "# team_map = team_map[['FULLNAME', 'FANPROSTEAM', 'BBREFTEAM', 'ROTOWIRETEAM']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52090baf-753b-4e96-8cfc-21b54bb84e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Today's Date\n",
    "# # YYYY-MM-DD (datetime)\n",
    "# todaysdate_dt = datetime.date.today()\n",
    "\n",
    "# # YYYY-MM-DD (string)\n",
    "# todaysdate_dash = str(todaysdate_dt)\n",
    "\n",
    "# # MM/DD/YYYY\n",
    "# todaysdate_slash = todaysdate_dash.split(\"-\")\n",
    "# todaysdate_slash = todaysdate_slash[1] + \"/\" + todaysdate_slash[2] + \"/\" + todaysdate_slash[0]\n",
    "\n",
    "# # YYYYMMDD\n",
    "# todaysdate = todaysdate_dash.replace(\"-\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8319d50b-fd72-448e-8bc7-52a2d324b40b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef38a468-2138-437e-afd2-56c7d04c9237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cee81fc1-0cb7-4f68-af90-6e57d9428ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify DraftKings slate name\n",
    "def pick_slate(Name):\n",
    "    if \"(Early)\" in Name:\n",
    "        slate = \"Early\"\n",
    "    elif \"(Late Night)\" in Name:\n",
    "        slate = \"Late Night\"\n",
    "    elif \"Night\" in Name:\n",
    "        slate = \"Night\"\n",
    "    elif \"Afternoon\" in Name:\n",
    "        slate = \"Afternoon\"\n",
    "    else:\n",
    "        slate = \"All\"\n",
    "        \n",
    "    return slate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b2de1d-3793-42c8-aee7-19fbebb05164",
   "metadata": {},
   "source": [
    "### Projections - Daily Fantasy Fuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fe305f3-4bda-4b51-b089-3de1356314e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dff_slates(date=todaysdate):\n",
    "    url = 'https://www.dailyfantasyfuel.com/data/slates/next/mlb/dk?x=1'\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "    else:\n",
    "        print(f\"Failed to fetch data from {url}. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    # Extract relevant fields from the data\n",
    "    formatted_data = []\n",
    "    for entry in data:\n",
    "        sport = entry.get('sport')\n",
    "        team_count = entry.get('team_count')\n",
    "        game_count = entry.get('game_count')\n",
    "        slate_type = entry.get('slate_type', '')\n",
    "        url = entry.get('url')\n",
    "        start_string = entry.get('start_string')\n",
    "        future_rank = entry.get('future_rank')\n",
    "        showdown_flag = entry.get('showdown_flag')\n",
    "\n",
    "        # Extract time from the \"Start Time\" string\n",
    "        time = start_string.split(\", \")[1]\n",
    "\n",
    "        row = {\n",
    "            'Sport': sport,\n",
    "            'Team Count': team_count,\n",
    "            'Game Count': game_count,\n",
    "            'Slate Type': slate_type,\n",
    "            'URL': url,\n",
    "            'Start Time': start_string,\n",
    "            'Time': time,  # New \"Time\" column\n",
    "            'Future Rank': future_rank,\n",
    "            'Showdown Flag': showdown_flag\n",
    "        }\n",
    "\n",
    "        formatted_data.append(row)\n",
    "\n",
    "    # Create a pandas DataFrame\n",
    "    df = pd.DataFrame(formatted_data)\n",
    "    df['date'] = todaysdate\n",
    "    \n",
    "    df['Slate Type'] = np.where(df['Slate Type'] == \"\", \"All\", df['Slate Type'])\n",
    "    df['URL'] = df['URL'].astype('str')\n",
    "    \n",
    "    df.to_csv(os.path.join(baseball_path, \"11. Projections\", \"DFF\", \"A. Slates\", \"Slates \" + date + \".csv\"), index=False)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5298c17-3f54-44c8-bc1e-c444a3657d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dff_projections(code):\n",
    "    url = f\"https://www.dailyfantasyfuel.com/data/playerdetails/mlb/dk/{code}?x=1\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "    else:\n",
    "        print(f\"Failed to fetch data from {url}. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    # Create a list to store player data\n",
    "    formatted_data = []\n",
    "\n",
    "    # Iterate over each player entry\n",
    "    for player in data:\n",
    "        sport = player.get('sport')\n",
    "        team = player.get('team')\n",
    "        location = player.get('location')\n",
    "        opp = player.get('opp')\n",
    "        first_name = player.get('first_name')\n",
    "        last_name = player.get('last_name')\n",
    "        position_detailed = player.get('position_detailed')\n",
    "        position_code = player.get('position_code')\n",
    "        hand = player.get('hand')\n",
    "        player_id = player.get('player_id')\n",
    "        salary = player.get('salary')\n",
    "        ppg = player.get('ppg')\n",
    "        value = player.get('value')\n",
    "        opp_rank = player.get('opp_rank')\n",
    "        depth_rank = player.get('depth_rank')\n",
    "        starter_flag = player.get('starter_flag')\n",
    "        team_spread = player.get('team_spread')\n",
    "        projected_team_score = player.get('projected_team_score')\n",
    "        probable_flag = player.get('probable_flag')\n",
    "\n",
    "        # Append player data to the list\n",
    "        formatted_data.append({\n",
    "            'Sport': sport,\n",
    "            'Team': team,\n",
    "            'Location': location,\n",
    "            'Opponent': opp,\n",
    "            'First Name': first_name,\n",
    "            'Last Name': last_name,\n",
    "            'Position Detailed': position_detailed,\n",
    "            'Position Code': position_code,\n",
    "            'Hand': hand,\n",
    "            'Player ID': player_id,\n",
    "            'Salary': salary,\n",
    "            'PPG': ppg,\n",
    "            'Value': value,\n",
    "            'Opp Rank': opp_rank,\n",
    "            'Depth Rank': depth_rank,\n",
    "            'Starter Flag': starter_flag,\n",
    "            'Team Spread': team_spread,\n",
    "            'Projected Team Score': projected_team_score,\n",
    "            'Probable Flag': probable_flag\n",
    "        })\n",
    "\n",
    "    # Create a pandas DataFrame\n",
    "    df = pd.DataFrame(formatted_data)\n",
    "    \n",
    "    # Calculate fantasy points using Salary and Value (they don't have points for some reason)\n",
    "    df['Salary'] = df['Salary'].astype('int')\n",
    "    df['Value'] = df['Value'].astype('float')\n",
    "    df['FP'] = df['Salary'] / 1000 * df['Value']\n",
    "\n",
    "    df.to_csv(os.path.join(baseball_path, \"11. Projections\", \"DFF\", \"B. Projections\", \"Slate \" + str(code) + \".csv\"), index=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34ac429a-3d95-4501-a28c-d9036bc07042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For evaluations\n",
    "def read_dff(contestKey):\n",
    "    # Identify index of contest\n",
    "    history_index = history_full.loc[history_full['contestKey'] == contestKey].index[0]\n",
    "    \n",
    "    # Extract name and date\n",
    "    name = history_full.loc[history_index, 'name']\n",
    "    date = history_full.loc[history_index, 'date']\n",
    "    date = str(int(date))\n",
    "    \n",
    "    # Use name to pick slate type (All, Afternoon, etc...)\n",
    "    slate = pick_slate(name)\n",
    "    \n",
    "\n",
    "    try:\n",
    "        # Match projections exactly using slate name and date\n",
    "        # Read in slates\n",
    "        dff_slates = pd.read_csv(os.path.join(baseball_path, \"11. Projections\", \"DFF\", \"A. Slates\", \"Slates \" + date + \".csv\"))\n",
    "        dff_index = dff_slates.loc[dff_slates['Slate Type'] == slate].index[0]\n",
    "        dff_slate = dff_slates.loc[dff_index, 'URL']\n",
    "        \n",
    "        dff_projections = pd.read_csv(os.path.join(baseball_path, \"11. Projections\", \"DFF\", \"B. Projections\", \"Slate \" + str(dff_slate) + \".csv\"), encoding='iso-8859-1')\n",
    "    \n",
    "    except:\n",
    "        # Match projections using date (worse match)\n",
    "        date_dash = date[:4] + \"-\" + date[4:6] + \"-\" + date[6:]\n",
    "        dff_projections = pd.read_csv(os.path.join(baseball_path, \"11. Projections\", \"A. DFF\", \"DFF_MLB_cheatsheet_\" + date_dash + \".csv\"), encoding='iso-8859-1')\n",
    "        \n",
    "    \n",
    "    \n",
    "    return dff_projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f979af-60cb-46d6-8f18-ae98be7f8216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "968da40a-4572-4db6-aaf1-0a76447c9f24",
   "metadata": {},
   "source": [
    "### Projections - RotoWire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9d8ee49-50a5-49e3-939d-c424cc7eb81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roto_slates(date):\n",
    "    date_dash = date[0:4] + \"-\" + date[4:6] + \"-\" + date[6:]\n",
    "    url = 'https://www.rotowire.com/daily/mlb/saved-lineups.php?date={}'.format(date_dash)\n",
    "    \n",
    "    def fetch_page_source(url):\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            return response.text\n",
    "        else:\n",
    "            raise Exception(f\"Failed to fetch page source. Status code: {response.status_code}\")\n",
    "\n",
    "    def extract_data_from_page(html_content):\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        slates_data = []\n",
    "        for slate in soup.find_all('a', class_='dfs-slate'):\n",
    "            date_fragment, time = [text.strip() for text in slate.find('div', class_='dfs-slate-desc').stripped_strings]\n",
    "            time = time.lower()\n",
    "\n",
    "            slate_name_parts = [text.strip() for text in slate.find('div', class_='dfs-slate-name').stripped_strings]\n",
    "            slate_name = slate_name_parts[0]\n",
    "            num_games = slate_name_parts[-1].split()[0]  # Extract the number of games from the last part\n",
    "\n",
    "            slate_id = slate['href'].split('slateID=')[1]\n",
    "\n",
    "            slates_data.append({'date': date, 'slateID': slate_id, 'name': slate_name, 'time': time, 'games': num_games})\n",
    "\n",
    "        return slates_data\n",
    "\n",
    "    page_source = fetch_page_source(url)\n",
    "    data = extract_data_from_page(page_source)\n",
    "    \n",
    "    # Create a pandas DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Games will be a string of one of the team abbreviations. Fix it.\n",
    "    df['games'] = pd.to_numeric(df['games'], errors='coerce')\n",
    "    df['games'].fillna(1, inplace=True)\n",
    "    df['games'] = df['games'].astype('int') \n",
    "        \n",
    "    df.to_csv(os.path.join(baseball_path, \"11. Projections\", \"RotoWire\", \"A. Slates\", \"Slates \" + date + \".csv\"), index=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90030ae1-b0bf-4388-b1c0-2f601db0053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roto_projections(slateID):\n",
    "    \n",
    "    url = f'https://www.rotowire.com/optimizer/api/mlb/players.php?slateID={slateID}'\n",
    "    \n",
    "    try:\n",
    "        # Fetch JSON data from the API\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an exception for unsuccessful responses\n",
    "        api_data = response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data from API: {e}\")\n",
    "        return None\n",
    "\n",
    "    if not api_data:\n",
    "        print(\"No data found in API response.\")\n",
    "        return None\n",
    "\n",
    "    extracted_data = []\n",
    "\n",
    "    for entry in api_data:\n",
    "        rwID = entry.get('rwID')\n",
    "        slate_id = entry.get('slateID')\n",
    "        first_name = entry.get('firstName')\n",
    "        last_name = entry.get('lastName')\n",
    "        roto_pos = entry.get('rotoPos')\n",
    "        position = ','.join(entry.get('pos', []))\n",
    "        throws = entry.get('throws')\n",
    "        bats = entry.get('bats')\n",
    "        is_pitcher = entry.get('isPitcher')\n",
    "        is_batter = entry.get('isBatter')\n",
    "        team_abbr = entry.get('team', {}).get('abbr')\n",
    "        team_city = entry.get('team', {}).get('city')\n",
    "        team_nickname = entry.get('team', {}).get('nickname')\n",
    "        game_date_time = entry.get('game', {}).get('dateTime')\n",
    "        game_is_dome = entry.get('game', {}).get('isDome')\n",
    "        salary = entry.get('salary')\n",
    "        points = entry.get('pts')\n",
    "        rostership = entry.get('rostership')\n",
    "\n",
    "        row = {\n",
    "            'rwID': rwID,\n",
    "            'slateID': slate_id,\n",
    "            'firstName': first_name,\n",
    "            'lastName': last_name,\n",
    "            'rotoPos': roto_pos,\n",
    "            'position': position,\n",
    "            'throws': throws,\n",
    "            'bats': bats,\n",
    "            'isPitcher': is_pitcher,\n",
    "            'isBatter': is_batter,\n",
    "            'teamAbbr': team_abbr,\n",
    "            'teamCity': team_city,\n",
    "            'teamNickname': team_nickname,\n",
    "            'gameDateTime': game_date_time,\n",
    "            'gameIsDome': game_is_dome,\n",
    "            'salary': salary,\n",
    "            'points': points, \n",
    "            'rostership': rostership\n",
    "        }\n",
    "\n",
    "        extracted_data.append(row)\n",
    "\n",
    "    # Create a pandas DataFrame\n",
    "    df = pd.DataFrame(extracted_data)\n",
    "    \n",
    "    df.to_csv(os.path.join(baseball_path, \"11. Projections\", \"RotoWire\", \"B. Projections\", \"Slate \" + str(slateID) + \".csv\"), index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5b7ba5f-ebd7-4512-a3bf-96a1ea33fb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_roto(contestKey):\n",
    "    # Identify index of contest\n",
    "    history_index = history_full.loc[history_full['contestKey'] == contestKey].index[0]\n",
    "    \n",
    "    # Extract name and date\n",
    "    name = history_full.loc[history_index, 'name']\n",
    "    date = history_full.loc[history_index, 'date']\n",
    "    \n",
    "    # Use name to pick slate type (All, Afternoon, etc...)\n",
    "    slate = pick_slate(name)\n",
    "    \n",
    "    # Read in slates\n",
    "    roto_slates = pd.read_csv(os.path.join(baseball_path, \"11. Projections\", \"RotoWire\", \"A. Slates\", \"Slates \" + str(int(date)) + \".csv\"))\n",
    "    roto_index = roto_slates.loc[roto_slates['name'] == slate].index[0]\n",
    "    roto_slate = roto_slates.loc[roto_index, 'slateID']\n",
    "\n",
    "    roto_projections = pd.read_csv(os.path.join(baseball_path, \"11. Projections\", \"RotoWire\", \"B. Projections\", \"Slate \" + str(roto_slate) + \".csv\"), encoding='iso-8859-1')\n",
    "    \n",
    "    return roto_projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad873246-8dc2-4bd3-a368-a97bd8a034fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7002c3e7-c01b-4414-b9bd-ee94aa249a06",
   "metadata": {},
   "source": [
    "### Odds - Fantasy Labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57382070-1baf-4f76-96bc-fca01085eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Has a lot more fun data too! Including, weirdly, team colors! Might want to add more to this later\n",
    "def gamble_df(jsonData):\n",
    "    list_list = []\n",
    "    for i in range(len(jsonData)):\n",
    "        try:\n",
    "            home_name = jsonData[i]['EventDetails']['Properties']['HomeTeamShort']\n",
    "            away_name = jsonData[i]['EventDetails']['Properties']['VisitorTeamShort']\n",
    "            home_runs = jsonData[i]['EventDetails']['Properties']['HomeVegasRuns']\n",
    "            away_runs = jsonData[i]['EventDetails']['Properties']['VisitorVegasRuns']\n",
    "\n",
    "            away_ml = jsonData[i]['EventDetails']['Properties']['VisitorGameMoneylineCurrent']\n",
    "            home_ml = jsonData[i]['EventDetails']['Properties']['HomeGameMoneylineCurrent']\n",
    "\n",
    "            home_ou = jsonData[i]['EventDetails']['Properties']['HomeGameOUCurrent']\n",
    "            home_ou_juice = jsonData[i]['EventDetails']['Properties']['HomeGameOUJuiceCurrent']\n",
    "\n",
    "            home_spread = jsonData[i]['EventDetails']['Properties']['HomeGameSpreadCurrent']\n",
    "            home_spread_juice = jsonData[i]['EventDetails']['Properties']['HomeGameSpreadJuiceCurrent']\n",
    "\n",
    "            date = jsonData[i]['EventDetails']['Properties']['EventDateId']\n",
    "\n",
    "            gamble_list = [away_name, away_runs, home_name, home_runs, home_ou, home_ou_juice, home_spread, home_spread_juice, away_ml, home_ml, date]\n",
    "            list_list.append(gamble_list)\n",
    "        except:\n",
    "            print(\"Broke\")\n",
    "    \n",
    "    df = pd.DataFrame(list_list, columns=['away_team','away_runs', 'home_team', 'home_runs', 'ou', 'ou_juice', 'spread', 'spread_juice', 'away_ml', 'home_ml', 'date'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71da153f-0c7e-4a41-8a2e-8b2f397107f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230719\n"
     ]
    }
   ],
   "source": [
    "def daily_gamble(date, team_map):\n",
    "    print(date)\n",
    "    dateStr = date[0:4] + \"-\" + date[4:6] + \"-\" + date[6:8]\n",
    "    \n",
    "    url = f'https://www.fantasylabs.com/api/sportevents/3/{dateStr}/vegas/?sportId=3&date={dateStr}'\n",
    "    headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36'}\n",
    "    jsonData = requests.get(url, headers=headers).json()\n",
    "    \n",
    "    # try:\n",
    "    df = gamble_df(jsonData)\n",
    "    \n",
    "    team_map.reset_index(inplace=True)\n",
    "    \n",
    "    df = df.merge(team_map, left_on='away_team', right_on='FANPROSTEAM', how='left')\n",
    "    df['away_team'] = df['BBREFTEAM']\n",
    "    df.drop(columns={'FULLNAME', 'FANPROSTEAM', 'BBREFTEAM'}, inplace=True)\n",
    "    \n",
    "    df = df.merge(team_map, left_on='home_team', right_on='FANPROSTEAM', how='left')\n",
    "    df['home_team'] = df['BBREFTEAM']\n",
    "    df.drop(columns={'FULLNAME', 'FANPROSTEAM', 'BBREFTEAM'}, inplace=True)\n",
    "\n",
    "    odds_filename = \"Odds \" + date + \".csv\"\n",
    "    df.to_csv(os.path.join(baseball_path, \"11. Projections\", \"C. Odds\", odds_filename))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a50ff92-9118-4af0-b69f-90114aea1896",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cd7cf7-1438-4a44-879c-eea25e607f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19e33df-34b9-4eba-bb31-ecc639b4f32c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
