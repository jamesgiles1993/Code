{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1930c203-5f98-4f1c-85ca-76a0ad6fcbeb",
   "metadata": {},
   "source": [
    "# A1. Depth Charts\n",
    "Source: MLB.com team depth charts <br>\n",
    "        Wayback Machine for past games <br>\n",
    "\n",
    "Description: This scrapes bullpen depth charts and infers leverage from order <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc34ffa-315c-4efa-9f22-b31af86edd1b",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db275dbd-d253-464f-ba22-6b1019571a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\")\n",
    "\n",
    "import sys \n",
    "sys.path.append(r'C:\\Users\\james\\Documents\\MLB\\Code')\n",
    "\n",
    "\n",
    "import import_ipynb\n",
    "from Utilities import *\n",
    "\n",
    "baseball_path = r\"C:\\Users\\james\\Documents\\MLB\\Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ce229b6-945b-481b-b4ea-1b16e4ddf955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Today's Date\n",
    "# YYYY-MM-DD (datetime)\n",
    "todaysdate_dt = datetime.date.today()\n",
    "\n",
    "# YYYY-MM-DD (string)\n",
    "todaysdate_dash = str(todaysdate_dt)\n",
    "\n",
    "# MM/DD/YYYY\n",
    "todaysdate_slash = todaysdate_dash.split(\"-\")\n",
    "todaysdate_slash = todaysdate_slash[1] + \"/\" + todaysdate_slash[2] + \"/\" + todaysdate_slash[0]\n",
    "\n",
    "# YYYYMMDD\n",
    "todaysdate = todaysdate_dash.replace(\"-\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cebaa248-8685-4f82-a703-2195363bdbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This reads in a map of team name, codes, and the shorthand MLB uses in their URLs\n",
    "team_map = pd.read_csv(os.path.join(baseball_path, \"Utilities\", \"Team Map.csv\"))\n",
    "\n",
    "# We just need teams right now\n",
    "team_map = team_map[['FULLNAME', 'BBREFTEAM', 'MLBURL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0863b04b-7645-4f96-b912-299f931f547d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01b0bec8-ce83-4298-a2a7-7de1825a3642",
   "metadata": {},
   "source": [
    "### Bullpen Depth Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0df0bbf-3737-48f9-afc3-976351d53517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This scrapes the bullpen depth chart for teams via their website or via the Wayback Machine\n",
    "# Top reliever will be the closer. Usually other high-leverage pitchers will be near top\n",
    "# Need this header to trick site into thinking this isn't a scrape\n",
    "header = {\n",
    "  \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\",\n",
    "  \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "}\n",
    "\n",
    "def scrape_bullpen(url, header, abbrev):\n",
    "    # Get data from URL\n",
    "    r = requests.get(url, headers=header)\n",
    "    dfs = pd.read_html(r.text, encoding='iso-8859-1')\n",
    "    # Bullpen can be one of two tables\n",
    "    try:\n",
    "        df = dfs[2]\n",
    "        # Remove if they're on IL\n",
    "        df = df[df[\"Bullpen.1\"].str.contains(\"IL-\")==False].reset_index()\n",
    "        # Or in the minors\n",
    "        df = df[df[\"Bullpen.1\"].str.contains(\" Minors\")==False].reset_index()\n",
    "    except:\n",
    "        df = dfs[1]\n",
    "        df = df[df[\"Bullpen.1\"].str.contains(\"IL-\")==False].reset_index()  \n",
    "        df = df[df[\"Bullpen.1\"].str.contains(\" Minors\")==False].reset_index()\n",
    "    # Assume leverage is 0\n",
    "    df['Leverage'] = 0\n",
    "    # Loop through rows\n",
    "    for i in range(len(df)):\n",
    "        if i == 0:\n",
    "            # The top guy should be the closer\n",
    "            df['Leverage'][i] = 4\n",
    "        elif i < 4:\n",
    "            # Then the next five are set up/high leverage\n",
    "            df['Leverage'][i] = 3\n",
    "        elif i < 11:\n",
    "            # Then low leverage\n",
    "            df['Leverage'][i] = 2\n",
    "\n",
    "    # Extract name from column Bullpen.1\n",
    "    df[['Name', 'drop']] = df['Bullpen.1'].str.split(\"B/T\", expand=True)\n",
    "    # Remove numbers\n",
    "    df['Name'] = df['Name'].str.replace('\\d+', '')\n",
    "    # Remove closer tag\n",
    "    df['Name'] = df['Name'].str.replace(\"\\(CL\\)\", '')\n",
    "    \n",
    "    # Clean name\n",
    "    df['Name'] = df.apply(lambda x: remove_accents(x['Name']), axis=1)  # remove accents\n",
    "    df['Name'] = df['Name'].str.strip()\n",
    "    \n",
    "    # Keep Name, Bats/Throws, Leverage\n",
    "    df = df[['Name', 'B/T', 'Leverage']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64acb9e-6a56-48b8-8aaa-b7e50bdd76e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0806e1a7-7a47-4f6f-b9cf-c5c14ce917e6",
   "metadata": {},
   "source": [
    "### All Depth Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e5b047a-c923-46cc-b8b9-058dc390d3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-29 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# This loops over teams and scrapes all depth charts\n",
    "def create_depth_charts(start_date, end_date):\n",
    "    # Date range\n",
    "    start_date = datetime.datetime.strptime(start_date, \"%Y%m%d\")\n",
    "    end_date = datetime.datetime.strptime(end_date, \"%Y%m%d\")\n",
    "    delta = datetime.timedelta(days=1)\n",
    "    \n",
    "    # Loop over dates\n",
    "    while start_date <= end_date:\n",
    "        print(start_date)\n",
    "        date = start_date.strftime(\"%Y%m%d\")\n",
    "        \n",
    "        # Create roster directory\n",
    "        directory = \"Depth\" + date\n",
    "        try:\n",
    "            os.mkdir(os.path.join(baseball_path, \"A1. Depth Charts\", directory))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        for index, row in team_map.iterrows():\n",
    "            mlburl = row['MLBURL']\n",
    "            abbrev = row['BBREFTEAM']\n",
    "        \n",
    "            # Wayback Machine is good for backtesting, but won't default to current date\n",
    "            # url = f\"https://web.archive.org/web/{date}/https://www.mlb.com/{mlburl}/roster/depth-chart\"\n",
    "            url = f\"https://www.mlb.com/{mlburl}/roster/depth-chart\"\n",
    "            df = scrape_bullpen(url, header, abbrev)\n",
    "        \n",
    "            filename = \"Depth_Chart_\" + abbrev + \"_\" + date + \".csv\"\n",
    "            df.to_csv(os.path.join(baseball_path, \"A1. Depth Charts\", directory, filename), encoding='iso-8859-1')\n",
    "        \n",
    "        start_date += delta\n",
    "        \n",
    "        \n",
    "# Last 20221021\n",
    "create_depth_charts(todaysdate, todaysdate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e0d9c1-fdd2-4851-9ee1-5531d76a694f",
   "metadata": {},
   "source": [
    "Note:\n",
    "Scraping past bullpens is possible using the Wayback Machine. It will provide the most recent data as of the data provided in the URL, even if the date isn't available. So if 4/3 exists and 4/4 doesn't, when you try to create the depth chart on 4/4, it'll give you the same depth chart as 4/3 <br>\n",
    "When running day-of, you don't want to use the Wayback Machine as it will choose the last date it scraped <br>\n",
    "May not provide a pitcher of each leverage level. Prone to missing closers on occassion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c802025d-1a25-44a1-86df-574097c4c81e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "624f5030-c90a-489b-91c6-6d9c88a2738c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code was last run on: 2023-05-29 at 14:42:10.\n"
     ]
    }
   ],
   "source": [
    "print(\"Code was last run on: {} at {}.\".format(datetime.date.today(), datetime.datetime.now().strftime(\"%H:%M:%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b384d9-334e-495c-b666-4c84c1ab5282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
