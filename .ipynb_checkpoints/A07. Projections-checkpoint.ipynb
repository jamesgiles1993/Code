{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45286e7d-c69c-4a12-8497-16109f4c549a",
   "metadata": {},
   "source": [
    "# A07. Projections\n",
    "This scrapes daily fantasy projectionss\n",
    "- Type: Data\n",
    "- Run Frequency: Slates - Once daily, Projections - Pre-contest, \n",
    "- Sources:\n",
    "    - Daily Fantasy Fuel\n",
    "    - RotoWire \n",
    "- Dates:\n",
    "    - Created: 9/23/2023\n",
    "    - Updated: 4/21/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511ac757-d7b6-480c-9a8a-d126e1b600be",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d71f0932-be75-4e2c-a606-68e7f0444efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports executed\n"
     ]
    }
   ],
   "source": [
    "if not hasattr(sys.modules['__main__'], '__file__'):\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U1. Imports.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U2. Utilities.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U3. Classes.ipynb\"\n",
    "    print(\"Imports executed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ef43f6-df5f-4716-b532-033a1282eead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a30b7216-8fcd-4551-90ee-e35ac4414260",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c90ce475-0fbc-4720-9d45-13e372ef2709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping slates: False\n"
     ]
    }
   ],
   "source": [
    "if \"scrape_slates\" not in globals():\n",
    "    # Set scrape_slates (only scrape once a day)\n",
    "    scrape_slates = False\n",
    "    \n",
    "print(f\"Scraping slates: {scrape_slates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344f889a-9052-42c9-9156-933838c867a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66647809-9dfa-43e5-a870-85b7bbd87006",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22f8e540-7ae7-4d5d-bca6-c97acb7e0820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify DraftKings slate name\n",
    "def pick_slate(Name):\n",
    "    if \"(Early)\" in Name:\n",
    "        slate = \"Early\"\n",
    "    elif \"(Late Night)\" in Name:\n",
    "        slate = \"Late Night\"\n",
    "    elif \"Night\" in Name:\n",
    "        slate = \"Night\"\n",
    "    elif \"Afternoon\" in Name:\n",
    "        slate = \"Afternoon\"\n",
    "    else:\n",
    "        slate = \"All\"\n",
    "        \n",
    "        \n",
    "    return slate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5e17ce-8b87-45bf-9dd1-dba9dccba5e0",
   "metadata": {},
   "source": [
    "#### 1. Slates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6f1380-825c-4bda-b4c8-51a4615028b7",
   "metadata": {},
   "source": [
    "##### 1. DFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "594c89ae-86c4-4c5f-9c2b-9faccbd65f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slates available on DFF\n",
    "def dff_slates(date):\n",
    "    url = 'https://www.dailyfantasyfuel.com/data/slates/next/mlb/dk?x=1'\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "    else:\n",
    "        print(f\"Failed to fetch data from {url}. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    # Extract relevant fields from the data\n",
    "    formatted_data = []\n",
    "    for entry in data:\n",
    "        sport = entry.get('sport')\n",
    "        team_count = entry.get('team_count')\n",
    "        game_count = entry.get('game_count')\n",
    "        slate_type = entry.get('slate_type', '')\n",
    "        url = entry.get('url')\n",
    "        start_string = entry.get('start_string')\n",
    "        future_rank = entry.get('future_rank')\n",
    "        showdown_flag = entry.get('showdown_flag')\n",
    "\n",
    "        # Extract time from the \"Start Time\" string\n",
    "        time = start_string.split(\", \")[1]\n",
    "\n",
    "        row = {\n",
    "            'Sport': sport,\n",
    "            'Team Count': team_count,\n",
    "            'Game Count': game_count,\n",
    "            'Slate Type': slate_type,\n",
    "            'URL': url,\n",
    "            'Start Time': start_string,\n",
    "            'Time': time,  # New \"Time\" column\n",
    "            'Future Rank': future_rank,\n",
    "            'Showdown Flag': showdown_flag\n",
    "            }\n",
    "\n",
    "        formatted_data.append(row)\n",
    "\n",
    "    # Create a pandas DataFrame\n",
    "    df = pd.DataFrame(formatted_data)\n",
    "    df['date'] = date\n",
    "\n",
    "    df['Slate Type'] = np.where(df['Slate Type'] == \"\", \"All\", df['Slate Type'])\n",
    "    df['URL'] = df['URL'].astype('str')\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab50c61-fb8b-477a-acf9-c2f8cddb6f9b",
   "metadata": {},
   "source": [
    "##### 2. RotoWire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77426004-3813-44f4-8a67-f788dbcc1de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roto_slates(date):\n",
    "    date_dash = date[0:4] + \"-\" + date[4:6] + \"-\" + date[6:]\n",
    "    url = 'https://www.rotowire.com/daily/mlb/saved-lineups.php?date={}'.format(date_dash)\n",
    "    \n",
    "    def fetch_page_source(url):\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            return response.text\n",
    "        else:\n",
    "            raise Exception(f\"Failed to fetch page source. Status code: {response.status_code}\")\n",
    "\n",
    "    def extract_data_from_page(html_content):\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        slates_data = []\n",
    "        for slate in soup.find_all('a', class_='dfs-slate'):\n",
    "            date_fragment, time = [text.strip() for text in slate.find('div', class_='dfs-slate-desc').stripped_strings]\n",
    "            time = time.lower()\n",
    "\n",
    "            slate_name_parts = [text.strip() for text in slate.find('div', class_='dfs-slate-name').stripped_strings]\n",
    "            slate_name = slate_name_parts[0]\n",
    "            num_games = slate_name_parts[-1].split()[0]  # Extract the number of games from the last part\n",
    "\n",
    "            slate_id = slate['href'].split('slateID=')[1]\n",
    "\n",
    "            slates_data.append({'date': date, 'slateID': slate_id, 'name': slate_name, 'time': time, 'games': num_games})\n",
    "\n",
    "        return slates_data\n",
    "\n",
    "    page_source = fetch_page_source(url)\n",
    "    data = extract_data_from_page(page_source)\n",
    "    \n",
    "    # Create a pandas DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Games will be a string of one of the team abbreviations. Fix it.\n",
    "    df['games'] = pd.to_numeric(df['games'], errors='coerce')\n",
    "    df['games'].fillna(1, inplace=True)\n",
    "    df['games'] = df['games'].astype('int') \n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b87aaed-19f7-4935-a6dd-e09cbddb19cd",
   "metadata": {},
   "source": [
    "#### Projections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0ea9e2-63db-4f1f-b1ed-539b4d2154c3",
   "metadata": {},
   "source": [
    "##### 1. DFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0cf0d5d-a9d8-42dc-844f-aba168ed30d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DFF Projections\n",
    "def dff_projections(date, code):\n",
    "    # DFF url\n",
    "    url = f\"https://www.dailyfantasyfuel.com/data/playerdetails/mlb/dk/{code}?x=1\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "    else:\n",
    "        print(f\"Failed to fetch data from {url}. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    # Create a list to store player data\n",
    "    formatted_data = []\n",
    "\n",
    "    # Iterate over each player entry\n",
    "    for player in data:\n",
    "        sport = player.get('sport')\n",
    "        team = player.get('team')\n",
    "        location = player.get('location')\n",
    "        opp = player.get('opp')\n",
    "        first_name = player.get('first_name')\n",
    "        last_name = player.get('last_name')\n",
    "        position_detailed = player.get('position_detailed')\n",
    "        position_code = player.get('position_code')\n",
    "        hand = player.get('hand')\n",
    "        player_id = player.get('player_id')\n",
    "        salary = player.get('salary')\n",
    "        ppg = player.get('ppg')\n",
    "        value = player.get('value')\n",
    "        opp_rank = player.get('opp_rank')\n",
    "        depth_rank = player.get('depth_rank')\n",
    "        starter_flag = player.get('starter_flag')\n",
    "        team_spread = player.get('team_spread')\n",
    "        projected_team_score = player.get('projected_team_score')\n",
    "        probable_flag = player.get('probable_flag')\n",
    "\n",
    "        # Append player data to the list\n",
    "        formatted_data.append({\n",
    "            'Sport': sport,\n",
    "            'Team': team,\n",
    "            'Location': location,\n",
    "            'Opponent': opp,\n",
    "            'First Name': first_name,\n",
    "            'Last Name': last_name,\n",
    "            'Position Detailed': position_detailed,\n",
    "            'Position Code': position_code,\n",
    "            'Hand': hand,\n",
    "            'Player ID': player_id,\n",
    "            'Salary': salary,\n",
    "            'PPG': ppg,\n",
    "            'Value': value,\n",
    "            'Opp Rank': opp_rank,\n",
    "            'Depth Rank': depth_rank,\n",
    "            'Starter Flag': starter_flag,\n",
    "            'Team Spread': team_spread,\n",
    "            'Projected Team Score': projected_team_score,\n",
    "            'Probable Flag': probable_flag\n",
    "        })\n",
    "\n",
    "    # Create a pandas DataFrame\n",
    "    df = pd.DataFrame(formatted_data)\n",
    "\n",
    "    # Calculate fantasy points using Salary and Value (they don't have points for some reason)\n",
    "    df['Salary'] = df['Salary'].fillna(99999).astype('int')\n",
    "    \n",
    "    df['Value'] = df['Value'].astype('float')\n",
    "    df['FP'] = df['Salary'] / 1000 * df['Value']\n",
    "    \n",
    "    df['date'] = date\n",
    "    df['code'] = code\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13484b6e-5d18-4ddc-b95b-ca548eaf2242",
   "metadata": {},
   "source": [
    "##### 2. RotoWire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98c360ad-152c-4196-9517-5bd3feefd4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roto_projections(date, slateID):\n",
    "    # RotoWire Optimizer URL\n",
    "    url = f'https://www.rotowire.com/optimizer/api/mlb/players.php?slateID={slateID}'\n",
    "    \n",
    "    try:\n",
    "        # Fetch JSON data from the API\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an exception for unsuccessful responses\n",
    "        api_data = response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data from API: {e}\")\n",
    "        return None\n",
    "\n",
    "    if not api_data:\n",
    "        print(\"No data found in API response.\")\n",
    "        return None\n",
    "\n",
    "    extracted_data = []\n",
    "\n",
    "    for entry in api_data:\n",
    "        rwID = entry.get('rwID')\n",
    "        slate_id = entry.get('slateID')\n",
    "        first_name = entry.get('firstName')\n",
    "        last_name = entry.get('lastName')\n",
    "        roto_pos = entry.get('rotoPos')\n",
    "        position = ','.join(entry.get('pos', []))\n",
    "        throws = entry.get('throws')\n",
    "        bats = entry.get('bats')\n",
    "        is_pitcher = entry.get('isPitcher')\n",
    "        is_batter = entry.get('isBatter')\n",
    "        team_abbr = entry.get('team', {}).get('abbr')\n",
    "        team_city = entry.get('team', {}).get('city')\n",
    "        team_nickname = entry.get('team', {}).get('nickname')\n",
    "        game_date_time = entry.get('game', {}).get('dateTime')\n",
    "        game_is_dome = entry.get('game', {}).get('isDome')\n",
    "        salary = entry.get('salary')\n",
    "        points = entry.get('pts')\n",
    "        rostership = entry.get('rostership')\n",
    "\n",
    "        row = {\n",
    "            'rwID': rwID,\n",
    "            'slateID': slate_id,\n",
    "            'firstName': first_name,\n",
    "            'lastName': last_name,\n",
    "            'rotoPos': roto_pos,\n",
    "            'position': position,\n",
    "            'throws': throws,\n",
    "            'bats': bats,\n",
    "            'isPitcher': is_pitcher,\n",
    "            'isBatter': is_batter,\n",
    "            'teamAbbr': team_abbr,\n",
    "            'teamCity': team_city,\n",
    "            'teamNickname': team_nickname,\n",
    "            'gameDateTime': game_date_time,\n",
    "            'gameIsDome': game_is_dome,\n",
    "            'salary': salary,\n",
    "            'points': points, \n",
    "            'rostership': rostership\n",
    "        }\n",
    "\n",
    "        extracted_data.append(row)\n",
    "\n",
    "    # Create a pandas DataFrame\n",
    "    df = pd.DataFrame(extracted_data)\n",
    "\n",
    "    # Assign date\n",
    "    df['date'] = date\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b46c78-5c32-4ed5-ad4f-0446aaf1a10f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ae00170-03d8-4032-88e5-12f198921ea0",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6b3f96-53e7-4815-8e13-e1ef70faa08a",
   "metadata": {},
   "source": [
    "#### 1. Slates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2501ce-a45d-4b05-b928-3c8f2ecd9ac5",
   "metadata": {},
   "source": [
    "Note: These only need to be scraped once in the morning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5147fc54-9e53-4dde-bb48-ff45db26f538",
   "metadata": {},
   "source": [
    "##### 1. DFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b8df29e-942f-4953-8e82-ab8b3bd7b638",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Slate Type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Slate Type'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scrape_slates \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Scrape slates\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     dff_slates_df \u001b[38;5;241m=\u001b[39m dff_slates(todaysdate)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# To csv\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     dff_slates_df\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(baseball_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA07. Projections\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1. DFF\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1. Slates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDFF Slates \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtodaysdate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[11], line 45\u001b[0m, in \u001b[0;36mdff_slates\u001b[1;34m(date)\u001b[0m\n\u001b[0;32m     42\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(formatted_data)\n\u001b[0;32m     43\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m date\n\u001b[1;32m---> 45\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSlate Type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSlate Type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll\u001b[39m\u001b[38;5;124m\"\u001b[39m, df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSlate Type\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     46\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mURL\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mURL\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Slate Type'"
     ]
    }
   ],
   "source": [
    "if scrape_slates == True:\n",
    "    # Scrape slates\n",
    "    dff_slates_df = dff_slates(todaysdate)\n",
    "    # To csv\n",
    "    dff_slates_df.to_csv(os.path.join(baseball_path, \"A07. Projections\", \"1. DFF\", \"1. Slates\", f\"DFF Slates {todaysdate}.csv\"), index=False)\n",
    "else:\n",
    "    # Read csv\n",
    "    dff_slates_df = pd.read_csv(os.path.join(baseball_path, \"A07. Projections\", \"1. DFF\", \"1. Slates\", f\"DFF Slates {todaysdate}.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f219c958-7322-4827-8202-d6d165d6b1bb",
   "metadata": {},
   "source": [
    "##### 2. RotoWire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45e1f526-ac18-489c-9184-f1fa3cdff8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if scrape_slates == True:\n",
    "    # Scrape slates\n",
    "    roto_slates_df = roto_slates(todaysdate)\n",
    "    # To csv\n",
    "    roto_slates_df.to_csv(os.path.join(baseball_path, \"A07. Projections\", \"2. RotoWire\", \"1. Slates\", f\"RotoWire Slates {todaysdate}.csv\"), index=False)\n",
    "else:\n",
    "    # Read csv\n",
    "    roto_slates_df = pd. read_csv(os.path.join(baseball_path, \"A07. Projections\", \"2. RotoWire\", \"1. Slates\", f\"RotoWire Slates {todaysdate}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf24f56-3ccc-46fc-94d0-fbd202f4b019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bcd5945-d9c5-41b6-8bfc-64e37c1942f2",
   "metadata": {},
   "source": [
    "#### 2. Projections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3d64c4-cebd-4fb4-ba24-388ee21bc4c8",
   "metadata": {},
   "source": [
    "Note: These should be re-run before each contest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46193e8f-1154-423f-98db-fbcc349a84e1",
   "metadata": {},
   "source": [
    "##### 1. DFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72436121-0f31-4c3b-84b4-5374529b429d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dff_slates_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Loop over slates\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m code \u001b[38;5;129;01min\u001b[39;00m dff_slates_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mURL\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;66;03m# Scrape projections\u001b[39;00m\n\u001b[0;32m      5\u001b[0m         dff_projections_df \u001b[38;5;241m=\u001b[39m dff_projections(todaysdate, code)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dff_slates_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Loop over slates\n",
    "for code in dff_slates_df['URL']:\n",
    "    try:\n",
    "        # Scrape projections\n",
    "        dff_projections_df = dff_projections(todaysdate, code)\n",
    "        # To csv\n",
    "        dff_projections_df.to_csv(os.path.join(baseball_path, \"A07. Projections\", \"1. DFF\", \"2. Projections\", f\"DFF Projections {code}.csv\"), index=False)\n",
    "    except KeyError as e:\n",
    "        print(\"KeyError\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5739427-7b26-4ed1-a4ca-3cd58a6b1a9f",
   "metadata": {},
   "source": [
    "##### 2. RotoWire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "642bf0f3-86e7-4a83-9dfa-0a9a90ad21f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over slates\n",
    "for code in roto_slates_df['slateID']:\n",
    "    # Scrape projections\n",
    "    roto_projections_df = roto_projections(todaysdate, code)\n",
    "    try:\n",
    "        # To csv\n",
    "        roto_projections_df.to_csv(os.path.join(baseball_path, \"A07. Projections\", \"2. RotoWire\", \"2. Projections\", f\"RotoWire Projections {code}.csv\"), index=False)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b1bf39-b4f9-43a5-bd6b-5a2b3f5075f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
