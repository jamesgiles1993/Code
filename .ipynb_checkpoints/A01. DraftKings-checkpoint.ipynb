{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dc54cbf-1cc6-4be3-8107-4fb20b04d6d0",
   "metadata": {},
   "source": [
    "# A01. DraftKings\n",
    "This extracts DraftKings contest data and saves results\n",
    "- Type: Data\n",
    "- Run Frequency: Once daily\n",
    "- Sources:\n",
    "    - DraftKings API\n",
    "    - DraftKings Contest Results\n",
    "- Dates:\n",
    "    - Created: 9/22/2023\n",
    "    - Updated: 4/21/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366da762-d93c-4a1f-b136-151d24843e47",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88e53e5-0beb-4c6c-bcb1-5e0f907c19df",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not hasattr(sys.modules['__main__'], '__file__'):\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U01. Imports.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U02. Functions.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U03. Classes.ipynb\"\n",
    "    print(\"Imports executed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51776c2e-3d12-41bf-a49f-2f122c70490b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62e96402-3969-47bc-9673-bfac30746c49",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ad2af8-cd00-4c18-8445-e10fb84f3b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not hasattr(sys.modules['__main__'], '__file__'):\n",
    "    # Only scrape the draftables (for right before games)\n",
    "    draftables_only = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196b29a4-f888-4921-93c9-7d74e69ec721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c0ec546-2b7a-4848-91c6-cb213b4120e5",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ca20cb-c973-4a0c-b737-bcb52cbbf7e8",
   "metadata": {},
   "source": [
    "##### 1. Contests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26de70a6-be3c-43aa-ae04-10417ff7bfd8",
   "metadata": {},
   "source": [
    "Create dataframe with today's contests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aa0144-e4cf-49a8-b381-3d579b9ef3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contests(date):\n",
    "    # Extract JSON data\n",
    "    response = requests.get(\"https://www.draftkings.com/lobby/getcontests?sport=MLB\")\n",
    "    json_data = response.json()\n",
    "\n",
    "    # Extract the \"Contests\" data\n",
    "    contests_data = json_data[\"Contests\"]\n",
    "\n",
    "    # Create an empty list to store the extracted data\n",
    "    rows = []\n",
    "\n",
    "    # Iterate over each contest\n",
    "    for contest in contests_data:\n",
    "        contest_dict = {}\n",
    "\n",
    "        # Extract the desired fields from the contest\n",
    "        contest_dict[\"Name\"] = contest[\"n\"]\n",
    "        contest_dict[\"Cash Prize\"] = contest[\"pd\"].get(\"Cash\", None)\n",
    "        contest_dict[\"Entry Fee\"] = contest[\"a\"]\n",
    "        contest_dict[\"contestKey\"] = contest[\"id\"]\n",
    "        contest_dict[\"draftGroupId\"] = contest[\"dg\"]\n",
    "        contest_dict['contestDate'] = contest[\"sd\"]\n",
    "        contest_dict['contestDate'] = contest_dict['contestDate'].replace(\"/Date(\", \"\").replace(\")/\",\"\")\n",
    "        contest_dict['contestTime'] = contest[\"sdstring\"]\n",
    "        contest_dict['gameType'] = contest['gameType']\n",
    "        \n",
    "        # Append the extracted data to the list\n",
    "        rows.append(contest_dict)\n",
    "\n",
    "    # Create a DataFrame from the extracted data\n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    # Fix date\n",
    "    df['contestDate'] = pd.to_numeric(df['contestDate'])\n",
    "    df['contestDate'] = df['contestDate'] / 1000  # Convert milliseconds to seconds\n",
    "    df['contestDate'] = df['contestDate'].apply(datetime.datetime.fromtimestamp)\n",
    "    \n",
    "    # Date (without time)\n",
    "    df['date'] = date\n",
    "    \n",
    "    # Sort by date\n",
    "    df.sort_values('contestDate', ascending=True, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d359baeb-8656-4439-a303-04cf7c5436ce",
   "metadata": {},
   "source": [
    "##### 2. Draftables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beb3400-b17b-47ae-92dd-09769d279e4d",
   "metadata": {},
   "source": [
    "Create dataframe with slate's salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d32e5b-f8c6-48de-b182-b92bd973ce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draftables(draftGroupId):\n",
    "    # Extract game info (used to determining away and home teams, date, time)\n",
    "    def get_game_info(row):\n",
    "        # Define the time zone conversion\n",
    "        source_timezone = pytz.timezone('UTC')\n",
    "        target_timezone = pytz.timezone('America/New_York')\n",
    "\n",
    "        # Extract competitions\n",
    "        competitions = row.get('competitions', [])\n",
    "        if competitions:\n",
    "            name_display = competitions[0].get('nameDisplay', [])\n",
    "            if len(name_display) >= 3:\n",
    "                # Extract team names\n",
    "                team1 = name_display[0]['value']\n",
    "                team2 = name_display[2]['value']\n",
    "                # And start time\n",
    "                start_time = dateutil.parser.parse(competitions[0]['startTime']).astimezone(target_timezone).strftime('%m/%d/%Y %I:%M%p')\n",
    "                # Convert to typical away@home datetime ET format\n",
    "                return f\"{team1}@{team2} {start_time} ET\"\n",
    "        return \"\"\n",
    "    \n",
    "    # Extract JSON data\n",
    "    response = requests.get(f'https://api.draftkings.com/draftgroups/v1/draftgroups/{draftGroupId}/draftables')\n",
    "    json_data = response.json()\n",
    "    \n",
    "    # Access the \"draftables\" key in the JSON data\n",
    "    draftables = json_data[\"draftables\"]\n",
    "\n",
    "    # Convert the \"draftables\" data to a DataFrame\n",
    "    df = pd.DataFrame(draftables)\n",
    "\n",
    "\n",
    "    # Extracting and formatting game information\n",
    "    df[\"Game Info\"] = df.apply(get_game_info, axis=1)\n",
    "    df[\"AvgPointsPerGame\"] = df[\"draftStatAttributes\"].apply(lambda x: x[0][\"value\"])\n",
    "    df['Name + ID'] = df['displayName'] + \" (\" + df['draftableId'].astype('str') + \")\" \n",
    "    df[\"Roster Position\"] = df[\"position\"].apply(lambda x: \"P\" if x in [\"SP\", \"RP\"] else x)\n",
    "    df[\"alertType\"] = df[\"draftAlerts\"].apply(lambda x: x[0][\"alertType\"] if isinstance(x, list) and len(x) > 0 else None)\n",
    "    \n",
    "    # Rename to match salary download files\n",
    "    df.rename(columns={'position':'Position', 'displayName': 'Name', 'salary':'Salary', 'teamAbbreviation':'TeamAbbrev', 'draftableId':'ID'}, inplace=True)\n",
    "\n",
    "    # Select relevant columns\n",
    "    df = df[['Position', 'Name + ID', 'Name', 'ID', 'Roster Position', 'Salary', 'Game Info', 'TeamAbbrev', 'AvgPointsPerGame', 'playerId', 'alertType']]\n",
    "\n",
    "    df.drop_duplicates(['Name', 'TeamAbbrev'], inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    df['draftGroupId'] = draftGroupId\n",
    "    \n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad9736b-3fbf-4b12-a03c-a23a9b3da514",
   "metadata": {},
   "source": [
    "##### 3. Payouts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe745555-4bd1-461c-9929-6b706ed36941",
   "metadata": {},
   "source": [
    "Create dataframe with contest's payouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5241f3f-c5fa-41b7-8ae1-d5f65b18d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This scrapes payouts\n",
    "def payouts(contestKey):\n",
    "    # Extract JSON data\n",
    "    response = requests.get(f\"https://api.draftkings.com/contests/v1/contests/{contestKey}?format=json\")\n",
    "    json_data = response.json()\n",
    "    \n",
    "    # Extract minPosition, maxPosition, and payoutDescription\n",
    "    payouts = json_data['contestDetail']['payoutSummary']\n",
    "    data = []\n",
    "    for payout in payouts:\n",
    "        min_pos = payout['minPosition']\n",
    "        max_pos = payout['maxPosition']\n",
    "        payout_desc = payout['payoutDescriptions'][0]['payoutDescription']\n",
    "        entry_fee = json_data['contestDetail']['entryFee']\n",
    "        entries = json_data['contestDetail']['entries']\n",
    "        max_entries_per_user = json_data['contestDetail']['maximumEntriesPerUser']\n",
    "        draft_group_id = json_data['contestDetail']['draftGroupId']\n",
    "        contest_key = json_data['contestDetail']['contestKey']\n",
    "        contest_start_time = json_data['contestDetail']['contestStartTime']\n",
    "        name = json_data['contestDetail']['name']\n",
    "        data.append([min_pos, max_pos, payout_desc, entry_fee, entries, max_entries_per_user, draft_group_id, contest_key, contest_start_time, name])\n",
    "\n",
    "    # Create a dataframe\n",
    "    df = pd.DataFrame(data, columns=['minPosition', 'maxPosition', 'payoutDescription', 'entryFee', 'entries', 'maximumEntriesPerUser', 'draftGroupId', 'contestKey', 'contestStartTime', 'name'])\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4feaad-7468-431f-a5d1-e4735d205b5f",
   "metadata": {},
   "source": [
    "##### 4. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa25176-ba41-47d2-8df9-42477b7d0892",
   "metadata": {},
   "source": [
    "Download contest's results CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24d14e7-64c9-4caa-aec2-667df80a5d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(contestKey, sleep_time=5):\n",
    "    # Open in a new tab (same window)\n",
    "    webbrowser.open(f\"https://www.draftkings.com/contest/exportfullstandingscsv/{contestKey}\")\n",
    "\n",
    "    # Wait for file to download\n",
    "    time.sleep(sleep_time)\n",
    "    \n",
    "    # Specify the path to the Downloads directory\n",
    "    downloads_folder = r'C:\\Users\\james\\Downloads'\n",
    "\n",
    "    # Get a list of all files in the Downloads directory\n",
    "    files = os.listdir(downloads_folder)\n",
    "\n",
    "\n",
    "    # Filter the list to include files starting with 'contest-standings' and sort by modification time (most recent first)\n",
    "    search_term = f'contest-standings-{contestKey}'\n",
    "    print(search_term)\n",
    "    relevant_files = [file for file in files if file.startswith(search_term)]\n",
    "    # print(files)\n",
    "    sorted_files = sorted(relevant_files, key=lambda x: os.path.getmtime(os.path.join(downloads_folder, x)), reverse=True)\n",
    "\n",
    "    print(sorted_files)\n",
    "        \n",
    "    # Look at relevant files\n",
    "    if sorted_files:\n",
    "        # Select the most recent file\n",
    "        most_recent_file = sorted_files[0]\n",
    "\n",
    "        # Specify the path to the most recent file\n",
    "        file_path = os.path.join(downloads_folder, most_recent_file)\n",
    "\n",
    "        print(file_path)\n",
    "        \n",
    "        # Specify the path to the destination folder where you want to save the file\n",
    "        destination_folder = r'C:\\Users\\james\\Documents\\MLB\\Database\\A01. DraftKings\\4. Results'\n",
    "\n",
    "        # If the file is a zip, unpack it; otherwise, copy it over\n",
    "        if file_path.endswith('.zip'):\n",
    "            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                # Extract all files from the zip file to the destination folder\n",
    "                zip_ref.extractall(destination_folder)\n",
    "            print('Zip file unpacked successfully!')\n",
    "        else:\n",
    "            # Copy the file to the destination folder\n",
    "            shutil.copy2(file_path, destination_folder)\n",
    "            print('File copied successfully!')\n",
    "    else:        \n",
    "        print('No relevant files found in the Downloads directory.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86666987-3c29-4e97-9323-b335ea8f0949",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### 5. Entry Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae1414e-18a7-452f-af43-89c32535577a",
   "metadata": {},
   "source": [
    "Create contest's entry results dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f040390-a6f2-4765-ad4d-1ddf08571830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entry_results(results_df):\n",
    "    # Entry results \n",
    "    entry_results_df = results_df[['Rank', 'EntryId', 'EntryName', 'TimeRemaining', 'Points', 'Lineup']].dropna()\n",
    "        \n",
    "    entry_results_df['Lineup_Copy'] = entry_results_df['Lineup'].copy()\n",
    "        \n",
    "    ### Prep for regular expression divisions \n",
    "    # Add space to the beginning    \n",
    "    entry_results_df['Lineup'] = ' ' + entry_results_df['Lineup']\n",
    "\n",
    "    # Add spaces around positions\n",
    "    for position in ['P', 'C', '1B', '2B', '3B', 'SS', 'OF']:\n",
    "        entry_results_df['Lineup'] = entry_results_df['Lineup'].str.replace(f\" {position} \", f\"  {position}  \")\n",
    "    \n",
    "    # Add space to the end\n",
    "    entry_results_df['Lineup'] = entry_results_df['Lineup'] + \"  \"\n",
    "\n",
    "    ### P\n",
    "    # Define the regex pattern to match \"P  {name}  \" and extract {name}\n",
    "    pattern = r'P\\s\\s(.*?)\\s\\s'\n",
    "\n",
    "    # Create empty columns for \"P\" and \"P.1\"\n",
    "    entry_results_df['P'] = None\n",
    "    entry_results_df['P.1'] = None\n",
    "\n",
    "    # Iterate through the DataFrame\n",
    "    for index, row in entry_results_df.iterrows():\n",
    "        matches = re.findall(pattern, row['Lineup'])\n",
    "        if len(matches) >= 2:\n",
    "            entry_results_df.at[index, 'P'] = matches[0]\n",
    "            entry_results_df.at[index, 'P.1'] = matches[1]\n",
    "    \n",
    "    ### C\n",
    "    # Define a regex pattern to match \"C  {name}  \" and extract {name}\n",
    "    pattern = r'C\\s\\s(.*?)\\s\\s'\n",
    "    \n",
    "    # Create empty column for \"C\"\n",
    "    entry_results_df['C'] = None\n",
    "\n",
    "    # Iterate through the DataFrame\n",
    "    for index, row in entry_results_df.iterrows():\n",
    "        matches = re.findall(pattern, row['Lineup'])\n",
    "        entry_results_df.at[index, 'C'] = matches[0]\n",
    "    \n",
    "    ### 1B\n",
    "    # Define a regex pattern to match \"1B  {name}  \" and extract {name}\n",
    "    pattern = r'1B\\s\\s(.*?)\\s\\s'\n",
    "    \n",
    "    # Create empty column for \"C\"\n",
    "    entry_results_df['1B'] = None\n",
    "\n",
    "    # Iterate through the DataFrame\n",
    "    for index, row in entry_results_df.iterrows():\n",
    "        matches = re.findall(pattern, row['Lineup'])\n",
    "        entry_results_df.at[index, '1B'] = matches[0]\n",
    "    \n",
    "    ### 2B\n",
    "    # Define a regex pattern to match \"2B  {name}  \" and extract {name}\n",
    "    pattern = r'2B\\s\\s(.*?)\\s\\s'\n",
    "    \n",
    "    # Create empty column for \"C\"\n",
    "    entry_results_df['2B'] = None\n",
    "\n",
    "    # Iterate through the DataFrame\n",
    "    for index, row in entry_results_df.iterrows():\n",
    "        matches = re.findall(pattern, row['Lineup'])\n",
    "        entry_results_df.at[index, '2B'] = matches[0]\n",
    "    \n",
    "    ### 3B\n",
    "    # Define a regex pattern to match \"3B  {name}  \" and extract {name}\n",
    "    pattern = r'3B\\s\\s(.*?)\\s\\s'\n",
    "    \n",
    "    # Create empty column for \"C\"\n",
    "    entry_results_df['3B'] = None\n",
    "\n",
    "    # Iterate through the DataFrame\n",
    "    for index, row in entry_results_df.iterrows():\n",
    "        matches = re.findall(pattern, row['Lineup'])\n",
    "        entry_results_df.at[index, '3B'] = matches[0]\n",
    "    \n",
    "    ### SS\n",
    "     # Define a regex pattern to match \"SS  {name}  \" and extract {name}\n",
    "    pattern = r'SS\\s\\s(.*?)\\s\\s'\n",
    "    \n",
    "    # Create empty column for \"C\"\n",
    "    entry_results_df['SS'] = None\n",
    "\n",
    "    # Iterate through the DataFrame\n",
    "    for index, row in entry_results_df.iterrows():\n",
    "        matches = re.findall(pattern, row['Lineup'])\n",
    "        entry_results_df.at[index, 'SS'] = matches[0]\n",
    "        \n",
    "    ### OF\n",
    "    # Define the regex pattern to match \"P  {name}  \" and extract {name}\n",
    "    pattern = r'OF\\s\\s(.*?)\\s\\s'\n",
    "\n",
    "    # Create empty columns for \"OF\" and \"OF.1\" and \"OF.2\"\n",
    "    entry_results_df['OF'] = None\n",
    "    entry_results_df['OF.1'] = None\n",
    "    entry_results_df['OF.2'] = None\n",
    "\n",
    "    # Iterate through the DataFrame\n",
    "    for index, row in entry_results_df.iterrows():\n",
    "        matches = re.findall(pattern, row['Lineup'])\n",
    "        if len(matches) >= 3:\n",
    "            entry_results_df.at[index, 'OF'] = matches[0]\n",
    "            entry_results_df.at[index, 'OF.1'] = matches[1]\n",
    "            entry_results_df.at[index, 'OF.2'] = matches[2]\n",
    "            \n",
    "    entry_results_df['Lineup'] = entry_results_df['Lineup_Copy']\n",
    "    entry_results_df.drop(columns={'Lineup_Copy'}, inplace=True)\n",
    "    \n",
    "    \n",
    "    return entry_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298cbb5a-093a-4e38-891b-66947877d848",
   "metadata": {},
   "source": [
    "##### 6. Player Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26baf25-4db6-4d48-a297-f0ac908cd12f",
   "metadata": {},
   "source": [
    "Create slate's player results dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7560aedc-f503-437e-b0e0-c1017bdedc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create entry dataframe\n",
    "def player_results(results_df):\n",
    "    # Player results \n",
    "    player_results = results_df[['Player', 'Roster Position', '%Drafted', 'FPTS']].dropna()    \n",
    "    \n",
    "    \n",
    "    return player_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cdfd8b-4804-4d87-8a64-7c41a0d2dbe2",
   "metadata": {},
   "source": [
    "##### 7. Subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30f0c3d-794e-4287-8ceb-d573e28f1b0d",
   "metadata": {},
   "source": [
    "Select contests for which we want to extract data from DraftKings and build contest guides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40e8716-4dc7-477d-9090-82286355b7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subset(contest_df, contests_per_draftGroupId=10, entry_fee_max=100, added_contestKeys=[], date_dash=todaysdate_dash):\n",
    "    # Create copy\n",
    "    subset_df = contest_df.copy()\n",
    "    \n",
    "    # Only keep \"Classic\" contests\n",
    "    subset_df = contest_df[contest_df['gameType'] == 'Classic']\n",
    "\n",
    "    # Always keep certain contests, regardless of cash prizes\n",
    "    four_seamer_df = subset_df[subset_df['Name'].str.contains(\"eamer\", case=False)]\n",
    "    knuckleball_df = subset_df[subset_df['Name'].str.contains(\"nuckleball\", case=False)]\n",
    "    \n",
    "    # Convert Cash Prize to numeric\n",
    "    subset_df['Cash Prize'] = subset_df['Cash Prize'].str.replace(\"$\", \"\").str.replace(\",\", \"\").astype('float')\n",
    "    # Only keep contests from today and those with reasonable entry fees\n",
    "    subset_df['date_dash'] = subset_df['contestDate'].astype('str').str[:10]\n",
    "    subset_df['Entry Fee'] = subset_df['Entry Fee'].astype('float')\n",
    "    subset_df = subset_df[(subset_df['date_dash'] == date_dash) & (subset_df['Entry Fee'] < entry_fee_max)]\n",
    "    \n",
    "    # Take the top n highest cash prizes based on draftGroupId\n",
    "    subset_df = subset_df.sort_values(['draftGroupId', 'Cash Prize'], ascending=[False, False]).groupby('draftGroupId').head(contests_per_draftGroupId).reset_index(drop=True)\n",
    "\n",
    "    # Append on additional contests\n",
    "    subset_df = pd.concat([subset_df, four_seamer_df, knuckleball_df], axis=0)\n",
    "\n",
    "    # Remove one game matchups\n",
    "    subset_df = subset_df[~subset_df['Name'].str.contains(\"vs\")]\n",
    "\n",
    "    # Filter contests based on added_contestKeys\n",
    "    if added_contestKeys != []:\n",
    "        subset_df = pd.concat([subset_df, contest_df[contest_df['contestKey'].isin(added_contestKeys)]], axis=0)\n",
    "\n",
    "    # Only keep one dataframe per contest\n",
    "    subset_df.drop_duplicates('contestKey', inplace=True, keep='first')\n",
    "\n",
    "    # Reset index\n",
    "    subset_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    \n",
    "    return subset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10343e0c-ccb4-4f6f-a3a1-926c3961e478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0a17db7-d99e-48e6-8279-e08c631a9dcf",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026a766a-1ba6-44a6-b30d-fa2ec4bce9bb",
   "metadata": {},
   "source": [
    "##### 1. Contests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc3b197-59f6-411b-afd0-f5e4d589c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if draftables_only == False:\n",
    "    # Scrape contests\n",
    "    contest_df = contests(todaysdate)\n",
    "    # Write to CSV\n",
    "    contest_df.to_csv(os.path.join(baseball_path, 'A01. DraftKings', '1. Contests', f'Contests {todaysdate}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7231514c-71d2-4f34-86c4-d38755035b8b",
   "metadata": {},
   "source": [
    "##### 7. Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb46b26-e4c1-4618-abb0-d9e6c753a1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if draftables_only == False:\n",
    "    # Select subset of contests\n",
    "    subset_df = create_subset(contest_df, contests_per_draftGroupId=5, entry_fee_max=100, added_contestKeys=[], date_dash=todaysdate_dash)\n",
    "    # Write to CSV\n",
    "    subset_df.to_csv(os.path.join(baseball_path, \"A01. DraftKings\", \"7. Subsets\", f'Subset {todaysdate}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b994aa10-fe5c-4924-9ef3-c70864827421",
   "metadata": {},
   "source": [
    "##### 2. Draftables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f768a38a-237b-4e5e-b20e-b3c43edebc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Read in subset_df\n",
    "subset_df = pd.read_csv(os.path.join(baseball_path, \"A01. DraftKings\", \"7. Subsets\", f'Subset {todaysdate}.csv'))\n",
    "\n",
    "# Loop over unique slates in subset of contests\n",
    "for draftGroupId in list(subset_df['draftGroupId'].unique()):\n",
    "    try:\n",
    "        # Scrape draftables (Salaries)\n",
    "        draftable_df = draftables(draftGroupId)\n",
    "        # Write to CSV\n",
    "        draftable_df.to_csv(os.path.join(baseball_path, \"A01. DraftKings\", \"2. Draftables\", f\"Draftables {draftGroupId}.csv\"), index=False, encoding='iso-8859-1')\n",
    "        print(f\"Saved {draftGroupId}\")\n",
    "    except:\n",
    "        print(f\"Didn't save {draftGroupId}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c32e27a-5b55-4f9e-9f31-f801f2e52247",
   "metadata": {},
   "source": [
    "##### 3. Payouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677422cc-b9d0-4d5c-93ec-052936f8b720",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if draftables_only == False:\n",
    "    # Loop over contests of interest\n",
    "    for i in range(len(subset_df)):\n",
    "        # Extract contestKey\n",
    "        contestKey = subset_df['contestKey'][i]\n",
    "        try:\n",
    "            # Scrape payouts\n",
    "            payout_df = payouts(contestKey)\n",
    "            # Write to CSV\n",
    "            payout_df.to_csv(os.path.join(baseball_path, \"A01. DraftKings\", \"3. Payouts\", f\"Payouts {contestKey}.csv\"), index=False, encoding='iso-8859-1')\n",
    "        except:\n",
    "            print(f\"Didn't save {contestKey}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad425c9-fb72-4677-b1cf-55f4a9d022f6",
   "metadata": {},
   "source": [
    "##### 4. Results, 5. Entry Results, and 6. Player Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e935040a-2b9f-449b-a523-fb7f0332e2b6",
   "metadata": {},
   "source": [
    "Note: This will break if there were no games yesterday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee034b3-8e96-4287-9cc9-f58bd17e0da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if draftables_only == False:\n",
    "    # Read in yesterdays subset\n",
    "    yesterdays_subset_df = pd.read_csv(os.path.join(baseball_path, 'A01. DraftKings', '7. Subsets', f'Subset {yesterdaysdate}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0864148a-27d7-452d-bd0f-b8e34f6bec55",
   "metadata": {},
   "outputs": [],
   "source": [
    "if draftables_only == False:\n",
    "    # Loop over yesterday's contests\n",
    "    for i in range(len(yesterdays_subset_df)):\n",
    "        # Extract contestKey\n",
    "        contestKey = yesterdays_subset_df['contestKey'][i]\n",
    "        print(contestKey)\n",
    "        # 4. Results\n",
    "        # Download\n",
    "        results(contestKey, sleep_time=5)\n",
    "\n",
    "        try:\n",
    "            # Read into pandas, if possible\n",
    "            results_df = pd.read_csv(os.path.join(baseball_path, \"A01. DraftKings\", \"4. Results\", f\"contest-standings-{contestKey}.csv\"))\n",
    "\n",
    "            # 5. Entry Results\n",
    "            # Extract contest results\n",
    "            entry_results_df = entry_results(results_df)\n",
    "            # Write to CSV\n",
    "            entry_results_df.to_csv(os.path.join(baseball_path, \"A01. DraftKings\", \"5. Entry Results\", f\"Entry Results {contestKey}.csv\"), index=False, encoding='iso-8859-1')\n",
    "\n",
    "            # 6. Player Results\n",
    "            # Extract player results\n",
    "            player_results_df = player_results(results_df)\n",
    "            # Write to CSV\n",
    "            player_results_df.to_csv(os.path.join(baseball_path, \"A01. DraftKings\", \"6. Player Results\", f\"Player Results {contestKey}.csv\"), index=False, encoding='iso-8859-1')\n",
    "        except IndexError as e:\n",
    "            print(f\"Downloaded contest-standings-{contestKey}. Non-traditional format.\")\n",
    "        except pd.errors.EmptyDataError as e:\n",
    "            print(f\"Downloaded contest-standings-{contestKey}. Empty file.\")\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Couldn't find {contestKey}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda-base)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
