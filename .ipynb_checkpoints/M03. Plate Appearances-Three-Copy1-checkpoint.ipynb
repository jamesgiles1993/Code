{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "246dcb35-a0f2-4ce2-a46e-f6b8c1053bf2",
   "metadata": {},
   "source": [
    "# M03. Predict PAs\n",
    "- This predicts the outcome of plate appearances\n",
    "- Type: Model\n",
    "- Run Frequency: Irregular\n",
    "- Sources:\n",
    "    - MLB API\n",
    "    - Steamer\n",
    "- Created: 4/19/2024\n",
    "- Updated: 2/1/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72339d03-2fb3-4067-97eb-994324eb3c21",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4534de56-4550-4dce-99fc-73d526095998",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"U1. Imports.ipynb\"\n",
    "%run \"U2. Utilities.ipynb\"\n",
    "%run \"U3. Classes.ipynb\"\n",
    "%run \"U4. Datasets.ipynb\"\n",
    "%run \"U5. Models.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67afe9b9-2ede-417d-873a-acfb5e5e7ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set option to display numbers without scientific notation\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034975ab-8382-4a5b-988d-64745d11cec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81a6014a-eb27-4083-9537-1ec7e127de15",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb08ca5-c5d6-4660-b5b7-3d9296d116ad",
   "metadata": {},
   "source": [
    "##### Park x Weather Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c8c4a68-63ea-4fc3-aeb8-f24391e9887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplier_df = pd.read_csv(os.path.join(baseball_path, \"Multiplier Dataset.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bd9517-fc3e-4366-bd46-2dfce7c7c7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3da3950c-f72c-489f-8d4c-58e39ffe3a89",
   "metadata": {},
   "source": [
    "##### Plate Appearances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0f5b102-3263-4a73-97c5-bf6c4945b0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset = create_pa_inputs(multiplier_df, start_year=2013, end_year=2024, short=50, long=300, adjust=True, generate=False, write=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9554945d-d2d4-4f4f-ab38-35dfdda23623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e19f930-66f1-4b0f-b301-7343dde08590",
   "metadata": {},
   "source": [
    "##### Steamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ef91c4c-14d8-4e8d-98d1-fcc3d34333d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_hitters_df = pd.read_csv(os.path.join(baseball_path, \"A03. Steamer\", \"steamer_hitters_weekly_log.csv\"), encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffe7d409-3aba-4c26-b7ff-4e0bac53dd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_pitchers_df = pd.read_csv(os.path.join(baseball_path, \"A03. Steamer\", \"steamer_pitchers_weekly_log.csv\"), encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3151bb4c-1be0-46c6-a287-b94567d6d25e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d4a2fea-7565-4c30-8703-29035d07ef48",
   "metadata": {},
   "source": [
    "### Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee27de4-ce5b-47c5-a4cf-c830466c46c8",
   "metadata": {},
   "source": [
    "##### MLB Stats API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52508861-52f1-4d58-8c14-f481006a1674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.28 s\n",
      "Wall time: 2.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "complete_dataset[batter_inputs] = scale_batter_stats.transform(complete_dataset[batter_inputs])\n",
    "complete_dataset[pitcher_inputs] = scale_pitcher_stats.transform(complete_dataset[pitcher_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b866ef9-6f8c-4e06-a7ed-e592704bbe89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31af98da-c1d1-43f0-a38d-7992b6b96f0a",
   "metadata": {},
   "source": [
    "##### Steamer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb08b20-1f0d-4272-868a-a071205b819a",
   "metadata": {},
   "source": [
    "Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4194d026-dbb6-43c7-aed1-0ba7f2dcc416",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_hitters_df2 = clean_steamer_hitters(steamer_hitters_df)\n",
    "steamer_hitters_df2.dropna(subset=batter_stats_fg, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bc62f8-205d-4fca-8fe7-77090575ca6f",
   "metadata": {},
   "source": [
    "Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23ecadf9-e251-4390-819a-ab4133a8e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_hitters_df2[batter_stats_fg] = scale_batter_stats_steamer.transform(steamer_hitters_df2[batter_stats_fg])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ba419a-58da-4569-a47f-81f42e99c149",
   "metadata": {},
   "source": [
    "Read in pitchers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e7bc1b-2165-40de-b18a-5ce4a5eeda4d",
   "metadata": {},
   "source": [
    "Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbc05c0e-a762-4dd1-b624-0a3eef35f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_pitchers_df2 = clean_steamer_pitchers(steamer_pitchers_df)\n",
    "steamer_pitchers_df2.dropna(subset=pitcher_stats_fg2, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2d3acf-0351-4fe4-8c58-324a41c7ffc7",
   "metadata": {},
   "source": [
    "Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96034fe3-b3ea-4798-a317-14644903ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_pitchers_df2[pitcher_stats_fg] = scale_pitcher_stats_steamer.transform(steamer_pitchers_df2[pitcher_stats_fg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ed059a-3722-4a35-89f9-29a67c57e0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c115569b-2eb1-4689-976b-2bec2de41de2",
   "metadata": {},
   "source": [
    "##### Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23ab6f4-8ad4-4553-b652-dc309cd750f4",
   "metadata": {},
   "source": [
    "Format dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83073ed4-4a17-4a52-818f-68aef1fc6f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset['date_time'] = pd.to_datetime(complete_dataset['date'], format='%Y%m%d')\n",
    "complete_dataset['date_time_copy'] = complete_dataset['date_time'].copy()\n",
    "steamer_hitters_df2['date_time'] = pd.to_datetime(steamer_hitters_df2['date'], format='%Y%m%d')\n",
    "steamer_pitchers_df2['date_time'] = pd.to_datetime(steamer_pitchers_df2['date'], format='%Y%m%d')\n",
    "\n",
    "steamer_hitters_df2.rename(columns={'mlbamid': 'batter'}, inplace=True)\n",
    "steamer_pitchers_df2.rename(columns={'mlbamid': 'pitcher'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f30dd3-3af8-4091-aa85-0ce10d34cc21",
   "metadata": {},
   "source": [
    "Sort to prep for merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f6487f3-2d3a-4610-9f93-2c9df6513a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset.sort_values('date_time', inplace=True)\n",
    "steamer_hitters_df2.sort_values('date_time', inplace=True)\n",
    "steamer_pitchers_df2.sort_values('date_time', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821f1b85-e5c8-4b0f-b14d-b74aa8ae8963",
   "metadata": {},
   "source": [
    "Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b979390c-a523-4916-887e-da6066b32fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_hitters_df2.drop(columns=['date', 'firstname', 'lastname', 'steamerid'], inplace=True)\n",
    "steamer_pitchers_df2.drop(columns=['date', 'firstname', 'lastname', 'steamerid'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11525c81-34ac-4b5e-b4be-93e480287dfb",
   "metadata": {},
   "source": [
    "Remove missing pitchers (occurs occassionally in 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d58197e4-5412-4374-be94-7431061c3d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_pitchers_df2 = steamer_pitchers_df2[~steamer_pitchers_df2['pitcher'].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94389ba7-2be4-401e-8010-0d9aa3f2acd5",
   "metadata": {},
   "source": [
    "Set data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0352f70a-489f-4ad8-a38b-4f9e1d0dfa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset['batter'] = complete_dataset['batter'].astype(int).astype(str)\n",
    "complete_dataset['pitcher'] = complete_dataset['pitcher'].astype(int).astype(str)\n",
    "steamer_hitters_df2['batter'] = steamer_hitters_df2['batter'].astype(int).astype(str)\n",
    "steamer_pitchers_df2['pitcher'] = steamer_pitchers_df2['pitcher'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27529d5a-52e6-4ab1-b1de-c0ff138312aa",
   "metadata": {},
   "source": [
    "Merge asof most recent date in Steamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12c448db-edaf-4259-9de4-641528042799",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df = pd.merge_asof(\n",
    "    complete_dataset,\n",
    "    steamer_hitters_df2,\n",
    "    on='date_time',\n",
    "    by='batter', \n",
    "    direction='backward'\n",
    ")\n",
    "# Correct datetime (might be unnecessary, but I'm not sure which date_time it takes after the merge)\n",
    "complete_merged_df['date_time'] = complete_merged_df['date_time_copy'].copy()\n",
    "\n",
    "complete_merged_df = pd.merge_asof(\n",
    "    complete_merged_df,\n",
    "    steamer_pitchers_df2,\n",
    "    on='date_time',\n",
    "    by='pitcher',\n",
    "    direction='backward'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c062496f-1cb1-42d2-bc85-1a505271bcfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "455ace11-7229-4b30-bf8f-d39d3d778dc5",
   "metadata": {},
   "source": [
    "##### Impute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf31f9e-9599-42f5-a2fd-57cabeb86a21",
   "metadata": {},
   "source": [
    "For players with insufficient sample sizes, stats are imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e123af-6012-4391-b253-5d6aadd9d5c5",
   "metadata": {},
   "source": [
    "Option 1: Steamer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded33168-3847-4abb-b652-3ef67fa1bfb1",
   "metadata": {},
   "source": [
    "First, remove from dataset if ever missing FG/Steamer stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4dbca98-3a4a-4644-80ef-9d5623791ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df = complete_merged_df[~complete_merged_df['b1_rate'].isna()]\n",
    "complete_merged_df = complete_merged_df[~complete_merged_df['H9'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "500f4ca2-ffde-4601-90d1-44826dc538f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add hands to use in imputation\n",
    "batter_stats_fg_imp = batter_stats_fg + ['b_L', 'p_L', 'imp_b']\n",
    "pitcher_stats_fg_imp = pitcher_stats_fg + ['b_L', 'p_L', 'imp_p']\n",
    "\n",
    "### Batters\n",
    "# Use Steamer stats to predict API/Statcast stats for those with limited samples\n",
    "batter_predictions = impute_batter_stats.predict(complete_merged_df.loc[complete_merged_df['pa_b'] < 40, batter_stats_fg_imp])\n",
    "\n",
    "# Impute inputs with limited sample size with predicted values\n",
    "complete_merged_df.loc[complete_merged_df['pa_b'] < 40, batter_inputs] = batter_predictions\n",
    "\n",
    "### Pitchers\n",
    "# Use Steamer stats to predict API/Statcast stats for those with limited samples\n",
    "pitcher_predictions = impute_pitcher_stats.predict(complete_merged_df.loc[complete_merged_df['pa_p'] < 40, pitcher_stats_fg_imp])\n",
    "\n",
    "# Impute inputs with limited sample size with predicted values\n",
    "complete_merged_df.loc[complete_merged_df['pa_p'] < 40, pitcher_inputs] = pitcher_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95462618-9051-4892-a8ff-89c721fcfd94",
   "metadata": {},
   "source": [
    "Option 2: 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6348bdb-6a17-4c4f-9e5f-96ca3143a06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing instead of imputing, just weighting with 0s\n",
    "# complete_merged_df[batter_inputs].fillna(0, inplace=True)\n",
    "# complete_merged_df[pitcher_inputs].fillna(0, inplace=True)\n",
    "\n",
    "# # Calculate the weighted average for each column in pitcher_stats\n",
    "# # Could be simplified, but I wanted to show the steps\n",
    "# # Weighted average of provided value and 0. PAs and 50-PAs are weights. \n",
    "# for col in batter_inputs:\n",
    "#     complete_merged_df[col] = (complete_merged_df[col] * complete_merged_df['pa_b'] + 0 * (50-complete_merged_df['pa_b']))/50\n",
    "\n",
    "# # Calculate the weighted average for each column in pitcher_stats\n",
    "# for col in pitcher_inputs:\n",
    "#     complete_merged_df[col] = (complete_merged_df[col] * complete_merged_df['pa_p'] + 0 * (50-complete_merged_df['pa_p']))/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4efb4e-3b69-40eb-bf50-41ff56292730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7ddb37c-4952-4f64-8adf-2041ee2d1fb4",
   "metadata": {},
   "source": [
    "### Select Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477bd072-5b6a-4fd0-a1e8-a6684523b347",
   "metadata": {},
   "source": [
    "Drop early observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "918584cf-b36e-4562-82e5-2a5de3f107b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df = complete_merged_df[complete_merged_df['game_date'] > '2015-07-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb32714-d856-448e-9cdd-1bbfe7c27a04",
   "metadata": {},
   "source": [
    "Drop atypical events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69b16b03-1a40-4dd9-9ec4-f01c5e0519ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df = complete_merged_df.query('eventsModel != \"Cut\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e08a90-2b2d-467b-8445-1d8429866b83",
   "metadata": {},
   "source": [
    "Drop observations from inactive parks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec6c585d-7a56-41bc-a08d-eea21df321c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_parks = list(team_map['VENUE_ID'].astype(int))\n",
    "complete_merged_df = complete_merged_df[complete_merged_df['venue_id'].astype(int).isin(active_parks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1075d6-44d5-42da-9622-344e8ce69d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c61f585-8825-4702-8b0c-48d8a395de5f",
   "metadata": {},
   "source": [
    "### Select Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9267867c-3798-4f29-8c55-8425e942f8fe",
   "metadata": {},
   "source": [
    "Batter Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48181dc2-7050-4041-aefe-77645c773707",
   "metadata": {},
   "outputs": [],
   "source": [
    "batter_input_list = batter_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216a9dbe-e758-408d-a5b1-7b4cd3782758",
   "metadata": {},
   "source": [
    "Pitcher Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d2a8b7a-080a-468e-b283-4d3f9bef2139",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitcher_input_list = pitcher_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929c7484-1d2c-43db-9ee0-9b700b758633",
   "metadata": {},
   "source": [
    "Hand Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c22bf85-b8b3-4c1e-811b-556c358b45c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_input_list = ['p_L', 'b_L']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c86ab67-81de-41af-832f-850c14bd4044",
   "metadata": {},
   "source": [
    "Imputation Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da664722-d6ad-4f0a-b6ce-a54300a94abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_input_list = ['imp_b', 'imp_p']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e637a605-ffe1-49ec-88d5-a8cdc84aee25",
   "metadata": {},
   "source": [
    "Starter Input(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92d1b44d-1399-4c73-9450-58e5e1278276",
   "metadata": {},
   "outputs": [],
   "source": [
    "starter_input_list = ['starter']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5dcf16-f5d1-4c56-9ca1-041b754d3b76",
   "metadata": {},
   "source": [
    "Cumulative Inning Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2be619b5-4a50-40a5-b5ba-92d371347db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_inning_input_list = [col for col in complete_merged_df.columns if col.endswith(\"_inning\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "759dce85-6a13-468d-843a-4233436e2427",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_inning_input_list.remove('rbi_inning')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0302e663-9682-4a5f-91bd-6563ac42bdd3",
   "metadata": {},
   "source": [
    "Cumulative Game Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3efd012-4862-45ef-bb1d-c46c45543db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_game_input_list = [col for col in complete_merged_df.columns if col.endswith(\"_game\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38ed7fe9-eedf-4b17-b50f-b063ac0a55b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_game_input_list.remove('rbi_game')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795b4150-e93b-4dde-9d8b-2177c7db5a52",
   "metadata": {},
   "source": [
    "Game State Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67b42c6b-2ce7-4b1a-8927-3ab99ef7caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df['winning'] = (complete_merged_df['preBatterScore'] > complete_merged_df['prePitcherScore']).astype(int)\n",
    "complete_merged_df['winning_big'] = (complete_merged_df['preBatterScore'] > complete_merged_df['prePitcherScore'] + 3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21ca381f-774a-46f2-84ab-754ede6e5f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_state_input_list = ['onFirst', 'onSecond', 'onThird', 'top', 'score_diff', 'prePitcherScore', 'preBatterScore', 'winning', 'winning_big', 'times_faced']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb871ab-93d1-4713-bf5a-c5c054a6f1c5",
   "metadata": {},
   "source": [
    "Inning Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73d221d8-c785-470b-81ea-e76334285b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inning in range(1, 12):\n",
    "    complete_merged_df[f'inning_{inning}'] = (complete_merged_df['inning'] == inning).astype(int)\n",
    "complete_merged_df['inning_11'] = (complete_merged_df['inning'] >= 11).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1caca2a2-47c9-40a6-abe3-283bb51b6c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "inning_input_list = [col for col in complete_merged_df.columns if col.startswith(\"inning_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaf70fd-d3ae-42ec-8d5b-02fa6b5a9135",
   "metadata": {},
   "source": [
    "Out Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9afbd8f1-a5a8-4703-9990-e276f9042f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for out in range(0, 3):\n",
    "    complete_merged_df[f'outs_{out}'] = (complete_merged_df['outs_pre'] == out).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0572d99b-6624-4d63-92d1-8885b73f736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_input_list = ['outs_0', 'outs_1', 'outs_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddbe787-85e0-4159-b55b-7dbe08d24899",
   "metadata": {},
   "source": [
    "Venue Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d4eab78-befd-4a87-adab-552915e74d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df['venue_id2'] = complete_merged_df['venue_id'].copy()\n",
    "complete_merged_df = pd.get_dummies(complete_merged_df, columns=['venue_id2'], prefix='venue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e87917ec-f544-4827-96dc-8deeecdb6615",
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_input_list = [col for col in complete_merged_df.columns if col.startswith(\"venue_\") and col != \"venue_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a0747f-5b85-4e2b-a391-222c834c3639",
   "metadata": {},
   "source": [
    "Multiplier Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b011c2b-b0b7-446e-bc1f-a1893183bf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in events_list:\n",
    "    # Assign multiplier for their \n",
    "    complete_merged_df[f'{event}_wfx'] = np.where(complete_merged_df['batSide'] == \"L\", complete_merged_df[f'{event}_wfx_l'], complete_merged_df[f'{event}_wfx_r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60285c38-348b-49d2-aa90-6b5c51fe5373",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplier_input_list = [f'{event}_wfx' for event in events_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c29133-5a3e-4a82-ac93-d7a49182ad87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f946de9-493a-40aa-8a11-926160decb3b",
   "metadata": {},
   "source": [
    "Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c12560e1-a3cb-4610-aed7-6bd8fd47d1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = batter_input_list + pitcher_input_list + hand_input_list + imp_input_list + starter_input_list + cumulative_inning_input_list + cumulative_game_input_list + game_state_input_list + inning_input_list + out_input_list + venue_input_list + multiplier_input_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ae1244-6769-41fa-b3b1-aeb037aa18c1",
   "metadata": {},
   "source": [
    "Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4040fa4-7f6b-4fcc-9cdd-c57065d82892",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list = ['is_out', 'eventsModel']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf12dfcf-2b69-4202-9bc2-054d431a8d67",
   "metadata": {},
   "source": [
    "Other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "003a0bb2-68bf-443e-ad98-82c3ad9177bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_list = ['pa_b', 'pa_p', 'year', 'date', 'gamePk', 'atBatIndex', 'venue_id', 'batterName', 'pitcherName']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410f8287-fae2-4324-b9c5-67d617767ffd",
   "metadata": {},
   "source": [
    "Variables to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "27a1844b-13c4-48ab-ab0b-a78f8598cd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_list = input_list + output_list + additional_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df9800d-be37-4b56-974e-ba86ce53bb01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d888da0-e487-48a5-a96e-6c86bedb3e25",
   "metadata": {},
   "source": [
    "### Shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12c7c0b-594f-4eab-ba8f-2198056b444a",
   "metadata": {},
   "source": [
    "Many batter and pitcher stats are calculated at the end of the plate appearance. For prediction purposes, we need these stats coming into the plate appearance, so we need to shift."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065f102b-3eab-4989-b453-206579c60fb8",
   "metadata": {},
   "source": [
    "##### Batter Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fea2bb1-777e-4181-a2a0-16cb7363bdab",
   "metadata": {},
   "source": [
    "Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd38ce01-6e7a-4027-a2d6-01ba978c9aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89923df4-805a-46d8-9027-7372749d0156",
   "metadata": {},
   "source": [
    "Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "87c180e3-f30f-4667-a6e0-a65a6a009c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df[batter_inputs + ['ab_b', 'pa_b', 'imp_b']] = complete_merged_df.groupby(['batter', 'pitchHand'])[batter_inputs + ['ab_b', 'pa_b', 'imp_b']].shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541793ed-0b9d-4a69-9e81-adba638bb0ed",
   "metadata": {},
   "source": [
    "##### Pitcher Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699542c3-f47b-4047-8eed-f232c73f6111",
   "metadata": {},
   "source": [
    "Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d45cce5-c6b9-4def-a41e-55e20d8332ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6aa9bb-1868-460d-aad3-b90f9bcfd748",
   "metadata": {},
   "source": [
    "Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e722928f-a6c7-41e6-b13a-fa802f830b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df[pitcher_inputs + ['ab_p', 'pa_p', 'imp_p']] = complete_merged_df.groupby(['pitcher', 'batSide'])[pitcher_inputs + ['ab_p', 'pa_p', 'imp_p']].shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c92d5b-f855-4e06-90ec-11fda6da6c54",
   "metadata": {},
   "source": [
    "##### Inning Sums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3cec77-5d6d-40f4-9729-d36b1fb0b233",
   "metadata": {},
   "source": [
    "Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1d0c8db5-1a52-4940-949a-13812a7d5856",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0edfd47-fdcf-45e6-9a49-1accd4623585",
   "metadata": {},
   "source": [
    "Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e56a5edf-701c-4a1c-8cac-cb06d858fac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df[cumulative_inning_input_list] = complete_merged_df.groupby(['gamePk', 'inning', 'pitcher'])[cumulative_inning_input_list].shift(1)\n",
    "complete_merged_df[cumulative_inning_input_list] = complete_merged_df[cumulative_inning_input_list].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bd248a-dfae-4e01-8e99-5e787fde5c8b",
   "metadata": {},
   "source": [
    "##### Game Sums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe139353-6358-46bf-907a-8a9812b65b47",
   "metadata": {},
   "source": [
    "Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4d656f8a-0193-4ac7-8267-113bedc83b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6474bf-3cad-4af6-9a1f-e04604695852",
   "metadata": {},
   "source": [
    "Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "af0f3c32-7ccd-48a4-86f1-45a2600c118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df[cumulative_game_input_list + ['times_faced']] = complete_merged_df.groupby(['gamePk', 'pitcher'])[cumulative_game_input_list + ['times_faced']].shift(1)\n",
    "complete_merged_df[cumulative_game_input_list + ['times_faced']] = complete_merged_df[cumulative_game_input_list + ['times_faced']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd7acb7-4bdd-4092-9a15-600b61ccc9b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f104c96b-c139-4103-a7dd-d1099ccb6a88",
   "metadata": {},
   "source": [
    "### Model Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39046c78-6248-49e0-b2bd-2ff8e67c3993",
   "metadata": {},
   "source": [
    "Create Model Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "742b9d1f-25fe-4ae2-8144-d73a99d3d582",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset = complete_merged_df[keep_list]\n",
    "\n",
    "model_dataset.dropna(subset=input_list, inplace=True)\n",
    "model_dataset.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b04c8b-cda8-4cd7-8824-97a57d6c71aa",
   "metadata": {},
   "source": [
    "Free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "feb30e14-a7d8-4368-a39b-bca912c1d93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del complete_merged_df, complete_dataset, steamer_hitters_df, steamer_hitters_df2, steamer_pitchers_df, steamer_pitchers_df2, multiplier_df,  batter_predictions, pitcher_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5d1f221c-b6a6-41b8-b677-385dc1abf2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = len(input_list) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf781d0f-ba06-4dc8-a82b-157ad1fea64e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b97fce27-c7a7-4d62-86b2-264bf6ecbab1",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a55de2-d5b1-4083-ba23-64b8ecd7298e",
   "metadata": {},
   "source": [
    "Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "21610309-387e-4a06-ad4b-63111f5c67c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "model_dataset['split'] = np.random.choice([0, 0, 1], size=len(model_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3a448c-5411-49f5-ba87-105cc2d1ca6e",
   "metadata": {},
   "source": [
    "Create masks to identify training and testing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb19a8-50f9-447f-b390-f860d3886435",
   "metadata": {},
   "source": [
    "Note: to train on the entire dataset, you can simply set split = 0 for the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8fa442b2-c628-461b-8c47-550e35edba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_mask = (model_dataset['split'] == 0)\n",
    "out_mask = (model_dataset['is_out'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cd433f-5a8b-4253-887b-191c9cdbc1fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e1bdc14-c6e1-4df4-b61c-9da997fd7fad",
   "metadata": {},
   "source": [
    "### Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb7900e-55ed-4571-a7cc-7e3fb89df587",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_stat_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f859cf-016b-47f1-b12c-c9a9803ef899",
   "metadata": {},
   "source": [
    "##### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000b64d5-3060-479c-88f2-63f2bf665f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Neural network layers\n",
    "# layers = (5,)\n",
    "layers = (n1,4)\n",
    "# layers = (196,196,196,196,196,196)\n",
    "layers_str = ''.join(str(x) for x in layers)\n",
    "activation = 'relu'\n",
    "max_iter = 1000\n",
    "alpha = 0.0001\n",
    "learning_rate = 0.00001\n",
    "batch_size='auto'\n",
    "# batch_size=16\n",
    "random_state = random.randint(1,99999)\n",
    "print(random_state)\n",
    "num_models = 50\n",
    "cv = 1 # Unused\n",
    "n_jobs = -1\n",
    "\n",
    "binary_filename = f\"predict_binary_{layers_str}_{todaysdate}.sav\"\n",
    "print(binary_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad15993f-3836-40fe-99ad-46c3463e26bc",
   "metadata": {},
   "source": [
    "##### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4161eb20-5f88-4de2-9196-44fe6ec51bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(num_models):\n",
    "    # Set filename\n",
    "    binary_filename = f\"predict_binary_{layers_str}_{random_state+i}_{todaysdate}.sav\"   \n",
    "    print(binary_filename)\n",
    "    \n",
    "    # Create Model\n",
    "    predict_binary = MLPClassifier(hidden_layer_sizes=layers, activation=activation, verbose=False, alpha=alpha, learning_rate_init=learning_rate, early_stopping=True, random_state=random_state+i, max_iter=max_iter, batch_size=batch_size)\n",
    "\n",
    "    # Fit\n",
    "    predict_binary.fit(model_dataset[training_mask][input_list], model_dataset[training_mask][['is_out']].values.ravel())\n",
    "\n",
    "    # Save model\n",
    "    pickle.dump(predict_binary, open(os.path.join(model_path, \"M03. Plate Appearances\", binary_filename), 'wb'))\n",
    "\n",
    "    # Predict\n",
    "    all_outputs = list(predict_binary.classes_)\n",
    "    all_outputs_pred = [\"is_safe_pred\", \"is_out_pred\"]\n",
    "    \n",
    "    model_dataset.loc[~training_mask, all_outputs_pred] = predict_binary.predict_proba(model_dataset[~training_mask][input_list])\n",
    "\n",
    "    # Set quantiles\n",
    "    quantiles = 10\n",
    "    \n",
    "    # Create quantiles\n",
    "    for var in ['is_out']:    \n",
    "        # Create actual outcome column\n",
    "        model_dataset.loc[~training_mask, f'{var}_act'] = (model_dataset.loc[~training_mask, 'eventsModel'] == var).astype(int)\n",
    "    \n",
    "        # Create actual is_out value\n",
    "        if var == \"is_out\":\n",
    "            model_dataset.loc[~training_mask, f'{var}_act'] = model_dataset.loc[~training_mask, 'eventsModel'].isin(['so', 'lo', 'po', 'go', 'fo']).astype(int)\n",
    "        \n",
    "        # Create deciles\n",
    "        model_dataset.loc[~training_mask, f'{var}_quantile'] = pd.qcut(model_dataset.loc[~training_mask, f'{var}_pred'], quantiles, duplicates='drop', labels=False)\n",
    "        \n",
    "        # Create aggregated dataframe\n",
    "        globals()[f\"{var}_df\"] = model_dataset.loc[~training_mask].groupby(f'{var}_quantile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()\n",
    "        globals()[f\"{var}_year_df\"] = model_dataset.query('year >= 2024').loc[~training_mask].groupby(f'{var}_quantile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()\n",
    "        globals()[f\"{var}_venue_df\"] = model_dataset.query('venue_id == 19').loc[~training_mask].groupby(f'{var}_quantile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()\n",
    "\n",
    "    # Calculate stats\n",
    "    var = \"is_out\"\n",
    "    year = 2024\n",
    "    \n",
    "    # All\n",
    "    actual = model_dataset.loc[~training_mask][f'{var}_act'].mean()\n",
    "    predicted = model_dataset.loc[~training_mask][f'{var}_pred'].mean()\n",
    "    mult = actual/predicted\n",
    "    stdev = model_dataset.loc[~training_mask][f'{var}_pred'].std()\n",
    "    globals()[f\"{var}_df\"]['se'] = (globals()[f\"{var}_df\"][f'{var}_act'] - globals()[f\"{var}_df\"][f'{var}_pred']) ** 2\n",
    "    mse = globals()[f\"{var}_df\"]['se'].mean()\n",
    "    all_df = pd.DataFrame([\"All\", actual, predicted, mult, stdev, mse])\n",
    "    \n",
    "    # Year\n",
    "    actual = model_dataset.query(f'year >= {year}').loc[~training_mask][f'{var}_act'].mean()\n",
    "    predicted = model_dataset.query(f'year == {year}').loc[~training_mask][f'{var}_pred'].mean()\n",
    "    mult = actual/predicted\n",
    "    stdev = model_dataset.query(f'year == {year}').loc[~training_mask][f'{var}_pred'].std()\n",
    "    globals()[f\"{var}_year_df\"]['se'] = (globals()[f\"{var}_year_df\"][f'{var}_act'] - globals()[f\"{var}_year_df\"][f'{var}_pred']) ** 2\n",
    "    mse = globals()[f\"{var}_year_df\"]['se'].mean()\n",
    "    recent_df = pd.DataFrame([str(int(year)), actual, predicted, mult, stdev, mse])\n",
    "    \n",
    "    # DataFrame\n",
    "    binary_stat_df = pd.concat([all_df, recent_df], axis=1).T.reset_index(drop=True)\n",
    "    binary_stat_df.columns = ['Year', 'Actual', 'Predicted', \"Multiplier\", 'Std. Dev', 'MSE']\n",
    "    binary_stat_df['Layers'] = str(layers)\n",
    "    binary_stat_df['Models'] = num_models\n",
    "    binary_stat_df['State'] = random_state+i\n",
    "    binary_stat_df['File'] = binary_filename\n",
    "    binary_stat_df = binary_stat_df[['Year', 'File', 'Layers', 'Models', 'State', 'Actual', 'Predicted', \"Multiplier\", 'Std. Dev', 'MSE']]\n",
    "\n",
    "    print(binary_stat_df)\n",
    "    \n",
    "    # Create figure and 3 subplots (1 row, 3 columns)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4), sharey=True)\n",
    "    \n",
    "    var = \"is_out\"\n",
    "    \n",
    "    # List of dataframes to plot\n",
    "    df_list = [globals()[f\"{var}_df\"], globals()[f\"{var}_year_df\"], globals()[f\"{var}_venue_df\"]]\n",
    "    titles = [var, f\"{var} - Recent\", f\"{var} - Venue\"]\n",
    "    \n",
    "    # Loop through and plot each dataframe on separate axes\n",
    "    for ax, df, title in zip(axes, df_list, titles):\n",
    "        ax.plot(df[f'{var}_quantile'], df[f'{var}_act'], color='black', label=\"Actual\")\n",
    "        ax.plot(df[f'{var}_quantile'], df[f'{var}_pred'], color='red', label=\"Predicted\")\n",
    "        ax.set_title(title)\n",
    "        ax.legend()\n",
    "    \n",
    "    # Adjust layout\n",
    "    fig.tight_layout(pad=0.5)\n",
    "    \n",
    "    # Show figure\n",
    "    plt.show()\n",
    "    \n",
    "    binary_stat_list.append(binary_stat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39671823-de3f-4d70-ad5c-39d2f9c9e3ee",
   "metadata": {},
   "source": [
    "##### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133f0f17-e2da-4e18-8c53-677d3ddec6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_stats = pd.concat(binary_stat_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5950caf-8255-4b00-86bf-cfc4349da9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pareto_optimal(df, objectives, directions):\n",
    "    data = df[objectives].values\n",
    "    num_points = data.shape[0]\n",
    "\n",
    "    # Convert objectives based on direction\n",
    "    for i, direction in enumerate(directions):\n",
    "        if direction == \"Maximize\":\n",
    "            data[:, i] *= -1\n",
    "\n",
    "    # Pareto front mask\n",
    "    pareto_mask = np.ones(num_points, dtype=bool)\n",
    "\n",
    "    # Check for dominance\n",
    "    for i in range(num_points):\n",
    "        for j in range(num_points):\n",
    "            if i != j:\n",
    "                # Row j dominates row i if it's better in at least one objective and not worse in others\n",
    "                if np.all(data[j] <= data[i]) and np.any(data[j] < data[i]):\n",
    "                    pareto_mask[i] = False\n",
    "                    break\n",
    "\n",
    "    # Return the Pareto-optimal rows\n",
    "    return df[pareto_mask].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb39b654-cfc6-403d-ba64-e575973a9bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pareto_front = pareto_optimal(binary_stats.query(\"Year == '2024'\"), \n",
    "                              ['MSE', 'Std. Dev'], \n",
    "                              ['Minimize', 'Maximize'])\n",
    "pareto_front[(pareto_front['Multiplier'] < 1.001) & (pareto_front['Multiplier'] > 0.999)].sort_values('Std. Dev')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b156f076-48e7-4e99-b004-c2a218541acc",
   "metadata": {},
   "source": [
    "##### Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036dbe53-aa12-4c29-b89f-64705c2d9cda",
   "metadata": {},
   "source": [
    "##### Select Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292902f7-100a-438e-b830-4e811e64ff94",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_binary_filename_list = [\n",
    "                                 \"predict_binary_3901954_3573_20250226.sav\",\n",
    "                                 \"predict_binary_3901954_3575_20250226.sav\"\n",
    "                                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8dfd3b-838d-476d-8bca-6127106a23f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load models from the file paths\n",
    "models = [(filename.split('.')[0], pickle.load(open(os.path.join(model_path, \"M03. Plate Appearances\", filename), 'rb')))\n",
    "          for filename in selected_binary_filename_list]\n",
    "\n",
    "# Create the VotingClassifier\n",
    "predict_binary_voting = VotingClassifier(\n",
    "    estimators=models,\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Fit the VotingClassifier on the entire training set\n",
    "predict_binary_voting.fit(model_dataset[training_mask][input_list], model_dataset[training_mask]['is_out'])\n",
    "\n",
    "binary_voting_filename = f\"predict_binary_voting_{layers_str}_{todaysdate}.sav\"   \n",
    "print(binary_voting_filename)\n",
    "# Save model\n",
    "pickle.dump(predict_binary_voting, open(os.path.join(model_path, \"M03. Plate Appearances\", binary_voting_filename), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d044fa-7ad8-408d-afa3-557e912d9448",
   "metadata": {},
   "source": [
    "##### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b54698-3ab2-4550-ac93-d9d9f58b162f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outputs = list(predict_binary.classes_)\n",
    "all_outputs_pred = [\"is_safe_pred\", \"is_out_pred\"]\n",
    "\n",
    "model_dataset.loc[~training_mask, all_outputs_pred] = predict_binary_voting.predict_proba(model_dataset[~training_mask][input_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28da951a-3ce6-4017-95b1-467be8b2f21e",
   "metadata": {},
   "source": [
    "##### Quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f2d7d5-e962-4184-8ec3-f19ca8650b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set quantiles\n",
    "quantiles = 10\n",
    "\n",
    "# Create quantiles\n",
    "for var in ['is_out']:    \n",
    "    # Create actual outcome column\n",
    "    model_dataset.loc[~training_mask, f'{var}_act'] = (model_dataset.loc[~training_mask, 'eventsModel'] == var).astype(int)\n",
    "\n",
    "    # Create actual is_out value\n",
    "    if var == \"is_out\":\n",
    "        model_dataset.loc[~training_mask, f'{var}_act'] = model_dataset.loc[~training_mask, 'eventsModel'].isin(['so', 'lo', 'po', 'go', 'fo']).astype(int)\n",
    "    \n",
    "    # Create deciles\n",
    "    model_dataset.loc[~training_mask, f'{var}_quantile'] = pd.qcut(model_dataset.loc[~training_mask, f'{var}_pred'], quantiles, labels=False)\n",
    "    \n",
    "    # Create aggregated dataframe\n",
    "    globals()[f\"{var}_df\"] = model_dataset.loc[~training_mask].groupby(f'{var}_quantile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()\n",
    "    globals()[f\"{var}_year_df\"] = model_dataset.query('year >= 2024').loc[~training_mask].groupby(f'{var}_quantile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()\n",
    "    globals()[f\"{var}_venue_df\"] = model_dataset.query('venue_id == 19').loc[~training_mask].groupby(f'{var}_quantile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb134231-b11e-437f-bf82-391d282eb4c4",
   "metadata": {},
   "source": [
    "##### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1857e3b0-8053-4498-8a84-6f7f0a7d61c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and 3 subplots (1 row, 3 columns)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4), sharey=True)\n",
    "\n",
    "var = \"is_out\"\n",
    "\n",
    "# List of dataframes to plot\n",
    "df_list = [globals()[f\"{var}_df\"], globals()[f\"{var}_year_df\"], globals()[f\"{var}_venue_df\"]]\n",
    "titles = [var, f\"{var} - Recent\", f\"{var} - Venue\"]\n",
    "\n",
    "# Loop through and plot each dataframe on separate axes\n",
    "for ax, df, title in zip(axes, df_list, titles):\n",
    "    ax.plot(df[f'{var}_quantile'], df[f'{var}_act'], color='black', label=\"Actual\")\n",
    "    ax.plot(df[f'{var}_quantile'], df[f'{var}_pred'], color='red', label=\"Predicted\")\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "\n",
    "# Adjust layout\n",
    "fig.tight_layout(pad=0.5)\n",
    "\n",
    "# Show figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aabc37-f721-45d2-8c01-812b244e973d",
   "metadata": {},
   "source": [
    "##### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c47d48-4770-4e29-b2b5-aaf3fcc3cee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"is_out\"\n",
    "year = 2024\n",
    "\n",
    "# All\n",
    "actual = model_dataset.loc[~training_mask][f'{var}_act'].mean()\n",
    "predicted = model_dataset.loc[~training_mask][f'{var}_pred'].mean()\n",
    "mult = actual/predicted\n",
    "stdev = model_dataset.loc[~training_mask][f'{var}_pred'].std()\n",
    "# globals()[f\"{var}_df\"] = model_dataset.loc[~training_mask].groupby(f'{var}_quantile')[[f'{var}_act', f'{var}_pred']].mean().reset_index() # graphing all, delete these\n",
    "globals()[f\"{var}_df\"]['se'] = (globals()[f\"{var}_df\"][f'{var}_act'] - globals()[f\"{var}_df\"][f'{var}_pred']) ** 2\n",
    "mse = globals()[f\"{var}_df\"]['se'].mean()\n",
    "all_df = pd.DataFrame([\"All\", actual, predicted, mult, stdev, mse])\n",
    "\n",
    "# Year\n",
    "actual = model_dataset.query(f'year >= {year}').loc[~training_mask][f'{var}_act'].mean()\n",
    "predicted = model_dataset.query(f'year == {year}').loc[~training_mask][f'{var}_pred'].mean()\n",
    "mult = actual/predicted\n",
    "stdev = model_dataset.query(f'year == {year}').loc[~training_mask][f'{var}_pred'].std()\n",
    "# globals()[f\"{var}_year_df\"] = model_dataset.query('year >= 2024').loc[~training_mask].groupby(f'{var}_quantile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()\n",
    "globals()[f\"{var}_year_df\"]['se'] = (globals()[f\"{var}_year_df\"][f'{var}_act'] - globals()[f\"{var}_year_df\"][f'{var}_pred']) ** 2\n",
    "mse = globals()[f\"{var}_year_df\"]['se'].mean()\n",
    "recent_df = pd.DataFrame([str(int(year)), actual, predicted, mult, stdev, mse])\n",
    "\n",
    "# DataFrame\n",
    "binary_stat_df = pd.concat([all_df, recent_df], axis=1).T.reset_index(drop=True)\n",
    "binary_stat_df.columns = ['Year', 'Actual', 'Predicted', \"Multiplier\", 'Std. Dev', 'MSE']\n",
    "binary_stat_df['Layers'] = str(layers)\n",
    "binary_stat_df['Models'] = num_models\n",
    "binary_stat_df['State'] = random_state\n",
    "binary_stat_df[['Year', 'Layers', 'Models', 'State', 'Actual', 'Predicted', \"Multiplier\", 'Std. Dev', 'MSE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2754fd9-572b-4f0e-97c8-92426312f875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "caa558fa-b15f-4bb9-85dc-e5f14391b25e",
   "metadata": {},
   "source": [
    "### Outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ef4b6c-346c-48fa-8ed8-682c53be38a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_stat_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ea99ea-7251-4d92-8d69-e9291ba5c1dd",
   "metadata": {},
   "source": [
    "##### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4b30e2-ef0f-4d9c-b2b1-036ba9e50fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Neural network layers\n",
    "# layers = (n1,n1)\n",
    "layers = (10,)\n",
    "# layers = (196,196,196,196,196,196)\n",
    "layers_str = ''.join(str(x) for x in layers)\n",
    "activation = 'relu'\n",
    "max_iter = 1000\n",
    "alpha = 0.0001\n",
    "learning_rate = 0.00001\n",
    "batch_size='auto'\n",
    "random_state = random.randint(1,99999)\n",
    "print(random_state)\n",
    "num_models = 5\n",
    "cv = 1 # Unused\n",
    "n_jobs = -1\n",
    "\n",
    "outs_filename = f\"predict_outs_{layers_str}_{todaysdate}.sav\"\n",
    "print(outs_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d8796e-67fa-4a6a-a0e9-9d4a5d9b8c88",
   "metadata": {},
   "source": [
    "##### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7547afd-81af-4f2d-b0bc-0c84c68f12e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(num_models):\n",
    "    # Set filename\n",
    "    outs_filename = f\"predict_outs_{layers_str}_{random_state+i}_{todaysdate}.sav\"\n",
    "    print(outs_filename)\n",
    "\n",
    "    # Create Model\n",
    "    predict_outs = MLPClassifier(hidden_layer_sizes=layers, activation=activation, verbose=False, alpha=alpha, learning_rate_init=learning_rate, early_stopping=True, random_state=random_state+i, max_iter=max_iter, batch_size=batch_size)\n",
    "\n",
    "    # Fit\n",
    "    predict_outs.fit(model_dataset[training_mask][out_mask][input_list], model_dataset[training_mask][out_mask][['eventsModel']].values.ravel())\n",
    "\n",
    "    # Save model\n",
    "    pickle.dump(predict_outs, open(os.path.join(model_path, \"M03. Plate Appearances\", outs_filename), 'wb'))\n",
    "\n",
    "    # Predict out types\n",
    "    outs_outputs = list(predict_outs.classes_)\n",
    "    outs_outputs_pred = [x + \"_pred\" for x in outs_outputs]\n",
    "    \n",
    "    model_dataset.loc[~training_mask & out_mask, outs_outputs_pred] = predict_outs.predict_proba(model_dataset[~training_mask][out_mask][input_list])\n",
    "\n",
    "    # FP\n",
    "    model_dataset.loc[~training_mask & out_mask, 'FP_act'] = (\n",
    "        (model_dataset.loc[~training_mask & out_mask, 'eventsModel'] == \"fo\").astype(int) * 0.2534 +\n",
    "        (model_dataset.loc[~training_mask & out_mask, 'eventsModel'] == \"go\").astype(int) * 0.2534 +\n",
    "        (model_dataset.loc[~training_mask & out_mask, 'eventsModel'] == \"po\").astype(int) * 0.2534 +\n",
    "        (model_dataset.loc[~training_mask & out_mask, 'eventsModel'] == \"lo\").astype(int) * 0.2534 +\n",
    "        (model_dataset.loc[~training_mask & out_mask, 'eventsModel'] == \"so\").astype(int) * 2.4866\n",
    "    )\n",
    "\n",
    "    model_dataset.loc[~training_mask & out_mask, 'FP_pred'] = (model_dataset[~training_mask][out_mask]['fo_pred'] * 0.2534 +\n",
    "                                                               model_dataset[~training_mask][out_mask]['go_pred'] * 0.2534 +\n",
    "                                                               model_dataset[~training_mask][out_mask]['po_pred'] * 0.2534 + \n",
    "                                                               model_dataset[~training_mask][out_mask]['lo_pred'] * 0.2534 +\n",
    "                                                               model_dataset[~training_mask][out_mask]['so_pred'] * 2.4866)\n",
    "                                        \n",
    "    # Quantiles\n",
    "    year = 2022\n",
    "    venue = 19\n",
    "    \n",
    "    for var in outs_outputs:\n",
    "        # Create actual outcome column\n",
    "        model_dataset.loc[~training_mask & out_mask, f'{var}_act'] = (model_dataset.loc[~training_mask & out_mask, 'eventsModel'] == var).astype(int)\n",
    "        \n",
    "        # Create deciles\n",
    "        model_dataset.loc[~training_mask & out_mask, f'{var}_decile'] = pd.qcut(model_dataset.loc[~training_mask & out_mask, f'{var}_pred'], 10, labels=False)\n",
    "        \n",
    "        # Create aggregated dataframe\n",
    "        globals()[f\"{var}_df\"] = model_dataset.loc[~training_mask & out_mask].groupby(f'{var}_decile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()\n",
    "        globals()[f\"{var}_year_df\"] = model_dataset.query(f'year >= {year}').loc[~training_mask & out_mask].groupby(f'{var}_decile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()\n",
    "        globals()[f\"{var}_venue_df\"] = model_dataset.query(f'venue_id == {venue}').loc[~training_mask & out_mask].groupby(f'{var}_decile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()\n",
    "    \n",
    "    for var in ['FP']:\n",
    "        # # Create actual outcome column\n",
    "        # model_dataset.loc[~training_mask & out_mask, f'{var}_act'] = (model_dataset.loc[~training_mask & out_mask, 'eventsModel'] == var).astype(int)\n",
    "        \n",
    "        # Create deciles\n",
    "        model_dataset.loc[~training_mask & out_mask, f'{var}_decile'] = pd.qcut(model_dataset.loc[~training_mask & out_mask, f'{var}_pred'], 10, labels=False)\n",
    "        \n",
    "        # Create aggregated dataframe\n",
    "        globals()[f\"{var}_df\"] = model_dataset.loc[~training_mask & out_mask].groupby(f'{var}_decile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()\n",
    "        globals()[f\"{var}_year_df\"] = model_dataset.query(f'year >= {year}').loc[~training_mask & out_mask].groupby(f'{var}_decile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()\n",
    "        globals()[f\"{var}_venue_df\"] = model_dataset.query(f'venue_id == {venue}').loc[~training_mask & out_mask].groupby(f'{var}_decile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()\n",
    "\n",
    "    # All\n",
    "    all_df_list = []\n",
    "    for var in outs_outputs + ['FP']:\n",
    "        actual = model_dataset.loc[~training_mask & out_mask][f'{var}_act'].mean()\n",
    "        predicted = model_dataset.loc[~training_mask & out_mask][f'{var}_pred'].mean()\n",
    "        mult = actual/predicted\n",
    "        stdev = model_dataset.loc[~training_mask & out_mask][f'{var}_pred'].std()\n",
    "        globals()[f\"{var}_df\"]['se'] = (globals()[f\"{var}_df\"][f'{var}_act'] - globals()[f\"{var}_df\"][f'{var}_pred']) ** 2\n",
    "        mse = globals()[f\"{var}_df\"]['se'].mean()\n",
    "        all_df = pd.DataFrame([\"All\", var, actual, predicted, mult, stdev, mse])\n",
    "        all_df_list.append(all_df)\n",
    "    \n",
    "    all_dfs = pd.concat(all_df_list, axis=1).T\n",
    "    \n",
    "    # Year\n",
    "    recent_df_list = []\n",
    "    for var in outs_outputs + ['FP']:\n",
    "        actual = model_dataset.query(f'year >= {year}').loc[~training_mask & out_mask][f'{var}_act'].mean()\n",
    "        predicted = model_dataset.query(f'year == {year}').loc[~training_mask & out_mask][f'{var}_pred'].mean()\n",
    "        mult = actual/predicted\n",
    "        stdev = model_dataset.query(f'year == {year}').loc[~training_mask & out_mask][f'{var}_pred'].std()\n",
    "        globals()[f\"{var}_year_df\"]['se'] = (globals()[f\"{var}_year_df\"][f'{var}_act'] - globals()[f\"{var}_year_df\"][f'{var}_pred']) ** 2\n",
    "        mse = globals()[f\"{var}_year_df\"]['se'].mean()\n",
    "        recent_df = pd.DataFrame([str(int(year)), var, actual, predicted, mult, stdev, mse])\n",
    "        recent_df_list.append(recent_df)\n",
    "    \n",
    "    recent_dfs = pd.concat(recent_df_list, axis=1).T\n",
    "    \n",
    "    # DataFrame\n",
    "    out_stat_df = pd.concat([all_dfs, recent_dfs], axis=0).reset_index(drop=True)\n",
    "    out_stat_df.columns = ['Year', 'Output', 'Actual', 'Predicted', \"Multiplier\", 'Std. Dev', 'MSE']\n",
    "    out_stat_df['File'] = outs_filename\n",
    "    out_stat_df['Layers'] = str(layers)\n",
    "    out_stat_df['Models'] = num_models\n",
    "    out_stat_df['State'] = random_state+i\n",
    "    out_stat_df[['Year', 'File', 'Layers', 'Models', 'State', 'Output', 'Actual', 'Predicted', \"Multiplier\", 'Std. Dev', 'MSE']]\n",
    "\n",
    "    print(out_stat_df)\n",
    "    \n",
    "    out_stat_list.append(out_stat_df)\n",
    "    \n",
    "    graph_options = [\"\", \"_year\", \"_venue\"]\n",
    "    graph_index = 0\n",
    "    graph = graph_options[graph_index]\n",
    "    print(f\"Graphing {graph}\")\n",
    "    \n",
    "    # Create figures\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "    \n",
    "    for i, var in enumerate(outs_outputs + ['FP']):\n",
    "        row = i // 3  # Calculate the row index based on the iteration\n",
    "        col = i % 3   # Calculate the column index based on the iteration\n",
    "        axs[row, col].plot(globals()[f\"{var}{graph}_df\"][f'{var}_decile'], globals()[f\"{var}{graph}_df\"][f'{var}_pred'], color='red')\n",
    "        axs[row, col].plot(globals()[f\"{var}{graph}_df\"][f'{var}_decile'], globals()[f\"{var}{graph}_df\"][f'{var}_act'], color='black')\n",
    "        axs[row, col].set_title(var)\n",
    "        # axs[row, col].set_ylim(0,0.35)\n",
    "    \n",
    "    \n",
    "    # Add some space between subplots to prevent overlapping\n",
    "    fig.tight_layout(pad=.0)\n",
    "    \n",
    "    # Show the figure\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382075be-e768-471e-988d-916199eddb3b",
   "metadata": {},
   "source": [
    "##### Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e12764-1bf6-47eb-bb14-8fbe3c488035",
   "metadata": {},
   "source": [
    "Create evaluations dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8201884-31da-442b-bab0-54e272b9f6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_out_stat_df = pd.concat(out_stat_list)\n",
    "all_out_stat_df = all_out_stat_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a211b304-6e63-47e7-87f3-2c56999727c5",
   "metadata": {},
   "source": [
    "Identify pareto-optimal models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2126d9-b90b-4f80-8caf-4fc3c1145bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = all_out_stat_df.query('Year == \"2022\"').query('Output == \"FP\"').reset_index(drop=True)\n",
    "pareto_front = pareto_optimal(subset, ['MSE', 'Std. Dev'], ['Minimize', 'Maximize']).sort_values('Std. Dev')\n",
    "pareto_front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1464e8d9-3790-4de2-9f01-1666046e889b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cb1ec3d-e0f7-4595-8d04-539add4edd04",
   "metadata": {},
   "source": [
    "### Safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4b0631a7-b565-415d-af04-6626cebe2225",
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_stat_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97ae434-ccee-4204-a913-047f9a279ac9",
   "metadata": {},
   "source": [
    "##### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09a2cdc-9115-4466-bb3b-b49be7a160e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# layers = (10,)\n",
    "layers = (390,n1,5)\n",
    "layers_str = ''.join(str(x) for x in layers)\n",
    "activation = 'relu'\n",
    "max_iter = 100\n",
    "alpha = 0.0001\n",
    "learning_rate = 0.00001\n",
    "batch_size=8\n",
    "random_state = random.randint(1,99999)\n",
    "print(random_state)\n",
    "# random_state = 95835\n",
    "num_models = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f0d2d4-0eee-4e24-afd0-2693f75b7e15",
   "metadata": {},
   "source": [
    "##### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87853b89-0ce5-470d-9a96-b21b365e4a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(num_models):\n",
    "    # Set filename\n",
    "    safe_filename = f\"predict_safe_{layers_str}_{random_state+i}_{todaysdate}.sav\"\n",
    "    print(safe_filename)\n",
    "\n",
    "    # Create Model\n",
    "    predict_safe = MLPClassifier(hidden_layer_sizes=layers, activation=activation, verbose=False, alpha=alpha, learning_rate_init=learning_rate, \n",
    "                                 early_stopping=True, random_state=random_state+i, max_iter=max_iter, batch_size=batch_size)\n",
    "\n",
    "    # Fit\n",
    "    predict_safe.fit(model_dataset[training_mask][~out_mask][input_list], model_dataset[training_mask][~out_mask][['eventsModel']].values.ravel())\n",
    "\n",
    "    # Save model\n",
    "    pickle.dump(predict_safe, open(os.path.join(model_path, \"M03. Plate Appearances\", safe_filename), 'wb'))\n",
    "\n",
    "    # Predict \n",
    "    safe_outputs_pred = [x + \"_pred\" for x in safe_outputs]\n",
    "    \n",
    "    model_dataset.loc[~training_mask & ~out_mask, safe_outputs_pred] = predict_safe.predict_proba(model_dataset[~training_mask][~out_mask][input_list])\n",
    "\n",
    "    # FP\n",
    "    model_dataset.loc[~training_mask & ~out_mask, 'FP_act'] = (\n",
    "        (model_dataset.loc[~training_mask & ~out_mask, 'eventsModel'] == \"b1\").astype(int)  *  4.3665 +\n",
    "        (model_dataset.loc[~training_mask & ~out_mask, 'eventsModel'] == \"b2\").astype(int)  *  6.8271 +\n",
    "        (model_dataset.loc[~training_mask & ~out_mask, 'eventsModel'] == \"b3\").astype(int)  * 10.8503 +\n",
    "        (model_dataset.loc[~training_mask & ~out_mask, 'eventsModel'] == \"hr\").astype(int)  * 15.2611 +\n",
    "        (model_dataset.loc[~training_mask & ~out_mask, 'eventsModel'] == \"bb\").astype(int)  *  2.8725 +\n",
    "        (model_dataset.loc[~training_mask & ~out_mask, 'eventsModel'] == \"hbp\").astype(int) *  2.9639\n",
    "        )\n",
    "\n",
    "    model_dataset.loc[~training_mask & out_mask, 'FP_pred'] = (model_dataset[~training_mask][~out_mask]['b1_pred']  *  4.3665 +\n",
    "                                                               model_dataset[~training_mask][~out_mask]['b2_pred']  *  6.8271 +\n",
    "                                                               model_dataset[~training_mask][~out_mask]['b3_pred']  * 10.8503 + \n",
    "                                                               model_dataset[~training_mask][~out_mask]['hr_pred']  * 15.2611 +\n",
    "                                                               model_dataset[~training_mask][~out_mask]['bb_pred']  *  2.872 +\n",
    "                                                               model_dataset[~training_mask][~out_mask]['hbp_pred'] *  2.9639\n",
    "                                                              )\n",
    "\n",
    "    # Quantiles\n",
    "    year = 2022\n",
    "    venue = 19\n",
    "    \n",
    "    for var in safe_outputs:\n",
    "        # Create actual outcome column\n",
    "        model_dataset.loc[~training_mask & ~out_mask, f'{var}_act'] = (model_dataset.loc[~training_mask & ~out_mask, 'eventsModel'] == var).astype(int)\n",
    "        \n",
    "        # Create deciles\n",
    "        model_dataset.loc[~training_mask & ~out_mask, f'{var}_decile'] = pd.qcut(model_dataset.loc[~training_mask & ~out_mask, f'{var}_pred'], 10, labels=False, duplicates='drop')\n",
    "        \n",
    "        # Create aggregated dataframe\n",
    "        globals()[f\"{var}_df\"] = model_dataset.loc[~training_mask & ~out_mask].groupby(f'{var}_decile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()\n",
    "        globals()[f\"{var}_year_df\"] = model_dataset.query(f'year >= {year}').loc[~training_mask & ~out_mask].groupby(f'{var}_decile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()\n",
    "        globals()[f\"{var}_venue_df\"] = model_dataset.query(f'venue_id == {venue}').loc[~training_mask & ~out_mask].groupby(f'{var}_decile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()\n",
    "    \n",
    "    for var in ['FP']:\n",
    "        # Create deciles\n",
    "        model_dataset.loc[~training_mask & ~out_mask, f'{var}_decile'] = pd.qcut(model_dataset.loc[~training_mask & ~out_mask, f'{var}_pred'], 10, labels=False)\n",
    "        \n",
    "        # Create aggregated dataframe\n",
    "        globals()[f\"{var}_df\"] = model_dataset.loc[~training_mask & ~out_mask].groupby(f'{var}_decile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()\n",
    "        globals()[f\"{var}_year_df\"] = model_dataset.query(f'year >= {year}').loc[~training_mask & ~out_mask].groupby(f'{var}_decile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()\n",
    "        globals()[f\"{var}_venue_df\"] = model_dataset.query(f'venue_id == {venue}').loc[~training_mask & ~out_mask].groupby(f'{var}_decile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()\n",
    "\n",
    "    # All\n",
    "    all_df_list = []\n",
    "    for var in safe_outputs + ['FP']:\n",
    "        actual = model_dataset.loc[~training_mask & ~out_mask][f'{var}_act'].mean()\n",
    "        predicted = model_dataset.loc[~training_mask & ~out_mask][f'{var}_pred'].mean()\n",
    "        mult = actual/predicted\n",
    "        stdev = model_dataset.loc[~training_mask & ~out_mask][f'{var}_pred'].std()\n",
    "        globals()[f\"{var}_df\"]['se'] = (globals()[f\"{var}_df\"][f'{var}_act'] - globals()[f\"{var}_df\"][f'{var}_pred']) ** 2\n",
    "        mse = globals()[f\"{var}_df\"]['se'].mean()\n",
    "        all_df = pd.DataFrame([\"All\", var, actual, predicted, mult, stdev, mse])\n",
    "        all_df_list.append(all_df)\n",
    "    \n",
    "    all_dfs = pd.concat(all_df_list, axis=1).T\n",
    "    \n",
    "    # Year\n",
    "    recent_df_list = []\n",
    "    for var in safe_outputs + ['FP']:\n",
    "        actual = model_dataset.query(f'year >= {year}').loc[~training_mask & ~out_mask][f'{var}_act'].mean()\n",
    "        predicted = model_dataset.query(f'year == {year}').loc[~training_mask & ~out_mask][f'{var}_pred'].mean()\n",
    "        mult = actual/predicted\n",
    "        stdev = model_dataset.query(f'year == {year}').loc[~training_mask & ~out_mask][f'{var}_pred'].std()\n",
    "        globals()[f\"{var}_year_df\"]['se'] = (globals()[f\"{var}_year_df\"][f'{var}_act'] - globals()[f\"{var}_year_df\"][f'{var}_pred']) ** 2\n",
    "        mse = globals()[f\"{var}_year_df\"]['se'].mean()\n",
    "        recent_df = pd.DataFrame([str(int(year)), var, actual, predicted, mult, stdev, mse])\n",
    "        recent_df_list.append(recent_df)\n",
    "    \n",
    "    recent_dfs = pd.concat(recent_df_list, axis=1).T\n",
    "    \n",
    "    # DataFrame\n",
    "    safe_stat_df = pd.concat([all_dfs, recent_dfs], axis=0).reset_index(drop=True)\n",
    "    safe_stat_df.columns = ['Year', 'Output', 'Actual', 'Predicted', \"Multiplier\", 'Std. Dev', 'MSE']\n",
    "    safe_stat_df['File'] = safe_filename\n",
    "    safe_stat_df['Layers'] = str(layers)\n",
    "    safe_stat_df['Models'] = num_models\n",
    "    safe_stat_df['State'] = random_state+i\n",
    "    safe_stat_df[['Year', 'File', 'Layers', 'Models', 'State', 'Output', 'Actual', 'Predicted', \"Multiplier\", 'Std. Dev', 'MSE']]\n",
    "\n",
    "    print(safe_stat_df)\n",
    "    \n",
    "    safe_stat_list.append(safe_stat_df)\n",
    "    \n",
    "    graph_options = [\"\", \"_year\", \"_venue\"]\n",
    "    graph_index = 1\n",
    "    graph = graph_options[graph_index]\n",
    "    print(f\"Graphing {graph}\")\n",
    "    \n",
    "    # Create figures\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(12, 12))\n",
    "    \n",
    "    for i, var in enumerate(safe_outputs + ['FP']):\n",
    "        row = i // 3  # Calculate the row index based on the iteration\n",
    "        col = i % 3   # Calculate the column index based on the iteration\n",
    "        axs[row, col].plot(globals()[f\"{var}{graph}_df\"][f'{var}_decile'], globals()[f\"{var}{graph}_df\"][f'{var}_pred'], color='red')\n",
    "        axs[row, col].plot(globals()[f\"{var}{graph}_df\"][f'{var}_decile'], globals()[f\"{var}{graph}_df\"][f'{var}_act'], color='black')\n",
    "        axs[row, col].set_title(var)\n",
    "        # axs[row, col].set_ylim(0,0.35)\n",
    "    \n",
    "    \n",
    "    # Add some space between subplots to prevent overlapping\n",
    "    fig.tight_layout(pad=.0)\n",
    "    \n",
    "    # Show the figure\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785529b1-1903-46ce-8e8e-903bd30c8301",
   "metadata": {},
   "source": [
    "##### Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2a2e14-70fc-466d-b529-c793ac994157",
   "metadata": {},
   "source": [
    "Create evaluations dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483ae167-c0f6-47a1-abe5-0e2293b6e661",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_safe_stat_df = pd.concat(safe_stat_list)\n",
    "all_safe_stat_df = all_safe_stat_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb1fbdb-5796-48ae-8d3f-2608bbd420ae",
   "metadata": {},
   "source": [
    "Identify pareto-optimal models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462345ec-9451-49ca-8459-01e2f0d6cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = all_safe_stat_df.query('Year == \"2022\"').query('Output == \"FP\"').query('1.02 > Multiplier > 0.98').reset_index(drop=True)\n",
    "pareto_front = pareto_optimal(subset, ['MSE', 'Std. Dev'], ['Minimize', 'Maximize']).sort_values('Std. Dev')\n",
    "pareto_front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eaeb86-415b-46ce-99e1-0d3989de2064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
