{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1b293f6-25db-4a7c-9bb0-b78be505d361",
   "metadata": {},
   "source": [
    "# A06. Weather "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d66c3d1-2a3f-4bc4-a77a-728a13dbbe93",
   "metadata": {},
   "source": [
    "Note: All historic Park and Weather Factors files are created from M01. Park and Weatehr Factors.ipynb upon the training of new models. A06. Weather is for daily files only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c6434d-8aa6-41c3-8b2c-5b9ef6075145",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b0b771-8bc9-4f75-9daf-1316bd2b5f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 models into ensemble\n",
      "Imports executed\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if not hasattr(sys.modules['__main__'], '__file__'):\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U1. Imports.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U2. Functions.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U3. Classes.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U4. Datasets.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U5. Models.ipynb\"\n",
    "    print(\"Imports executed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f93710-16ec-421a-a2f5-b31fec6633de",
   "metadata": {},
   "source": [
    "### Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c011b295-fa27-4240-a02d-536a5a9114d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not hasattr(sys.modules['__main__'], '__file__'):\n",
    "    # Set date range \n",
    "    start_date = '20250528'\n",
    "    end_date = '20250528'\n",
    "    all_game_df = pd.read_csv(os.path.join(baseball_path, \"game_df.csv\"))\n",
    "    game_df = all_game_df[(all_game_df['date'].astype(str) >= start_date) & (all_game_df['date'].astype(str) <= end_date)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47f8e18-6292-4ac4-848a-5da53a9ef2d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb1b8a7a-e097-4905-9618-822f2417730c",
   "metadata": {},
   "source": [
    "### Venue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0e57d2-1c5e-4271-8810-b8e353b881cb",
   "metadata": {},
   "source": [
    "Merge in venue-specific data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eff19019-9e4e-4bba-a294-47e88425caa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df = pd.merge(game_df, venue_map_df[['id', 'location.defaultCoordinates.latitude', 'location.defaultCoordinates.longitude',\n",
    "                                          'fieldInfo.leftLine', 'fieldInfo.center', 'fieldInfo.rightLine', 'fieldInfo.leftCenter', 'fieldInfo.rightCenter', \n",
    "                                          'location.elevation', 'location.azimuthAngle', 'fieldInfo.roofType', 'active']], \n",
    "                                           left_on=['venue_id'], right_on=['id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ba6392-d79b-4502-a8d0-67bca7753d64",
   "metadata": {},
   "source": [
    "Convert to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc5915f7-a077-4e08-be6f-2d3ed73e3ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df[\"game_datetime\"] = pd.to_datetime(game_df[\"game_datetime\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd5d88f-6c22-4ef1-94cd-a0ebdb753ed5",
   "metadata": {},
   "source": [
    "Drop if missing coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ea13794-cc82-4412-af64-0c80c469fc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df.dropna(subset=['location.defaultCoordinates.latitude', 'location.defaultCoordinates.longitude'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442729a4-42a8-4d6e-b8e5-085a869c7abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2994902-4534-4e19-a8ee-9a7425e42b90",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82db4ae-9635-4cbb-b97f-533995dcedf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_games = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94a0c75-050a-4472-b664-2f81f1a4f8aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3c503c7-9876-416a-8fda-3c7014283079",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cc3cc7-2984-46e4-b4dc-30d4c0344b59",
   "metadata": {},
   "source": [
    "##### 1. Open Meteo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687d33a7-e6f7-4059-a63f-ee682f62ffcb",
   "metadata": {},
   "source": [
    "Historic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "70a87683-d40d-40f8-a871-22aa5729155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Open-Meteo API client with cache and retry on error\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after=-1)\n",
    "retry_session = retry(cache_session, retries=5, backoff_factor=0.2)\n",
    "openmeteo = openmeteo_requests.Client(session=retry_session)\n",
    "\n",
    "def fetch_historical_weather_data(latitude, longitude, game_datetime):\n",
    "    game_date = game_datetime.strftime(\"%Y-%m-%d\")\n",
    "    next_day = (game_datetime + pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    params = {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"start_date\": game_date,\n",
    "        \"end_date\": next_day,  # include next day to cover all 24 hours\n",
    "        \"hourly\": [\n",
    "            \"temperature_2m\", \"relative_humidity_2m\", \"dew_point_2m\", \n",
    "            \"weather_code\", \"surface_pressure\", \"wind_speed_10m\", \"wind_direction_10m\"\n",
    "        ],\n",
    "        \"temperature_unit\": \"fahrenheit\",\n",
    "        \"wind_speed_unit\": \"mph\",\n",
    "        \"precipitation_unit\": \"inch\",\n",
    "        \"timezone\": \"UTC\"  # important!\n",
    "    }\n",
    "\n",
    "    responses = openmeteo.weather_api(url, params=params)\n",
    "    response = responses[0]\n",
    "\n",
    "    hourly = response.Hourly()\n",
    "    hourly_data = {\n",
    "        \"datetime\": pd.date_range(\n",
    "            start=pd.to_datetime(hourly.Time(), unit=\"s\", utc=True),\n",
    "            end=pd.to_datetime(hourly.TimeEnd(), unit=\"s\", utc=True),\n",
    "            freq=pd.Timedelta(seconds=hourly.Interval()),\n",
    "            inclusive=\"left\"\n",
    "        ),\n",
    "        \"temperature_2m\": hourly.Variables(0).ValuesAsNumpy(),\n",
    "        \"relative_humidity_2m\": hourly.Variables(1).ValuesAsNumpy(),\n",
    "        \"dew_point_2m\": hourly.Variables(2).ValuesAsNumpy(),\n",
    "        \"weather_code\": hourly.Variables(3).ValuesAsNumpy(),\n",
    "        \"surface_pressure\": hourly.Variables(4).ValuesAsNumpy(),\n",
    "        \"wind_speed_10m\": hourly.Variables(5).ValuesAsNumpy(),\n",
    "        \"wind_direction_10m\": hourly.Variables(6).ValuesAsNumpy()\n",
    "    }\n",
    "\n",
    "    \n",
    "    return pd.DataFrame(hourly_data)\n",
    "\n",
    "\n",
    "def create_historic_weather_df(game_df):\n",
    "    \"\"\"Append weather data to each game in game_df based on game_datetime.\"\"\"\n",
    "\n",
    "    # Convert game_datetime to UTC\n",
    "    game_df[\"game_datetime\"] = pd.to_datetime(game_df[\"game_datetime\"], utc=True)\n",
    "\n",
    "    # Lists to store the matched weather data\n",
    "    weather_columns = [\n",
    "        \"temperature_2m\", \"relative_humidity_2m\", \"dew_point_2m\",\n",
    "        \"weather_code\", \"surface_pressure\", \"wind_speed_10m\", \"wind_direction_10m\"\n",
    "    ]\n",
    "    weather_data_lists = {col: [] for col in weather_columns}\n",
    "\n",
    "    # Loop through each game in the DataFrame\n",
    "    for _, row in game_df.iterrows():\n",
    "        latitude = row[\"location.defaultCoordinates.latitude\"]\n",
    "        longitude = row[\"location.defaultCoordinates.longitude\"]\n",
    "        game_datetime = row[\"game_datetime\"]\n",
    "\n",
    "        # Fetch historical weather data for that day\n",
    "        weather_data = fetch_historical_weather_data(latitude, longitude, game_datetime)\n",
    "        \n",
    "        # Find the closest weather timestamp to game_datetime (typically, first top of the hour after game starts)\n",
    "        closest_weather_row = weather_data.iloc[\n",
    "            (weather_data[\"datetime\"] - game_datetime).abs().argsort()[0]\n",
    "        ]\n",
    "\n",
    "        # Append the closest weather data to lists\n",
    "        for col in weather_columns:\n",
    "            weather_data_lists[col].append(closest_weather_row[col])\n",
    "\n",
    "    # Add the weather data as new columns in game_df\n",
    "    for col in weather_columns:\n",
    "        game_df[col] = weather_data_lists[col]\n",
    "\n",
    "\n",
    "    return game_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7784841-f895-4724-8859-127d04f3cedc",
   "metadata": {},
   "source": [
    "Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e1d8a934-2b64-499a-b02c-d7b582be9f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_weather_data(latitude, longitude, start, end):\n",
    "    \"\"\"Fetch hourly weather forecast or recent past data from Open-Meteo.\"\"\"\n",
    "    cache_session = requests_cache.CachedSession('.cache', expire_after=3600)\n",
    "    retry_session = retry(cache_session, retries=5, backoff_factor=0.2)\n",
    "    openmeteo = openmeteo_requests.Client(session=retry_session)\n",
    "\n",
    "    url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    params = {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"hourly\": [\n",
    "            \"temperature_2m\", \"relative_humidity_2m\", \"dew_point_2m\", \n",
    "            \"precipitation_probability\", \"surface_pressure\", \n",
    "            \"wind_speed_10m\", \"wind_direction_10m\", \"weather_code\"\n",
    "        ],\n",
    "        \"start\": start,  # ISO 8601\n",
    "        \"end\": end,      # ISO 8601\n",
    "        \"wind_speed_unit\": \"mph\",\n",
    "        \"temperature_unit\": \"fahrenheit\",\n",
    "        \"precipitation_unit\": \"inch\",\n",
    "        \"timezone\": \"UTC\",       # ✅ Ensure UTC so hourly timestamps align\n",
    "        \"past_days\": 2           # ✅ Include recent data in case game time is recent past\n",
    "    }\n",
    "\n",
    "    responses = openmeteo.weather_api(url, params=params)\n",
    "    response = responses[0]\n",
    "    hourly = response.Hourly()\n",
    "\n",
    "    hourly_data = {\n",
    "        \"datetime\": pd.date_range(\n",
    "            start=pd.to_datetime(hourly.Time(), unit=\"s\", utc=True),\n",
    "            end=pd.to_datetime(hourly.TimeEnd(), unit=\"s\", utc=True),\n",
    "            freq=pd.Timedelta(seconds=hourly.Interval()),\n",
    "            inclusive=\"left\"\n",
    "        ),\n",
    "        \"temperature_2m\": hourly.Variables(0).ValuesAsNumpy(),\n",
    "        \"relative_humidity_2m\": hourly.Variables(1).ValuesAsNumpy(),\n",
    "        \"dew_point_2m\": hourly.Variables(2).ValuesAsNumpy(),\n",
    "        \"precipitation_probability\": hourly.Variables(3).ValuesAsNumpy(),\n",
    "        \"surface_pressure\": hourly.Variables(4).ValuesAsNumpy(),\n",
    "        \"wind_speed_10m\": hourly.Variables(5).ValuesAsNumpy(),\n",
    "        \"wind_direction_10m\": hourly.Variables(6).ValuesAsNumpy(),\n",
    "        \"weather_code\": hourly.Variables(7).ValuesAsNumpy(),\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(hourly_data)\n",
    "\n",
    "    # Filter the data to only include the requested window\n",
    "    df = df[(df[\"datetime\"] >= pd.to_datetime(start, utc=True)) &\n",
    "            (df[\"datetime\"] <= pd.to_datetime(end, utc=True))]\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_daily_weather_df(game_df):\n",
    "    \"\"\"Append hourly weather data (forecast or recent) to each game.\"\"\"\n",
    "    weather_columns = [\n",
    "        \"temperature_2m\", \"relative_humidity_2m\", \"dew_point_2m\",\n",
    "        \"precipitation_probability\", \"surface_pressure\",\n",
    "        \"wind_speed_10m\", \"wind_direction_10m\", \"weather_code\"\n",
    "    ]\n",
    "    weather_data_lists = {col: [] for col in weather_columns}\n",
    "\n",
    "    for _, row in game_df.iterrows():\n",
    "        latitude = row[\"location.defaultCoordinates.latitude\"]\n",
    "        longitude = row[\"location.defaultCoordinates.longitude\"]\n",
    "        game_datetime = pd.to_datetime(row[\"game_datetime\"], utc=True)\n",
    "\n",
    "        # Fetch 2 hours around game start to ensure coverage\n",
    "        start = (game_datetime - pd.Timedelta(hours=1)).isoformat()\n",
    "        end = (game_datetime + pd.Timedelta(hours=1)).isoformat()\n",
    "\n",
    "        try:\n",
    "            weather_data = fetch_weather_data(latitude, longitude, start, end)\n",
    "            if not weather_data.empty:\n",
    "                # Find record closest to game time\n",
    "                closest = weather_data.iloc[(weather_data[\"datetime\"] - game_datetime).abs().argsort()[0]]\n",
    "                for col in weather_columns:\n",
    "                    weather_data_lists[col].append(closest[col])\n",
    "            else:\n",
    "                # If API returned no data, append NaN\n",
    "                for col in weather_columns:\n",
    "                    weather_data_lists[col].append(np.nan)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Weather fetch failed for {latitude},{longitude} at {game_datetime}: {e}\")\n",
    "            for col in weather_columns:\n",
    "                weather_data_lists[col].append(np.nan)\n",
    "\n",
    "    # Add the weather columns\n",
    "    for col in weather_columns:\n",
    "        game_df[col] = weather_data_lists[col]\n",
    "\n",
    "    \n",
    "    return game_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392f23a2-d7eb-4541-a9cb-ae70b688e767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a1ed6df-103d-49bb-9194-8e83acb0e1b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 1. Swish Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cee7f9-76d2-4639-a001-66c8f0603dc4",
   "metadata": {},
   "source": [
    "Swish Analytics contains weather projections to be used before MLB Stats API updates theirs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f911a879-6dac-429f-8e42-28f8b17c1977",
   "metadata": {},
   "source": [
    "Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c9cdb2-c7c2-4356-a7d9-36bcd2299748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape Swish Analytics for weather data\n",
    "def swishanalytics(date):\n",
    "    # Reformat date to fit URL\n",
    "    date_dash = f\"{date[:4]}-{date[4:6]}-{date[6:8]}\"\n",
    "    \n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(f\"https://swishanalytics.com/mlb/weather?date={date_dash}\")\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find all divs with the class 'weather-card'\n",
    "        weather_cards = soup.find_all('div', class_='weather-card')\n",
    "        \n",
    "        # Initialize an empty list to store DataFrames\n",
    "        dfs = []\n",
    "        \n",
    "        # Iterate over each weather card\n",
    "        for weather_card in weather_cards:\n",
    "            # Extract relevant information from the weather card\n",
    "            time_info = weather_card.find('small', class_='text-muted')\n",
    "            location_info = weather_card.find('h4', class_='lato inline vert-mid bold')\n",
    "            \n",
    "            # Extract time and location information\n",
    "            time = time_info.text.strip() if time_info else None\n",
    "            location = location_info.text.strip() if location_info else None\n",
    "            \n",
    "            # Find the table within the weather card\n",
    "            table = weather_card.find('table', class_='table-bordered')\n",
    "            \n",
    "            # If table exists, extract data from it\n",
    "            if table:\n",
    "                # Extract table data into a list of lists\n",
    "                rows = table.find_all('tr')\n",
    "                data = []\n",
    "                for row in rows:\n",
    "                    cells = row.find_all(['th', 'td'])\n",
    "                    row_data = [cell.text.strip() for cell in cells]\n",
    "                    data.append(row_data)\n",
    "                \n",
    "                # Convert data into a pandas DataFrame\n",
    "                df = pd.DataFrame(data)\n",
    "                \n",
    "                # Set the first row as the column headers\n",
    "                df.columns = df.iloc[0]\n",
    "                df = df[1:]  # Remove the first row since it's the header row\n",
    "                \n",
    "                # Add time and location as additional columns\n",
    "                df['Time'] = time\n",
    "                df['Location'] = location\n",
    "\n",
    "                # Create dataframem from the second time period scraped\n",
    "                daily_weather_df = pd.DataFrame(df.iloc[:, 2]).T\n",
    "                # Extract home team name \n",
    "                daily_weather_df['Matchup'] = df['Location'][1]\n",
    "                daily_weather_df['FANGRAPHSTEAM'] = daily_weather_df['Matchup'].str.split(\"@\", expand=True).iloc[:, 1]\n",
    "                daily_weather_df['FANGRAPHSTEAM'] = daily_weather_df['FANGRAPHSTEAM'].str.replace(\"\\xa0\\xa0\", \"\")\n",
    "\n",
    "                dfs.append(daily_weather_df)\n",
    "        \n",
    "    else:\n",
    "        print(\"Failed to retrieve the page. Status code:\", response.status_code)\n",
    "\n",
    "    # Append together dataframes\n",
    "    df = pd.concat(dfs, axis=0)\n",
    "    \n",
    "    # Rename columns\n",
    "    df.rename(columns={1:'Weather', 2:'Temperature', 3:'Feels Like', 4:'Humidity', 5:'Speed', 6:'Direction', 'BBREFTEAM': 'home_team'}, inplace=True)\n",
    "\n",
    "    # Clean\n",
    "    df['Speed'] = df['Speed'].str.replace(\" mph\", \"\").astype(float)\n",
    "    df['Temperature'] = df['Temperature'].str.replace('°', '')\n",
    "    df['Feels Like'] = df['Feels Like'].str.replace('°', '')\n",
    "    df.reset_index(drop=False, inplace=True, names='Time')\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d1a5d5-af47-463b-8708-911b012cf77b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0feb060b-9677-4f9e-9d2e-de88f9874c7b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 2. RotoGrinders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f5cd41-3e3d-472a-9c6b-721ea3d1db24",
   "metadata": {},
   "source": [
    "RotoGrinders hosts weather warnings used to identify matchups to avoid based on weather risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63e3674-87ac-4227-9a07-7e552894006b",
   "metadata": {},
   "source": [
    "Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cbe8bc-5e6f-4c13-8453-4f4caf44bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotogrinders(date, team_map):\n",
    "    # Send a GET request to the URL and retrieve the response\n",
    "    response = requests.get(\"https://rotogrinders.com/weather/mlb\")\n",
    "\n",
    "    # Check if the response is successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Get the HTML content from the response\n",
    "        html_content = response.text\n",
    "\n",
    "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "        # Find all <li> elements within the <ul>\n",
    "        li_elements = soup.find_all(\"li\", class_=\"weather-blurb\")\n",
    "\n",
    "        # Create an empty list to store the data\n",
    "        data = []\n",
    "\n",
    "        for li_element in li_elements:\n",
    "            # Extract the tag colors from the <span> elements\n",
    "            tag_elements = li_element.find_all(\"span\", class_=[\"green\", \"yellow\", \"orange\", \"red\"])\n",
    "        \n",
    "            # Extract the first tag color\n",
    "            tag = tag_elements[0].text.strip() if tag_elements else None\n",
    "        \n",
    "            # Extract the second tag color if it exists\n",
    "            tag2 = tag_elements[1].text.strip() if len(tag_elements) > 1 else None\n",
    "        \n",
    "            # Extract the matchup from the <span> element with class \"bold\"\n",
    "            matchup_span = li_element.find(\"span\", class_=\"bold\")\n",
    "            matchup = matchup_span.text.strip() if matchup_span else None\n",
    "        \n",
    "            # Extract the description if it exists\n",
    "            if matchup_span:\n",
    "                description_span = matchup_span.find_next_sibling(\"span\")\n",
    "                description = description_span.text.strip() if description_span else None\n",
    "            else:\n",
    "                description = None\n",
    "        \n",
    "            # Append the data to the list\n",
    "            data.append({\"Tag\": tag, \"Tag2\": tag2, \"Matchup\": matchup, \"Description\": description})\n",
    "\n",
    "\n",
    "        # Convert the list of dictionaries to a DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        df[['away', 'home']] = df['Matchup'].str.split(\" @ \", expand=True)\n",
    "\n",
    "        # Add in DK team abbreviations \n",
    "        df = df.merge(team_map[['ROTOGRINDERSTEAM', 'DKTEAM']], left_on=['away'], right_on=['ROTOGRINDERSTEAM'], how='left', suffixes=(\"\", \"_away\"))\n",
    "        df = df.merge(team_map[['ROTOGRINDERSTEAM', 'DKTEAM']], left_on=['home'], right_on=['ROTOGRINDERSTEAM'], how='left', suffixes=(\"\", \"_home\"))\n",
    "        df = df[['Tag', 'Tag2', 'Matchup', 'DKTEAM', 'DKTEAM_home', 'Description']]\n",
    "        df.rename(columns={'DKTEAM':'Away', 'DKTEAM_home': 'Home'}, inplace=True)\n",
    "        \n",
    "        # Add the date column to the DataFrame\n",
    "        df['date'] = date\n",
    "\n",
    "        return df\n",
    "    else:\n",
    "        # Return an error message if the response is not successful\n",
    "        return \"Failed to retrieve data. Response status code: {}\".format(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d82a29-46f9-4318-b170-46ae15462ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b3b4d98-8ef6-4622-ab4b-1d492d48c65f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 3. Park x Weather Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2e9aea-1d4c-40d6-93a3-96a05f159ad3",
   "metadata": {},
   "source": [
    "Calculate wind x and y vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecab4f83-7852-4009-8b8c-6887bb2d5f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vectors(row, azimuth_column, wind_column, speed_column):\n",
    "    angle = row[wind_column] - row[azimuth_column]\n",
    "    \n",
    "    # Calculate vectors\n",
    "    x_vect = round(math.sin(math.radians(angle)), 5) * row[speed_column] * -1\n",
    "    y_vect = round(math.cos(math.radians(angle)), 5) * row[speed_column] * -1\n",
    "\n",
    "    return pd.Series([x_vect, y_vect], index=['x_vect', 'y_vect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65d0aec-75ff-4191-8979-07eafb32b0b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca8a3b07-f812-4a86-87e6-c79adcbb62f1",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5752c8b6-6f18-43c3-96fc-ff954227f4cc",
   "metadata": {},
   "source": [
    "##### 1. Open Meteo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29756881-3e43-4093-867e-8652cf5f0a6f",
   "metadata": {},
   "source": [
    "Columns to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4e717a2e-e383-4c4a-a87a-a233a4b3e8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns from game_df\n",
    "game_columns = ['game_id', 'game_datetime', 'game_date', 'date', 'year', 'game_type', 'status', 'away_team', 'home_team', 'doubleheader', 'game_num', 'venue_id', 'venue_name']\n",
    "# Columns Venue Map\n",
    "venue_columns = ['location.defaultCoordinates.latitude', 'location.defaultCoordinates.longitude', \n",
    "                 'fieldInfo.leftLine', 'fieldInfo.center', 'fieldInfo.rightLine', 'fieldInfo.leftCenter',\n",
    "                 'fieldInfo.rightCenter', 'location.elevation', 'location.azimuthAngle', 'fieldInfo.roofType', 'active']\n",
    "# Columns from Open Mateo \n",
    "weather_columns = ['temperature_2m', 'relative_humidity_2m', 'dew_point_2m', 'surface_pressure', 'wind_speed_10m', 'wind_direction_10m', 'weather_code']\n",
    "# Forecast-only columns from Open Meteo\n",
    "forecast_only_columns = ['precipitation_probability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b2b7c14f-6ca7-4db1-83b4-82ae218deeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open Meteo: Historic\n",
      "CPU times: total: 78.1 ms\n",
      "Wall time: 2.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Loop over dates\n",
    "for date in game_df['date'].unique():\n",
    "    print(date)\n",
    "    if int(date) == int(todaysdate):\n",
    "        print(\"Open Meteo: Today\")\n",
    "        # Create daily weather dataframe (forecast)\n",
    "        create_daily_weather_df(game_df[game_df['date'].astype(int) == date])[game_columns + venue_columns + weather_columns + forecast_only_columns].to_csv(\n",
    "            os.path.join(baseball_path, \"A06. Weather\", \"1. Open Meteo\", f\"Open Meteo {date}.csv\"), index=False)\n",
    "    else:\n",
    "        print(\"Open Meteo: Historic\")\n",
    "        # Create historic weather dataframe\n",
    "        create_historic_weather_df(game_df[game_df['date'] == date])[game_columns + venue_columns + weather_columns].to_csv(\n",
    "            os.path.join(baseball_path, \"A06. Weather\", \"1. Open Meteo\", f\"Open Meteo {date}.csv\"), index=False)\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8651c3e-f3d9-47c5-9ddb-e1d43a9c9808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20250528\n",
       "1    20250528\n",
       "2    20250528\n",
       "3    20250528\n",
       "4    20250528\n",
       "Name: date, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_df['date'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e995618-7cd1-4af1-b01c-19e9ce1060e1",
   "metadata": {},
   "source": [
    "##### 1. Swish Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a707003-941c-4acc-8fd0-596008959fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not scrape Swish Analytics weather data.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Scrape Swish Analytics\n",
    "    swishanalytics_df = swishanalytics(todaysdate)\n",
    "    # To CSV\n",
    "    swishanalytics_df.to_csv(os.path.join(baseball_path, \"A06. Weather\", \"1. Swish Analytics\", f\"Swish Analytics {todaysdate}.csv\"), index=False, encoding='iso-8859-1')\n",
    "except:\n",
    "    print(\"Could not scrape Swish Analytics weather data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491b471b-a217-478d-ae6f-6704d87675c0",
   "metadata": {},
   "source": [
    "##### 2. RotoGrinders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7527eda-bb27-46c5-8b7b-7ed0e4a30022",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Scrape RotoGrinders\n",
    "    rotogrinders_df = rotogrinders(todaysdate, team_map)\n",
    "    # To CSV\n",
    "    rotogrinders_df.to_csv(os.path.join(baseball_path, \"A06. Weather\", \"2. RotoGrinders\", f\"RotoGrinders {todaysdate}.csv\"), index=False)\n",
    "except:\n",
    "    print(\"Could not scrape RotoGrinders weather data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fa4ad3-4ddb-467c-80ae-28717461422d",
   "metadata": {},
   "source": [
    "##### 3. Park x Weather Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd268cd4-2f92-4f43-a86c-83ce67264593",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb_weather_variables = ['x_vect', 'y_vect', 'temperature'] # drop weather\n",
    "meteo_duplicates_variables = ['meteo_x_vect', 'meteo_y_vect', 'temperature_2m']\n",
    "meteo_weather_variables = ['relative_humidity_2m', 'dew_point_2m', 'surface_pressure']\n",
    "mlb_park_variables = ['fieldInfo.leftLine', 'fieldInfo.center', 'fieldInfo.rightLine', 'fieldInfo.leftCenter', 'fieldInfo.rightCenter', 'location.elevation'] # drop roof type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fa8421-0b33-4253-8ea8-748d1b14b730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Would be nice to generate this in a cleverer way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55dbb9a-a843-4644-9470-0f0006ba02d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_dummy_list = ['venue_1', 'venue_2', 'venue_3', 'venue_4', 'venue_5', 'venue_7', 'venue_10', 'venue_12', 'venue_13', 'venue_14', 'venue_15', 'venue_17', 'venue_19', 'venue_22', 'venue_31', 'venue_32', 'venue_680', 'venue_2392', 'venue_2394', 'venue_2395', 'venue_2602', 'venue_2680', 'venue_2681', 'venue_2889', 'venue_3289', 'venue_3309', 'venue_3312', 'venue_3313', 'venue_4169', 'venue_4705', 'venue_5325']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618ba6b2-f744-42d1-96dd-d30aaf4111b6",
   "metadata": {},
   "source": [
    "Read in Meteo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff675c13-ae64-4304-9c7b-e0921bb0ac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_df = pd.read_csv(os.path.join(baseball_path, \"A06. Weather\", \"1. Open Meteo\", f\"Open Meteo {todaysdate}.csv\"), encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9724576-43fe-41c0-8563-3a5854ce9925",
   "metadata": {},
   "source": [
    "Read in park latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88ea7f6-972b-4dc9-afaf-300bfb7c5790",
   "metadata": {},
   "outputs": [],
   "source": [
    "park_latest_df = pd.read_csv(os.path.join(baseball_path, \"Park Latest.csv\"))\n",
    "l_park_latest_df = park_latest_df[park_latest_df['batSide'] == \"L\"]\n",
    "r_park_latest_df = park_latest_df[park_latest_df['batSide'] == \"R\"]\n",
    "\n",
    "pfx_variables = [col for col in park_latest_df if col.endswith(\"pfx\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb1e239-3e72-4de0-b09d-a6ab3aa0ea08",
   "metadata": {},
   "source": [
    "Read in event averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ebdf2f-2a37-4bde-9222-f464aaae06e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_averages = pd.read_csv(os.path.join(baseball_path, \"Event Averages.csv\"))\n",
    "event_averages = event_averages.add_suffix(\"_pred_batted\")\n",
    "event_variables = list(event_averages.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cad369-1c52-4c99-8fc3-2b207a8c07a3",
   "metadata": {},
   "source": [
    "Add weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dca4d0e-6139-4649-b6ca-c502be6986f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_df[['meteo_x_vect', 'meteo_y_vect']] = meteo_df.apply(lambda row: calculate_vectors(row, 'location.azimuthAngle', 'wind_direction_10m', 'wind_speed_10m'), axis=1)\n",
    "meteo_df[['weather', 'wind', 'venue', 'date', 'missing_weather']] = meteo_df['game_id'].apply(lambda game_id: pd.Series(create_box(game_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787aa9a1-86a3-4eb7-be38-8d31b7a30938",
   "metadata": {},
   "source": [
    "Adjust weather data in dome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9285c48f-f861-4632-a68c-f9fd2f3d3854",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = meteo_df['weather'].str.contains('Roof|Dome', case=False, na=False)\n",
    "\n",
    "meteo_df.loc[mask, 'temperature_2m'] = 68\n",
    "meteo_df.loc[mask, 'meteo_x_vect'] = 0\n",
    "meteo_df.loc[mask, 'meteo_y_vect'] = 0\n",
    "meteo_df.loc[mask, 'relative_humidity_2m'] = 60\n",
    "meteo_df.loc[mask, 'dew_point_2m'] = 57"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13361763-e847-4aee-8e4b-c4801f883f88",
   "metadata": {},
   "source": [
    "##### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a5db45-7f4f-4f97-9fd1-6db38f9bf8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wfx_inputs = event_variables + pfx_variables + meteo_duplicates_variables + meteo_weather_variables + venue_dummy_list + ['b_L']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64259e0f-dcef-4f61-8526-ab91e1ba02a0",
   "metadata": {},
   "source": [
    "##### LHB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a875698e-1c44-4311-b7a1-c27f7b700911",
   "metadata": {},
   "source": [
    "Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35e4076-90b5-4ace-a472-48519bd9dc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_wfx_df = meteo_df.merge(l_park_latest_df, on=['venue_id'], how='left')\n",
    "l_wfx_df = l_wfx_df.merge(event_averages, how='cross')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddec4186-e1d7-4237-9913-d96b9c55d3f0",
   "metadata": {},
   "source": [
    "Assign venue dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6759658-fcf3-40d0-87ab-275c1c313a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for venue_dummy in venue_dummy_list:\n",
    "    l_wfx_df[venue_dummy] = (venue_dummy == \"venue_\" + l_wfx_df[\"venue_id\"].astype(str)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6d7e0f-185c-4b55-ae32-2aa2be7255b3",
   "metadata": {},
   "source": [
    "Assign batter is lefty dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a91d9d2-81ae-42d9-b296-47f8ef15c513",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_wfx_df['b_L'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefc1288-41dd-4fbf-b981-26d6fbeb58c8",
   "metadata": {},
   "source": [
    "Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc73f40-74a6-4825-ad9f-5c9633dd3afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = l_wfx_df[wfx_inputs].values\n",
    "X2_scaled = scale_wfx.transform(X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839dbc4f-bfdc-4957-a75f-1d5e8bf3db33",
   "metadata": {},
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a841db1d-9926-42a0-855f-d3cecebc21c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = predict_wfx.predict(X2_scaled)\n",
    "\n",
    "prediction_df2 = pd.DataFrame(predictions2, columns=events_list)\n",
    "prediction_df2 = prediction_df2.add_suffix('_pred_weather')\n",
    "\n",
    "\n",
    "l_wfx_df = pd.concat([l_wfx_df, prediction_df2.reset_index()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f649ed34-1d9b-49f1-aff1-17708e9768c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_wfx_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d586c3-7964-4026-acfd-c8876df21444",
   "metadata": {},
   "source": [
    "Calculate WFX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b978e8a6-29f3-4864-a610-0315b76a87fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in events_list:\n",
    "    l_wfx_df[f'{event}_wfx_unadj'] = l_wfx_df[f'{event}_pred_weather'] / l_wfx_df[f'{event}_pred_batted']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc917d7-e23b-40a6-9e2b-54362c201a73",
   "metadata": {},
   "source": [
    "Calibrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975a2335-f629-43ac-bdbe-702ec2421d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "park_and_weather_df = pd.read_csv(os.path.join(baseball_path, \"Park and Weather Factors.csv\"))\n",
    "park_and_weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff0fcbf-07ae-4450-ae9c-6b1082faa553",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in events_list:\n",
    "    pred_weather_col = f'{event}_pred_weather'\n",
    "    ref_pred_weather_col = f'{event}_pred_weather_l'\n",
    "    ref_pred_batted_col = f'{event}_pred_batted_l'\n",
    "    ref_actual_col = f'{event}_l'\n",
    "\n",
    "    pred_batted_output = []\n",
    "    actual_output = []\n",
    "\n",
    "    # Pull reference columns as arrays for speed\n",
    "    pwf_venue = park_and_weather_df['venue_id'].values\n",
    "    pwf_pred_weather = park_and_weather_df[ref_pred_weather_col].values\n",
    "    pwf_pred_batted = park_and_weather_df[ref_pred_batted_col].values\n",
    "    pwf_actual = park_and_weather_df[ref_actual_col].values\n",
    "\n",
    "    for i, row in l_wfx_df.iterrows():\n",
    "        venue = row['venue_id']\n",
    "        target_pred_weather = row[pred_weather_col]\n",
    "\n",
    "        mask = pwf_venue == venue\n",
    "        pred_weather_vals = pwf_pred_weather[mask]\n",
    "        pred_batted_vals = pwf_pred_batted[mask]\n",
    "        actual_vals = pwf_actual[mask]\n",
    "\n",
    "        if len(pred_weather_vals) == 0 or np.isnan(target_pred_weather):\n",
    "            pred_batted_output.append(np.nan)\n",
    "            actual_output.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        nearest_idx = np.argsort(np.abs(pred_weather_vals - target_pred_weather))[:similar_games]\n",
    "        pred_batted_output.append(np.nanmean(pred_batted_vals[nearest_idx]))\n",
    "        actual_output.append(np.nanmean(actual_vals[nearest_idx]))\n",
    "\n",
    "    # Save results to l_wfx_df\n",
    "    l_wfx_df[f'{event}_pred_batted'] = pred_batted_output\n",
    "    l_wfx_df[event] = actual_output\n",
    "\n",
    "    # Calculate adjusted wfx\n",
    "    l_wfx_df[f'{event}_wfx_adj'] = l_wfx_df[event] / l_wfx_df[f'{event}_pred_batted'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6477ddff-4ea9-42b8-b8a6-dbdc279ed127",
   "metadata": {},
   "source": [
    "##### RHB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479c6324-cf52-4f92-9179-42150ba5921b",
   "metadata": {},
   "source": [
    "Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79436b4f-c6a9-48ba-8c77-e1eea70047d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_wfx_df = meteo_df.merge(r_park_latest_df, on=['venue_id'], how='left')\n",
    "r_wfx_df = r_wfx_df.merge(event_averages, how='cross')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00c6a09-699a-42a1-93ad-10aa45d1d27b",
   "metadata": {},
   "source": [
    "Assign venue dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ad265d-a82c-44c1-b525-4df0f493b298",
   "metadata": {},
   "outputs": [],
   "source": [
    "for venue_dummy in venue_dummy_list:\n",
    "    r_wfx_df[venue_dummy] = (venue_dummy == \"venue_\" + r_wfx_df[\"venue_id\"].astype(str)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8312b02-512e-499b-97d0-a5794c239b74",
   "metadata": {},
   "source": [
    "Assign batter is lefty dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5db0178-740c-40d8-a7f5-373af99122b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_wfx_df['b_L'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4427440-9140-47e2-ab13-a3d1b86a9bf1",
   "metadata": {},
   "source": [
    "Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e640e2d-9377-468b-bb5b-5bdab12922ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = r_wfx_df[wfx_inputs].values\n",
    "X2_scaled = scale_wfx.transform(X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ca685e-0be9-4e7e-a4ee-01186b7548f5",
   "metadata": {},
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8879bbb-f23b-4292-88e3-094574ecda48",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = predict_wfx.predict(X2_scaled)\n",
    "\n",
    "prediction_df2 = pd.DataFrame(predictions2, columns=events_list)\n",
    "prediction_df2 = prediction_df2.add_suffix('_pred_weather')\n",
    "\n",
    "\n",
    "r_wfx_df = pd.concat([r_wfx_df, prediction_df2.reset_index()], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe331f59-b3ef-45e6-8e5e-7968b3feebf3",
   "metadata": {},
   "source": [
    "Calculate WFX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522e91f6-e8c4-449b-8fcd-b64031f81a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in events_list:\n",
    "    r_wfx_df[f'{event}_wfx_unadj'] = r_wfx_df[f'{event}_pred_weather'] / r_wfx_df[f'{event}_pred_batted']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d860c51-85b5-4b06-a7c0-af361b2ad2d0",
   "metadata": {},
   "source": [
    "Calibrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35bd394-efd8-4601-b89b-91536a989653",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in events_list:\n",
    "    pred_weather_col = f'{event}_pred_weather'\n",
    "    ref_pred_weather_col = f'{event}_pred_weather_r'\n",
    "    ref_pred_batted_col = f'{event}_pred_batted_r'\n",
    "    ref_actual_col = f'{event}_r'\n",
    "\n",
    "    pred_batted_output = []\n",
    "    actual_output = []\n",
    "\n",
    "    # Pull reference columns as arrays for speed\n",
    "    pwf_venue = park_and_weather_df['venue_id'].values\n",
    "    pwf_pred_weather = park_and_weather_df[ref_pred_weather_col].values\n",
    "    pwf_pred_batted = park_and_weather_df[ref_pred_batted_col].values\n",
    "    pwf_actual = park_and_weather_df[ref_actual_col].values\n",
    "\n",
    "    for i, row in r_wfx_df.iterrows():\n",
    "        venue = row['venue_id']\n",
    "        target_pred_weather = row[pred_weather_col]\n",
    "\n",
    "        mask = pwf_venue == venue\n",
    "        pred_weather_vals = pwf_pred_weather[mask]\n",
    "        pred_batted_vals = pwf_pred_batted[mask]\n",
    "        actual_vals = pwf_actual[mask]\n",
    "\n",
    "        if len(pred_weather_vals) == 0 or np.isnan(target_pred_weather):\n",
    "            pred_batted_output.append(np.nan)\n",
    "            actual_output.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        nearest_idx = np.argsort(np.abs(pred_weather_vals - target_pred_weather))[:similar_games]\n",
    "        pred_batted_output.append(np.nanmean(pred_batted_vals[nearest_idx]))\n",
    "        actual_output.append(np.nanmean(actual_vals[nearest_idx]))\n",
    "\n",
    "    # Save results to l_wfx_df\n",
    "    r_wfx_df[f'{event}_pred_batted'] = pred_batted_output\n",
    "    r_wfx_df[event] = actual_output\n",
    "\n",
    "    # Calculate adjusted wfx\n",
    "    r_wfx_df[f'{event}_wfx_adj'] = r_wfx_df[event] / r_wfx_df[f'{event}_pred_batted'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0943183-31de-4af7-9bc4-88c22452f8f9",
   "metadata": {},
   "source": [
    "Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9816bec7-e32a-481d-90b2-08fe56c61d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "wfx_df = pd.merge(l_wfx_df, r_wfx_df[[\"venue_id\", \"game_num\"] + [col for col in r_wfx_df if \"wfx\" in col]], on=['venue_id', 'game_num'], how='left', suffixes=(\"_l\", \"_r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1649198c-04c2-4c3b-86ca-d76004e8d560",
   "metadata": {},
   "source": [
    "Rename (game_id is generated in historic wfx code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bf8f09-e951-4d35-986b-7691e3a50ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wfx_df.rename(columns={'game_id': 'gamePk'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c837bc2e-7348-4f1a-b98e-e1f6881b72c5",
   "metadata": {},
   "source": [
    "Keep relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b34c979-9259-46a4-ae6d-3b8a4847a4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_columns = ['gamePk', 'game_datetime', 'game_date', 'date', 'year', 'game_type', 'status', 'away_team', 'home_team', 'doubleheader', 'game_num', 'venue_id', 'venue_name', \n",
    "                'location.defaultCoordinates.latitude', 'location.defaultCoordinates.longitude', 'fieldInfo.leftLine', 'fieldInfo.center', 'fieldInfo.rightLine', 'fieldInfo.leftCenter', 'fieldInfo.rightCenter', \n",
    "                'location.elevation', 'location.azimuthAngle', 'fieldInfo.roofType', 'active', \n",
    "                'temperature_2m', 'relative_humidity_2m', 'dew_point_2m', 'surface_pressure', 'wind_speed_10m', 'wind_direction_10m', 'weather_code', 'precipitation_probability', \n",
    "                'meteo_x_vect', 'meteo_y_vect', 'weather', 'wind', 'missing_weather']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1b1d80-a5de-4789-9301-032cb445972c",
   "metadata": {},
   "source": [
    "Write to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f41e103-ed2c-4cbc-9c9a-5468ab8d830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wfx_df[keep_columns + [col for col in wfx_df if \"wfx\" in col]].to_csv(os.path.join(baseball_path, \"A06. Weather\", \"3. Park and Weather Factors\", f\"Park and Weather Factors {todaysdate}.csv\"), index=False, encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caef7724-ff9e-4bf9-948d-8620027d40db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda-base)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
