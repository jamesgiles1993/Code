{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b0b771-8bc9-4f75-9daf-1316bd2b5f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if not hasattr(sys.modules['__main__'], '__file__'):\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U1. Imports.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U2. Utilities.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U3. Classes.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U4. Datasets.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U5. Models.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8ce0f6-2eb6-4ecd-841b-2e99fc13c281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28e8cff1-f59e-4a58-a766-4747509c0168",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplier_df = pd.read_csv(os.path.join(baseball_path, \"Multiplier Dataset.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02405859-9235-419d-bb06-52eb83ede249",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b979a91-7a59-4d4b-b126-73771a2536ca",
   "metadata": {},
   "source": [
    "Create Latest PA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d2e8b3d-20de-4811-9084-667cf64004db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_data(df):\n",
    "    original_index = df.index  # Save the original index\n",
    "    \n",
    "    pl_df = pl.from_pandas(df)\n",
    "\n",
    "    # Calculate hits, total bases, reached, and faced\n",
    "    pl_df = pl_df.with_columns([\n",
    "        (pl.col('b1').cast(pl.Float64) + pl.col('b2').cast(pl.Float64) + pl.col('b3').cast(pl.Float64) + pl.col('hr').cast(pl.Float64)).alias('h'),\n",
    "        (pl.col('b1') * 1 + pl.col('b2') * 2 + pl.col('b3') * 3 + pl.col('hr') * 4).alias('tb'),\n",
    "        (pl.col('b1').cast(pl.Float64) + pl.col('b2').cast(pl.Float64) + pl.col('b3').cast(pl.Float64) + pl.col('hr').cast(pl.Float64) + pl.col('bb').cast(pl.Float64) + pl.col('hbp').cast(pl.Float64)).alias('reached'),\n",
    "        pl.lit(1).alias('faced'),\n",
    "        (((pl.col('inning') - 1) * 3) + pl.col('outs')).alias('outs_total')\n",
    "    ])\n",
    "\n",
    "    # Outs per PA\n",
    "    pl_df = pl_df.sort(['gamePk', 'inning', 'halfInning', 'atBatIndex'])\n",
    "    pl_df = pl_df.with_columns([\n",
    "        (pl.col('outs_total') - pl.col('outs_total').shift(1)).over(['gamePk', 'inning', 'halfInning']).alias('outs_pa')\n",
    "    ]).with_columns([\n",
    "        pl.when(pl.col('outs_pa').is_null()).then(pl.col('outs')).otherwise(pl.col('outs_pa')).alias('outs_pa')\n",
    "    ])\n",
    "\n",
    "    # Sort before cumulative calculations\n",
    "    pl_df = pl_df.sort(['gamePk', 'pitcher', 'inning', 'atBatIndex'])\n",
    "    \n",
    "    # Rolling cumulative stats per inning\n",
    "    for stat in events_list + ['h', 'tb', 'reached', 'faced', 'rbi', 'outs_pa']:\n",
    "        pl_df = pl_df.with_columns([\n",
    "            pl.col(stat).cum_sum().over(['gamePk', 'pitcher', 'inning']).alias(f'{stat}_inning')\n",
    "        ])\n",
    "\n",
    "    # Rolling cumulative stats per game\n",
    "    for stat in events_list + ['h', 'tb', 'reached', 'faced', 'rbi', 'outs_pa']:\n",
    "        pl_df = pl_df.with_columns([\n",
    "            pl.col(stat).cum_sum().over(['gamePk', 'pitcher']).alias(f'{stat}_game')\n",
    "        ])\n",
    "\n",
    "    # Bottom of the inning flag\n",
    "    pl_df = pl_df.with_columns([\n",
    "        (pl.col('top') == 0).cast(pl.Int8).alias('bottom')\n",
    "    ])\n",
    "\n",
    "    # Sort to identify starting pitchers\n",
    "    pl_df = pl_df.sort(['date', 'gamePk', 'bottom', 'atBatIndex'])\n",
    "\n",
    "    # Identify first at-bat for each bottom\n",
    "    pl_df = pl_df.with_columns([\n",
    "        pl.col('atBatIndex').min().over(['gamePk', 'bottom']).alias('atBatIndex_min')\n",
    "    ]).with_columns([\n",
    "        (pl.col('atBatIndex') == pl.col('atBatIndex_min')).cast(pl.Int8).alias('first_ab')\n",
    "    ])\n",
    "\n",
    "    # Identify pulled pitcher\n",
    "    pl_df = pl_df.with_columns([\n",
    "        pl.col('atBatIndex').max().over(['gamePk', 'pitcher']).alias('atBatIndex_max')\n",
    "    ]).with_columns([\n",
    "        (pl.col('atBatIndex') == pl.col('atBatIndex_max')).cast(pl.Int8).alias('pulled')\n",
    "    ])\n",
    "\n",
    "    # Times faced in game (adjusted for total batters faced)\n",
    "    pl_df = pl_df.with_columns([\n",
    "        (pl.col('faced_game') / 9).floor().fill_null(0).alias('times_faced')\n",
    "    ])\n",
    "\n",
    "    result = pl_df.to_pandas()\n",
    "    result.index = original_index  # Restore the original index\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63b489a5-ec0d-4c00-9b76-2de12fe7f1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_pas(df, pa_num, adjust, events_list=events_list):\n",
    "    if adjust:\n",
    "        events_list_copy = [f\"{event}_copy\" for event in events_list]\n",
    "        df[events_list_copy] = df[events_list].copy()\n",
    "        df[events_list] = df[events_list_adj].copy()\n",
    "\n",
    "    \n",
    "    # Renaming columns on df before conversion to Polars\n",
    "    df.rename(columns={'hit_distance_sc': 'totalDistance', 'launch_speed': 'launchSpeed'}, inplace=True)\n",
    "\n",
    "    # Convert to Polars after renaming\n",
    "    pl_df = pl.from_pandas(df)\n",
    "\n",
    "    # Ensure types are correctly set after converting to Polars\n",
    "    pl_df = pl_df.with_columns([\n",
    "        pl.col('date').cast(pl.Int32),\n",
    "        pl.col('gamePk').cast(pl.Int32),\n",
    "        pl.col('atBatIndex').cast(pl.Int32),\n",
    "        pl.col('batter').cast(pl.Int32),\n",
    "        pl.col('pitcher').cast(pl.Int32)\n",
    "    ])\n",
    "\n",
    "    # Sorting is done in Polars\n",
    "    pl_df = pl_df.sort(['date', 'gamePk', 'atBatIndex'])\n",
    "\n",
    "    # Create expressions for batter and pitcher stats\n",
    "    batter_avg_exprs = [\n",
    "        pl.col(col).rolling_mean(window_size=pa_num, min_periods=1).over(['batter', 'pitchHand']).alias(col + '_b')\n",
    "        for col in events_list + statcast_list\n",
    "    ]\n",
    "    batter_max_exprs = [\n",
    "        pl.col(col).rolling_max(window_size=pa_num, min_periods=1).over(['batter', 'pitchHand']).alias(col + '_b')\n",
    "        for col in max_list\n",
    "    ]\n",
    "    batter_sum_exprs = [\n",
    "        pl.col(col).rolling_sum(window_size=pa_num, min_periods=1).over(['batter', 'pitchHand']).alias(col + '_b')\n",
    "        for col in ['ab', 'pa']\n",
    "    ]\n",
    "\n",
    "    pitcher_avg_exprs = [\n",
    "        pl.col(col).rolling_mean(window_size=pa_num, min_periods=1).over(['pitcher', 'batSide']).alias(col + '_p')\n",
    "        for col in events_list + statcast_list\n",
    "    ]\n",
    "    pitcher_max_exprs = [\n",
    "        pl.col(col).rolling_max(window_size=pa_num, min_periods=1).over(['pitcher', 'batSide']).alias(col + '_p')\n",
    "        for col in max_list\n",
    "    ]\n",
    "    pitcher_sum_exprs = [\n",
    "        pl.col(col).rolling_sum(window_size=pa_num, min_periods=1).over(['pitcher', 'batSide']).alias(col + '_p')\n",
    "        for col in ['ab', 'pa']\n",
    "    ]\n",
    "\n",
    "    # Add the computed columns to pl_df\n",
    "    pl_df = pl_df.with_columns(\n",
    "        batter_avg_exprs + batter_max_exprs + batter_sum_exprs +\n",
    "        pitcher_avg_exprs + pitcher_max_exprs + pitcher_sum_exprs\n",
    "    )\n",
    "\n",
    "    # Create 'imp_b' and 'imp_p' directly in Polars\n",
    "    pl_df = pl_df.with_columns([\n",
    "        (pl.col('pa_b') < 40).cast(pl.Int32).alias('imp_b'),\n",
    "        (pl.col('pa_p') < 40).cast(pl.Int32).alias('imp_p')\n",
    "    ])\n",
    "\n",
    "    # Clean up date and other columns directly in Polars\n",
    "    pl_df = pl_df.with_columns([\n",
    "        pl.col('game_date').str.replace_all('-', '').cast(pl.Int32).alias('date'),\n",
    "        pl.col('gamePk').cast(pl.Int32),\n",
    "        pl.col('atBatIndex').cast(pl.Int32),\n",
    "        pl.col('batter').cast(pl.Int32),\n",
    "        pl.col('pitcher').cast(pl.Int32)\n",
    "    ])\n",
    "\n",
    "    # Sort the data as needed\n",
    "    pl_df = pl_df.sort(['date', 'gamePk', 'atBatIndex'])\n",
    "\n",
    "    # Calculating wOBA, SLG, OBP, and ISO directly in Polars\n",
    "    pl_df = pl_df.with_columns([\n",
    "        (0.690 * pl.col('bb_b') + 0.721 * pl.col('hbp_b') +\n",
    "         0.885 * pl.col('b1_b') + 1.262 * pl.col('b2_b') +\n",
    "         1.601 * pl.col('b3_b') + 2.070 * pl.col('hr_b')).alias('woba_b'),\n",
    "        (0.690 * pl.col('bb_p') + 0.721 * pl.col('hbp_p') +\n",
    "         0.885 * pl.col('b1_p') + 1.262 * pl.col('b2_p') +\n",
    "         1.601 * pl.col('b3_p') + 2.070 * pl.col('hr_p')).alias('woba_p'),\n",
    "\n",
    "        ((1 * pl.col('b1_b') + 2 * pl.col('b2_b') + 3 * pl.col('b3_b') + 4 * pl.col('hr_b')) *\n",
    "         (1 / (1 - (pl.col('bb_b') + pl.col('hbp_b'))))).alias('slg_b'),\n",
    "        ((1 * pl.col('b1_p') + 2 * pl.col('b2_p') + 3 * pl.col('b3_p') + 4 * pl.col('hr_p')) *\n",
    "         (1 / (1 - (pl.col('bb_p') + pl.col('hbp_p'))))).alias('slg_p'),\n",
    "\n",
    "        (pl.col('b1_b') + pl.col('b2_b') + pl.col('b3_b') + pl.col('hr_b') +\n",
    "         pl.col('bb_b') + pl.col('hbp_b')).alias('obp_b'),\n",
    "        (pl.col('b1_p') + pl.col('b2_p') + pl.col('b3_p') + pl.col('hr_p') +\n",
    "         pl.col('bb_p') + pl.col('hbp_p')).alias('obp_p'),\n",
    "\n",
    "        ((pl.col('b2_b') + 2 * pl.col('b3_b') + 3 * pl.col('hr_b')) *\n",
    "         (1 / (1 - (pl.col('bb_b') + pl.col('hbp_b'))))).alias('iso_b'),\n",
    "        ((pl.col('b2_p') + 2 * pl.col('b3_p') + 3 * pl.col('hr_p')) *\n",
    "         (1 / (1 - (pl.col('bb_p') + pl.col('hbp_p'))))).alias('iso_p')\n",
    "    ])\n",
    "\n",
    "    # Convert back to pandas for final operations\n",
    "    df_copy = pl_df.to_pandas()\n",
    "    \n",
    "    if adjust:\n",
    "        df_copy[events_list] = df_copy[events_list_copy].copy()\n",
    "\n",
    "        df_copy.drop(columns=events_list_copy, inplace=True)\n",
    "        \n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68fb2766-19ae-419d-b64d-36fcf2c51bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_weather(df):\n",
    "    import numpy as np\n",
    "\n",
    "    # Split weather into temperature and weather type\n",
    "    weather_split = df['weather'].str.split(\", \", expand=True)\n",
    "    df['temperature'] = pd.to_numeric(weather_split[0].str.replace(\" degrees\", \"\"), errors='coerce')\n",
    "    df['weather'] = weather_split[1]\n",
    "\n",
    "    # Split wind into speed and direction\n",
    "    wind_split = df['wind'].str.split(\", \", expand=True)\n",
    "    df['windSpeed'] = pd.to_numeric(wind_split[0].str.replace(\" mph\", \"\"), errors='coerce').fillna(0)\n",
    "    df['windDirection'] = wind_split[1].fillna('L to R').str.replace(\".\", \"\", regex=False)\n",
    "\n",
    "    wind_speed = df['windSpeed'].to_numpy()\n",
    "    angled = wind_speed / 2 * np.sqrt(2)\n",
    "    direction = df['windDirection'].to_numpy()\n",
    "\n",
    "    # Create lookup tables\n",
    "    y_lookup = {\n",
    "        \"Out To CF\": wind_speed,\n",
    "        \"Out To RF\": angled,\n",
    "        \"L To R\": np.zeros_like(wind_speed),\n",
    "        \"In From LF\": -angled,\n",
    "        \"In From CF\": -wind_speed,\n",
    "        \"In From RF\": -angled,\n",
    "        \"R To L\": np.zeros_like(wind_speed),\n",
    "        \"Out To LF\": angled\n",
    "    }\n",
    "\n",
    "    x_lookup = {\n",
    "        \"L To R\": wind_speed,\n",
    "        \"In From LF\": angled,\n",
    "        \"In From CF\": np.zeros_like(wind_speed),\n",
    "        \"In From RF\": -angled,\n",
    "        \"R To L\": -wind_speed,\n",
    "        \"Out To LF\": -angled,\n",
    "        \"Out To CF\": np.zeros_like(wind_speed),\n",
    "        \"Out To RF\": angled\n",
    "    }\n",
    "\n",
    "    df['y_vect'] = np.zeros(len(df))\n",
    "    df['x_vect'] = np.zeros(len(df))\n",
    "\n",
    "    for key, values in y_lookup.items():\n",
    "        df.loc[direction == key, 'y_vect'] = values[direction == key]\n",
    "    for key, values in x_lookup.items():\n",
    "        df.loc[direction == key, 'x_vect'] = values[direction == key]\n",
    "\n",
    "    # Overwrite for domes/roofs\n",
    "    is_dome = df['weather'].str.contains('Roof|Dome', na=False)\n",
    "    df.loc[is_dome, 'temperature'] = 70\n",
    "    df.loc[is_dome, ['x_vect', 'y_vect']] = 0\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2dd5945-e839-4390-8d59-6cbfa20b5c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge_datasets took 16.68 seconds\n",
      "clean_weather took 11.93 seconds\n",
      "create_events took 0.16 seconds\n",
      "create_variables took 7.00 seconds\n",
      "start_data took 17.75 seconds\n",
      "Short took 10.69 seconds\n",
      "Long took 14.01 seconds\n",
      "CPU times: total: 3min 53s\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_df_unadj = create_pa_inputs(None, start_year=2015, end_year=2025, short=50, long=300, adjust=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8898caae-e05c-417d-ba6c-2a41c9bc521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del new_df_unadj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e8b3eac-7580-42ed-9b64-69058102e4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 53s\n",
      "Wall time: 3min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_df_unadj.to_csv(os.path.join(baseball_path, \"Complete Dataset - Unadjusted (test).csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5b635c2-9888-4944-864d-7c61c8139550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge_datasets took 17.75 seconds\n",
      "clean_weather took 14.53 seconds\n",
      "create_events took 0.18 seconds\n",
      "create_variables took 7.25 seconds\n",
      "park_adjustments took 4.73 seconds\n",
      "start_data took 28.71 seconds\n",
      "Short took 21.26 seconds\n",
      "Long took 39.78 seconds\n",
      "CPU times: total: 7min 27s\n",
      "Wall time: 2min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_df_adj = create_pa_inputs(multiplier_df, start_year=2015, end_year=2025, short=50, long=300, adjust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70fed7dd-5b5c-4b85-b82c-f086bfba644f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5min 58s\n",
      "Wall time: 6min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_df_adj.to_csv(os.path.join(baseball_path, \"Complete Dataset - Adjusted (test).csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2255d49-8e4b-44fe-a38a-7727f7916740",
   "metadata": {},
   "outputs": [],
   "source": [
    "del new_df_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9df78a7-67dd-4cfb-b272-54f9c73dc92d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda-base)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
