{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70f6002-fbcb-4ecf-8100-e79898c3c294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d7c18de-6413-4a03-a86d-fcf45a739286",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\james\\anaconda3\\envs\\MLB\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run \"C:\\Users\\james\\Documents\\MLB\\Code\\U1. Imports.ipynb\"\n",
    "%run \"C:\\Users\\james\\Documents\\MLB\\Code\\U2. Utilities.ipynb\"\n",
    "%run \"C:\\Users\\james\\Documents\\MLB\\Code\\U3. Classes.ipynb\"\n",
    "\n",
    "baseball_path = r'C:\\Users\\james\\Documents\\MLB\\Database'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45e2a603-51ad-4130-8f47-de38e78d7f15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_games_df = read_and_save_games(team_map, generate=False)\n",
    "all_games_df['away_score'] = all_games_df['away_score'].astype('int')\n",
    "all_games_df['home_score'] = all_games_df['home_score'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06ade8c1-3d2d-42b9-9098-cbcf2c2e420d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_datetimes = list(all_games_df['game_datetime'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bded960-ea86-410c-aacc-7023d3f12d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dab9593-7135-4672-8559-7092338227e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# An api key is emailed to you when you sign up to a plan\n",
    "# Get a free API key at https://api.the-odds-api.com/\n",
    "API_KEY = 'd26e1a8d59392c1f035a1b9b1db0a1e0'\n",
    "\n",
    "# Sport key\n",
    "# More info at https://the-odds-api.com/sports-odds-data/sports-apis.html\n",
    "SPORT = 'baseball_mlb'\n",
    "\n",
    "# Bookmaker regions\n",
    "# uk | us | eu | au. Multiple can be specified if comma delimited.\n",
    "# More info at https://the-odds-api.com/sports-odds-data/bookmaker-apis.html\n",
    "REGIONS = 'us' \n",
    "\n",
    "# Odds markets\n",
    "# h2h | spreads | totals. Multiple can be specified if comma delimited\n",
    "# More info at https://the-odds-api.com/sports-odds-data/betting-markets.html\n",
    "# Note only featured markets (h2h, spreads, totals) are available with the historical odds endpoint.\n",
    "MARKETS = ('h2h,spreads,totals')\n",
    "\n",
    "# Odds format\n",
    "# decimal | american\n",
    "ODDS_FORMAT = 'american'\n",
    "\n",
    "# Date format\n",
    "# iso | unix\n",
    "DATE_FORMAT = 'iso'\n",
    "\n",
    "# Historical timestamp\n",
    "# Must be in ISO8601 format\n",
    "DATE = '2022-04-07T23:10:00Z'\n",
    "\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
    "#\n",
    "# Query bookmaker odds for live and upcoming games as they were at the specified DATE parameter.\n",
    "# The usage quota cost = 10 x [number of markets specified] x [number of regions specified]\n",
    "# For examples of usage quota costs, see https://the-odds-api.com/liveapi/guides/v4/#usage-quota-costs-3\n",
    "#\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
    "\n",
    "\n",
    "def extract_odds_api(API_KEY, SPORT, REGIONS, MARKETS, ODDS_FORMAT, DATE_FORMAT, DATE):\n",
    "    odds_response = requests.get(f'https://api.the-odds-api.com/v4/historical/sports/{SPORT}/odds', params={\n",
    "        'api_key': API_KEY,\n",
    "        'regions': REGIONS,\n",
    "        'markets': MARKETS,\n",
    "        'oddsFormat': ODDS_FORMAT,\n",
    "        'dateFormat': DATE_FORMAT,\n",
    "        'date': DATE,\n",
    "    })\n",
    "\n",
    "    if odds_response.status_code != 200:\n",
    "        print(f'Failed to get odds: status_code {odds_response.status_code}, response body {odds_response.text}')\n",
    "\n",
    "    else:\n",
    "        odds_json = odds_response.json()\n",
    "\n",
    "        # print(json.dumps(odds_json['data'], indent=4))\n",
    "\n",
    "        print(f\"Timestamp: {odds_json['timestamp']}\")\n",
    "        print(f\"Previous available timestamp: {odds_json['previous_timestamp']}\")\n",
    "        print(f\"Next available timestamp: {odds_json['next_timestamp']}\")\n",
    "\n",
    "        # Check the usage quota\n",
    "        print('Remaining requests', odds_response.headers['x-requests-remaining'])\n",
    "        print('Used requests', odds_response.headers['x-requests-used'])\n",
    "        \n",
    "    return odds_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6029d5da-c95e-4500-830b-70af5f92baf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "026c5df1-1f8b-4784-ba2a-dcf7b03979ca",
   "metadata": {},
   "source": [
    "# Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "226ae922-a014-4887-8849-b21c6c752fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2022-06-11T00:05:00Z\n",
      "Previous available timestamp: 2022-06-10T23:55:00Z\n",
      "Next available timestamp: 2022-06-11T00:15:00Z\n",
      "Remaining requests 47\n",
      "Used requests 19953\n",
      "Timestamp: 2022-06-11T00:15:00Z\n",
      "Previous available timestamp: 2022-06-11T00:05:00Z\n",
      "Next available timestamp: 2022-06-11T00:25:00Z\n",
      "Remaining requests 17\n",
      "Used requests 19983\n"
     ]
    }
   ],
   "source": [
    "# # Loop over unique datetimes\n",
    "# # Start at 659 next time.\n",
    "# for datetime in unique_datetimes[657:659]:\n",
    "#     # Extract odds\n",
    "#     odds_json = extract_odds_api(API_KEY, SPORT, REGIONS, MARKETS, ODDS_FORMAT, DATE_FORMAT, datetime)\n",
    "    \n",
    "#     # Convert date to usable name\n",
    "#     datetime = datetime.replace(\":\", \"\")\n",
    "    \n",
    "#     # Open the file in write mode and write the JSON data to it\n",
    "#     with open(os.path.join(baseball_path, \"A08. Odds API\", \"Raw\", f\"{datetime}.txt\"), \"w\") as file:\n",
    "#         json.dump(odds_json, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f5e4da-13ab-42de-9adc-1f7ae6ef4378",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "341313c0-8a94-45c4-8739-0ff95e43253d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_json(datetime):\n",
    "    # Format to match text file\n",
    "    datetime = datetime.replace(\":\", \"\")\n",
    "    \n",
    "    # Open the file in read mode and load the JSON data\n",
    "    with open(os.path.join(baseball_path, \"A08. Odds API\", \"Raw\", f\"{datetime}.txt\"), 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "        \n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d879655f-8d56-4a57-b964-6e9e375740c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_json(json_data):\n",
    "    # Extracting the 'data' part from your JSON\n",
    "    data = json_data['data']\n",
    "\n",
    "    # Creating an empty list to store the extracted information\n",
    "    all_data = []\n",
    "\n",
    "    # Looping through each item in the data\n",
    "    for item in data:\n",
    "        id = item['id']\n",
    "        sport_key = item['sport_key']\n",
    "        commence_time = item['commence_time']\n",
    "        home_team = item['home_team']\n",
    "        away_team = item['away_team']\n",
    "\n",
    "        bookmakers = item['bookmakers']\n",
    "\n",
    "        for bookmaker in bookmakers:\n",
    "            book = bookmaker['key']\n",
    "\n",
    "            markets = bookmaker['markets']\n",
    "\n",
    "            for market in markets:\n",
    "                bet = market['key']\n",
    "                last_update = market['last_update']\n",
    "\n",
    "                outcomes = market['outcomes']\n",
    "\n",
    "                for outcome in outcomes:\n",
    "                    name = outcome['name']\n",
    "                    price = outcome['price']\n",
    "                    if bet in ['spreads', 'totals']:\n",
    "                        point = outcome['point']\n",
    "                    else:\n",
    "                        point = \"0\"\n",
    "\n",
    "                    row = [id, sport_key, commence_time, away_team, home_team, book, bet, last_update, name, price, point]\n",
    "\n",
    "                    all_data.append(row)\n",
    "\n",
    "\n",
    "    # Creating a DataFrame from the list of extracted information\n",
    "    df = pd.DataFrame(all_data, columns=['id', 'sport_key', 'commence_time', 'away_team', 'home_team', 'book', 'bet', 'last_update', 'side', 'price', 'point'])\n",
    "\n",
    "    # Create a mask to identify rows where df['bet'] is not equal to \"totals\"\n",
    "    mask = df['bet'] != \"totals\"\n",
    "\n",
    "    # Apply the condition only to the rows identified by the mask\n",
    "    df.loc[mask, 'side'] = np.where(df.loc[mask, 'side'] == df.loc[mask, 'away_team'], 'Away', 'Home')\n",
    "\n",
    "    \n",
    "    # Pivot the dataframe\n",
    "    pivot_df = df.pivot_table(index=['id', 'sport_key', 'book', 'commence_time', 'away_team', 'home_team', 'last_update'],\n",
    "                              columns=['bet', 'side'],\n",
    "                              values=['price', 'point'],\n",
    "                              aggfunc='first')\n",
    "\n",
    "    # Flatten column names\n",
    "    new_columns = []\n",
    "    for col in pivot_df.columns:\n",
    "        new_col = '_'.join(col)\n",
    "        new_columns.append(new_col)\n",
    "    pivot_df.columns = new_columns\n",
    "\n",
    "    # Reset index to make it flat\n",
    "    final_df = pivot_df.reset_index()\n",
    "\n",
    "    final_df = final_df.merge(team_map[['FULLNAME', 'BASEBALLPRESSTEAM']], left_on='away_team', right_on='FULLNAME', how='left')\n",
    "    final_df = final_df.merge(team_map[['FULLNAME', 'BASEBALLPRESSTEAM']], left_on='home_team', right_on='FULLNAME', how='left')\n",
    "\n",
    "    final_df.rename(columns={'BASEBALLPRESSTEAM_x':'VisitorTeamShort', 'BASEBALLPRESSTEAM_y':'HomeTeamShort'}, inplace=True)\n",
    "    final_df.rename(columns={'point_spreads_Home':'Spread', 'point_totals_Over':'OU'}, inplace=True)\n",
    "    final_df.rename(columns={'price_spreads_Away':'SpreadMoney1', 'price_spreads_Home':'SpreadMoney2'}, inplace=True)\n",
    "    final_df.rename(columns={'price_totals_Over':'OuMoney1', 'price_totals_Under':'OuMoney2'}, inplace=True)\n",
    "    final_df.rename(columns={'price_h2h_Away':'MLMoney1', 'price_h2h_Home':'MLMoney2'}, inplace=True)\n",
    "    final_df.rename(columns={'commence_time':'EventDateTime'}, inplace=True)\n",
    "    final_df['date'] = pd.to_datetime(final_df['EventDateTime']).dt.strftime('%Y%m%d')\n",
    "\n",
    "    # Maintaining to keep compatibility with Fantasy Labs. Could calculate on my own later.\n",
    "    final_df['VisitorVegasRuns'] = np.nan\n",
    "    final_df['HomeVegasRuns'] = np.nan\n",
    "\n",
    "    final_df = final_df[['book', 'last_update', 'VisitorTeamShort', 'HomeTeamShort', 'Spread', 'OU', 'SpreadMoney1', 'SpreadMoney2', 'OuMoney1', 'OuMoney2', 'MLMoney1', 'MLMoney2', 'VisitorVegasRuns', 'HomeVegasRuns', 'EventDateTime', 'date']]\n",
    "\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495c319d-ed89-4301-accc-9f08819ccc18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "aa013a39-e8d0-430c-ae56-929261a3ce46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def closing_lines(all_games_df, date):\n",
    "    # Merge in BASEBALLPRESSTEAM for away team so we can identify matchups better.\n",
    "    all_games_df = all_games_df.merge(team_map[['BBREFTEAM', 'BASEBALLPRESSTEAM']], left_on='away_team', right_on='BBREFTEAM', how='left')\n",
    "    \n",
    "    # Extract games from specified date\n",
    "    df = all_games_df.query(f'date == \"{date}\"').reset_index(drop=True)\n",
    "    \n",
    "    # List of closing lines\n",
    "    closing_lines = []\n",
    "    # Loop over games\n",
    "    for i in range(len(df)):\n",
    "        # Identify datetime\n",
    "        datetime = df['game_datetime'][i]\n",
    "        \n",
    "        # Read in relevant json data\n",
    "        json_data = read_json(datetime)\n",
    "        odds_df = clean_json(json_data)\n",
    "        \n",
    "        # Identify away team \n",
    "        away_team = df['BASEBALLPRESSTEAM'][i]\n",
    "        # Only keep odds for that away team (should be their last update before start)\n",
    "        odds_df = odds_df[odds_df['VisitorTeamShort'] == away_team]\n",
    "        \n",
    "        \n",
    "        # Select books:\n",
    "        # Could do average or best (recent) odds.\n",
    "        \n",
    "        odds_df = odds_df.query('book == \"betmgm\"')\n",
    "        \n",
    "        # Avoid doubleheaders\n",
    "        odds_df.drop_duplicates('VisitorTeamShort', keep='first', inplace=True)\n",
    "        \n",
    "        # Add file\n",
    "        odds_df['file'] = datetime.replace(\":\", \"\")\n",
    "        \n",
    "        closing_lines.append(odds_df)\n",
    "        \n",
    "    # Concatenate all together\n",
    "    closing_line_df = pd.concat(closing_lines, axis=0).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    return closing_line_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d5b726d1-c4d3-4955-abf6-f3b3d62919df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20220407\n",
      "20220408\n",
      "20220409\n",
      "20220410\n",
      "20220411\n",
      "20220412\n",
      "20220413\n",
      "20220414\n",
      "20220415\n",
      "20220416\n",
      "20220417\n",
      "20220418\n",
      "20220419\n",
      "20220420\n",
      "20220421\n",
      "20220422\n",
      "20220423\n",
      "20220424\n",
      "20220425\n",
      "20220426\n",
      "20220427\n",
      "20220428\n",
      "20220429\n",
      "20220430\n",
      "20220501\n",
      "20220502\n",
      "20220503\n",
      "20220504\n",
      "20220505\n",
      "20220506\n",
      "20220507\n",
      "20220508\n",
      "20220509\n",
      "20220510\n",
      "20220511\n",
      "20220512\n",
      "20220513\n",
      "20220514\n",
      "20220515\n",
      "20220516\n",
      "20220517\n",
      "20220518\n",
      "20220519\n",
      "20220520\n",
      "20220521\n",
      "20220522\n",
      "20220523\n",
      "20220524\n",
      "20220525\n",
      "20220526\n",
      "20220527\n",
      "20220528\n",
      "20220529\n",
      "20220530\n",
      "20220531\n",
      "20220601\n",
      "20220602\n",
      "20220603\n",
      "20220604\n",
      "20220605\n",
      "20220606\n",
      "20220607\n",
      "20220608\n",
      "20220609\n",
      "20220610\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\james\\\\Documents\\\\MLB\\\\Database\\\\A08. Odds API\\\\Raw\\\\2022-06-11T013800Z.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[102], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m all_games_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(date)\n\u001b[1;32m----> 3\u001b[0m     daily_game_df \u001b[38;5;241m=\u001b[39m \u001b[43mclosing_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_games_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     daily_game_df\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(baseball_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA08. Odds API\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOdds \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[101], line 16\u001b[0m, in \u001b[0;36mclosing_lines\u001b[1;34m(all_games_df, date)\u001b[0m\n\u001b[0;32m     13\u001b[0m datetime \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgame_datetime\u001b[39m\u001b[38;5;124m'\u001b[39m][i]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Read in relevant json data\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m json_data \u001b[38;5;241m=\u001b[39m \u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatetime\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m odds_df \u001b[38;5;241m=\u001b[39m clean_json(json_data)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Identify away team \u001b[39;00m\n",
      "Cell \u001b[1;32mIn[83], line 6\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(datetime)\u001b[0m\n\u001b[0;32m      3\u001b[0m datetime \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Open the file in read mode and load the JSON data\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbaseball_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mA08. Odds API\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRaw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdatetime\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      7\u001b[0m     json_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m json_data\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MLB\\lib\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\james\\\\Documents\\\\MLB\\\\Database\\\\A08. Odds API\\\\Raw\\\\2022-06-11T013800Z.txt'"
     ]
    }
   ],
   "source": [
    "for date in all_games_df['date'].unique():\n",
    "    print(date)\n",
    "    daily_game_df = closing_lines(all_games_df, date)\n",
    "    daily_game_df.to_csv(os.path.join(baseball_path, \"A08. Odds API\", \"Clean\", f\"Odds {date}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded468a5-26de-49dc-acef-44137ddccc47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
