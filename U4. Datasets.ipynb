{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e5d0f6-3979-4a21-a770-fbc7209992ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in boxscore for weather\n",
    "def create_box(gamePk):\n",
    "    # Read in boxscore as json\n",
    "    box = pd.json_normalize(statsapi.boxscore_data(gamePk, timecode=None), record_path='gameBoxInfo')\n",
    "    \n",
    "    # Define default values\n",
    "    default_weather = \"75 degrees, Clear.\"\n",
    "    default_wind = \"0 mph, L To R.\"\n",
    "    default_venue = \"Missing Park.\"\n",
    "    default_date = \"November 30, 1993\"\n",
    "    \n",
    "    # Extract weather, wind, venue, and date\n",
    "    weather = box.loc[box['label'] == \"Weather\", \"value\"].item() if 'Weather' in box['label'].values else default_weather\n",
    "    wind = box.loc[box['label'] == \"Wind\", \"value\"].item() if 'Wind' in box['label'].values else default_wind\n",
    "    venue = box.loc[box['label'] == \"Venue\", \"value\"].item() if 'Venue' in box['label'].values else default_venue\n",
    "    \n",
    "    try:\n",
    "        date = box.iloc[-1, box.columns.get_loc('label')]\n",
    "    except:\n",
    "        date = default_date\n",
    "\n",
    "    if \"Weather\" not in list(box['label']):\n",
    "        missing_weather = True\n",
    "    else:\n",
    "        missing_weather = False\n",
    "        \n",
    "    \n",
    "    \n",
    "    return weather, wind, venue, date, missing_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671be6f8-e3ca-42bf-ac8f-5a11c49071e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This instance of startdata can be cut - fixed it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cec745-caa0-4285-9959-0b95c0f16713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This creates information about starts for use in pulling pitchers\n",
    "# def start_data(df):\n",
    "#     # Calculate the sum for each group\n",
    "#     df['br'] = df[['b1', 'b2', 'b3', 'hr', 'bb', 'hbp']].astype('float').sum(axis=1)\n",
    "\n",
    "#     # Calculate the cumulative sum within each group\n",
    "#     df['br_inning'] = df.groupby(['gamePk', 'inning', 'halfInning'])['br'].cumsum()\n",
    "    \n",
    "#     # Convert to numeric\n",
    "#     df['inning'] = pd.to_numeric(df['inning'])\n",
    "#     df['outs'] = pd.to_numeric(df['outs'])\n",
    "#     df['rbi'] = df['rbi'].astype('int')\n",
    "    \n",
    "#     # Number of batters faced (will be used to calculate rolling sum)\n",
    "#     df['faced'] = 1\n",
    "    \n",
    "#     # Cumulative counts\n",
    "#     # Stats to sum\n",
    "#     sums_list = ['gamePk', 'pitcher'] + events_list + ['rbi', 'faced']\n",
    "#     # Calculate\n",
    "#     sums = df[sums_list].groupby(['gamePk', 'pitcher']).cumsum()\n",
    "#     # Add suffix\n",
    "#     sums = sums.add_suffix(\"_sum\")\n",
    "    \n",
    "#     # Add rolling sums\n",
    "#     df = pd.concat([df, sums], axis=1)\n",
    "    \n",
    "#     # Identify if it's the bottom of the inning (a little more helpful than \"top\" as it's sortable)\n",
    "#     df['bottom'] = (df['top'] == 0).astype('int')\n",
    "    \n",
    "#     # Sort to identify starting pitchers\n",
    "#     df = df.sort_values(by=['date', 'gamePk', 'bottom', 'atBatIndex'])\n",
    "    \n",
    "#     # The starter has the lowest atBatIndex\n",
    "#     df['atBatIndex_min'] = df.groupby(['gamePk', 'bottom'])['atBatIndex'].transform('min')\n",
    "#     df['first_ab'] = (df['atBatIndex'] == df['atBatIndex_min']).astype('int')\n",
    "        \n",
    "#     # Identify starter throughout\n",
    "#     df['starter'] = df.groupby(['pitcher', 'gamePk'])['first_ab'].cumsum()\n",
    "    \n",
    "#     # Keep only starters\n",
    "#     df = df.query('starter == 1')\n",
    "    \n",
    "#     # The starter is pulled at their highest atBatIndex\n",
    "#     df['atBatIndex_max'] = df.groupby(['gamePk', 'bottom'])['atBatIndex'].transform('max')\n",
    "#     df['pulled'] = (df['atBatIndex'] == df['atBatIndex_max']).astype('int')\n",
    "    \n",
    "#     # Batters faced that inning\n",
    "#     df['faced_inning'] = df.groupby(['gamePk', 'inning', 'bottom']).cumcount()+1\n",
    "#     df['faced_inning'] = np.where(df['outs'] == 3, 0, df['faced_inning'])\n",
    "    \n",
    "#     # Rolling sums stats (post-rolling sum)\n",
    "#     rolled_sums_list = [f'{stat}_sum' for stat in events_list] + ['rbi_sum', 'faced_sum']\n",
    "    \n",
    "#     # Outs recorded by starting pitcher \n",
    "#     df['OUT'] = ((df['inning'] - 1) * 3) + df['outs']\n",
    "    \n",
    "#     # This adjusts timing to better reflect when pitchers are pulled\n",
    "#     # If a pitcher is pulled after 6 innings in the data, that's the same as pulling at the top of the 7th, which more closely reflects how the sim works\n",
    "#     df['inning_adj'] = df['inning'] + (df['outs'] == 3).astype('int')\n",
    "#     df['outs_adj'] = np.where(df['outs'] == 3, 0, df['outs'])\n",
    "\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c5acb4-9cbe-460e-b824-ebe49417a56e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fe547cf-a769-4a55-b045-3b64196406e4",
   "metadata": {},
   "source": [
    "##### 1. Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6301ff8f-a957-4c1a-a179-996c9cadd3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_datasets(start_year=2015, end_year=2024):\n",
    "    # List of merged datasets\n",
    "    df_list = []\n",
    "    # Read in datasets\n",
    "    for year in range(start_year, end_year+1):\n",
    "        statsapi_df = pd.read_csv(os.path.join(baseball_path, \"A02. MLB API\", \"1. Stats API\", f\"Stats API {year}.csv\"), encoding='iso-8859-1')\n",
    "        statcast_df = pd.read_csv(os.path.join(baseball_path, \"A02. MLB API\", \"2. Statcast\", f\"Statcast {year}.csv\"), encoding='iso-8859-1')\n",
    "        \n",
    "        # Merge them together\n",
    "        merged_df = pd.merge(statsapi_df, statcast_df, on=['gamePk', 'atBatIndex'], how='left', suffixes=(\"\", \"_copy\"))\n",
    "\n",
    "        # Drop duplicate observations\n",
    "        merged_df.drop_duplicates(['gamePk', 'atBatIndex'], keep='first', inplace=True)\n",
    "        \n",
    "        # Drop duplicate variables\n",
    "        merged_df.drop(columns={'game_type_copy'}, inplace=True)\n",
    "        \n",
    "        # Add them to a list\n",
    "        df_list.append(merged_df)\n",
    "        \n",
    "    # Create raw dataset\n",
    "    df = pd.concat(df_list, axis=0)\n",
    "    \n",
    "    # Sort\n",
    "    df.sort_values(['game_date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "\n",
    "    # Only keep one observation per at bat\n",
    "    df.drop_duplicates(['gamePk', 'atBatIndex'], keep='first', inplace=True)\n",
    "    \n",
    "    # Reset index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ce5d5f-5e1e-4d14-9b39-9a73e2836397",
   "metadata": {},
   "source": [
    "##### 2. Clean Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe770413-e196-4f24-81e4-af1d677f765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive to centerfield, negative from centerfield\n",
    "def y_vect(df):\n",
    "    wind_speed = df['windSpeed']\n",
    "    angled = df['windSpeed'] / 2 * math.sqrt(2)\n",
    "    \n",
    "    if df['windDirection'] == \"Out To CF\": \n",
    "        y_vect = wind_speed\n",
    "    elif df['windDirection'] == \"Out To RF\": \n",
    "        y_vect = angled\n",
    "    elif df['windDirection'] == \"L To R\": \n",
    "        y_vect = 0\n",
    "    elif df['windDirection'] == \"In From LF\": \n",
    "        y_vect = angled * -1\n",
    "    elif df['windDirection'] == \"In From CF\": \n",
    "        y_vect = wind_speed * - 1\n",
    "    elif df['windDirection'] == \"In From RF\": \n",
    "        y_vect = angled * -1\n",
    "    elif df['windDirection'] == \"R To L\": \n",
    "        y_vect = 0\n",
    "    elif df['windDirection'] == \"Out To LF\": \n",
    "        y_vect = angled\n",
    "    else:\n",
    "        y_vect = 0\n",
    "\n",
    "    \n",
    "    return y_vect\n",
    "\n",
    "# Positive from left to right, negative from right to left\n",
    "def x_vect(df):\n",
    "    wind_speed = df['windSpeed']\n",
    "    angled = df['windSpeed'] / 2 * math.sqrt(2)\n",
    "    \n",
    "    if df['windDirection'] == \"L To R\": \n",
    "        x_vect = wind_speed\n",
    "    elif df['windDirection'] == \"In From LF\": \n",
    "        x_vect = angled\n",
    "    elif df['windDirection'] == \"In From CF\": \n",
    "        x_vect = 0\n",
    "    elif df['windDirection'] == \"In From RF\": \n",
    "        x_vect = angled * -1\n",
    "    elif df['windDirection'] == \"R To L\": \n",
    "        x_vect = wind_speed * - 1\n",
    "    elif df['windDirection'] == \"Out To LF\": \n",
    "        x_vect = angled * -1\n",
    "    elif df['windDirection'] == \"Out To CF\": \n",
    "        x_vect = 0\n",
    "    elif df['windDirection'] == \"Out To RF\": \n",
    "        x_vect = angled\n",
    "    else:\n",
    "        x_vect = 0\n",
    "\n",
    "    \n",
    "    return x_vect\n",
    "\n",
    "# 2 is to centerfield, 6 is from centerfield, clockwise\n",
    "# Assumption is wind is blowing in 8 cardinal directions, so we can use simple right isosceles triangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fd07eb1-f8ea-490a-9116-288b54e6f5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_weather(df):  \n",
    "    # Separate weather into temperature and weather type\n",
    "    df[['temperature', 'weather']] = df['weather'].str.split(\", \", expand=True)\n",
    "    df['temperature'] = df['temperature'].str.replace(\" degrees\", \"\").astype('int')\n",
    "    # Separate wind into speed and direction\n",
    "    df[['windSpeed', 'windDirection']] = df['wind'].str.split(\", \", expand=True)\n",
    "    df['windSpeed'].fillna(\"0 mph\", inplace=True)\n",
    "    df['windSpeed'] = df['windSpeed'].str.replace(\" mph\", \"\")\n",
    "    df['windSpeed'] = pd.to_numeric(df['windSpeed'], errors='coerce')\n",
    "    df['windSpeed'].fillna(0, inplace=True)\n",
    "    df['windDirection'].fillna('L to R', inplace=True)\n",
    "    df['windDirection'] = df['windDirection'].str.replace(\".\", \"\")\n",
    "    # Calculate vectors\n",
    "    df['x_vect'] = df.apply(x_vect, axis=1)\n",
    "    df['y_vect'] = df.apply(y_vect, axis=1)\n",
    "\n",
    "\n",
    "    ### TESTING:\n",
    "    # Set temperature to 70 degrees if it's a dome or the roof is close\n",
    "    df['temperature'] = df.apply(lambda row: 70 if 'Roof' in row['weather'] or 'Dome' in row['weather'] else row['temperature'], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c88c9b0-0cdd-4814-b2be-8ba2f3b3af3e",
   "metadata": {},
   "source": [
    "##### 3. Create PA Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0c0bed1-43d5-4976-8bbc-3d3743518e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign play categories to full descriptions\n",
    "def create_events(df):\n",
    "    event_mapping = {\n",
    "        'Strikeout': 'so',\n",
    "        'Strikeout Double Play': 'so',\n",
    "        'Groundout': 'go',\n",
    "        'Fielders Choice': 'go',\n",
    "        'Fielders Choice Out': 'go',\n",
    "        'Double Play': 'go',\n",
    "        'Grounded Into DP': 'go',\n",
    "        'Triple Play': 'go',\n",
    "        'Field Error': 'go',\n",
    "        'Forceout': 'go',\n",
    "        'Sac Bunt': 'go',\n",
    "        'Sac Bunt Double Play': 'go', \n",
    "        'Bunt Groundout': 'go',\n",
    "        'Lineout': 'lo',\n",
    "        'Bunt Lineout': 'lo',\n",
    "        'Flyout': 'fo',\n",
    "        'Sac Fly': 'fo',\n",
    "        'Sac Fly Double Play': 'fo',\n",
    "        'Pop Out': 'po',\n",
    "        'Bunt Pop Out': 'po',\n",
    "        'Hit By Pitch': 'hbp',\n",
    "        'Walk': 'bb',\n",
    "        'Intent Walk': 'bb',\n",
    "        'Single': 'b1',\n",
    "        'Double': 'b2',\n",
    "        'Triple': 'b3',\n",
    "        'Home Run': 'hr'\n",
    "    }\n",
    "\n",
    "    df['eventsModel'] = df['event'].map(event_mapping).fillna('Cut')\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7368a3-1ae2-4fe5-9bd2-bf265e46bc96",
   "metadata": {},
   "source": [
    "##### 4. Create Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b97c232-0f40-4761-93a9-6e9b7bf93f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This turns several variables, including events, venues, hands, and bases into dummies\n",
    "def create_variables(df):    \n",
    "    # Events\n",
    "    event_dummies = pd.get_dummies(df['eventsModel'])\n",
    "    \n",
    "    # Venues\n",
    "    df['venue_id'] = df['venue_id'].astype('str')\n",
    "    # venue_dummies = pd.get_dummies(df['venue_id'], prefix='venue')\n",
    "    # Hands\n",
    "    pitcher_dummies = pd.get_dummies(df['pitchHand'], prefix='p')\n",
    "    batter_dummies = pd.get_dummies(df['batSide'], prefix='b')\n",
    "    # Years\n",
    "    df['year'] = df['game_date'].str[:4]\n",
    "    # year_dummies = pd.get_dummies(df['year'], prefix='year')\n",
    "    \n",
    "    # Add dummies to dataframe\n",
    "    # df = pd.concat([df, event_dummies, venue_dummies, pitcher_dummies, batter_dummies, year_dummies], axis=1)\n",
    "    df = pd.concat([df, event_dummies, pitcher_dummies, batter_dummies], axis=1)\n",
    "\n",
    "    # Identify starting pitcher\n",
    "    df['startingPitcher'] = df.groupby(['gamePk', 'halfInning'])['pitcherName'].transform('first')\n",
    "    df['starter'] = (df['startingPitcher'] == df['pitcherName']).astype('int')\n",
    "    \n",
    "    # Determine outs coming into PA\n",
    "    df['outs_pre'] = df.groupby(['gamePk', 'inning', 'halfInning'])['outs'].shift(fill_value=0)\n",
    "    \n",
    "    # Determine if PA ended in an out \n",
    "    df['is_out'] = df[['so', 'go', 'lo', 'po', 'fo']].sum(axis=1)\n",
    "    \n",
    "    # Create compatible date variable\n",
    "    df['date'] = df['game_date'].str.replace('-', '')\n",
    "    \n",
    "    # Convert to numeric for sorting\n",
    "    df['date'] = df['date'].astype('int')\n",
    "    df['gamePk'] = df['gamePk'].astype('int')\n",
    "    df['atBatIndex'] = df['atBatIndex'].astype('int')\n",
    "    \n",
    "    # Sort\n",
    "    df.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "    \n",
    "    # Create dummy for runners on base\n",
    "    df['preOnFirst'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnFirst'].shift(1)\n",
    "    df['preOnSecond'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnSecond'].shift(1)\n",
    "    df['preOnThird'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnThird'].shift(1)\n",
    "    \n",
    "    df['onFirst'] = df['preOnFirst'].apply(lambda x: 1 if isinstance(x, str) and 'id' in x else 0)\n",
    "    df['onSecond'] = df['preOnSecond'].apply(lambda x: 1 if isinstance(x, str) and 'id' in x else 0)\n",
    "    df['onThird'] = df['preOnThird'].apply(lambda x: 1 if isinstance(x, str) and 'id' in x else 0)\n",
    "    \n",
    "    # Top of the inning dummy\n",
    "    df['top'] = np.where(df['halfInning'] == \"top\", 1, 0)\n",
    "    \n",
    "    # Convert to numeric\n",
    "    df['awayScore'] = df['awayScore'].astype('int')\n",
    "    df['homeScore'] = df['homeScore'].astype('int')\n",
    "    \n",
    "    # Determine score before PA\n",
    "    df['preAwayScore'] = df.groupby(['gamePk'])['awayScore'].shift(1)\n",
    "    df['preHomeScore'] = df.groupby(['gamePk'])['homeScore'].shift(1)\n",
    "    \n",
    "    # If it's the first PA, it'll be missing. \n",
    "    df['preAwayScore'] = df['preAwayScore'].fillna(0)\n",
    "    df['preHomeScore'] = df['preHomeScore'].fillna(0)\n",
    "    \n",
    "    # Calculate differential\n",
    "    df['score_diff'] = np.where(df['top'] == 1, df['preAwayScore'] - df['preHomeScore'], df['preHomeScore'] - df['preAwayScore'])\n",
    "    \n",
    "    # Determine hitter and pitcher scores\n",
    "    df['batterScore'] = np.where(df['halfInning'] == 'top', df['awayScore'], df['homeScore'])\n",
    "    df['pitcherScore'] = np.where(df['halfInning'] == 'top', df['homeScore'], df['awayScore'])\n",
    "    \n",
    "    # Determine score before PA\n",
    "    df['preBatterScore'] = np.where(df['halfInning'] == 'top', df['preAwayScore'], df['preHomeScore'])\n",
    "    df['prePitcherScore'] = np.where(df['halfInning'] == 'top', df['preHomeScore'], df['preAwayScore'])\n",
    "    \n",
    "    # Calculate PAs and ABs\n",
    "    df['pa'] = np.where(df['eventsModel'] != \"Cut\", 1, 0)\n",
    "    df['ab'] = df['pa'] - df['hbp'] - df['bb']           \n",
    "    \n",
    "    \n",
    "    # Fix Guardians name to make uniform\n",
    "    df['away_name'] = np.where(df['away_name'] == \"Cleveland Indians\", \"Cleveland Guardians\", df['away_name'])\n",
    "    df['home_name'] = np.where(df['home_name'] == \"Cleveland Indians\", \"Cleveland Guardians\", df['home_name'])\n",
    "\n",
    "    \n",
    "    ### Statcast\n",
    "    # Convert variables to numeric\n",
    "    df['launch_speed'] = pd.to_numeric(df['launch_speed'], errors='coerce')\n",
    "    df['launch_speed_angle'] = pd.to_numeric(df['launch_speed_angle'], errors='coerce')\n",
    "    df['hc_x'] = pd.to_numeric(df['hc_x'], errors='coerce')\n",
    "    df['hc_y'] = pd.to_numeric(df['hc_y'], errors='coerce')\n",
    "    \n",
    "    # Hard hit dummy\n",
    "    df['hard_hit'] = (df['launch_speed'] >= 95).astype('int')\n",
    "    \n",
    "    # Barrel dummy\n",
    "    df['barrel'] = (df['launch_speed_angle'] == 6).astype('int')\n",
    "\n",
    "    # Spray \n",
    "    df['spray_angle'] = np.arctan((df['hc_x'] - 125.42) / (198.27 - df['hc_y'])) * 180 / np.pi * 0.75\n",
    "    df['to_left'] = (df['spray_angle'] < -15).astype('int')\n",
    "    df['to_middle'] = ((df['spray_angle'] >= -15) & (df['spray_angle'] <= 15)).astype('int')\n",
    "    df['to_right'] = (df['spray_angle'] > 15).astype('int')\n",
    "\n",
    "    \n",
    "        \n",
    "    # Sort\n",
    "    df.sort_values(['date', 'gamePk', 'atBatIndex'], inplace=True)\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34750e0a-9132-403f-81f9-7577815ca00e",
   "metadata": {},
   "source": [
    "##### 5. Park Adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d6fd63-b9fe-43a4-addd-577ad84ed686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New park adjustments\n",
    "def park_adjustments(df, multiplier_df):       \n",
    "    # Merge with park factors\n",
    "    pfx_columns = [col for col in multiplier_df.columns if \"pfx\" in col]\n",
    "    wfx_columns = [col for col in multiplier_df.columns if \"wfx\" in col]\n",
    "    df = df.merge(multiplier_df[['gamePk'] + pfx_columns + wfx_columns], on=['gamePk'], how='left')\n",
    "    df[pfx_columns] = df[pfx_columns].fillna(1)\n",
    "    df[wfx_columns] = df[wfx_columns].fillna(1)\n",
    "\n",
    "    # Loop over events\n",
    "    for event in events_list:\n",
    "        # Adjust based on calculated multiplier\n",
    "        df[f'{event}_adj'] = np.where(df['batSide'] == \"L\", df[event].astype(float) / df[f'{event}_wfx_l'].astype(float), df[event].astype(float) / df[f'{event}_wfx_r'].astype(float))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af98d36a-9485-4652-a334-4a2118a18d7a",
   "metadata": {},
   "source": [
    "##### 6. Rolling Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2f862055-9a96-49e2-8844-6fde8b4bb5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return a dataframe that can eventually be used as the model input. Has pitcher vs hitter stats, specific to hand\n",
    "def rolling_pas(df, pa_num):\n",
    "    # Copy dataframe\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Note: batter_avg_short will work even when pa_num refers to the \"long\" period. Suffix will be added in post.\n",
    "    # Rename for compatibility purposes\n",
    "    df_copy.rename(columns={'hit_distance_sc':'totalDistance', 'launch_speed':'launchSpeed'}, inplace=True)          \n",
    "            \n",
    "    # Convert to numeric and fill with 0s\n",
    "    combined_list = avg_list + max_list\n",
    "    for col in combined_list:\n",
    "        # Check if the column is not numeric\n",
    "        if not pd.api.types.is_numeric_dtype(df_copy[col]):\n",
    "            # Convert the non-numeric column to numeric and fill missing values with 0\n",
    "            df_copy[col] = pd.to_numeric(df_copy[col], errors='coerce')\n",
    "            df_copy[col] = df_copy[col].fillna(0)\n",
    "\n",
    "    # Sort\n",
    "    df_copy.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "            \n",
    "    # Data types may vary. This makes grouping impossible. \n",
    "    df_copy['batter'] = df_copy['batter'].astype('int')\n",
    "    df_copy['pitcher'] = df_copy['pitcher'].astype('int')\n",
    "        \n",
    "    ### Batter stats \n",
    "    # Stats for which you want the average \n",
    "    df_copy[batter_avg_short] = df_copy.groupby(['batter', 'pitchHand'])[events_list_adj + statcast_list].transform(lambda x: x.rolling(pa_num, min_periods=1).mean())\n",
    "    # Stats for which you want the maximum\n",
    "    df_copy[batter_max_short] = df_copy.groupby(['batter', 'pitchHand'])[max_list].transform(lambda x: x.rolling(pa_num, min_periods=1).max())\n",
    "    # Stats for which you just want the sum \n",
    "    df_copy[['ab_b', 'pa_b']] = df_copy.groupby(['batter', 'pitchHand'])[['ab', 'pa']].transform(lambda x: x.rolling(pa_num, min_periods=1).sum())\n",
    "                \n",
    "    ### Pitcher stats\n",
    "    # Stats for which you want the average\n",
    "    df_copy[pitcher_avg_short] = df_copy.groupby(['pitcher', 'batSide'])[events_list_adj + statcast_list].transform(lambda x: x.rolling(pa_num, min_periods=1).mean())\n",
    "    # Stats for which you want the maximum\n",
    "    df_copy[pitcher_max_short] = df_copy.groupby(['pitcher', 'batSide'])[max_list].transform(lambda x: x.rolling(pa_num, min_periods=1).max())\n",
    "    # Stats for which you just want the sum \n",
    "    df_copy[['ab_p', 'pa_p']] = df_copy.groupby(['pitcher', 'batSide'])[['ab', 'pa']].transform(lambda x: x.rolling(pa_num, min_periods=1).sum())\n",
    "                \n",
    "        \n",
    "    # Create imputation flags (these observations will have imputed inputs)\n",
    "    df_copy['imp_b'] = (df_copy['pa_b'] < 40).astype('int')\n",
    "    df_copy['imp_p'] = (df_copy['pa_p'] < 40).astype('int')\n",
    "\n",
    "    # Create compatible date variable\n",
    "    df_copy['date'] = df_copy['game_date'].str.replace('-', '')\n",
    "    \n",
    "    # Convert to numeric for sorting\n",
    "    df_copy['date'] = df_copy['date'].astype('int')\n",
    "    df_copy['gamePk'] = df_copy['gamePk'].astype('int')\n",
    "    df_copy['atBatIndex'] = df_copy['atBatIndex'].astype('int')\n",
    "    df_copy['batter'] = df_copy['batter'].astype('int')\n",
    "    df_copy['pitcher'] = df_copy['pitcher'].astype('int')\n",
    "    \n",
    "    # Sort\n",
    "    df_copy.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "\n",
    "    ### Advanced stats\n",
    "    # wOBA - using 2022 values throughout - may use slightly different implied denominator\n",
    "    df_copy['woba_b'] = (0.690 * df_copy['bb_b']) + (0.721 * df_copy['hbp_b']) + (0.885 * df_copy['b1_b']) + (1.262 * df_copy['b2_b']) + (1.601 * df_copy['b3_b']) + (2.070 * df_copy['hr_b'])\n",
    "    df_copy['woba_p'] = (0.690 * df_copy['bb_p']) + (0.721 * df_copy['hbp_p']) + (0.885 * df_copy['b1_p']) + (1.262 * df_copy['b2_p']) + (1.601 * df_copy['b3_p']) + (2.070 * df_copy['hr_p'])\n",
    "    \n",
    "    # Slugging\n",
    "    df_copy['slg_b'] = ((1 * df_copy['b1_b']) + (2 * df_copy['b2_b']) + (3 * df_copy['b3_b']) + (4 * df_copy['hr_b'])) * (1 / (1-(df_copy['bb_b'] + df_copy['hbp_b'])))\n",
    "    df_copy['slg_p'] = ((1 * df_copy['b1_p']) + (2 * df_copy['b2_p']) + (3 * df_copy['b3_p']) + (4 * df_copy['hr_p'])) * (1 / (1-(df_copy['bb_p'] + df_copy['hbp_p'])))\n",
    "    \n",
    "    # OBP    \n",
    "    df_copy['obp_b'] = df_copy[['b1_b', 'b2_b', 'b3_b', 'hr_b', 'bb_b', 'hbp_b']].sum(axis=1)\n",
    "    df_copy['obp_p'] = df_copy[['b1_p', 'b2_p', 'b3_p', 'hr_p', 'bb_p', 'hbp_p']].sum(axis=1)\n",
    "    \n",
    "    # ISO\n",
    "    df_copy['iso_b'] = (df_copy['b2_b'] * 1 + df_copy['b3_b'] * 2 + df_copy['hr_b'] * 3) * (1 / (1-(df_copy['bb_b'] + df_copy['hbp_b'])))\n",
    "    df_copy['iso_p'] = (df_copy['b2_p'] * 1 + df_copy['b3_p'] * 2 + df_copy['hr_p'] * 3) * (1 / (1-(df_copy['bb_p'] + df_copy['hbp_p'])))\n",
    "\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069dbaa1-7085-41ca-a0a0-d0621601144c",
   "metadata": {},
   "source": [
    "##### 7. Starter Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e05d7f0-c0d5-485d-806c-5d5e10f9e86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates information about starts for use in pulling pitchers\n",
    "def start_data(df):\n",
    "    ### PA-level\n",
    "    # Calculate hits\n",
    "    df['h'] = df[['b1', 'b2', 'b3', 'hr']].astype('float').sum(axis=1)\n",
    "    # Calculate total bases\n",
    "    df['tb'] = df['b1'] * 1 + df['b2'] * 2 + df['b3'] * 3 + df['hr'] * 4\n",
    "    # Calculate batters reached\n",
    "    df['reached'] = df[['b1', 'b2', 'b3', 'hr', 'bb', 'hbp']].astype('float').sum(axis=1)\n",
    "    # Calculate batters faced\n",
    "    df['faced'] = 1    \n",
    "    # Identify outs on play\n",
    "    df['outs_total'] = ((df['inning'] - 1) * 3) + df['outs']\n",
    "    df['outs_pa'] = (df.groupby(['gamePk', 'inning', 'halfInning'])['outs_total'].apply(lambda x: x - x.shift(1)).reset_index(level=[0, 1, 2], drop=True))\n",
    "    df['outs_pa'].fillna(df['outs'], inplace=True)\n",
    "\n",
    "    # Sort\n",
    "    df = df.sort_values(by=['date', 'gamePk', 'atBatIndex'])\n",
    "    \n",
    "    \n",
    "    ### Cumulative - Inning (Excludes current PA)\n",
    "    for stat in events_list + ['h', 'tb', 'reached', 'faced', 'rbi', 'outs_pa']:\n",
    "        df[f'{stat}_inning'] = df.groupby(['gamePk', 'pitcher', 'inning'])[stat].apply(lambda x: x.cumsum()).reset_index(level=[0, 1, 2], drop=True)\n",
    "        df[f'{stat}_inning'].fillna(0, inplace=True)\n",
    "\n",
    "    ### Cumulative - Game (Excludes current PA)\n",
    "    for stat in events_list + ['h', 'tb', 'reached', 'faced', 'rbi', 'outs_pa']:\n",
    "        df[f'{stat}_game'] = df.groupby(['gamePk', 'pitcher'])[stat].apply(lambda x: x.cumsum()).reset_index(level=[0, 1], drop=True)\n",
    "        df[f'{stat}_game'].fillna(0, inplace=True)\n",
    "        \n",
    "    # Identify if it's the bottom of the inning (a little more helpful than \"top\" as it's sortable)\n",
    "    df['bottom'] = (df['top'] == 0).astype('int')\n",
    "    \n",
    "    # Sort to identify starting pitchers\n",
    "    df = df.sort_values(by=['date', 'gamePk', 'bottom', 'atBatIndex'])\n",
    "    \n",
    "    # The starter has the lowest atBatIndex\n",
    "    df['atBatIndex_min'] = df.groupby(['gamePk', 'bottom'])['atBatIndex'].transform('min')\n",
    "    df['first_ab'] = (df['atBatIndex'] == df['atBatIndex_min']).astype('int')\n",
    "    \n",
    "    # A pitcher is pulled at their highest atBatIndex\n",
    "    df['atBatIndex_max'] = df.groupby(['gamePk', 'pitcher'])['atBatIndex'].transform('max')\n",
    "    df['pulled'] = (df['atBatIndex'] == df['atBatIndex_max']).astype('int')\n",
    "        \n",
    "    # Number of times a matchup has happened that game\n",
    "    df['times_faced'] = (df['faced_game']) // 9\n",
    "    df['times_faced'].fillna(0, inplace=True)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611ae87b-8d9d-4651-98f0-e8926b21d2ef",
   "metadata": {},
   "source": [
    "##### Model Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eba83b-563d-4dbf-85eb-081559c50ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates model inputs\n",
    "def create_pa_inputs(multiplier_df, start_year=2014, end_year=2024, short=50, long=300, adjust=True):\n",
    "    # Merge together raw Stats API and Statcast data\n",
    "    df = merge_datasets(start_year, end_year)\n",
    "    # Clean weather\n",
    "    df2 = clean_weather(df)\n",
    "    # Create PA events \n",
    "    df3 = create_events(df2)\n",
    "    # Create dummy variables \n",
    "    df4 = create_variables(df3)\n",
    "    # Adjust for park factors\n",
    "    if adjust == True:\n",
    "        df5 = park_adjustments(df4, multiplier_df)\n",
    "        # df5.drop(columns={'_merge'}, inplace=True)\n",
    "    else:\n",
    "        df5 = df4.copy()\n",
    "    # Add start/pitcher depth information\n",
    "    df6 = start_data(df5)\n",
    "    \n",
    "    ### Rolling stats\n",
    "    # Short\n",
    "    df_short = rolling_pas(df6, short)\n",
    "    # Long\n",
    "    df_long = rolling_pas(df6, long)\n",
    "    df_long = df_long.add_suffix(\"_long\")\n",
    "        \n",
    "    # We only need the rolling stats \n",
    "    long_stats = batter_stats_long + pitcher_stats_long\n",
    "    df_long = df_long[long_stats]\n",
    "    \n",
    "    # Dataset\n",
    "    complete_dataset = pd.concat([df_short, df_long], axis=1)\n",
    "\n",
    "    # Normalize so stats add up to 1\n",
    "    complete_dataset['sum_b'] = complete_dataset[['b1_b', 'b2_b', 'b3_b', 'hr_b', 'bb_b', 'hbp_b', 'so_b', 'lo_b', 'fo_b', 'go_b', 'po_b']].sum(axis=1)\n",
    "    for stat in ['b1_b', 'b2_b', 'b3_b', 'hr_b', 'bb_b', 'hbp_b', 'so_b', 'lo_b', 'fo_b', 'go_b', 'po_b']:\n",
    "        complete_dataset[stat] = complete_dataset[stat] / complete_dataset['sum_b']\n",
    "    \n",
    "    complete_dataset['sum_b_long'] = complete_dataset[['b1_b_long', 'b2_b_long', 'b3_b_long', 'hr_b_long', 'bb_b_long', 'hbp_b_long', 'so_b_long', 'lo_b_long', 'fo_b_long', 'go_b_long', 'po_b_long']].sum(axis=1)\n",
    "    for stat in ['b1_b_long', 'b2_b_long', 'b3_b_long', 'hr_b_long', 'bb_b_long', 'hbp_b_long', 'so_b_long', 'lo_b_long', 'fo_b_long', 'go_b_long', 'po_b_long']:\n",
    "        complete_dataset[stat] = complete_dataset[stat] / complete_dataset['sum_b_long']\n",
    "        \n",
    "    complete_dataset['sum_p'] = complete_dataset[['b1_p', 'b2_p', 'b3_p', 'hr_p', 'bb_p', 'hbp_p', 'so_p', 'lo_p', 'fo_p', 'go_p', 'po_p']].sum(axis=1)\n",
    "    for stat in ['b1_p', 'b2_p', 'b3_p', 'hr_p', 'bb_p', 'hbp_p', 'so_p', 'lo_p', 'fo_p', 'go_p', 'po_p']:\n",
    "        complete_dataset[stat] = complete_dataset[stat] / complete_dataset['sum_p']\n",
    "        \n",
    "    complete_dataset['sum_p_long'] = complete_dataset[['b1_p_long', 'b2_p_long', 'b3_p_long', 'hr_p_long', 'bb_p_long', 'hbp_p_long', 'so_p_long', 'lo_p_long', 'fo_p_long', 'go_p_long', 'po_p_long']].sum(axis=1)\n",
    "    for stat in ['b1_p_long', 'b2_p_long', 'b3_p_long', 'hr_p_long', 'bb_p_long', 'hbp_p_long', 'so_p_long', 'lo_p_long', 'fo_p_long', 'go_p_long', 'po_p_long']:\n",
    "        complete_dataset[stat] = complete_dataset[stat] / complete_dataset['sum_p_long']\n",
    "\n",
    "    # Only keep regular season\n",
    "    complete_dataset = complete_dataset[complete_dataset['game_type'] == \"R\"]\n",
    "\n",
    "    # Reset index\n",
    "    complete_dataset.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Sort\n",
    "    complete_dataset.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "    \n",
    "    \n",
    "    return complete_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bed1bf-2e5b-4278-9ffd-1ed51f954cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1506c1fc-dd11-47ce-87e9-1d5f5f58cd98",
   "metadata": {},
   "source": [
    "### Steamer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06c0a65-8fa9-4fd1-9b72-d501c3361a7a",
   "metadata": {},
   "source": [
    "##### 1. Hitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2053516-8f29-4c3c-87e1-49f5fbc91361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_steamer_hitters(df):\n",
    "    ### Hitting\n",
    "    # Basic stats\n",
    "    hit_list = ['1B', '2B', '3B', 'HR', 'BB', 'HBP', 'K']\n",
    "\n",
    "    # Advance stats\n",
    "    rate_list = ['OBP', 'SLG', 'wOBA']\n",
    "    for stat in hit_list:\n",
    "        rate = stat + \"_rate\"\n",
    "        rate_list.append(rate)\n",
    "        df[rate] = df[stat] / df['PA']\n",
    "\n",
    "    ### Base running\n",
    "    # Stolen base attempts\n",
    "    df['SBA'] = df['SB'] + df['CS']\n",
    "    # Stolen base opportunities (times on first)\n",
    "    df['SBO'] = df['1B'] + df['BB'] + df['HBP']\n",
    "    # # Implied stolen base attempt rate\n",
    "    # df['sba_imp'] = df['SBA'] / df['SBO']\n",
    "\n",
    "    # # # Cap implied stolen base attempt rate\n",
    "    # # df['sba_imp'] = np.where(df['sba_imp'] > 0.15, 0.15, df['sba_imp'])\n",
    "    \n",
    "    # # Determine stolen base success rate\n",
    "    # df['sbr'] = df['SB'] / df['SBA']\n",
    "    \n",
    "    # # Fill in missings\n",
    "    # df['sbr'].fillna(0.69, inplace=True) # assume 50th percentile \n",
    "    # df['sba_imp'].fillna(0.0677, inplace=True) # assume 50th percentile\n",
    "    \n",
    "    # Date\n",
    "    df['date'] = df['proj_date'].str.replace(\"-\", \"\")\n",
    "    df['date'] = df['date'].astype('int')\n",
    "    \n",
    "    # Keep relevant variables\n",
    "    keep_list = ['date', 'firstname', 'lastname', 'mlbamid', 'steamerid'] + ['SB', 'SBA', 'SBO'] + rate_list\n",
    "    df = df[keep_list]\n",
    "    \n",
    "    # Clean up\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.rename(columns={'1b_rate': 'b1_rate', '2b_rate': 'b2_rate', '3b_rate': 'b3_rate', 'k_rate':'so_rate'}, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Drop duplicates\n",
    "    df.drop_duplicates(subset=['steamerid', 'date'], inplace=True)\n",
    "\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc95785-c051-452e-aa5a-f8b9fbdd6c4a",
   "metadata": {},
   "source": [
    "##### 2. Pitchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3876f6da-1d0d-461f-8ab3-b002df855e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_steamer_pitchers(df):\n",
    "    # Hits per 9 innings\n",
    "    df['H9'] = df['H'] / df['IP'] * 9\n",
    "    \n",
    "    # Calculate average innings per game started\n",
    "    df['IP_start'] = df['start_IP'] / df['GS']\n",
    "    df['IP_start'].fillna(0, inplace=True)\n",
    "    # Replace infinites\n",
    "    df['IP_start'].replace([np.inf, -np.inf], 3, inplace=True)\n",
    "\n",
    "    # Date\n",
    "    df['date'] = df['proj_date'].str.replace(\"-\", \"\")\n",
    "    df['date'] = df['date'].astype('int')\n",
    "    \n",
    "    # Keep relevant variables\n",
    "    keep_list = ['date', 'firstname', 'lastname', 'mlbamid', 'steamerid'] + pitcher_stats_fg2 \n",
    "    df = df[keep_list]\n",
    "    \n",
    "    # Drop duplicates\n",
    "    df.drop_duplicates(subset=['steamerid', 'date'], inplace=True)\n",
    "\n",
    "    \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
