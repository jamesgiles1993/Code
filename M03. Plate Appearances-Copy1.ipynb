{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "246dcb35-a0f2-4ce2-a46e-f6b8c1053bf2",
   "metadata": {},
   "source": [
    "# M03. Predict PAs\n",
    "- This predicts the outcome of plate appearances\n",
    "- Type: Model\n",
    "- Run Frequency: Irregular\n",
    "- Sources:\n",
    "    - MLB API\n",
    "    - Steamer\n",
    "- Created: 4/19/2024\n",
    "- Updated: 11/4/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14f17ee-717d-4342-b5b3-634e2e869e91",
   "metadata": {},
   "source": [
    "Consider: \n",
    "- imputed starter, imputed reliever, unimputed starter, unimputed reliever variables\n",
    "- Using batter woba and pitcher woba to determine quantiles, not projected\n",
    "- imp_wfx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72339d03-2fb3-4067-97eb-994324eb3c21",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4534de56-4550-4dce-99fc-73d526095998",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"U01. Imports.ipynb\"\n",
    "%run \"U02. Functions.ipynb\"\n",
    "%run \"U03. Classes.ipynb\"\n",
    "%run \"U04. Datasets.ipynb\"\n",
    "%run \"U05. Models.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67afe9b9-2ede-417d-873a-acfb5e5e7ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set option to display numbers without scientific notation\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baf8183-bbb0-476a-a23b-8fd347373475",
   "metadata": {},
   "source": [
    "##### Test Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b22a6c96-9515-47aa-868c-50f166f82b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n"
     ]
    }
   ],
   "source": [
    "def test_cuda():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA is available!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"CUDA is NOT available. Check your GPU and drivers.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab99a78-7409-4a6b-b0f1-f47d83c77eec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81a6014a-eb27-4083-9537-1ec7e127de15",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb08ca5-c5d6-4660-b5b7-3d9296d116ad",
   "metadata": {},
   "source": [
    "##### Park x Weather Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8c4a68-63ea-4fc3-aeb8-f24391e9887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplier_df = pd.read_csv(os.path.join(baseball_path, \"Park and Weather Factors.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c55c2d0-66e7-4fad-ac34-cf93c9a397e1",
   "metadata": {},
   "source": [
    "Choose WFX\n",
    "- _unadj: predicted based on weather / predicted based on batted ball <br>\n",
    "- _adj: average of actual rates in similarly predicted games / predicted based on batted ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4671324-fe46-4128-9298-9f5c686b7218",
   "metadata": {},
   "outputs": [],
   "source": [
    "wfx_type = 'adj'\n",
    "for event in events_list:\n",
    "    multiplier_df[f'{event}_wfx_l'] = multiplier_df[f'{event}_wfx_{wfx_type}_l'].copy()\n",
    "    multiplier_df[f'{event}_wfx_r'] = multiplier_df[f'{event}_wfx_{wfx_type}_r'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bb23a3-9158-4c4d-b5b1-3f1f73b484d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplier_df['date'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da3950c-f72c-489f-8d4c-58e39ffe3a89",
   "metadata": {},
   "source": [
    "##### Plate Appearances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f5b102-3263-4a73-97c5-bf6c4945b0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset = pd.read_csv(os.path.join(baseball_path, \"Final Dataset.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e19f930-66f1-4b0f-b301-7343dde08590",
   "metadata": {},
   "source": [
    "##### Steamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef91c4c-14d8-4e8d-98d1-fcc3d34333d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_hitters_df = pd.read_csv(os.path.join(baseball_path, \"A03. Steamer\", \"steamer_hitters_weekly_log.csv\"), encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe7d409-3aba-4c26-b7ff-4e0bac53dd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_pitchers_df = pd.read_csv(os.path.join(baseball_path, \"A03. Steamer\", \"steamer_pitchers_weekly_log.csv\"), encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3151bb4c-1be0-46c6-a287-b94567d6d25e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d4a2fea-7565-4c30-8703-29035d07ef48",
   "metadata": {},
   "source": [
    "### Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee27de4-ce5b-47c5-a4cf-c830466c46c8",
   "metadata": {},
   "source": [
    "##### MLB Stats API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43658684-9551-4cf7-bd43-0ea5d6638520",
   "metadata": {},
   "source": [
    "Remove missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7679c510-0c46-4575-8daa-49173bcd20b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset = complete_dataset[~complete_dataset[batter_inputs].isin([np.inf, -np.inf]).any(axis=1)]\n",
    "complete_dataset = complete_dataset[~complete_dataset[pitcher_inputs].isin([np.inf, -np.inf]).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f440928b-6299-44f1-94d9-eeb81d176e30",
   "metadata": {},
   "source": [
    "Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52508861-52f1-4d58-8c14-f481006a1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "complete_dataset[batter_inputs] = scale_batter_stats.transform(complete_dataset[batter_inputs])\n",
    "complete_dataset[pitcher_inputs] = scale_pitcher_stats.transform(complete_dataset[pitcher_inputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39400e0-f3a5-49a1-b5d5-cf80739421c5",
   "metadata": {},
   "source": [
    "Set data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e839a430-c12f-43a8-b92e-19d9d2b054c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset['date_time'] = pd.to_datetime(complete_dataset['date'], format='%Y%m%d')\n",
    "complete_dataset['date_time_copy'] = complete_dataset['date_time'].copy()\n",
    "\n",
    "complete_dataset['batter'] = complete_dataset['batter'].astype(int).astype(str)\n",
    "complete_dataset['pitcher'] = complete_dataset['pitcher'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7098b37-5f21-4d51-9ccd-ab2010fcbe2a",
   "metadata": {},
   "source": [
    "Sort to prep for merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5badfae-cea6-4e80-b9d2-d344b201d48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset.sort_values('date_time', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31af98da-c1d1-43f0-a38d-7992b6b96f0a",
   "metadata": {},
   "source": [
    "##### Steamer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb08b20-1f0d-4272-868a-a071205b819a",
   "metadata": {},
   "source": [
    "Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4194d026-dbb6-43c7-aed1-0ba7f2dcc416",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_hitters_df2 = clean_steamer_hitters(steamer_hitters_df).dropna(subset=batter_stats_fg)\n",
    "steamer_pitchers_df2 = clean_steamer_pitchers(steamer_pitchers_df).dropna(subset=pitcher_stats_fg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bc62f8-205d-4fca-8fe7-77090575ca6f",
   "metadata": {},
   "source": [
    "Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ecadf9-e251-4390-819a-ab4133a8e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_hitters_df2[batter_stats_fg] = scale_batter_stats_steamer.transform(steamer_hitters_df2[batter_stats_fg])\n",
    "steamer_pitchers_df2[pitcher_stats_fg] = scale_pitcher_stats_steamer.transform(steamer_pitchers_df2[pitcher_stats_fg])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11525c81-34ac-4b5e-b4be-93e480287dfb",
   "metadata": {},
   "source": [
    "Remove missing pitchers (occurs occassionally in 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58197e4-5412-4374-be94-7431061c3d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_pitchers_df2 = steamer_pitchers_df2[~steamer_pitchers_df2['mlbamid'].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94389ba7-2be4-401e-8010-0d9aa3f2acd5",
   "metadata": {},
   "source": [
    "Set data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0352f70a-489f-4ad8-a38b-4f9e1d0dfa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_hitters_df2['date_time'] = pd.to_datetime(steamer_hitters_df2['date'], format='%Y%m%d')\n",
    "steamer_pitchers_df2['date_time'] = pd.to_datetime(steamer_pitchers_df2['date'], format='%Y%m%d')\n",
    "\n",
    "steamer_hitters_df2['mlbamid'] = steamer_hitters_df2['mlbamid'].astype(int).astype(str)\n",
    "steamer_pitchers_df2['mlbamid'] = steamer_pitchers_df2['mlbamid'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aaccf7-e25c-4be3-8801-c71bb884125c",
   "metadata": {},
   "source": [
    "Rename for compatibility with MLB Stats API data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83073ed4-4a17-4a52-818f-68aef1fc6f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_hitters_df2.rename(columns={'mlbamid': 'batter'}, inplace=True)\n",
    "steamer_pitchers_df2.rename(columns={'mlbamid': 'pitcher'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821f1b85-e5c8-4b0f-b14d-b74aa8ae8963",
   "metadata": {},
   "source": [
    "Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b979390c-a523-4916-887e-da6066b32fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_hitters_df2.drop(columns=['date', 'firstname', 'lastname', 'steamerid'], inplace=True)\n",
    "steamer_pitchers_df2.drop(columns=['date', 'firstname', 'lastname', 'steamerid'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f30dd3-3af8-4091-aa85-0ce10d34cc21",
   "metadata": {},
   "source": [
    "Sort to prep for merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6487f3-2d3a-4610-9f93-2c9df6513a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_hitters_df2.sort_values('date_time', inplace=True)\n",
    "steamer_pitchers_df2.sort_values('date_time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ed059a-3722-4a35-89f9-29a67c57e0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c115569b-2eb1-4689-976b-2bec2de41de2",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08498d4e-efaa-4bec-b1be-8a239752e7e4",
   "metadata": {},
   "source": [
    "##### Merge #1. Plate Appearances and Steamer Batters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb84caf4-aa8d-456a-a35c-2ea848baaf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset = pd.merge_asof(\n",
    "    complete_dataset,\n",
    "    steamer_hitters_df2,\n",
    "    on='date_time',\n",
    "    by='batter',\n",
    "    direction='backward'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27529d5a-52e6-4ab1-b1de-c0ff138312aa",
   "metadata": {},
   "source": [
    "##### Merge #2. Add Steamer Pitchers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c448db-edaf-4259-9de4-641528042799",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset = pd.merge_asof(\n",
    "    complete_dataset,\n",
    "    steamer_pitchers_df2,\n",
    "    on='date_time',\n",
    "    by='pitcher',\n",
    "    direction='backward'  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99df7797-9153-401e-bf0f-0f8f02a5d4f5",
   "metadata": {},
   "source": [
    "##### Merge #3. Add WFX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c062496f-1cb1-42d2-bc85-1a505271bcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset = pd.merge(complete_dataset, multiplier_df, on=['gamePk', 'date', 'venue_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b04c8b-cda8-4cd7-8824-97a57d6c71aa",
   "metadata": {},
   "source": [
    "##### Free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb30e14-a7d8-4368-a39b-bca912c1d93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del steamer_hitters_df, steamer_hitters_df2, steamer_pitchers_df, steamer_pitchers_df2, multiplier_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f767f9c-b74c-4c9f-88be-164dbf3d689c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "455ace11-7229-4b30-bf8f-d39d3d778dc5",
   "metadata": {},
   "source": [
    "### Impute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf31f9e-9599-42f5-a2fd-57cabeb86a21",
   "metadata": {},
   "source": [
    "For players with insufficient sample sizes, stats are imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e123af-6012-4391-b253-5d6aadd9d5c5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Option 1: Steamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500f4ca2-ffde-4601-90d1-44826dc538f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First, remove from dataset if ever missing FG/Steamer stats\n",
    "# complete_dataset = complete_dataset[~complete_dataset['b1_rate'].isna()]\n",
    "# complete_dataset = complete_dataset[~complete_dataset['H9'].isna()]\n",
    "\n",
    "# # Add hands to use in imputation\n",
    "# batter_stats_fg_imp = batter_stats_fg + ['b_L', 'p_L', 'imp_b']\n",
    "# pitcher_stats_fg_imp = pitcher_stats_fg + ['b_L', 'p_L', 'imp_p']\n",
    "\n",
    "# ### Batters\n",
    "# # Use Steamer stats to predict API/Statcast stats for those with limited samples\n",
    "# batter_predictions = impute_batter_stats.predict(complete_dataset.loc[complete_dataset['pa_b'] < 40, batter_stats_fg_imp])\n",
    "\n",
    "# # Impute inputs with limited sample size with predicted values\n",
    "# complete_dataset.loc[complete_dataset['pa_b'] < 40, batter_inputs] = batter_predictions\n",
    "\n",
    "# ### Pitchers\n",
    "# # Use Steamer stats to predict API/Statcast stats for those with limited samples\n",
    "# pitcher_predictions = impute_pitcher_stats.predict(complete_dataset.loc[complete_dataset['pa_p'] < 40, pitcher_stats_fg_imp])\n",
    "\n",
    "# # Impute inputs with limited sample size with predicted values\n",
    "# complete_dataset.loc[complete_dataset['pa_p'] < 40, pitcher_inputs] = pitcher_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95462618-9051-4892-a8ff-89c721fcfd94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Option 2: Middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6348bdb-6a17-4c4f-9e5f-96ca3143a06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First, remove from dataset if ever missing FG/Steamer stats\n",
    "# complete_dataset = complete_dataset[~complete_dataset['b1_rate'].isna()]\n",
    "# complete_dataset = complete_dataset[~complete_dataset['H9'].isna()]\n",
    "\n",
    "# # Instead of imputing, just weighting with 0s\n",
    "# complete_dataset[batter_inputs].fillna(0.0, inplace=True)\n",
    "# complete_dataset[pitcher_inputs].fillna(0.0, inplace=True)\n",
    "\n",
    "# # Calculate the weighted average for each column in pitcher_stats\n",
    "# # Could be simplified, but I wanted to show the steps\n",
    "# # Weighted average of provided value and 0. PAs and 50-PAs are weights. \n",
    "# for col in batter_inputs:\n",
    "#     complete_dataset[col] = (complete_dataset[col] * complete_dataset['pa_b'] + 0.0 * (50-complete_dataset['pa_b']))/50\n",
    "\n",
    "# # Calculate the weighted average for each column in pitcher_stats\n",
    "# for col in pitcher_inputs:\n",
    "#     complete_dataset[col] = (complete_dataset[col] * complete_dataset['pa_p'] + 0.0 * (50-complete_dataset['pa_p']))/50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346275c5-d7d0-4c93-bb15-dcd4d4e75e0f",
   "metadata": {},
   "source": [
    "##### Option 3: 0s and 1s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b023e1f-0c15-4ca4-a6ea-d98b6f6e6232",
   "metadata": {},
   "source": [
    "Assume 0s for player stats where sample is insufficient or missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4efb4e-3b69-40eb-bf50-41ff56292730",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset.loc[complete_dataset['pa_b'] < 40, batter_inputs] = 0\n",
    "complete_dataset.loc[complete_dataset['pa_p'] < 40, pitcher_inputs] = 0\n",
    "\n",
    "complete_dataset[batter_stats_fg] = complete_dataset[batter_stats_fg].fillna(0)\n",
    "complete_dataset[pitcher_stats_fg] = complete_dataset[pitcher_stats_fg].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc292f42-6548-4aaa-8cff-5412c1bf56ee",
   "metadata": {},
   "source": [
    "Assume 1 for WFX where WFX are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789f7345-748c-42a2-98d4-a4900df7f776",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset['imp_wfx'] = (complete_dataset['hr_wfx_l'].isna() | complete_dataset['hr_wfx_r'].isna()).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1ec6b5-5f9c-4970-940f-8b0d62130ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset[[f'{event}_wfx_l' for event in events_list]] = complete_dataset[[f'{event}_wfx_l' for event in events_list]].fillna(1)\n",
    "complete_dataset[[f'{event}_wfx_r' for event in events_list]] = complete_dataset[[f'{event}_wfx_r' for event in events_list]].fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96c2773-9d30-467e-9c1c-e55db9cb43d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7ddb37c-4952-4f64-8adf-2041ee2d1fb4",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477bd072-5b6a-4fd0-a1e8-a6684523b347",
   "metadata": {},
   "source": [
    "Drop early observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918584cf-b36e-4562-82e5-2a5de3f107b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset = complete_dataset[(complete_dataset['game_date'] > '2018-01-01') & (complete_dataset['game_date'] < '2025-01-01')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb32714-d856-448e-9cdd-1bbfe7c27a04",
   "metadata": {},
   "source": [
    "Drop atypical events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b16b03-1a40-4dd9-9ec4-f01c5e0519ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset = complete_dataset.query('eventsModel != \"Cut\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e08a90-2b2d-467b-8445-1d8429866b83",
   "metadata": {},
   "source": [
    "Drop observations from inactive parks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6c585d-7a56-41bc-a08d-eea21df321c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_parks = list(team_map['VENUE_ID'].astype(int))\n",
    "complete_dataset = complete_dataset[complete_dataset['venue_id'].astype(int).isin(active_parks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cd9aed-1756-4a79-9000-ca0f88da0919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d888da0-e487-48a5-a96e-6c86bedb3e25",
   "metadata": {},
   "source": [
    "### Shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12c7c0b-594f-4eab-ba8f-2198056b444a",
   "metadata": {},
   "source": [
    "Many batter and pitcher stats are calculated at the end of the plate appearance. For prediction purposes, we need these stats coming into the plate appearance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065f102b-3eab-4989-b453-206579c60fb8",
   "metadata": {},
   "source": [
    "##### Batter Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fea2bb1-777e-4181-a2a0-16cb7363bdab",
   "metadata": {},
   "source": [
    "Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd38ce01-6e7a-4027-a2d6-01ba978c9aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89923df4-805a-46d8-9027-7372749d0156",
   "metadata": {},
   "source": [
    "Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c180e3-f30f-4667-a6e0-a65a6a009c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset[batter_inputs + ['ab_b', 'pa_b', 'imp_b']] = complete_dataset.groupby(['batter', 'pitchHand'])[batter_inputs + ['ab_b', 'pa_b', 'imp_b']].shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541793ed-0b9d-4a69-9e81-adba638bb0ed",
   "metadata": {},
   "source": [
    "##### Pitcher Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699542c3-f47b-4047-8eed-f232c73f6111",
   "metadata": {},
   "source": [
    "Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d45cce5-c6b9-4def-a41e-55e20d8332ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6aa9bb-1868-460d-aad3-b90f9bcfd748",
   "metadata": {},
   "source": [
    "Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e722928f-a6c7-41e6-b13a-fa802f830b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset[pitcher_inputs + ['ab_p', 'pa_p', 'imp_p']] = complete_dataset.groupby(['pitcher', 'batSide'])[pitcher_inputs + ['ab_p', 'pa_p', 'imp_p']].shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c92d5b-f855-4e06-90ec-11fda6da6c54",
   "metadata": {},
   "source": [
    "##### Inning Sums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3cec77-5d6d-40f4-9729-d36b1fb0b233",
   "metadata": {},
   "source": [
    "Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0c8db5-1a52-4940-949a-13812a7d5856",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0edfd47-fdcf-45e6-9a49-1accd4623585",
   "metadata": {},
   "source": [
    "Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56a5edf-701c-4a1c-8cac-cb06d858fac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_inning_input_list = [col for col in complete_dataset.columns if col.endswith(\"_inning\")]\n",
    "\n",
    "complete_dataset[cumulative_inning_input_list] = complete_dataset.groupby(['gamePk', 'inning', 'pitcher'])[cumulative_inning_input_list].shift(1)\n",
    "complete_dataset[cumulative_inning_input_list] = complete_dataset[cumulative_inning_input_list].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bd248a-dfae-4e01-8e99-5e787fde5c8b",
   "metadata": {},
   "source": [
    "##### Game Sums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe139353-6358-46bf-907a-8a9812b65b47",
   "metadata": {},
   "source": [
    "Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d656f8a-0193-4ac7-8267-113bedc83b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6474bf-3cad-4af6-9a1f-e04604695852",
   "metadata": {},
   "source": [
    "Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0f3c32-7ccd-48a4-86f1-45a2600c118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_game_input_list = [col for col in complete_dataset.columns if col.endswith(\"_game\")]\n",
    "cumulative_game_input_list.remove('rbi_game')\n",
    "\n",
    "complete_dataset[cumulative_game_input_list + ['times_faced']] = complete_dataset.groupby(['gamePk', 'pitcher'])[cumulative_game_input_list + ['times_faced']].shift(1)\n",
    "complete_dataset[cumulative_game_input_list + ['times_faced']] = complete_dataset[cumulative_game_input_list + ['times_faced']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf781d0f-ba06-4dc8-a82b-157ad1fea64e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b97fce27-c7a7-4d62-86b2-264bf6ecbab1",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a55de2-d5b1-4083-ba23-64b8ecd7298e",
   "metadata": {},
   "source": [
    "Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21610309-387e-4a06-ad4b-63111f5c67c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "complete_dataset['split'] = np.random.choice([0, 0, 1], size=len(complete_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3a448c-5411-49f5-ba87-105cc2d1ca6e",
   "metadata": {},
   "source": [
    "Create masks to identify training and testing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb19a8-50f9-447f-b390-f860d3886435",
   "metadata": {},
   "source": [
    "Note: to train on the entire dataset, you can simply set split = 0 for the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa442b2-c628-461b-8c47-550e35edba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_mask = (complete_dataset['split'] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b68e7d-c4d3-4747-a3bd-6fd7a2040de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc9e64b4-ecf7-4b43-849e-6fcbb2dc87b9",
   "metadata": {},
   "source": [
    "### Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013d185d-3fa5-496a-94d9-a865458df694",
   "metadata": {},
   "source": [
    "##### Constructed Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b33024a-7665-44c5-a0fa-6b5f2a10ad45",
   "metadata": {},
   "source": [
    "This builds stats used for evaluating model performance (actual event rates, FP, wOBA, outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d6388b-ff9b-4676-8894-e16e048136e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructed_stats(complete_dataset):\n",
    "    # Actual Stats\n",
    "    for event in events_list:\n",
    "        complete_dataset[f'{event}_act'] = (complete_dataset['eventsModel'] == event).astype(int)\n",
    "\n",
    "    # FP - Pitchers\n",
    "    pitcher_weights = {'fo': 1.0460, 'go': 1.0460, 'po': 1.0460, 'lo': 1.0460, 'so': 3.0408, 'bb': -1.3508, 'b1': -1.7427, 'b2': -1.7427, 'b3': -1.7427, 'hr': -3.6639}\n",
    "    for suffix in ['act', 'pred']:\n",
    "        complete_dataset.loc[~training_mask, f'FP_P_{suffix}'] = sum(\n",
    "            complete_dataset.loc[~training_mask, f'{col}_{suffix}'] * w\n",
    "            for col, w in pitcher_weights.items()\n",
    "        )\n",
    "    \n",
    "    # FP - Batters\n",
    "    batter_weights = {'b1': 4.3665, 'b2': 6.8271, 'b3': 10.8503, 'hr': 15.2611, 'bb':  2.8725, 'hbp': 2.9639}\n",
    "    for suffix in ['act', 'pred']:\n",
    "        complete_dataset.loc[~training_mask, f'FP_B_{suffix}'] = sum(\n",
    "            complete_dataset.loc[~training_mask, f'{col}_{suffix}'] * w\n",
    "            for col, w in batter_weights.items()\n",
    "        )\n",
    "\n",
    "    # wOBA (roughly)\n",
    "    woba_weights = {'b1': 0.882, 'b2': 1.254, 'b3': 1.590, 'hr': 2.050, 'bb': 0.689, 'hbp': 0.720}\n",
    "    for suffix in ['act', 'pred']:\n",
    "        complete_dataset.loc[~training_mask, f'wOBA_{suffix}'] = sum(\n",
    "            complete_dataset.loc[~training_mask, f'{col}_{suffix}'] * w\n",
    "            for col, w in woba_weights.items()\n",
    "        )\n",
    "    \n",
    "    # Out\n",
    "    complete_dataset['is_out_act'] = complete_dataset['is_out'].copy()\n",
    "    complete_dataset.loc[~training_mask, 'is_out_pred'] = complete_dataset.loc[~training_mask, ['fo_pred','go_pred','po_pred','lo_pred','so_pred']].sum(axis=1)\n",
    "    \n",
    "\n",
    "    return complete_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b053b858-863e-40f4-8d07-17b1fc1a387d",
   "metadata": {},
   "source": [
    "##### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b6fd17-9ad8-4040-a149-a52c419d89d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_statistics(complete_dataset, year, parameters, filename, le):\n",
    "    \"\"\"\n",
    "    Full sklearn-style summary_statistics restored for the PyTorch models.\n",
    "    Includes per-output quantile dataframes like b1_year_df, hr_year_df, etc.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    # Outputs from the label encoder + additional continuous targets\n",
    "    output_vars = list(le.classes_) + ['is_out', 'wOBA', 'FP_B', 'FP_P']\n",
    "\n",
    "    quantiles = 10  # used throughout\n",
    "\n",
    "    # ==============================\n",
    "    #  Figure 1 – Pitchers: starter/imputation\n",
    "    # ==============================\n",
    "    print(\"\\nFigure 1: Pitchers by Starter and Imputation Status\")\n",
    "    print(\n",
    "        complete_dataset[~training_mask]\n",
    "        .query(f'year == {year}')\n",
    "        .groupby(['imp_p', 'starter'])[\n",
    "            ['FP_P_pred', 'FP_P_act', 'wOBA_act', 'so_act']\n",
    "        ].mean()\n",
    "    )\n",
    "\n",
    "    # ==============================\n",
    "    #  Figure 2 – Pitchers: imputation only\n",
    "    # ==============================\n",
    "    print(\"\\nFigure 2: Pitchers by Imputation Status\")\n",
    "    print(\n",
    "        complete_dataset[~training_mask]\n",
    "        .query(f'year == {year}')\n",
    "        .groupby(['imp_p'])[\n",
    "            ['FP_P_pred', 'FP_P_act', 'wOBA_act', 'so_act']\n",
    "        ].mean()\n",
    "    )\n",
    "\n",
    "    # ==============================\n",
    "    #  Figure 3 – Batters by Imputation Status\n",
    "    # ==============================\n",
    "    print(\"\\nFigure 3: Batters by Imputation Status\")\n",
    "    print(\n",
    "        complete_dataset[~training_mask]\n",
    "        .query(f'year == {year}')\n",
    "        .groupby(['imp_b'])[\n",
    "            ['FP_B_pred', 'FP_B_act', 'wOBA_act', 'hr_act']\n",
    "        ].mean()\n",
    "    )\n",
    "\n",
    "    # ==============================\n",
    "    #  Figure 4 – FP by Venue\n",
    "    # ==============================\n",
    "    print(\"\\nFigure 4: FP by Venue\")\n",
    "    venue_cols = ['FP_B_pred', 'FP_B_act', 'FP_P_pred', 'FP_P_act']\n",
    "    means = (\n",
    "        complete_dataset[~training_mask]\n",
    "        .query(f'year == {year}')\n",
    "        .groupby('venue_id')[venue_cols]\n",
    "        .mean()\n",
    "    )\n",
    "    print(means)\n",
    "    print(f\"FP_B MSE: {np.mean((means['FP_B_pred'] - means['FP_B_act'])**2):.4f}\")\n",
    "    print(f\"FP_P MSE: {np.mean((means['FP_P_pred'] - means['FP_P_act'])**2):.4f}\")\n",
    "\n",
    "    # ==============================\n",
    "    #  Figure 5 – HR by WFX quantile\n",
    "    # ==============================\n",
    "    print(\"\\nFigure 5: HRs by Quantile\")\n",
    "    complete_dataset['hr_wfx_quantile'] = (\n",
    "        pd.qcut(\n",
    "            complete_dataset['hr_wfx'],\n",
    "            q=quantiles,\n",
    "            duplicates='drop',\n",
    "            labels=False,\n",
    "        ) + 1\n",
    "    )\n",
    "    print(\n",
    "        complete_dataset[~training_mask]\n",
    "        .groupby('hr_wfx_quantile')[['hr_pred', 'hr_act']]\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    # ==============================\n",
    "    #  Quantile performance tables + all_stat_df\n",
    "    # ==============================\n",
    "    all_stat_list = []\n",
    "\n",
    "    for var in output_vars:\n",
    "        pred_col = f\"{var}_pred\"\n",
    "        act_col = f\"{var}_act\"\n",
    "        q_col = f\"{var}_quantile\"\n",
    "\n",
    "        # Assign quantile column\n",
    "        complete_dataset.loc[~training_mask, q_col] = pd.qcut(\n",
    "            complete_dataset.loc[~training_mask, pred_col],\n",
    "            quantiles,\n",
    "            labels=False,\n",
    "            duplicates='drop'\n",
    "        )\n",
    "\n",
    "        # ---- ALL years quantile table ----\n",
    "        df_all = (\n",
    "            complete_dataset[~training_mask]\n",
    "            .groupby(q_col)[[act_col, pred_col]]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "        mse_all = ((df_all[act_col] - df_all[pred_col]) ** 2).mean()\n",
    "\n",
    "        # ---- Specific year quantile table ----\n",
    "        df_year = (\n",
    "            complete_dataset.query(f'year == {year}')\n",
    "            .loc[~training_mask]\n",
    "            .groupby(q_col)[[act_col, pred_col]]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "        mse_year = ((df_year[act_col] - df_year[pred_col]) ** 2).mean()\n",
    "\n",
    "        # Aggregate stats (ALL)\n",
    "        actual_all = complete_dataset.loc[~training_mask, act_col].mean()\n",
    "        predicted_all = complete_dataset.loc[~training_mask, pred_col].mean()\n",
    "        mult_all = actual_all / predicted_all\n",
    "        stdev_all = complete_dataset.loc[~training_mask, pred_col].std()\n",
    "\n",
    "        all_stat_list.append([\n",
    "            \"All\", var, actual_all, predicted_all, mult_all,\n",
    "            stdev_all, mse_all, filename, str(parameters['hidden_layer_sizes'])\n",
    "        ])\n",
    "\n",
    "        # Aggregate stats (YEAR)\n",
    "        actual_year = (\n",
    "            complete_dataset.query(f'year == {year}')\n",
    "            .loc[~training_mask, act_col]\n",
    "            .mean()\n",
    "        )\n",
    "        predicted_year = (\n",
    "            complete_dataset.query(f'year == {year}')\n",
    "            .loc[~training_mask, pred_col]\n",
    "            .mean()\n",
    "        )\n",
    "        mult_year = actual_year / predicted_year\n",
    "        stdev_year = (\n",
    "            complete_dataset.query(f'year == {year}')\n",
    "            .loc[~training_mask, pred_col]\n",
    "            .std()\n",
    "        )\n",
    "\n",
    "        all_stat_list.append([\n",
    "            year, var, actual_year, predicted_year, mult_year,\n",
    "            stdev_year, mse_year, filename, str(parameters['hidden_layer_sizes'])\n",
    "        ])\n",
    "\n",
    "        # ==============================\n",
    "        #  Restore per-variable quantile dataframes (your old behavior)\n",
    "        # ==============================\n",
    "        varname = f\"{var}_year_df\"\n",
    "        globals()[varname] = df_year   # same behavior as old sklearn pipeline\n",
    "\n",
    "\n",
    "    # ==============================\n",
    "    #  Build and return all_stat_df\n",
    "    # ==============================\n",
    "    all_stat_df = pd.DataFrame(\n",
    "        all_stat_list,\n",
    "        columns=['Year', 'Output', 'Actual', 'Predicted', 'Multiplier',\n",
    "                 'Std. Dev', 'MSE', 'File', 'Layers']\n",
    "    )\n",
    "\n",
    "    print(all_stat_df[['Year','Output','Actual','Predicted','Multiplier','Std. Dev','MSE']])\n",
    "\n",
    "    return all_stat_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d28cd5-2c0f-4cdc-8d83-9362a1604b34",
   "metadata": {},
   "source": [
    "##### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5486a1-986b-4bbe-96a8-d889df982d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def graph_by_quantile(graph, le):\n",
    "    \"\"\"\n",
    "    Plot predicted vs actual values by quantile for outputs.\n",
    "    graph: a string suffix used in globals() variable names (e.g., '')\n",
    "    le: LabelEncoder with class names\n",
    "    \"\"\"\n",
    "    rows, columns = 5, 3\n",
    "    fig, axs = plt.subplots(rows, columns, figsize=(columns*4, rows*4))\n",
    "\n",
    "    total_plots = rows * columns\n",
    "    output_vars = list(le.classes_) + ['is_out','wOBA','FP_B','FP_P']\n",
    "    output_vars = output_vars[:total_plots]\n",
    "\n",
    "    for i, var in enumerate(output_vars):\n",
    "        row = i // columns\n",
    "        col = i % columns\n",
    "        df_name = f\"{var}{graph}_df\"\n",
    "        if df_name not in globals():\n",
    "            print(f\"Warning: dataframe {df_name} not found, skipping\")\n",
    "            continue\n",
    "        df = globals()[df_name]\n",
    "        axs[row, col].plot(df[f'{var}_quantile'], df[f'{var}_pred'], color='red', label='Predicted')\n",
    "        axs[row, col].plot(df[f'{var}_quantile'], df[f'{var}_act'], color='black', label='Actual')\n",
    "        axs[row, col].set_title(var)\n",
    "        axs[row, col].legend()\n",
    "\n",
    "    fig.tight_layout(pad=2.0)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1bdc14-c6e1-4df4-b61c-9da997fd7fad",
   "metadata": {},
   "source": [
    "### Model A. All - Unadjusted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c61f585-8825-4702-8b0c-48d8a395de5f",
   "metadata": {},
   "source": [
    "##### Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9267867c-3798-4f29-8c55-8425e942f8fe",
   "metadata": {},
   "source": [
    "Batter Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48181dc2-7050-4041-aefe-77645c773707",
   "metadata": {},
   "outputs": [],
   "source": [
    "batter_input_list = batter_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353bac1c-fd4c-4d7a-a887-d8b265b50c32",
   "metadata": {},
   "source": [
    "Remove directional proclivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adad0f9c-c4dd-4a76-871a-fedef720b94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batter_input_list = [stat for stat in batter_input_list if \"to_\" not in stat]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216a9dbe-e758-408d-a5b1-7b4cd3782758",
   "metadata": {},
   "source": [
    "Pitcher Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2a8b7a-080a-468e-b283-4d3f9bef2139",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitcher_input_list = pitcher_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b54d9a-5f5a-4e06-8f52-c5118f808ee0",
   "metadata": {},
   "source": [
    "Remove directional proclivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c93944-94a4-4715-bf12-b2898867e622",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitcher_input_list = [stat for stat in pitcher_input_list if \"to_\" not in stat]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929c7484-1d2c-43db-9ee0-9b700b758633",
   "metadata": {},
   "source": [
    "Hand Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c22bf85-b8b3-4c1e-811b-556c358b45c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_input_list = ['p_L', 'b_L']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c86ab67-81de-41af-832f-850c14bd4044",
   "metadata": {},
   "source": [
    "Imputation Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da664722-d6ad-4f0a-b6ce-a54300a94abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_input_list = ['imp_b', 'imp_p']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e637a605-ffe1-49ec-88d5-a8cdc84aee25",
   "metadata": {},
   "source": [
    "Starter Input(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d1b44d-1399-4c73-9450-58e5e1278276",
   "metadata": {},
   "outputs": [],
   "source": [
    "starter_input_list = ['starter']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5dcf16-f5d1-4c56-9ca1-041b754d3b76",
   "metadata": {},
   "source": [
    "Cumulative Inning Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be619b5-4a50-40a5-b5ba-92d371347db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_inning_input_list = [col for col in complete_dataset.columns if col.endswith(\"_inning\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759dce85-6a13-468d-843a-4233436e2427",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_inning_input_list.remove('rbi_inning')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0302e663-9682-4a5f-91bd-6563ac42bdd3",
   "metadata": {},
   "source": [
    "Cumulative Game Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3efd012-4862-45ef-bb1d-c46c45543db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_game_input_list = [col for col in complete_dataset.columns if col.endswith(\"_game\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ed7fe9-eedf-4b17-b50f-b063ac0a55b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_game_input_list.remove('rbi_game')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795b4150-e93b-4dde-9d8b-2177c7db5a52",
   "metadata": {},
   "source": [
    "Game State Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b42c6b-2ce7-4b1a-8927-3ab99ef7caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset['winning'] = (complete_dataset['preBatterScore'] > complete_dataset['prePitcherScore']).astype(int)\n",
    "complete_dataset['winning_big'] = (complete_dataset['preBatterScore'] > complete_dataset['prePitcherScore'] + 3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ca381f-774a-46f2-84ab-754ede6e5f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_state_input_list = ['onFirst', 'onSecond', 'onThird', 'top', 'score_diff', 'prePitcherScore', 'preBatterScore', 'winning', 'winning_big', 'times_faced']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb871ab-93d1-4713-bf5a-c5c054a6f1c5",
   "metadata": {},
   "source": [
    "Inning Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d221d8-c785-470b-81ea-e76334285b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inning in range(1, 12):\n",
    "    complete_dataset[f'inning_{inning}'] = (complete_dataset['inning'] == inning).astype(int)\n",
    "complete_dataset['inning_11'] = (complete_dataset['inning'] >= 11).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caca2a2-47c9-40a6-abe3-283bb51b6c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "inning_input_list = [col for col in complete_dataset.columns if col.startswith(\"inning_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaf70fd-d3ae-42ec-8d5b-02fa6b5a9135",
   "metadata": {},
   "source": [
    "Out Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afbd8f1-a5a8-4703-9990-e276f9042f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for out in range(0, 3):\n",
    "    complete_dataset[f'outs_{out}'] = (complete_dataset['outs_pre'] == out).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0572d99b-6624-4d63-92d1-8885b73f736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_input_list = ['outs_0', 'outs_1', 'outs_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddbe787-85e0-4159-b55b-7dbe08d24899",
   "metadata": {},
   "source": [
    "Venue Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fedd3e-87a6-4855-bb4e-bd6aa946d5c0",
   "metadata": {},
   "source": [
    "Note: venue inputs are not preferred following integrating into WFX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4eab78-befd-4a87-adab-552915e74d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset['venue_id2'] = complete_dataset['venue_id'].copy()\n",
    "complete_dataset = pd.get_dummies(complete_dataset, columns=['venue_id2'], prefix='venue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87917ec-f544-4827-96dc-8deeecdb6615",
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_input_list = [col for col in complete_dataset.columns if col.startswith(\"venue_\") and col != \"venue_id\" and col != \"venue_name\"]\n",
    "venue_input_list = list(dict.fromkeys(venue_input_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a0747f-5b85-4e2b-a391-222c834c3639",
   "metadata": {},
   "source": [
    "Assign batSide-specific Weather Multipliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b011c2b-b0b7-446e-bc1f-a1893183bf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in events_list:\n",
    "    complete_dataset[f'{event}_wfx'] = np.where(complete_dataset['batSide'] == \"L\", complete_dataset[f'{event}_wfx_l'], \n",
    "                                                                                    complete_dataset[f'{event}_wfx_r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60285c38-348b-49d2-aa90-6b5c51fe5373",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplier_input_list = [f'{event}_wfx' for event in events_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c93fddc-7383-4fc5-b731-7f895e957a35",
   "metadata": {},
   "source": [
    "Imputation and starter interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdadc7c1-7fe2-44d7-807c-cb4a835f7754",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset['imputed_starter'] = complete_dataset['imp_p'] * complete_dataset['starter']\n",
    "complete_dataset['imputed_reliever'] = complete_dataset['imp_p'] * (complete_dataset['starter'] == 0).astype(int)\n",
    "complete_dataset['unimputed_starter'] = (complete_dataset['imp_p'] == 0).astype(int) * complete_dataset['starter']\n",
    "complete_dataset['unimputed_reliever'] = (complete_dataset['imp_p'] == 0).astype(int) * (complete_dataset['starter'] == 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372324ab-91f7-45aa-b35c-726701bccfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_starter_input_list = ['imputed_starter', 'imputed_reliever', 'unimputed_starter', 'unimputed_reliever']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a486967-e6f5-415b-9caf-7946c5dafca0",
   "metadata": {},
   "source": [
    "Model Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d80a183-893a-4ad8-920c-86f1a1897022",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a_input_list = (batter_input_list + pitcher_input_list + hand_input_list + imp_input_list + starter_input_list + \n",
    "                      cumulative_inning_input_list + cumulative_game_input_list + game_state_input_list + \n",
    "                      inning_input_list + out_input_list + imp_starter_input_list + batter_stats_fg + pitcher_stats_fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1f221c-b6a6-41b8-b677-385dc1abf2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = len(model_a_input_list) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bfc448-31b8-4f61-9e69-5ddf2b941060",
   "metadata": {},
   "source": [
    "Fill in missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4141991-c821-43d2-b384-b10e72853cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset[model_a_input_list] = complete_dataset[model_a_input_list].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ae1244-6769-41fa-b3b1-aeb037aa18c1",
   "metadata": {},
   "source": [
    "Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4040fa4-7f6b-4fcc-9cdd-c57065d82892",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list = ['is_out', 'eventsModel']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf12dfcf-2b69-4202-9bc2-054d431a8d67",
   "metadata": {},
   "source": [
    "Other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003a0bb2-68bf-443e-ad98-82c3ad9177bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_list = ['pa_b', 'pa_p', 'year', 'date', 'gamePk', 'atBatIndex', 'venue_id', 'batterName', 'pitcherName', 'imp_wfx']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410f8287-fae2-4324-b9c5-67d617767ffd",
   "metadata": {},
   "source": [
    "Variables to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a1844b-13c4-48ab-ab0b-a78f8598cd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_list = model_a_input_list + output_list + multiplier_input_list + additional_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb392e48-babd-4f24-8ba1-73ef28c381cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f45adc1-8932-4ebe-8b0e-b78d7ede871a",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5986f8ed-1931-460a-8d97-125f6b124d01",
   "metadata": {},
   "source": [
    "Single model, adjusted multiplier inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed64616b-00d8-4f5e-97ad-0d00bbdb2a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset.loc[:, multiplier_input_list] = (complete_dataset.loc[:, multiplier_input_list] - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a447c6-787b-4408-b9c1-b2a8cdad9b10",
   "metadata": {},
   "source": [
    "One model, all inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f0681e-4c09-4f47-aa54-e110b5788f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a_input_list = (batter_input_list + pitcher_input_list + hand_input_list + imp_input_list + starter_input_list + \n",
    "                      cumulative_inning_input_list + cumulative_game_input_list + game_state_input_list + \n",
    "                      inning_input_list + out_input_list + imp_starter_input_list + batter_stats_fg + pitcher_stats_fg + multiplier_input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b799a1-7aaf-47e8-87f8-8adc76eefda1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f104c96b-c139-4103-a7dd-d1099ccb6a88",
   "metadata": {},
   "source": [
    "##### Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39046c78-6248-49e0-b2bd-2ff8e67c3993",
   "metadata": {},
   "source": [
    "Remove unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742b9d1f-25fe-4ae2-8144-d73a99d3d582",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset = complete_dataset[keep_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea07630-1fd6-4cef-bf12-eac6bb50a36f",
   "metadata": {},
   "source": [
    "Convert boolean columns to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914f26e7-a656-4335-a1a4-f9741bf0cbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_cols = complete_dataset.select_dtypes(include=\"bool\").columns\n",
    "complete_dataset[bool_cols] = complete_dataset[bool_cols].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125fad52-53b9-4fc4-b981-2e05ed7a0c74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78cf69d9-3739-4930-9703-6f72db8f28a5",
   "metadata": {},
   "source": [
    "##### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cead55b8-0959-49cd-937b-af6b81b21436",
   "metadata": {},
   "source": [
    "Create a class that works like sklearn's neural network but uses Pytorch and predicts with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66370701-703c-4f06-9d16-f52d21b85b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictAll:\n",
    "    def __init__(self, ensemble_numpy, input_columns, classes, metadata=None):\n",
    "        \"\"\"\n",
    "        ensemble_numpy: list of models, each a list of [W1, b1, W2, b2, ..., Wn, bn]\n",
    "        input_columns: list of feature names used during training (order matters!)\n",
    "        classes: list of class labels (same order as in training)\n",
    "        metadata: optional dict with additional info (hidden_layers, num_classifiers, etc.)\n",
    "        \"\"\"\n",
    "        self.ensemble = ensemble_numpy\n",
    "        self.input_columns = input_columns\n",
    "        self.classes_ = classes\n",
    "        self.metadata = metadata or {}\n",
    "\n",
    "    @staticmethod\n",
    "    def _softmax(x):\n",
    "        e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return e_x / e_x.sum(axis=1, keepdims=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def _forward(model_layers, x):\n",
    "        \"\"\"\n",
    "        Forward pass for a single model.\n",
    "        model_layers: [W1, b1, W2, b2, ..., Wn, bn]\n",
    "        x: numpy array of shape [n_samples, n_features]\n",
    "        \"\"\"\n",
    "        n_layers = len(model_layers) // 2\n",
    "        h = x\n",
    "        for i in range(n_layers - 1):\n",
    "            W = model_layers[2*i]\n",
    "            b = model_layers[2*i + 1]\n",
    "            h = np.maximum(0, h @ W + b)  # ReLU\n",
    "        # final layer\n",
    "        W = model_layers[-2]\n",
    "        b = model_layers[-1]\n",
    "        logits = h @ W + b\n",
    "        return PredictAll._softmax(logits)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        X: pandas DataFrame, Series, or NumPy array\n",
    "        Returns: numpy array [n_samples, n_classes] with probabilities\n",
    "        \"\"\"\n",
    "        # Convert DataFrame or Series to NumPy array\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            # Reorder columns to match training\n",
    "            x_np = X[self.input_columns].to_numpy(dtype=np.float32)\n",
    "        elif isinstance(X, pd.Series):\n",
    "            # Single row\n",
    "            x_np = X[self.input_columns].to_numpy(dtype=np.float32).reshape(1, -1)\n",
    "        else:\n",
    "            x_np = np.array(X, dtype=np.float32)\n",
    "            if x_np.ndim == 1:\n",
    "                x_np = x_np.reshape(1, -1)\n",
    "\n",
    "        # Check input size\n",
    "        expected_size = self.ensemble[0][0].shape[0]\n",
    "        if x_np.shape[1] != expected_size:\n",
    "            raise ValueError(\n",
    "                f\"Input feature size ({x_np.shape[1]}) does not match model first layer ({expected_size})\"\n",
    "            )\n",
    "\n",
    "        # Run all models in ensemble\n",
    "        probs_list = [self._forward(model, x_np) for model in self.ensemble]\n",
    "\n",
    "        # Average probabilities\n",
    "        avg_probs = np.mean(probs_list, axis=0)\n",
    "        return avg_probs\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Returns predicted class labels (argmax), like sklearn's predict()\n",
    "        \"\"\"\n",
    "        probs = self.predict_proba(X)\n",
    "        return np.array([self.classes_[i] for i in np.argmax(probs, axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b811d4-df2e-4b83-87eb-3b31877607f4",
   "metadata": {},
   "source": [
    "Define Pytorch MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217b5915-ad05-4c3a-a483-ba4424b30d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, output_size):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        for h in hidden_layers:\n",
    "            layers.append(nn.Linear(prev_size, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev_size = h\n",
    "        layers.append(nn.Linear(prev_size, output_size))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b698d94a-8352-4c6f-8788-295fc675f414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c33e537e-6aee-4891-8949-00783e0a725d",
   "metadata": {},
   "source": [
    "##### Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef725d55-7604-461a-baa6-3482b953e1e3",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8c9954-9207-4a88-a1c7-c15b98725d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classifiers = 3 # Ensemble size\n",
    "num_models = 40 # Number of voting classifiers to run in loop\n",
    "random_state = random.randint(10000,90000) \n",
    "\n",
    "all_stat_list = [] # List of dataframes with evaluation data\n",
    "\n",
    "model_a_parameters = {\n",
    "    'hidden_layer_sizes': (168,80,40),\n",
    "    'activation': 'relu',\n",
    "    'max_iter': 100,\n",
    "    'alpha': 0.00001,\n",
    "    'learning_rate_init': 0.01, \n",
    "    'batch_size': 'auto',\n",
    "    'random_state': random_state,\n",
    "    # dropout = 0.1 # Need to switch to MLPDropout to use\n",
    "    'early_stopping': True,\n",
    "    'tol': 0.00001,\n",
    "    'n_iter_no_change': 20,\n",
    "    'validation_fraction': 0.05\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71690a68-df1d-4e18-8e52-25fa8d6b34ca",
   "metadata": {},
   "source": [
    "Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50b5d21-18ef-445b-8cbe-5a4b4bae7284",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = 10\n",
    "year = 2024\n",
    "venue = 19\n",
    "graph = '_year' # options include '_year', '_venue', or '' (for all years and venues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a245c7-fbf0-4535-b4b0-53ee536e5bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e518e039-ab83-4b83-ae9c-fba78ea19f57",
   "metadata": {},
   "source": [
    "##### Train, Predict, and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d2887f-1689-4d50-abef-e18e306a0bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Encode string outputs to integers\n",
    "le = LabelEncoder()\n",
    "y_train_np = le.fit_transform(complete_dataset['eventsModel'].values[training_mask])\n",
    "y_train = torch.tensor(y_train_np, dtype=torch.long, device=device)\n",
    "\n",
    "# Convert numeric inputs to torch tensor\n",
    "X_train_np = complete_dataset.loc[training_mask, model_a_input_list].astype(float).values\n",
    "X_train = torch.tensor(X_train_np, dtype=torch.float32, device=device)\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "output_size = len(le.classes_)\n",
    "hidden_layers = model_a_parameters['hidden_layer_sizes']\n",
    "lr = model_a_parameters['learning_rate_init']\n",
    "num_epochs = model_a_parameters['max_iter']\n",
    "\n",
    "all_stat_list = []\n",
    "\n",
    "# Training loop\n",
    "for i in range(num_models):\n",
    "    print(f\"Training ensemble {i+1}/{num_models}\")\n",
    "    ensemble = []\n",
    "\n",
    "    all_filename = f\"predict_all_{''.join(str(x) for x in hidden_layers)}_{random_state+i}_{todaysdate}\"\n",
    "    print(all_filename)\n",
    "    \n",
    "    for j in range(num_classifiers):\n",
    "        # Ensure different random weights for each model\n",
    "        seed = random_state + 100*j + i\n",
    "        torch.manual_seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed(seed)\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "        model = MLP(input_size, hidden_layers, output_size).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Train model\n",
    "        model.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train)\n",
    "            loss = criterion(outputs, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        ensemble.append(model)\n",
    "\n",
    "    # Save PyTorch ensemble as before\n",
    "    torch.save({\n",
    "        'state_dicts': [m.state_dict() for m in ensemble],\n",
    "        'input_size': input_size,\n",
    "        'hidden_layers': hidden_layers,\n",
    "        'output_size': output_size\n",
    "    }, os.path.join(model_path, \"M03. Plate Appearances\", f'{all_filename}.pt'))\n",
    "    \n",
    "    # ---- NEW: Export NumPy weights for PredictAll ----\n",
    "    ensemble_numpy = []\n",
    "    for m in ensemble:\n",
    "        state_dict = m.state_dict()\n",
    "        layers = []\n",
    "    \n",
    "        # Identify Linear layers in order\n",
    "        linear_keys = [k for k in state_dict.keys() if \"weight\" in k]\n",
    "        linear_keys.sort()  # ensure order\n",
    "        \n",
    "        for i, key in enumerate(linear_keys):\n",
    "            layers.append(state_dict[key].cpu().numpy().T)          # W\n",
    "            bias_key = key.replace(\"weight\", \"bias\")\n",
    "            layers.append(state_dict[bias_key].cpu().numpy())       # b\n",
    "        \n",
    "        ensemble_numpy.append(layers)\n",
    "\n",
    "    \n",
    "    # ---- NEW: Build PredictAll wrapper with metadata ----\n",
    "    metadata = {\n",
    "        \"hidden_layers\": hidden_layers,\n",
    "        \"num_classifiers\": num_classifiers,\n",
    "        \"random_seed\": random_state,\n",
    "        \"training_epochs\": num_epochs\n",
    "    }\n",
    "    \n",
    "    predict_all_wrapper = PredictAll(\n",
    "        ensemble_numpy=ensemble_numpy,\n",
    "        input_columns=model_a_input_list,\n",
    "        classes=le.classes_.tolist(),\n",
    "        metadata=metadata\n",
    "    )\n",
    "    \n",
    "    # ---- NEW: Save wrapper to disk ----\n",
    "    pickle_filename = os.path.join(model_path, \"M03. Plate Appearances\", f\"{all_filename}_wrapper.pkl\")\n",
    "    with open(pickle_filename, \"wb\") as f:\n",
    "        pickle.dump(predict_all_wrapper, f)\n",
    "    print(f\"Saved PredictAll wrapper to {pickle_filename}\")\n",
    "    \n",
    "    # Predict on test set as before\n",
    "    X_test_np = complete_dataset.loc[~training_mask, model_a_input_list].astype(float).values\n",
    "    X_test = torch.tensor(X_test_np, dtype=torch.float32, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        probs_list = [F.softmax(m(X_test), dim=1) for m in ensemble]\n",
    "        avg_probs = torch.stack(probs_list).mean(dim=0)\n",
    "\n",
    "    # Store predictions in dataframe\n",
    "    all_outputs_pred = [c + \"_pred\" for c in le.classes_]\n",
    "    complete_dataset.loc[~training_mask, all_outputs_pred] = avg_probs.cpu().numpy()\n",
    "\n",
    "    # Call your summary/stat functions\n",
    "    complete_dataset = constructed_stats(complete_dataset)\n",
    "    all_stat_df = summary_statistics(complete_dataset, year, parameters=model_a_parameters, filename=all_filename, le=le)\n",
    "    all_stat_list.append(all_stat_df)\n",
    "    graph_by_quantile(graph, le=le)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814e271a-cb58-4d96-a884-709d49102ed2",
   "metadata": {},
   "source": [
    "Pareto-Optimal Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceff3a0d-610c-4871-9167-62bde567bc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stat_df = pd.concat(all_stat_list, ignore_index=True)\n",
    "\n",
    "pareto_optimal(all_stat_df.query(f'Year == \"{year}\"') # Will accept variable year and string \"All\"\n",
    "                          .query('Output == \"wOBA\"')\n",
    "                          .query('1.01 > Multiplier > 0.99').reset_index(drop=True), ['MSE', 'Std. Dev'], ['Minimize', 'Maximize']).sort_values('Std. Dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af09e48-12a2-43e3-a42a-0a7ef72daee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6835a2b-c9c1-462c-b44d-0f732c22eb39",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189a8f7b-00ec-4987-b751-223c47f3dda1",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ed79a7-9773-47d8-8002-8012f8b60ea7",
   "metadata": {},
   "source": [
    "Note: this will overwrite predict_all model from U5. Models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315582c1-a4bc-43d9-8cf2-01290c2da606",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filename = \"predict_all_16080_36421_20251105.sav\"\n",
    "\n",
    "predict_all = pickle.load(open(os.path.join(model_path, \"M03. Plate Appearances\", all_filename), 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c15796-39dd-49da-a158-2cc8adccc647",
   "metadata": {},
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42397d7e-9d8c-4141-adf9-48d73441298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outputs_pred = [x + \"_pred1\" for x in list(predict_all.classes_)]\n",
    "\n",
    "complete_dataset[all_outputs_pred] = predict_all.predict_proba(complete_dataset[model_a_input_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdc805a-b1c2-45da-98f3-6138604e67c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aac18b63-4607-4a0b-8688-406224d4941f",
   "metadata": {},
   "source": [
    "### Model B. All - WFX Adjusted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fea482-4555-4b47-a84d-4686e305c47d",
   "metadata": {},
   "source": [
    "##### Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c390f1-144e-4a60-afe0-e306e5d0c945",
   "metadata": {},
   "source": [
    "Calculate Predicted Rate x WFX Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6313c795-0706-44bb-90f5-cca6bcfd9150",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_list = []\n",
    "\n",
    "for event in events_list:\n",
    "    complete_dataset[f'{event}_int'] = complete_dataset[f'{event}_pred1'] * complete_dataset[f'{event}_wfx']\n",
    "    interactions_list.append(f'{event}_int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b079d24-97d9-47fd-ab95-58c77cc11b03",
   "metadata": {},
   "source": [
    "Model Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2768033d-cdfc-457b-a504-17f8c3768dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b_input_list = interactions_list + imp_starter_input_list #+ ['imp_wfx']\n",
    "model_b_input_list = ([f\"{event}_pred1\" for event in events_list] + multiplier_input_list + imp_starter_input_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba77b4d-48ba-4927-84db-d7983633470f",
   "metadata": {},
   "source": [
    "##### Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cdcbe4-92b8-4dbe-91a8-5e1c7490149e",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b361f5-6bd9-4d35-b3ae-b75d9657f72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classifiers = 3 # Ensemble size\n",
    "num_models = 40 # Number of voting classifiers to run in loop\n",
    "random_state = random.randint(10000,90000) \n",
    "\n",
    "all_adjusted_stat_list = [] # List of dataframes with evaluation data\n",
    "\n",
    "model_b_parameters = {\n",
    "    'hidden_layer_sizes': (16,),\n",
    "    'activation': 'relu',\n",
    "    'max_iter': 100,\n",
    "    'alpha': 0.00001,\n",
    "    'learning_rate_init': 0.001, \n",
    "    'batch_size': 1024,\n",
    "    'random_state': random_state,\n",
    "    # dropout = 0.1 # Need to switch to MLPDropout to use\n",
    "    'early_stopping': True,\n",
    "    'tol': 0.00001,\n",
    "    'n_iter_no_change': 10,\n",
    "    'validation_fraction': 0.05\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f822ab8f-3298-4ab8-a0c8-9425f3aec4a8",
   "metadata": {},
   "source": [
    "Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07536e00-d0c4-41b3-bab0-ff20d8e0fa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = 10\n",
    "year = 2024 \n",
    "venue = 19\n",
    "graph = '_year' # options include '_year', '_venue', or '' (for all years and venues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb429e0-d80c-477e-ac67-01f653652870",
   "metadata": {},
   "source": [
    "##### Train, Predict, and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c319d-ae98-4324-a65f-8f932e2a7d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(f\"Ensemble Size: {num_classifiers}\")\n",
    "for i in range(num_models):\n",
    "    # Set filename\n",
    "    all_adjusted_filename = f\"predict_all_adjusted_{''.join(str(x) for x in model_b_parameters['hidden_layer_sizes'])}_{random_state+i}_{todaysdate}.sav\"\n",
    "    print(f\"Model {i}: {all_adjusted_filename}\")\n",
    "\n",
    "    ### Train\n",
    "    # Build list of MLP classifiers with varied random_state\n",
    "    estimators = []\n",
    "    for j in range(num_classifiers):\n",
    "        # Determine random state\n",
    "        model_b_parameters['random_state'] = random_state + 100 * j + i\n",
    "        # Create model\n",
    "        clf = SafeMLPClassifier(**model_b_parameters)\n",
    "        estimators.append((f\"mlp_{j}\", clf))\n",
    "    # Combine into a soft voting classifier\n",
    "    predict_all_adjusted = VotingClassifier(estimators=estimators, voting='soft', n_jobs=-1)\n",
    "\n",
    "    # Fit\n",
    "    predict_all_adjusted.fit(complete_dataset[training_mask][model_b_input_list], complete_dataset[training_mask][['eventsModel']].values.ravel())\n",
    "\n",
    "    # Save model\n",
    "    pickle.dump(predict_all_adjusted, open(os.path.join(model_path, \"M03. Plate Appearances\", all_adjusted_filename), 'wb'))\n",
    "\n",
    "    \n",
    "    ### Predict\n",
    "    all_outputs_pred = [x + \"_pred\" for x in list(predict_all_adjusted.classes_)]\n",
    "    complete_dataset.loc[~training_mask, all_outputs_pred] = predict_all_adjusted.predict_proba(complete_dataset[~training_mask][model_b_input_list])\n",
    "\n",
    "\n",
    "    ### Evaluate\n",
    "    # Construct stats required for model evaluations\n",
    "    complete_dataset = constructed_stats(complete_dataset)\n",
    "\n",
    "    # Print summary statistics\n",
    "    all_stat_df = summary_statistics(complete_dataset, year, parameters=model_b_parameters, filename=all_adjusted_filename, model=predict_all_adjusted)\n",
    "\n",
    "    # Add model statistics to a running dataframe list for later evaluation across models\n",
    "    all_adjusted_stat_list.append(all_stat_df)\n",
    "\n",
    "    # Graph\n",
    "    graph_by_quantile(graph, model=predict_all_adjusted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c29a7c-3f28-4c0c-b6b1-2cc185bd7871",
   "metadata": {},
   "source": [
    "Pareto-Optimal Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635fc89e-fb41-4b0c-81f1-4848ea859766",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_adjusted_stat_df = pd.concat(all_adjusted_stat_list, ignore_index=True)\n",
    "\n",
    "pareto_optimal(all_adjusted_stat_df.query(f'Year == \"{year}\"') # Will accept variable year and string \"All\"\n",
    "                                   .query('Output == \"wOBA\"')\n",
    "                                   .query('1.01 > Multiplier > 0.99').reset_index(drop=True), ['MSE', 'Std. Dev'], ['Minimize', 'Maximize']).sort_values('Std. Dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02a13f7-4acf-4cb6-8c56-47243bca96d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99579f50-bc51-4cb9-9eca-f89f03d59202",
   "metadata": {},
   "source": [
    "Note: We have the following options for predicting plate appearances using player, game, and weather inputs:\n",
    "1. Kitchen Sink: One model with all features\n",
    "2. Interacted Outputs: One model with player/game features. Outputs are then multiplied by wfx multipliers to create probabilities.\n",
    "3. Split: Two models. First has player/game stats. Second has model 1 outputs and wfx multipliers as inputs.\n",
    "4. Interacted Inputs: Two models. First has player/game stats. Second has model 1 outputs x wfx multipliers as inputs.\n",
    "5. No Rain: One model with player/game stats. No wfx at all. (Just a baseline for comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2172de2a-d7ca-4682-8551-cc93db9836e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
