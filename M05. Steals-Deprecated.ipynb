{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c4abac0-f6a9-4356-9826-f74bc0c2a5c6",
   "metadata": {},
   "source": [
    "# M05. Steals\n",
    "- This predicts stolen base attempt and success rates\n",
    "- Type: Model\n",
    "- Run Frequency: Irregular\n",
    "- Sources:\n",
    "    - MLB API\n",
    "    - Steamer\n",
    "- Created: 12/16/2023\n",
    "- Updated: 2/3/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e52dba-3a79-47b4-b58d-1c85e0c51c60",
   "metadata": {},
   "source": [
    "Warning: This was modified from M04. Base Running and may contain some vestigial code. This isn't a problem, but just a reminder."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a56fb39e-d60e-49f4-9b29-e78a78d1c033",
   "metadata": {},
   "source": [
    "Should this use base running dataset generated in m04??\n",
    "Should the code be the same?\n",
    "Do these need to be different codes?\n",
    "Fix df read \n",
    "Fix merge (use as of)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610f5185-ffb8-44d8-84e4-35984463efe1",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e76e73f3-a8b9-4145-90b3-e9e89c97071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"U1. Imports.ipynb\"\n",
    "%run \"U2. Utilities.ipynb\"\n",
    "%run \"U3. Classes.ipynb\"\n",
    "%run \"U4. Datasets.ipynb\"\n",
    "%run \"U5. Models.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b7e48c9-678d-40e6-8951-6ea3479ec632",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428425e9-ebc7-4d52-9c73-929e134d6c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a73dc03d-9b62-49e3-88b8-06f753717677",
   "metadata": {},
   "source": [
    "Create directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc3657a7-f118-4986-a9b0-ef0f9b5a428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(model_path, \"M06. Steals\", todaysdate), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95d8168-5d83-43a0-ad02-f2f320111054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25835a34-6514-4dca-beba-4a20d33fa9eb",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ef1cb2-0d72-4115-84d0-4dff50149019",
   "metadata": {},
   "source": [
    "Notes: \n",
    "- This cannot use the same complete dataset as elsewhere because multiple records per plate appearance are required and those are typically dropped\n",
    "- MLB Stats API calls are highly prone to connection errors. Because of this, it's highly discouraged to run them all in parallel. Sadly, the below approach is the best I've got."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6366407-f18b-4fd3-bda1-d137331f0444",
   "metadata": {},
   "source": [
    "Create yearly dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a269198-d5a4-48ad-aecf-b7e88d35a834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2015 = plays_statsapi(\"04/01/2015\", \"10/31/2015\")\n",
    "# df2016 = plays_statsapi(\"04/01/2016\", \"10/31/2016\")\n",
    "# df2017 = plays_statsapi(\"04/01/2017\", \"10/31/2017\")\n",
    "# df2018 = plays_statsapi(\"04/01/2018\", \"10/31/2018\")\n",
    "# df2019 = plays_statsapi(\"04/01/2019\", \"10/31/2019\")\n",
    "# df2020 = plays_statsapi(\"04/01/2020\", \"10/31/2020\")\n",
    "# df2021 = plays_statsapi(\"04/01/2021\", \"10/31/2021\")\n",
    "# df2022 = plays_statsapi(\"04/01/2022\", \"10/31/2022\")\n",
    "# df2023 = plays_statsapi(\"04/01/2023\", \"10/31/2023\")\n",
    "# df2024 = plays_statsapi(\"04/01/2024\", \"10/31/2024\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddbb608-f8a0-4120-a1de-3bdb39eebea0",
   "metadata": {},
   "source": [
    "Concatenate yearly dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "329e9b21-a857-4522-84cf-ced0aa114299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running_dataset = pd.concat([df2015, df2016, df2017, df2018, df2019, df2020, df2021, df2022, df2023, df2024], axis=0).query('game_type == \"R\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d688c8-4a8e-417a-aafe-01109c11fa4d",
   "metadata": {},
   "source": [
    "Write to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a4a4990-d001-4c9f-ba69-6b292fb1c495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running_dataset.to_csv(os.path.join(baseball_path, \"Running Dataset.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba28aae-9961-4882-8942-3f40c5b5adf7",
   "metadata": {},
   "source": [
    "Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "210958ce-db2f-4be8-bb03-6dd624b35305",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_dataset = pd.read_csv(os.path.join(baseball_path, \"Running Dataset.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434f6d66-3698-4a7c-8298-88f42d866076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f53ff3bc-e2ea-41be-9f78-fd15879114cc",
   "metadata": {},
   "source": [
    "### Movement Reasons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cf9008-c79f-4cdb-b825-589e5f9b7273",
   "metadata": {},
   "source": [
    "r_adv_force: advanced on a ball in play because they were forced to <br>\n",
    "r_adv_play: advanced on a ball in play without being forced to <br>\n",
    "r_force_out: out on a force play <br>\n",
    "r_adv_throw: advanced on the throw, not the contact <br>\n",
    "r_runner_out: out not on a force play <br>\n",
    "r_thrown_out: out on a hit (base runner) <br>\n",
    "r_doubled_off: out on a ball caught and thrown to base <br>\n",
    "r_out_stretching: out on a hit (hitter) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b55312b-be7b-4cee-9d94-22a219d9c2b5",
   "metadata": {},
   "source": [
    "We now have where every runner, including the batter, started and finished. However, we have two problems:\n",
    "- Some base runners don't move. They are not included in the dataset yet. \n",
    "- Some base runners move more than once in a play. They may go from 1B to 2B on a hit and then 2B to 3B on a throw."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dca8183-de42-4dd7-b8d8-63c60b1d6052",
   "metadata": {},
   "source": [
    "### Clean and Create Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4bbbd19-6cfa-4baa-a6c6-fafb13a1a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in missings\n",
    "running_dataset['description'].fillna(\"Missing\", inplace=True)\n",
    "\n",
    "# Identify errors\n",
    "running_dataset['error'] = running_dataset['description'].str.contains('error', case=False).astype('int')\n",
    "# Double Play dummy (will be cleaned a bit later)\n",
    "running_dataset['double_play'] = running_dataset['eventType'].isin(['grounded_into_double_play', 'double_play', 'sac_fly_double_play', 'strikeout_double_play', 'sac_bunt_double_play']).astype(int)\n",
    "\n",
    "# Create bottom half inning dummy\n",
    "running_dataset['bottom'] = (running_dataset['halfInning'] == \"bottom\").astype('int')\n",
    "\n",
    "# Determine outs before at bat\n",
    "running_dataset['outs_pre'] = running_dataset.groupby(['gamePk', 'inning', 'bottom'])['outs'].shift(1)\n",
    "running_dataset['outs_pre'] = running_dataset.groupby(['gamePk', 'atBatIndex'])['outs_pre'].transform('min')\n",
    "running_dataset['outs_pre'] = np.where(running_dataset['outs_pre'] == 3, 0, running_dataset['outs_pre'])\n",
    "\n",
    "# Fill in missings\n",
    "running_dataset['outs_pre'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75df5e0-9633-42b8-b346-7c4cb99b26b3",
   "metadata": {},
   "source": [
    "### Multiple Movements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3921ea8c-e2be-4538-b2fc-c056cf5b9e3a",
   "metadata": {},
   "source": [
    "Identify where a runner starts and ends in an at bat. Only keep one instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b780c19a-b8de-4704-a1eb-3cdf64fc12cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine start and end base by number\n",
    "# 0 is AB, 1 is 1B, 2 is 2B, 3 is 3B, 4 is scored, 5 is out\n",
    "running_dataset['startInt'] = running_dataset['start'].apply(lambda x: 0 if pd.isna(x) else int(x[0]) if x[0].isdigit() else 0)\n",
    "running_dataset['endInt'] = running_dataset['end'].apply(lambda x: 5 if pd.isna(x) else 4 if x.lower() == 'score' else int(x[0]) if x[0].isdigit() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78ea14c0-21b0-4381-bc1d-a6fa7f562fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_dataset['minBase'] = running_dataset.groupby(['gamePk', 'atBatIndex', 'runner_id'])['startInt'].transform('min')\n",
    "running_dataset['maxBase'] = running_dataset.groupby(['gamePk', 'atBatIndex', 'runner_id'])['endInt'].transform('max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "360dd731-69c3-4175-a12f-27c9fcb5a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the number after \"id\" using regular expression\n",
    "running_dataset['postOnFirst'] = running_dataset['postOnFirst'].str.extract(r\"'id': (\\d+)\")\n",
    "running_dataset['postOnSecond'] = running_dataset['postOnSecond'].str.extract(r\"'id': (\\d+)\")\n",
    "running_dataset['postOnThird'] = running_dataset['postOnThird'].str.extract(r\"'id': (\\d+)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7ee863c-a48a-4f74-8d19-ba5c2c0a041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine where runners were to start PA\n",
    "# Note that the exact id may be incorrect due to pinch runners, but we don't really care.\n",
    "running_dataset['preOnFirst'] = running_dataset.groupby(['gamePk', 'halfInning'])['postOnFirst'].shift(1)\n",
    "running_dataset['preOnSecond'] = running_dataset.groupby(['gamePk', 'halfInning'])['postOnSecond'].shift(1)\n",
    "running_dataset['preOnThird'] = running_dataset.groupby(['gamePk', 'halfInning'])['postOnThird'].shift(1)\n",
    "\n",
    "# Create a mask to identify the first occurrence of each combination\n",
    "first_occurrence_mask = ~running_dataset.duplicated(subset=['gamePk', 'atBatIndex'], keep='first')\n",
    "\n",
    "# Set 'preOnFirst' to NaN for non-first occurrences\n",
    "running_dataset['preOnFirst'] = running_dataset['preOnFirst'].where(first_occurrence_mask, other=None)\n",
    "running_dataset['preOnSecond'] = running_dataset['preOnSecond'].where(first_occurrence_mask, other=None)\n",
    "running_dataset['preOnThird'] = running_dataset['preOnThird'].where(first_occurrence_mask, other=None)\n",
    "# Fill in missings\n",
    "running_dataset['preOnFirst'] = running_dataset.groupby(['gamePk', 'atBatIndex'])['preOnFirst'].ffill()\n",
    "running_dataset['preOnSecond'] = running_dataset.groupby(['gamePk', 'atBatIndex'])['preOnSecond'].ffill()\n",
    "running_dataset['preOnThird'] = running_dataset.groupby(['gamePk', 'atBatIndex'])['preOnThird'].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796be349-3d69-4ebe-8029-f6820d6e1d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1e5c043-3a71-45c9-830f-038e4dea81e5",
   "metadata": {},
   "source": [
    "### Batters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f510189-989c-4e88-9ac1-2e869cf1a8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "atBat = running_dataset.query('id == batter')\n",
    "\n",
    "# Only keep runners at bat\n",
    "atBat.drop_duplicates(['gamePk', 'atBatIndex', 'runner_id'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd17b4b-cf71-4e50-bba5-89aebaf641e1",
   "metadata": {},
   "source": [
    "### Runners on 1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "882399d2-5b60-447d-abf7-e773d4989f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "on1B = running_dataset[~running_dataset['preOnFirst'].isna()]\n",
    "\n",
    "# Step 1: Create a dummy column is_runner = 1 if column id == preOnFirst\n",
    "on1B['is_runner'] = (on1B['start'] == \"1B\").astype(int)\n",
    "\n",
    "# Step 2: Identify instances where there are no observations for which is_runner = 1\n",
    "no_runner_mask = ~on1B.groupby(['gamePk', 'atBatIndex'])['is_runner'].transform('max').astype(bool)\n",
    "\n",
    "# Step 3: Set id = preOnFirst for instances where there are no runners\n",
    "on1B.loc[no_runner_mask, 'id'] = on1B.loc[no_runner_mask, 'preOnFirst']\n",
    "on1B.loc[no_runner_mask, 'runner_id'] = on1B.loc[no_runner_mask, 'preOnFirst']\n",
    "\n",
    "# Step 4: Create the added_1b column\n",
    "on1B['added_1b'] = 0\n",
    "on1B.loc[no_runner_mask, 'added_1b'] = 1\n",
    "\n",
    "# Step 5: Set startInt, endInt, minBase, maxBase for added_1b == 1\n",
    "on1B.loc[on1B['added_1b'] == 1, ['startInt', 'endInt', 'minBase', 'maxBase']] = 1\n",
    "on1B.loc[on1B['added_1b'] == 1, ['start', 'end']] = \"1B\"\n",
    "\n",
    "# Step 6: Keep one observation per runner\n",
    "on1B.drop_duplicates(['gamePk', 'atBatIndex', 'runner_id'], keep='first', inplace=True)\n",
    "\n",
    "# Step 7: Only keep runners on specified base\n",
    "on1B = on1B.query('minBase == 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ede82b5-f38e-4374-a63c-655449834a89",
   "metadata": {},
   "source": [
    "### Runners on 2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b296b5c9-3f08-41fc-ae0b-595114e72646",
   "metadata": {},
   "outputs": [],
   "source": [
    "on2B = running_dataset[~running_dataset['preOnSecond'].isna()]\n",
    "\n",
    "# Step 1: Create a dummy column is_runner = 1 if column id == preOnSecond\n",
    "on2B['is_runner'] = (on2B['start'] == \"2B\").astype(int)\n",
    "\n",
    "# Step 2: Identify instances where there are no observations for which is_runner = 1\n",
    "no_runner_mask = ~on2B.groupby(['gamePk', 'atBatIndex'])['is_runner'].transform('max').astype(bool)\n",
    "\n",
    "# Step 3: Set id = preOnSecond for instances where there are no runners\n",
    "on2B.loc[no_runner_mask, 'id'] = on2B.loc[no_runner_mask, 'preOnSecond']\n",
    "on2B.loc[no_runner_mask, 'runner_id'] = on2B.loc[no_runner_mask, 'preOnSecond']\n",
    "\n",
    "# Step 4: Create the added_2b column\n",
    "on2B['added_2b'] = 0\n",
    "on2B.loc[no_runner_mask, 'added_2b'] = 1\n",
    "\n",
    "# Step 5: Set startInt, endInt, minBase, maxBase for added_2b == 1\n",
    "on2B.loc[on2B['added_2b'] == 1, ['startInt', 'endInt', 'minBase', 'maxBase']] = 2\n",
    "on2B.loc[on2B['added_2b'] == 1, ['start', 'end']] = \"2B\"\n",
    "\n",
    "# Step 6: Keep one observation per runner\n",
    "on2B.drop_duplicates(['gamePk', 'atBatIndex', 'runner_id'], keep='first', inplace=True)\n",
    "\n",
    "# Step 7: Only keep runners on specified base\n",
    "on2B = on2B.query('minBase == 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cc1726-c440-417f-a75e-52d92510965a",
   "metadata": {},
   "source": [
    "### Runners on 3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8584e7e-597a-4ff6-b4ad-e0b3f25cac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "on3B = running_dataset[~running_dataset['preOnThird'].isna()]\n",
    "\n",
    "# Step 1: Create a dummy column is_runner = 1 if column id == preOnSecond\n",
    "on3B['is_runner'] = (on3B['start'] == \"3B\").astype(int)\n",
    "\n",
    "# Step 2: Identify instances where there are no observations for which is_runner = 1\n",
    "no_runner_mask = ~on3B.groupby(['gamePk', 'atBatIndex'])['is_runner'].transform('max').astype(bool)\n",
    "\n",
    "# Step 3: Set id = preOnSecond for instances where there are no runners\n",
    "on3B.loc[no_runner_mask, 'id'] = on3B.loc[no_runner_mask, 'preOnThird']\n",
    "on3B.loc[no_runner_mask, 'runner_id'] = on3B.loc[no_runner_mask, 'preOnThird']\n",
    "\n",
    "# Step 4: Create the added_2b column\n",
    "on3B['added_3b'] = 0\n",
    "on3B.loc[no_runner_mask, 'added_3b'] = 1\n",
    "\n",
    "# Step 5: Set startInt, endInt, minBase, maxBase for added_3b == 1\n",
    "on3B.loc[on3B['added_3b'] == 1, ['startInt', 'endInt', 'minBase', 'maxBase']] = 3\n",
    "on3B.loc[on3B['added_3b'] == 1, ['start', 'end']] = \"3B\"\n",
    "\n",
    "# Step 6: Keep one observation per runner\n",
    "on3B.drop_duplicates(['gamePk', 'atBatIndex', 'runner_id'], keep='first', inplace=True)\n",
    "\n",
    "# Step 7: Only keep runners on specified base\n",
    "on3B = on3B.query('minBase == 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2440da61-2420-4cad-8773-6ce226cb54c7",
   "metadata": {},
   "source": [
    "### Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bba4b8e1-782a-4b0d-a349-5c164b505075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the original DataFrame with the modified rows\n",
    "df = pd.concat([atBat, on1B, on2B, on3B], ignore_index=True)\n",
    "\n",
    "# Count up observations within an atBatIndex\n",
    "df['atBatIndexNum'] = df.groupby(['gamePk', 'atBatIndex']).cumcount() + 1\n",
    "\n",
    "# Sort\n",
    "df.sort_values(['gamePk', 'atBatIndex', 'atBatIndexNum'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e3429a-c37d-483e-896d-e96463ba67f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8210eb9d-3b65-4ce6-8b05-176752f3e7f4",
   "metadata": {},
   "source": [
    "### Start Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73ac8876-f04b-4293-ada7-623e35866ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any runner started on these bases\n",
    "# Create start location dummies\n",
    "df['pre_1b'] = (df['minBase'] == 1).astype('int')\n",
    "df['pre_2b'] = (df['minBase'] == 2).astype('int')\n",
    "df['pre_3b'] = (df['minBase'] == 3).astype('int')\n",
    "\n",
    "# Group by 'gamePk' and 'atBatIndex', then use transform to calculate the max for each group\n",
    "df['pre_1b'] = df.groupby(['gamePk', 'atBatIndex'])['pre_1b'].transform('max')\n",
    "df['pre_2b'] = df.groupby(['gamePk', 'atBatIndex'])['pre_2b'].transform('max')\n",
    "df['pre_3b'] = df.groupby(['gamePk', 'atBatIndex'])['pre_3b'].transform('max')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f53132-65bb-444e-8d02-888e65052fa1",
   "metadata": {},
   "source": [
    "### Fix End Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbfb263e-7c9a-4402-8817-827445da1719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End locations: Runner\n",
    "df['post_1b'] = (df['maxBase'] == 1).astype('int')\n",
    "df['post_2b'] = (df['maxBase'] == 2).astype('int')\n",
    "df['post_3b'] = (df['maxBase'] == 3).astype('int')\n",
    "\n",
    "# End locations: At Bat (team)\n",
    "df['post_1b'] = df.groupby(['gamePk', 'atBatIndex'])['post_1b'].transform('max')\n",
    "df['post_2b'] = df.groupby(['gamePk', 'atBatIndex'])['post_2b'].transform('max')\n",
    "df['post_3b'] = df.groupby(['gamePk', 'atBatIndex'])['post_3b'].transform('max')\n",
    "\n",
    "# End locations: Blocked - this occurs when someone other than the runner is already on a base\n",
    "# Note: You can't be blocked from advancing to a base you're on or have passed\n",
    "df['blocked_1b'] = ((df['post_1b'] == 1) & (df['maxBase'] < 1)).astype('int')\n",
    "df['blocked_2b'] = ((df['post_2b'] == 1) & (df['maxBase'] < 2)).astype('int')\n",
    "df['blocked_3b'] = ((df['post_3b'] == 1) & (df['maxBase'] < 3)).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd3e7e5-71ce-4aa4-9fff-bbc20ad6d504",
   "metadata": {},
   "source": [
    "### Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c79552c-0c8a-4f28-9dae-1729e3f51d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create game events\n",
    "df = create_events(df)\n",
    "\n",
    "# Encode events as integer\n",
    "df['eventsModelInt'] = df['eventsModel'].map({'b1': 1, 'b2': 2, 'b3': 3, 'hr': 4, 'bb': 5, 'hbp': 6, 'so': 7, 'fo': 8, 'go': 9, 'lo': 10, 'po': 11})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20703969-6527-4270-b3a2-71ba669d40ce",
   "metadata": {},
   "source": [
    "### Out locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73e97d71-3e05-48b9-b9d0-0ee59557af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if a runner is out\n",
    "df['out'] = (df['maxBase'] == 5).astype('int')\n",
    "\n",
    "df['out_home'] = ((df['out'] == 1) & (df['minBase'] == 0)).astype('int')\n",
    "df['out_1b'] = ((df['out'] == 1) & (df['minBase'] == 1)).astype('int')\n",
    "df['out_2b'] = ((df['out'] == 1) & (df['minBase'] == 2)).astype('int')\n",
    "df['out_3b'] = ((df['out'] == 1) & (df['minBase'] == 3)).astype('int')\n",
    "\n",
    "df['out_home'] = df.groupby(['gamePk', 'atBatIndex'])['out_home'].transform('max')\n",
    "df['out_1b'] = df.groupby(['gamePk', 'atBatIndex'])['out_1b'].transform('max')\n",
    "df['out_2b'] = df.groupby(['gamePk', 'atBatIndex'])['out_2b'].transform('max')\n",
    "df['out_3b'] = df.groupby(['gamePk', 'atBatIndex'])['out_3b'].transform('max')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e03f217-f6b3-4a8a-ae59-613100a92243",
   "metadata": {},
   "source": [
    "### Cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e46cf3c-43c5-4eb2-84eb-a3646ce30ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop less relevant events\n",
    "# df = df.query('eventsModel != \"Cut\"')\n",
    "\n",
    "# Keep only regular season games\n",
    "df = df.query('game_type == \"R\"')\n",
    "\n",
    "# Duplicates (should be very rare. I believe they're mlb's errors, not mine)\n",
    "df.drop_duplicates(subset=['gamePk', 'atBatIndex', 'minBase'], keep='first', inplace=True)\n",
    "\n",
    "# Calculate outs in PA\n",
    "df['outs_calculated'] = df.groupby(['gamePk', 'atBatIndex'])['out'].transform('sum')\n",
    "\n",
    "# Sometimes, there will be two outs without a double play recorded (typically a pickoff) but we need these for the math to work\n",
    "df['double_play'] = np.where(df['outs_calculated'] == 2, 1, df['double_play'])\n",
    "# Sometimes, there will be no outs on a play that's traditionally an out. These are errors.\n",
    "df['error'] = np.where((df['outs_calculated'] == 0) & (df['eventType'] == 'fielders_choice'), 1, df['error'])\n",
    "\n",
    "# Drop triple plays\n",
    "df = df.query('outs_calculated != 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab2bb7d-3689-45e6-999d-8de9785a2ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e495dba0-501c-4e4d-9eb0-2261be521c77",
   "metadata": {},
   "source": [
    "### Read in Steamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7b93790-da04-47c1-8aa8-2b68439e1815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Steamer hitters \n",
    "steamer_hitters_df = pd.read_csv(os.path.join(baseball_path, \"A03. Steamer\", \"steamer_hitters_weekly_log.csv\"), encoding='iso-8859-1')\n",
    "# Clean\n",
    "steamer_hitters_df2 = clean_steamer_hitters(steamer_hitters_df)\n",
    "steamer_hitters_df2.dropna(subset=batter_stats_fg, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0f5a39e-7cdb-4872-bc77-9088cc3a2912",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert to YYYYMMDD int\n",
    "df['date'] = df['game_date'].str.replace(\"-\", \"\").astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c458e69f-3cec-40db-9a85-338a0ea8f164",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find the dates of Steamer projections\n",
    "# We'll take the most recent and merge in that projection for each player\n",
    "batter_steamer_dates = list(steamer_hitters_df2['date'].unique())\n",
    "\n",
    "# Define a function to find the largest number in \"steamer_dates\" less than or equal to a given \"date\"\n",
    "def find_steamer_date(date, steamer_dates):\n",
    "    max_steamer_date = max(filter(lambda d: d <= date, steamer_dates), default=None)\n",
    "    return max_steamer_date\n",
    "\n",
    "# Apply the function to create the \"steamer_date\" column in your DataFrame\n",
    "df[\"batter_date\"] = df[\"date\"].apply(lambda x: find_steamer_date(x, batter_steamer_dates))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1899b68c-5941-4289-ad97-5498d56a9a4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Identify steals and attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90a8b110-32d1-493a-8e24-de37a40b4aa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['sb_2b'] = df['movementReason'].isin(['r_stolen_base_2b']).astype('int') \n",
    "df['sb_3b'] = df['movementReason'].isin(['r_stolen_base_3b']).astype('int') \n",
    "df['sba_2b'] = df['movementReason'].isin(['r_stolen_base_2b', 'r_caught_stealing_2b', 'r_pickoff_caught_stealing_2b']).astype('int') \n",
    "df['sba_3b'] = df['movementReason'].isin(['r_stolen_base_3b', 'r_caught_stealing_3b', 'r_pickoff_caught_stealing_3b']).astype('int') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6940e89e-7b11-40d8-8b3a-3c5736c605c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008657461877197356"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sb_2b'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4aae80fa-f107-4abf-9e64-fed00208ccca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create year variable\n",
    "df['year'] = df[\"date\"].astype('str').str[:4].astype('int')\n",
    "\n",
    "# Creating dummy variables\n",
    "dummy_years = pd.get_dummies(df['year'], prefix='year').astype('int')\n",
    "\n",
    "# Concatenating dummy variables with original DataFrame\n",
    "df = pd.concat([df, dummy_years], axis=1)\n",
    "\n",
    "# Convert to numeric\n",
    "df['runner_id'] = df['runner_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2f7e695-1f56-48b3-889a-5c3e291a69fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge\n",
    "steal_df = pd.merge(df[['year', 'gamePk', 'eventsModel', 'atBatIndex', 'atBatIndexNum', 'minBase', 'maxBase', 'runner_id', 'movementReason', 'batter_date', 'sba_2b', 'sba_3b', 'sb_2b', 'sb_3b', 'outs_pre', 'pre_1b', 'pre_2b', 'pre_3b'] + list(dummy_years.columns)], steamer_hitters_df2[['mlbamid', 'date', 'sb', 'sbo', 'sba']], left_on=['runner_id', 'batter_date'], right_on=['mlbamid', 'date'], how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6b3977-e120-419c-acdc-f60e63e627d3",
   "metadata": {},
   "source": [
    "Define model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65f48653-3450-4e0a-bf93-aef0af56863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "steal_df['sba_imp'] = steal_df['sba'] / steal_df['sbo']\n",
    "steal_df['sb_imp'] = steal_df['sb'] / steal_df['sba']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ce45f4-d49e-4034-845b-9323cda0d75f",
   "metadata": {},
   "source": [
    "Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ede83e59-c8cd-486f-b200-ddbecb6e7833",
   "metadata": {},
   "outputs": [],
   "source": [
    "steal_df.sort_values(['gamePk', 'atBatIndex', 'atBatIndexNum'], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1bc30e-ef08-47c8-9851-6e020dcb56a9",
   "metadata": {},
   "source": [
    "Only keep runners with meaningful sample size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8a1fa6-fbd2-40b0-98ec-cf0e1fd7963e",
   "metadata": {},
   "source": [
    "Note: this may drop very late season base runners as sbo are projected for the rest of season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef409b65-ba9a-4c44-9816-b4d03eddff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 30\n",
    "\n",
    "steal_df = steal_df.query(f'sbo > {cutoff}').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b110dc-0e95-4c88-abf8-0710bc95e7d1",
   "metadata": {},
   "source": [
    "Calculate medians for the purpose of providing fill-in rates for those with small sbo values and unusually high rates in matchup files (we won't use those here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c769b70f-83fc-49f3-a961-585b74d1b07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sba_imp</th>\n",
       "      <th>sb_imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>384981.0000</td>\n",
       "      <td>384981.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0994</td>\n",
       "      <td>0.7385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0820</td>\n",
       "      <td>0.0382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.6420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.7050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0746</td>\n",
       "      <td>0.7390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.1407</td>\n",
       "      <td>0.7670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.5621</td>\n",
       "      <td>0.8480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sba_imp      sb_imp\n",
       "count 384981.0000 384981.0000\n",
       "mean       0.0994      0.7385\n",
       "std        0.0820      0.0382\n",
       "min        0.0031      0.6420\n",
       "25%        0.0364      0.7050\n",
       "50%        0.0746      0.7390\n",
       "75%        0.1407      0.7670\n",
       "max        0.5621      0.8480"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steal_df.query('year >= 2023')[['sba_imp', 'sb_imp']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "688fbfcf-b09b-41db-89a3-c5b8c636880b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08830815393740624"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steal_df.query('pre_1b == 1 and pre_2b == 0 and minBase == 1').query('year >= 2024')['sba_2b'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8835b677-a715-41b9-bb06-c1468af2dc3d",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1fb3f0-7aa1-4898-888c-b7dac931952a",
   "metadata": {},
   "source": [
    "### Steals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f774936-98cf-445d-92d9-aa43ec5e733f",
   "metadata": {},
   "source": [
    "### Attempt to steal 2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5fb5d040-b818-4b2a-81bc-7bf958d40b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sba_2b\n",
       "0    26130\n",
       "1     2531\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steal_df.query('pre_1b == 1 and pre_2b == 0 and minBase == 1').query('year >= 2024')['sba_2b'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5344be3e-f400-4776-90a5-2c3d51631e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Select relevant columns and handle missing values\n",
    "X = steal_df.query('pre_1b == 1 and pre_2b == 0 and minBase == 1').query('year >= 2024')[['outs_pre', 'sba_imp', 'sb_imp']]\n",
    "y = steal_df.query('pre_1b == 1 and pre_2b == 0 and minBase == 1').query('year >= 2024')['sba_2b']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the MLPClassifier\n",
    "predict_sba_2b = MLPClassifier(hidden_layer_sizes=(4,4), activation='relu', early_stopping=False, max_iter=100, random_state=10)\n",
    "predict_sba_2b.fit(X_train, y_train)\n",
    "\n",
    "# Get probability predictions on the test set\n",
    "probabilities = predict_sba_2b.predict_proba(X_test)\n",
    "\n",
    "# Create DataFrame from probabilities\n",
    "probability_df = pd.DataFrame(probabilities, columns=['sba_2b_not', 'sba_2b_pred'], index=X_test.index)\n",
    "\n",
    "# Concatenate probability_df with y_test and X_test\n",
    "sba_2b_df = pd.concat([X_test, y_test, probability_df], axis=1)\n",
    "\n",
    "# Create directory\n",
    "os.makedirs(os.path.join(model_path, \"M05. Steals\", todaysdate), exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "pickle.dump(predict_sba_2b, open(os.path.join(model_path, \"M05. Steals\", todaysdate, \"predict_sba_2b.sav\"), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21149d11-428c-4f0d-a3a4-42410837870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = 40\n",
    "\n",
    "# Add xtiles (to examine how well predictions match actual results)\n",
    "sba_2b_df['quantile'] = pd.qcut(sba_2b_df['sba_2b_pred'], quantiles, labels=False)\n",
    "globals()[\"sba_2b_df_quantiles\"] = sba_2b_df.groupby('quantile')[['sba_2b', 'sba_2b_pred']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6113a2-467b-41b1-8f48-8daebde2505b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create figures\n",
    "plt.plot(sba_2b_df_quantiles['quantile'], sba_2b_df_quantiles['sba_2b_pred'], color='red')\n",
    "plt.plot(sba_2b_df_quantiles['quantile'], sba_2b_df_quantiles['sba_2b'], color='black')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e9fbe-f322-4ab4-8e90-e4abc6dcf28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sba_2b_df[['sba_2b_pred', 'sba_2b']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a32e8c6-5b4d-4ab4-9532-98827d2f7d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b02ed451-25c6-4d20-8059-31e936eb86db",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Attempt to steal 3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47da1bfc-e6df-4033-b2c3-b14a47ce1188",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Select relevant columns and handle missing values\n",
    "X = steal_df.query('pre_2b == 1 and pre_3b == 0 and minBase == 2').query('year >= 2024')[['outs_pre', 'sba_imp', 'sb_imp']] # + list(dummy_years.columns)]\n",
    "y = steal_df.query('pre_2b == 1 and pre_3b == 0 and minBase == 2').query('year >= 2024')['sba_3b']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the MLPClassifier\n",
    "predict_sba_3b = MLPClassifier(hidden_layer_sizes=(4,4,), activation='relu', early_stopping=False, max_iter=100, random_state=30000000)\n",
    "predict_sba_3b.fit(X_train, y_train)\n",
    "\n",
    "# Get probability predictions on the test set\n",
    "probabilities = predict_sba_3b.predict_proba(X_test)\n",
    "\n",
    "# Create DataFrame from probabilities\n",
    "probability_df = pd.DataFrame(probabilities, columns=['sba_3b_not', 'sba_3b_pred'], index=X_test.index)\n",
    "\n",
    "# Concatenate probability_df with y_test and X_test\n",
    "sba_3b_df = pd.concat([X_test, y_test, probability_df], axis=1)\n",
    "\n",
    "# Create directory\n",
    "os.makedirs(os.path.join(model_path, \"M05. Steals\", todaysdate), exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "pickle.dump(predict_sba_3b, open(os.path.join(model_path, \"M05. Steals\", todaysdate, \"predict_sba_3b.sav\"), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09fcb30-cee0-44fa-8748-5aabac250f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = 10 \n",
    "\n",
    "# Add xtiles (to examine how well predictions match actual results)\n",
    "sba_3b_df['quantile'] = pd.qcut(sba_3b_df['sba_3b_pred'], 10, labels=False)\n",
    "globals()[\"sba_3b_df_quantiles\"] = sba_3b_df.groupby('quantile')[['sba_3b', 'sba_3b_pred']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560bf87f-c360-4ecb-b2fa-b576fbdc6efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figures\n",
    "plt.plot(sba_3b_df_quantiles['quantile'], sba_3b_df_quantiles['sba_3b_pred'], color='red')\n",
    "plt.plot(sba_3b_df_quantiles['quantile'], sba_3b_df_quantiles['sba_3b'], color='black')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3737a76-2b19-4f67-99ea-aaca17d49aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sba_3b_df[['sba_3b_pred', 'sba_3b']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d107226b-3360-44d7-a132-421ab6eace94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23d83267-90af-4fc5-a8f1-ea311d4e876b",
   "metadata": {},
   "source": [
    "### Steal 2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ab52a-52d8-436a-8f4a-1f61cb7755b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Select relevant columns and handle missing values\n",
    "X = steal_df.query('pre_1b == 1 and pre_2b == 0 and sba_2b == 1 and minBase == 1').query('year >= 2023')[['outs_pre', 'sba_imp', 'sb_imp']] # + list(dummy_years.columns)]\n",
    "y = steal_df.query('pre_1b == 1 and pre_2b == 0 and sba_2b == 1 and minBase == 1').query('year >= 2023')['sb_2b']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the MLPClassifier\n",
    "predict_sb_2b = MLPClassifier(hidden_layer_sizes=(4,4), activation='relu', max_iter=100, random_state=1000)\n",
    "predict_sb_2b.fit(X_train, y_train)\n",
    "\n",
    "# Get probability predictions on the test set\n",
    "probabilities = predict_sb_2b.predict_proba(X_test)\n",
    "\n",
    "# Create DataFrame from probabilities\n",
    "probability_df = pd.DataFrame(probabilities, columns=['sb_2b_not', 'sb_2b_pred'], index=X_test.index)\n",
    "\n",
    "# Concatenate probability_df with y_test and X_test\n",
    "sb_2b_df = pd.concat([X_test, y_test, probability_df], axis=1)\n",
    "\n",
    "# Create directory\n",
    "os.makedirs(os.path.join(model_path, \"M05. Steals\", todaysdate), exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "pickle.dump(predict_sb_2b, open(os.path.join(model_path, \"M05. Steals\", todaysdate, \"predict_sb_2b.sav\"), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50db40ea-91b9-49ae-90ef-c3a85777d6da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "quantiles = 10\n",
    "\n",
    "# Add xtiles (to examine how well predictions match actual results)\n",
    "sb_2b_df['quantile'] = pd.qcut(sb_2b_df['sb_2b_pred'], quantiles, labels=False)\n",
    "globals()[\"sb_2b_df\"] = sb_2b_df.groupby('quantile')[['sb_2b', 'sb_2b_pred']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a073fe11-198d-4b22-9bf6-7ef62b473fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figures\n",
    "plt.plot(sb_2b_df['quantile'], sb_2b_df['sb_2b_pred'], color='red')\n",
    "plt.plot(sb_2b_df['quantile'], sb_2b_df['sb_2b'], color='black')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9426db1c-dcb5-4f33-aab7-4b18e0a77da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb_2b_df[['sb_2b_pred', 'sb_2b']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007e7dd7-3be1-46b9-aedd-e8fa09565478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdcccc66-2137-4489-bd32-bf30bf505264",
   "metadata": {},
   "source": [
    "### Steal 3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ddb0d-e56d-4d27-99a6-9682f6830eb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Select relevant columns and handle missing values\n",
    "X = steal_df.query('pre_2b == 1 and pre_3b == 0 and sba_3b == 1 and minBase == 2').query('year >= 2023')[['outs_pre', 'sba_imp', 'sb_imp']] # + list(dummy_years.columns)]\n",
    "y = steal_df.query('pre_2b == 1 and pre_3b == 0 and sba_3b == 1 and minBase == 2').query('year >= 2023')['sb_3b']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the MLPClassifier\n",
    "predict_sb_3b = MLPClassifier(hidden_layer_sizes=(10,10,), activation='relu', max_iter=100, random_state=42)\n",
    "predict_sb_3b.fit(X_train, y_train)\n",
    "\n",
    "# Get probability predictions on the test set\n",
    "probabilities = predict_sb_3b.predict_proba(X_test)\n",
    "\n",
    "# Create DataFrame from probabilities\n",
    "probability_df = pd.DataFrame(probabilities, columns=['sb_3b_not', 'sb_3b_pred'], index=X_test.index)\n",
    "\n",
    "# Concatenate probability_df with y_test and X_test\n",
    "sb_3b_df = pd.concat([X_test, y_test, probability_df], axis=1)\n",
    "\n",
    "# Create directory\n",
    "os.makedirs(os.path.join(model_path, \"M05. Steals\", todaysdate), exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "pickle.dump(predict_sb_3b, open(os.path.join(model_path, \"M05. Steals\", todaysdate, \"predict_sb_3b.sav\"), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fd5c06-e7db-47cf-83a6-ebc5227116ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "quantiles = 10\n",
    "\n",
    "# Add xtiles (to examine how well predictions match actual results)\n",
    "sb_3b_df['quantile'] = pd.qcut(sb_3b_df['sb_3b_pred'], quantiles, labels=False)\n",
    "globals()[\"sb_3b_df\"] = sb_3b_df.groupby('quantile')[['sb_3b', 'sb_3b_pred']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51f402e-19c0-4e9b-97e0-bcc86c41392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figures\n",
    "plt.plot(sb_3b_df['quantile'], sb_3b_df['sb_3b_pred'], color='red')\n",
    "plt.plot(sb_3b_df['quantile'], sb_3b_df['sb_3b'], color='black')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf37366-fdb8-4fbe-9067-39b3c1674600",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb_3b_df[['sb_3b_pred', 'sb_3b']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399e3ed3-7b83-4491-8dca-3431e2135c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
