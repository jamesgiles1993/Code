{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6805bf9e",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0,
     "end_time": "2025-02-03T00:40:05.993842",
     "exception": false,
     "start_time": "2025-02-03T00:40:05.993842",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# 001. Sim Pipeline\n",
    "- This runs the pre-contest pipeline, simulations, and optimizations\n",
    "- Type: Pipeline\n",
    "- Run Frequency: Daily (Contest)\n",
    "- Created: 1/1/2025\n",
    "- Updated: 5/29/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749cb034",
   "metadata": {
    "papermill": {
     "duration": 0.015739,
     "end_time": "2025-02-03T00:40:06.009581",
     "exception": false,
     "start_time": "2025-02-03T00:40:05.993842",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20f0fe65",
   "metadata": {
    "papermill": {
     "duration": 5.141166,
     "end_time": "2025-02-03T00:40:11.161498",
     "exception": false,
     "start_time": "2025-02-03T00:40:06.020332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run \"C:\\Users\\james\\Documents\\MLB\\Code\\U1. Imports.ipynb\"\n",
    "%run \"C:\\Users\\james\\Documents\\MLB\\Code\\U2. Utilities.ipynb\"\n",
    "%run \"C:\\Users\\james\\Documents\\MLB\\Code\\U3. Classes.ipynb\"\n",
    "%run \"C:\\Users\\james\\Documents\\MLB\\Code\\U4. Datasets.ipynb\"\n",
    "%run \"C:\\Users\\james\\Documents\\MLB\\Code\\U5. Models.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35e25ae9",
   "metadata": {
    "papermill": {
     "duration": 0.179874,
     "end_time": "2025-02-03T00:40:11.348662",
     "exception": false,
     "start_time": "2025-02-03T00:40:11.168788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time until 12:30PM. -332 hours, 21 minutes, and 24 seconds.\n"
     ]
    }
   ],
   "source": [
    "pause_code(start_time='2025-06-15T12:30:00', timezone='EST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3612d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toronto - not always getting most updated weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac6a5e5",
   "metadata": {
    "papermill": {
     "duration": 0,
     "end_time": "2025-02-03T00:40:11.475767",
     "exception": false,
     "start_time": "2025-02-03T00:40:11.475767",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ea197e5",
   "metadata": {
    "papermill": {
     "duration": 0.015783,
     "end_time": "2025-02-03T00:40:11.412399",
     "exception": false,
     "start_time": "2025-02-03T00:40:11.396616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_date, end_date = \"20240101\", \"20241231\"\n",
    "# start_date, end_date = \"20240522\", \"20241231\"\n",
    "# start_date, end_date = todaysdate, todaysdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3af4656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "historic, slate_only = True, False\n",
    "# historic, slate_only = False, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce5f482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fe56fcf",
   "metadata": {
    "papermill": {
     "duration": 0.012034,
     "end_time": "2025-02-03T00:40:11.380878",
     "exception": false,
     "start_time": "2025-02-03T00:40:11.368844",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Games"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4d096c",
   "metadata": {
    "papermill": {
     "duration": 0.018009,
     "end_time": "2025-02-03T00:40:11.430408",
     "exception": false,
     "start_time": "2025-02-03T00:40:11.412399",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Read in games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a99d68b2-d7b9-4a9f-9bd0-27201a3a1b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 203 ms\n",
      "Wall time: 480 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "historic_game_df = pd.read_csv(os.path.join(baseball_path, \"game_df.csv\"))\n",
    "recent_game_df = create_games(yesterdaysdate, todaysdate, team_dict)\n",
    "historic_game_df = historic_game_df[~historic_game_df['date'].astype(str).isin([yesterdaysdate, todaysdate])]\n",
    "all_game_df = pd.concat([historic_game_df, recent_game_df], axis=0)\n",
    "all_game_df.to_csv(os.path.join(baseball_path, \"game_df.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd9bcac-b9ac-432d-b93f-0b5c7976e869",
   "metadata": {},
   "source": [
    "Select games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74d4ca49",
   "metadata": {
    "papermill": {
     "duration": 0.016483,
     "end_time": "2025-02-03T00:40:11.454907",
     "exception": false,
     "start_time": "2025-02-03T00:40:11.438424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "game_df = all_game_df[(all_game_df['date'].astype(str) >= start_date) & (all_game_df['date'].astype(str) <= end_date)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fab7bd9-e868-4270-81f6-b2611d090b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "646ae517",
   "metadata": {
    "papermill": {
     "duration": 0,
     "end_time": "2025-02-03T00:40:11.523558",
     "exception": false,
     "start_time": "2025-02-03T00:40:11.523558",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 002. Night Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c57d16-456a-4f83-87bb-7928cc66012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"game_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed096bb4",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.011815,
     "end_time": "2025-02-03T00:40:11.575418",
     "exception": false,
     "start_time": "2025-02-03T00:40:11.563603",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if historic == False:\n",
    "    %run \"002. Night Pipeline.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda6df8d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c631413",
   "metadata": {},
   "source": [
    "### Contests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef70f0f",
   "metadata": {},
   "source": [
    "Read in contests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0297141c",
   "metadata": {
    "papermill": {
     "duration": 0.00401,
     "end_time": "2025-02-03T00:40:11.368844",
     "exception": false,
     "start_time": "2025-02-03T00:40:11.364834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "contest_df = create_contests(start_date=start_date, end_date=end_date, name=\"Four\", entryFee=None, exclusions=['vs', 'Turbo', '@'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ca8c06-da8e-4e58-bb7a-789a63e4446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "contest_df = contest_df.drop(columns=['game_type', 'game_num', 'date', 'away_score', 'home_score']).merge(game_df, on=['game_id'], how='left')\n",
    "contest_df.sort_values('game_datetime').drop_duplicates('contestKey', keep='first').reset_index(drop=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcafc119",
   "metadata": {},
   "source": [
    "Select contestKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da14ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selections = [178137794]\n",
    "\n",
    "if selections == []:\n",
    "    selections = contest_df['contestKey'].astype(int).unique()\n",
    "\n",
    "selected_contest_df = contest_df[contest_df['contestKey'].astype(int).isin(selections)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88cfe22-d12e-4e43-aaab-3026ad24cfc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2807e09c",
   "metadata": {
    "papermill": {
     "duration": 0.015871,
     "end_time": "2025-02-03T00:40:11.603112",
     "exception": false,
     "start_time": "2025-02-03T00:40:11.587241",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1920def9-5431-4d0f-b968-9241dd9078ff",
   "metadata": {},
   "source": [
    "Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3b7cfdb-7eb5-413d-9a31-6981c509b97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_rows_by_tag(row):\n",
    "    color_map = {\n",
    "        'green': 'background-color: lightgreen',\n",
    "        'yellow': 'background-color: lightyellow',\n",
    "        'orange': 'background-color: lightsalmon',\n",
    "        'red': 'background-color: lightcoral'\n",
    "    }\n",
    "    color = color_map.get(row['Tag'], '')\n",
    "    return [color] * len(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f631815a-a4a4-4a30-a9cc-ceead8ffcb56",
   "metadata": {},
   "source": [
    "Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9607cec2",
   "metadata": {
    "papermill": {
     "duration": 0.01985,
     "end_time": "2025-02-03T00:40:11.638776",
     "exception": false,
     "start_time": "2025-02-03T00:40:11.618926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If the file exists and it's not a historic run\n",
    "if os.path.exists(os.path.join(baseball_path, \"A06. Weather\", \"2. RotoGrinders\", f\"RotoGrinders {todaysdate}.csv\")) and historic == False:\n",
    "    # Read RotoGrinders weather\n",
    "    rotogrinders_df = pd.read_csv(os.path.join(baseball_path, \"A06. Weather\", \"2. RotoGrinders\", f\"RotoGrinders {todaysdate}.csv\"))\n",
    "    # If it's missing, it's Oakland\n",
    "    rotogrinders_df['Away'].fillna(\"OAK\", inplace=True)\n",
    "    rotogrinders_df['Home'].fillna(\"OAK\", inplace=True)\n",
    "    # rotogrinders_df['Away'] = rotogrinders_df['Away'].str.replace(\"nan\", \"OAK\")\n",
    "    # Identify high-risk matchups\n",
    "    red_list = list(rotogrinders_df.query('Tag == \"red\" or Tag2 == \"red\"')['Away']) + list(rotogrinders_df.query('Tag == \"red\" or Tag2 == \"red\"')['Home'])\n",
    "    orange_list = list(rotogrinders_df.query('Tag == \"orange\" or Tag2 == \"orange\"')['Away']) + list(rotogrinders_df.query('Tag == \"orange\" or Tag2 == \"orange\"')['Home'])\n",
    "    # Display RotoGrinders weather\n",
    "    display(rotogrinders_df[['Tag', 'Tag2', 'Away', 'Home', 'date', 'Description']].style.apply(color_rows_by_tag, axis=1))\n",
    "\n",
    "else:    \n",
    "    red_list, orange_list = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17be5de",
   "metadata": {
    "papermill": {
     "duration": 0.008014,
     "end_time": "2025-02-03T00:40:11.654119",
     "exception": false,
     "start_time": "2025-02-03T00:40:11.646105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92d025b4",
   "metadata": {},
   "source": [
    "### Lineup Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7516aaf1",
   "metadata": {
    "papermill": {
     "duration": 0.011851,
     "end_time": "2025-02-03T00:40:12.011672",
     "exception": false,
     "start_time": "2025-02-03T00:40:11.999821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if historic == False:\n",
    "    # Might struggle in bulk daily runs\n",
    "    draftGroupId, contestDate, contestTime = selected_contest_df['draftGroupId'][0], selected_contest_df['Game Info'][0].split(\" \")[1], selected_contest_df['Game Info'][0].split(\" \")[2]\n",
    "    \n",
    "    # Openers\n",
    "    draftables = pd.read_csv(os.path.join(baseball_path, \"A01. DraftKings\", \"2. Draftables\", f\"Draftables {draftGroupId}.csv\"), encoding='iso-8859-1')\n",
    "    opener_list = list(draftables.query('Salary <= 5500 and `Roster Position` == \"P\"')['Name'])\n",
    "\n",
    "    # Teams with Projected Lineups\n",
    "    projected_lineups = pd.read_csv(os.path.join(baseball_path, \"A05. Rosters\", \"3. Batting Orders Projected\", f\"Batting Orders Projected {todaysdate}.csv\"))\n",
    "else:\n",
    "    opener_list, projected_lineups = [], None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12177cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3106f8a5",
   "metadata": {
    "papermill": {
     "duration": 0,
     "end_time": "2025-02-03T00:40:11.807562",
     "exception": false,
     "start_time": "2025-02-03T00:40:11.807562",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### B02. Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "234ebeb0",
   "metadata": {
    "papermill": {
     "duration": 0.135584,
     "end_time": "2025-02-03T00:40:11.958892",
     "exception": false,
     "start_time": "2025-02-03T00:40:11.823308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run \"C:\\Users\\james\\Documents\\MLB\\Code\\B02. Simulations.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb862f5e-0af1-4a7d-85b8-69ce035513ab",
   "metadata": {},
   "source": [
    "##### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "947ea858",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.022466,
     "end_time": "2025-02-03T00:40:11.992617",
     "exception": false,
     "start_time": "2025-02-03T00:40:11.970151",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1008"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wfx_type = \"adj\"\n",
    "num_batches, batch_size = os.cpu_count(), 63\n",
    "# num_batches, batch_size = 1, 1\n",
    "num_batches * batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bf3b72",
   "metadata": {},
   "source": [
    "##### Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5101239b",
   "metadata": {
    "papermill": {
     "duration": 0.013724,
     "end_time": "2025-02-03T00:40:12.032425",
     "exception": false,
     "start_time": "2025-02-03T00:40:12.018701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if slate_only == True:\n",
    "    # Just the slate(s) - Note: if running multiple contestKeys, overlapping slates, we don't need to rerun the same gmaes\n",
    "    sim_game_df = selected_contest_df.sort_values('game_datetime').reset_index(drop=True).drop_duplicates('game_id').copy()\n",
    "else:\n",
    "    # All games\n",
    "    sim_game_df = game_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d3f44e-88ea-40e3-be07-19fde758c3ea",
   "metadata": {},
   "source": [
    "##### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7c7f2b",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2025-02-03T00:40:12.032425",
     "status": "running"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAD@SDP 2024-03-20 06:05:00\n",
      "SDP@LAD 2024-03-21 06:05:00\n",
      "LAA@BAL 2024-03-28 15:05:00\n",
      "WSN@CIN 2024-03-28 16:10:00\n",
      "SFG@SDP 2024-03-28 16:10:00\n",
      "STL@LAD 2024-03-28 16:10:00\n",
      "TOR@TBR 2024-03-28 16:10:00\n",
      "MIN@KCR 2024-03-28 16:10:00\n",
      "DET@CHW 2024-03-28 16:10:00\n",
      "PIT@MIA 2024-03-28 16:10:00\n",
      "NYY@HOU 2024-03-28 16:10:00\n",
      "CHC@TEX 2024-03-28 19:35:00\n",
      "CLE@OAK 2024-03-28 22:07:00\n",
      "COL@ARI 2024-03-28 22:10:00\n",
      "BOS@SEA 2024-03-28 22:10:00\n",
      "20240320\n",
      "Projected batting orders not found.\n",
      "20240320 LAD@SDP 745444 0605\n",
      "Missing Baseball Monster order.\n",
      "Missing Baseball Monster order.\n",
      "Simming 1008 games took 30.77 seconds.\n",
      "LAD: 4.94 SDP: 3.91\n",
      "20240321\n",
      "Projected batting orders not found.\n",
      "20240321 SDP@LAD 746175 0605\n",
      "Missing Baseball Monster order.\n",
      "Missing Baseball Monster order.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Print out games to simulate\n",
    "_ = [print(f\"{row['away_team']}@{row['home_team']} {pd.to_datetime(row['game_datetime']).tz_convert('US/Eastern').strftime('%Y-%m-%d %H:%M:%S')}\") for index, row in sim_game_df.head(15).iterrows()]\n",
    "\n",
    "# Loop over dates of interest\n",
    "for date in list(sim_game_df['date'].astype(str).unique()): \n",
    "    print(date)\n",
    "    \n",
    "    # Extract matchups\n",
    "    matchup_list = [os.path.splitext(f)[0] for f in os.listdir(os.path.join(baseball_path, \"B01. Matchups\", f\"Matchups {date}\"))]\n",
    "    \n",
    "    # Create Game Sim path\n",
    "    os.makedirs(os.path.join(baseball_path, \"B02. Simulations\", \"1. Game Sims\", f\"Matchups {date}\"), exist_ok=True)  \n",
    "    \n",
    "    # Read in weather\n",
    "    try:\n",
    "        daily_weather_df = pd.read_csv(os.path.join(baseball_path, \"A06. Weather\", \"3. Park and Weather Factors\", f\"Park and Weather Factors {date}.csv\"))\n",
    "        # Choose WFX\n",
    "        for event in events_list:\n",
    "            daily_weather_df[f'{event}_wfx_l'] = daily_weather_df[f'{event}_wfx_{wfx_type}_l'].copy()\n",
    "            daily_weather_df[f'{event}_wfx_r'] = daily_weather_df[f'{event}_wfx_{wfx_type}_r'].copy()        \n",
    "    except:\n",
    "        print(\"Weather dataframe not created.\")\n",
    "        continue\n",
    "        \n",
    "    # Read in projected lineups\n",
    "    try:\n",
    "        # Read in dataframe\n",
    "        daily_order_bm_df = pd.read_csv(os.path.join(baseball_path, \"A05. Rosters\", \"3. Batting Orders Projected\", f\"Batting Orders Projected {date}.csv\"))\n",
    "        # Create BBREFTEAM column\n",
    "        daily_order_bm_df['BBREFTEAM'] = daily_order_bm_df['team code'].map(team_dict)\n",
    "        # Clean whitespace from column names\n",
    "        daily_order_bm_df.columns = [col.strip() for col in daily_order_bm_df.columns]\n",
    "        # Rename\n",
    "        daily_order_bm_df.rename(columns={'mlb id': 'id', 'batting order': 'batting_order'}, inplace=True)\n",
    "    except:\n",
    "        daily_order_bm_df = None\n",
    "        print(\"Projected batting orders not found.\")\n",
    "    \n",
    "    # Loop over games\n",
    "    daily_df = sim_game_df[sim_game_df['date'].astype(str) == str(date)].reset_index()\n",
    "    for i in range(len(daily_df)):            \n",
    "        # Extract info from sim_game_df to look up proper file in matchups path\n",
    "        away_team = daily_df['away_team'][i]\n",
    "        home_team = daily_df['home_team'][i]\n",
    "        game_id = daily_df['game_id'][i]\n",
    "        game_num = daily_df['game_num'][i]\n",
    "        \n",
    "        # Beginning of filename in matchup folder\n",
    "        lookup = f\"{away_team}@{home_team} {game_id}\"\n",
    "        \n",
    "        # Find the matchup file\n",
    "        matchup = next((matchup for matchup in matchup_list if matchup.startswith(lookup)), None)\n",
    "        print(date, matchup)\n",
    "        \n",
    "        ### Read in lineups\n",
    "        ## Away\n",
    "        # MLB API\n",
    "        away_order_api_df = create_order_api(date=date, team=away_team, game_id=game_id)\n",
    "        # Baseball Monster\n",
    "        away_order_bm_df = create_order_bm(daily_order_bm_df, away_team, game_num=game_num)\n",
    "        # Choose Baseball Monster if it's complete and API is not\n",
    "        if away_order_bm_df is not None and away_order_bm_df['batting_order'].sum() == 45 and away_order_api_df['batting_order'].sum() != 45:\n",
    "            away_order_df = away_order_bm_df.copy()\n",
    "        else:\n",
    "            away_order_df = away_order_api_df.copy()\n",
    "        \n",
    "        ## Home\n",
    "        # MLB API\n",
    "        home_order_api_df = create_order_api(date=date, team=home_team, game_id=game_id)\n",
    "        # Baseball Monster\n",
    "        home_order_bm_df = create_order_bm(daily_order_bm_df, home_team, game_num=game_num)\n",
    "        # Choose Baseball Monster if it's complete and API is not\n",
    "        if home_order_bm_df is not None and home_order_bm_df['batting_order'].sum() == 45 and home_order_api_df['batting_order'].sum() != 45:\n",
    "            home_order_df = home_order_bm_df.copy()\n",
    "        else:\n",
    "            home_order_df = home_order_api_df.copy()    \n",
    "            \n",
    "        ### Player Dataframes\n",
    "        # Create matchup path\n",
    "        matchup_path = os.path.join(baseball_path, \"B01. Matchups\", f\"Matchups {date}\", f\"{matchup}.xlsx\")\n",
    "        \n",
    "        # Read in Dataframes\n",
    "        away_batter_df = pd.read_excel(matchup_path, sheet_name=\"AwayBatters\")\n",
    "        home_batter_df = pd.read_excel(matchup_path, sheet_name=\"HomeBatters\")\n",
    "        away_pitcher_df = pd.read_excel(matchup_path, sheet_name=\"AwayPitchers\")\n",
    "        home_pitcher_df = pd.read_excel(matchup_path, sheet_name=\"HomePitchers\")\n",
    "        \n",
    "        ####### Remove from matchup files later - then this can be deleted\n",
    "        away_batter_df.drop(columns={'batting_order'}, inplace=True)\n",
    "        home_batter_df.drop(columns={'batting_order'}, inplace=True)\n",
    "        ###### Remove from matchup files later - then this can be deleted\n",
    "        \n",
    "        \n",
    "        ### Player Objects\n",
    "        AwayBatters = create_batter_objects(away_batter_df, away_order_df, scale_batter_stats, scale_batter_stats_steamer, impute_batter_stats)\n",
    "        HomeBatters = create_batter_objects(home_batter_df, home_order_df, scale_batter_stats, scale_batter_stats_steamer, impute_batter_stats)\n",
    "        AwayPitchers = create_pitcher_objects(away_pitcher_df, scale_pitcher_stats, scale_pitcher_stats_steamer, impute_pitcher_stats)\n",
    "        HomePitchers = create_pitcher_objects(home_pitcher_df, scale_pitcher_stats, scale_pitcher_stats_steamer, impute_pitcher_stats)       \n",
    "    \n",
    "\n",
    "        ### Park Object\n",
    "        # Subset weather\n",
    "        weather_df = daily_weather_df.query(f'gamePk == {game_id}').reset_index(drop=True)\n",
    "        # Create object\n",
    "        try:\n",
    "            row_data = weather_df.iloc[0].to_dict()  # Convert the single row to a dictionary\n",
    "            park_object = Park(**row_data)\n",
    "        except:\n",
    "            print(\"Game missing from weather dataframe.\")\n",
    "            continue\n",
    "            \n",
    "        ### Scoreboard Object\n",
    "        game_template = Scoreboard(AwayBatters, HomeBatters, AwayPitchers, HomePitchers, 9)       \n",
    "        \n",
    "        ### Sim games\n",
    "        start = time.time()\n",
    "        game_list = Parallel(n_jobs=num_batches, verbose=False)(delayed(sim_game_batch)(game_template, predict_pulls, predict_leverage, predict_binary, predict_outs, \n",
    "                                                                                        predict_safe, predict_all, predict_all_adjusted, \n",
    "                                                                                        opener_list, park_object, innings=9, debug=True, \n",
    "                                                                                        batch_size=batch_size) for batches in range(num_batches))\n",
    "        \n",
    "        game_list = [game for sublist in game_list for game in sublist]\n",
    "        print(f\"Simming {batch_size*num_batches} games took {round(time.time() - start, 2)} seconds.\")\n",
    "        \n",
    "        # Create player path\n",
    "        player_path = os.path.join(baseball_path, \"B02. Simulations\", \"2. Player Sims\", f\"Matchups {date}\", f\"{matchup}\") \n",
    "        # Clear it \n",
    "        if os.path.exists(player_path):\n",
    "            shutil.rmtree(player_path)\n",
    "        # Make folder\n",
    "        os.makedirs(player_path, exist_ok=True)\n",
    "        \n",
    "        # Create list of game scores\n",
    "        game_score_df_list = []\n",
    "        # Save each object in the list to a separate file\n",
    "        for i, game_object in enumerate(game_list):\n",
    "            # Delete unnecessary attributes from batter objects\n",
    "            for batter in game_object.away_batters + game_object.home_batters:\n",
    "                batter = batter.keep_selected_attributes()\n",
    "            # Delete unnecessary attributes from pitcher objects\n",
    "            for pitcher in game_object.away_pitchers + game_object.home_pitchers:\n",
    "                pitcher = pitcher.keep_selected_attributes()\n",
    "            # Delete unnecessary attributes from game objects\n",
    "            game_object.keep_selected_attributes()\n",
    "\n",
    "            ### Construct DataFrames\n",
    "            # Game\n",
    "            game_score_df = pd.DataFrame({\n",
    "                \"away_score\": [game_object.away_score],\n",
    "                \"home_score\": [game_object.home_score]\n",
    "            })\n",
    "            # Append game_scores\n",
    "            game_score_df_list.append(game_score_df)\n",
    "\n",
    "            # Batters\n",
    "            away_batters_df = pd.DataFrame([vars(batter) for batter in game_object.away_batters])\n",
    "            away_batters_df['team'] = \"away\"\n",
    "            home_batters_df = pd.DataFrame([vars(batter) for batter in game_object.home_batters])\n",
    "            home_batters_df['team'] = \"home\"\n",
    "            batters_df = pd.concat([away_batters_df, home_batters_df], axis=0)\n",
    "            # Save\n",
    "            batters_df.to_csv(os.path.join(player_path, \"batters_{}.csv\").format(i), index=False)\n",
    "\n",
    "            # Pitchers\n",
    "            away_pitchers_df = pd.DataFrame([vars(pitcher) for pitcher in game_object.away_pitchers])\n",
    "            away_pitchers_df['team'] = \"away\"\n",
    "            home_pitchers_df = pd.DataFrame([vars(pitcher) for pitcher in game_object.home_pitchers])\n",
    "            home_pitchers_df['team'] = \"home\"\n",
    "            pitchers_df = pd.concat([away_pitchers_df, home_pitchers_df], axis=0)\n",
    "            # Save\n",
    "            pitchers_df.to_csv(os.path.join(player_path, \"pitchers_{}.csv\").format(i), index=False)\n",
    "            \n",
    "        # Concatenate game scores\n",
    "        game_scores_df = pd.concat(game_score_df_list, axis=0).reset_index(drop=True)\n",
    "        # Write to CSV\n",
    "        game_scores_df.to_csv(os.path.join(baseball_path, \"B02. Simulations\", \"1. Game Sims\", f\"Matchups {date}\", f\"game_{game_id}.csv\"), index=False)\n",
    "        # Print average score\n",
    "        print(f\"{away_team}: {round(game_scores_df['away_score'].mean(), 2)}\", f\"{home_team}: {round(game_scores_df['home_score'].mean(), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87136225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big Q: Are individual game scores drawn toward each other or toward the average?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5159e139",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### B03. Lineups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a9e97f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run \"B03. Optimizer.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b10914a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pareto Set\n",
    "pareto_set = ['Plus3', 'batter rostership']\n",
    "sense_list = ['Max', 'Min']\n",
    "# Lineup ranking method\n",
    "sort_by = ['pareto', 'Plus3']\n",
    "ascending_list = [False, False]\n",
    "\n",
    "# Options\n",
    "sort_by_list = ['P50', 'P75', 'P90', 'P95', 'P99', 'P100', 'Tail', 'Sim STD', 'Plus2', 'Plus3', \n",
    "                'Top1%', 'Top5%', 'Top10%', 'Top20%', 'Top50%', 'rostership', 'pitcher rostership', 'batter rostership', 'pareto']\n",
    "\n",
    "\n",
    "# Set maximum ownership by position group \n",
    "max_exposure_batters, max_exposure_pitchers = 0.5, 0.7\n",
    "\n",
    "# Share of each stack type\n",
    "stack_dictionary = {\"5-2-1\":   0.37,\n",
    "                    \"5-3\":     0.23,\n",
    "                    \"5-1-1-1\": 0.18,\n",
    "                    \"4-3-1\":   0.11,\n",
    "                    \"4-2-1-1\": 0.11}\n",
    "\n",
    "# Number of lineups to create\n",
    "num_lineups = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d03fd6c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "##### Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2ba727",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "##### 1. Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeef162",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for _, row in selected_contest_df.drop_duplicates(subset=['contestKey'])[['contestKey', 'draftGroupId', 'roto_slate']].iterrows():\n",
    "    contestKey, draftGroupId, roto_slate = row['contestKey'], row['draftGroupId'], row['roto_slate']\n",
    "    print(contestKey)\n",
    "    guide = selected_contest_df[selected_contest_df['contestKey'] == contestKey].reset_index(drop=True)\n",
    "    # Create draftables with sims\n",
    "    draftables_with_sims = create_player_file(contestKey, guide, draftGroupId, roto_slate, max_exposure_pitchers, max_exposure_batters, \n",
    "                                              projections='robot', rostership='roto', ownership_spread=0.25)\n",
    "    # Write to CSV\n",
    "    draftables_with_sims.to_csv(os.path.join(baseball_path, \"B03. Lineups\", \"1. Players\", f\"Players {contestKey}.csv\"), index=False, encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d12971-f32b-430d-a3c8-fd42b6f4685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_button(os.path.join(baseball_path, \"B03. Lineups\", \"1. Players\", f\"Players {contestKey}.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13f9b63",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "##### 2. Lineups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305b558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for _, row in selected_contest_df.drop_duplicates(subset=['contestKey'])[['contestKey', 'slate_size']].iterrows():\n",
    "    contestKey, slate_size = row['contestKey'], row['slate_size']\n",
    "    print(contestKey, slate_size)\n",
    "    \n",
    "    # Define the constraints\n",
    "    maximum_constraints = [\n",
    "        (contestKey, 49000, 4, [5, 2, 1],    red_list + orange_list, 10, None, 0.2, 0.05, math.ceil(stack_dictionary['5-2-1']   * num_lineups), \"Max\"),\n",
    "        (contestKey, 49000, 4, [5, 3],       red_list + orange_list, 10, None, 0.2, 0.05, math.ceil(stack_dictionary['5-3']     * num_lineups), \"Max\"),\n",
    "        (contestKey, 49000, 4, [5, 1, 1, 1], red_list + orange_list, 10, None, 0.2, 0.05, math.ceil(stack_dictionary['5-1-1-1'] * num_lineups), \"Max\"),\n",
    "        (contestKey, 49000, 4, [4, 3, 1],    red_list + orange_list, 10, None, 0.2, 0.05, math.ceil(stack_dictionary['4-3-1']   * num_lineups), \"Max\"),\n",
    "        (contestKey, 49000, 4, [4, 2, 1, 1], red_list + orange_list, 10, None, 0.2, 0.05, math.ceil(stack_dictionary['4-2-1-1'] * num_lineups), \"Max\")\n",
    "    ]\n",
    "    \n",
    "    minimum_constraints = [\n",
    "        (contestKey, 49000, 1, [5, 2, 1],    red_list, 0, None, 0.2, 0.05, math.ceil(stack_dictionary['5-2-1']   * num_lineups), \"Min\"),\n",
    "        (contestKey, 49000, 1, [5, 3],       red_list, 0, None, 0.2, 0.05, math.ceil(stack_dictionary['5-3']     * num_lineups), \"Min\"),\n",
    "        (contestKey, 49000, 1, [5, 1, 1, 1], red_list, 0, None, 0.2, 0.05, math.ceil(stack_dictionary['5-1-1-1'] * num_lineups), \"Min\"),\n",
    "        (contestKey, 49000, 1, [4, 3, 1],    red_list, 0, None, 0.2, 0.05, math.ceil(stack_dictionary['4-3-1']   * num_lineups), \"Min\"),\n",
    "        (contestKey, 49000, 1, [4, 2, 1, 1], red_list, 0, None, 0.2, 0.05, math.ceil(stack_dictionary['4-2-1-1'] * num_lineups), \"Min\")\n",
    "    ]\n",
    "    \n",
    "    # Track failed constraints\n",
    "    failed_max_constraints = []\n",
    "    failed_max_indices = []\n",
    "\n",
    "    # Create lineups with maximum constraints\n",
    "    print(\"Attempting Maximum Constraints.\")\n",
    "    optimizers = Parallel(n_jobs=-1, backend=\"threading\", verbose=0)(delayed(create_lineups2)(params) for params in maximum_constraints)\n",
    "    \n",
    "    # Print errors and store failed constraints with their indices\n",
    "    for i, optimizer in enumerate(optimizers):\n",
    "        if type(optimizer) == str:\n",
    "            print(optimizer)\n",
    "            failed_max_constraints.append(maximum_constraints[i])  # Store failed constraints\n",
    "            failed_max_indices.append(i)  # Track the index of the failed constraint\n",
    "\n",
    "    # Combine the optimizers from maximum constraints\n",
    "    combined_optimizers = optimizers.copy()\n",
    "\n",
    "    # If there are any failed constraints, attempt to run the corresponding minimum constraints for them\n",
    "    if failed_max_constraints:\n",
    "        print(\"Maximum Constraints Failed. Attempting Minimum Constraints for failed stacks.\")\n",
    "        \n",
    "        # Create lineups with corresponding minimum constraints for failed stacks\n",
    "        min_optimizers = Parallel(n_jobs=-1, backend=\"threading\", verbose=0)(\n",
    "            delayed(create_lineups2)(minimum_constraints[i]) for i in failed_max_indices)\n",
    "        \n",
    "        # Print errors for minimum constraints\n",
    "        for optimizer in min_optimizers:\n",
    "            if type(optimizer) == str:\n",
    "                print(optimizer)\n",
    "\n",
    "        # Combine the optimizers from minimum constraints with the maximum ones\n",
    "        combined_optimizers.extend(min_optimizers)\n",
    "\n",
    "    # Write to CSV\n",
    "    try:\n",
    "        write_lineups(combined_optimizers)\n",
    "    except:\n",
    "        print(f\"Couldn't run contest {contestKey}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2816d87",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "##### 3. Lineups Ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccd1a94",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for _, row in selected_contest_df.drop_duplicates(subset=['contestKey'])[['contestKey', 'roto_slate']].iterrows():\n",
    "    contestKey, roto_slate = row['contestKey'], row['roto_slate']\n",
    "    print(contestKey)\n",
    "    lineups_ranked = choose_lineups(contestKey, roto_slate, pareto_set, sense_list, sort_by, ascending_list)\n",
    "    lineups_ranked.to_csv(os.path.join(baseball_path, \"B03. Lineups\", \"3. Lineups Ranked\", f\"Lineups Ranked {contestKey}.csv\"), index=False)\n",
    "    \n",
    "    lineups_ranked.reset_index(drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef1ba67",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "excel_button(os.path.join(baseball_path, \"B03. Lineups\", \"3. Lineups Ranked\", f\"Lineups Ranked {contestKey}.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b02342",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "##### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21428f1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    lineups_ranked,\n",
    "    y='Plus3', # should this be sort_by?\n",
    "    x='batter rostership',\n",
    "    color='pareto',\n",
    "    hover_data={\n",
    "        'index': True,\n",
    "        'P': True,\n",
    "        'P.1': True,\n",
    "        '1B': True,\n",
    "        '2B': True,\n",
    "        '3B': True,\n",
    "        'SS': True,\n",
    "        'OF': True,\n",
    "        'OF.1': True,\n",
    "        'OF.2': True,\n",
    "        'Wins': True,\n",
    "        'Top1%': True},\n",
    "    title='Scatter Plot of Plus3 vs Batter Rostership',\n",
    "    labels={'Plus3': 'Plus3', 'batter rostership': 'Batter Rostership'}\n",
    ")\n",
    "\n",
    "# Update the size of the figure and invert the y-axis\n",
    "fig.update_layout(\n",
    "    width=1000,  # Set the width of the plot\n",
    "    height=1000,  # Set the height of the plot\n",
    "    xaxis=dict(autorange='reversed')  # Invert the y-axis\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=10))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeac04d6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "##### 4. Uploads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871c3bd3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "upload = create_upload_file(contestKey, sort_by)\n",
    "upload.head(50).to_csv(os.path.join(baseball_path, \"B03. Lineups\", \"4. Uploads\", f\"Upload {contestKey}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f47ed59",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "##### 5. Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d4cd93",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "entry = create_entry_file(draftGroupId, contestKey)\n",
    "entry.to_csv(os.path.join(baseball_path, \"B03. Lineups\", \"5. Entries\", f\"Entries {draftGroupId}.csv\"), index=False, encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b95d42",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "##### Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bc70e9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "upload_entries(draftGroupId)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb086421",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "##### Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be87b0b4-39d5-4a33-9837-ef77c2985054",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "email_upload_file(draftGroupId, contestKey, contestTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26ff391-ec82-4bc3-80cb-feafdbd98f87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4af5b0b-375f-4b7f-a30f-c6165e8793d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89055069-35f7-4721-9476-adf920d6a654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b224a1-d732-414d-88a8-7ebb5ca0d770",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@deathbeds/ipydrawio": {
   "xml": ""
  },
  "kernelspec": {
   "display_name": "Python (conda-base)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "C:\\Users\\james\\Documents\\MLB\\Code\\000. Sim Pipeline.ipynb",
   "output_path": "C:\\Users\\james\\Documents\\MLB\\Code\\000. Sim Pipeline.ipynb",
   "parameters": {},
   "start_time": "2025-02-03T00:40:04.217908",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
