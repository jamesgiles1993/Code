{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c333deb8-8bf3-4890-a652-0eee019ab5f8",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfd4f0ff-0070-4710-b2b9-caccc2aa1f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running imports...\n",
      "Imports in.\n"
     ]
    }
   ],
   "source": [
    "if \"running_pipeline\" not in globals():\n",
    "    print(\"Running imports...\")\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U1. Imports.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U2. Utilities.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U3. Classes.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U4. Datasets.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U5. Models.ipynb\"\n",
    "    print(\"Imports in.\")\n",
    "else:\n",
    "    print(\"Imports already in.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a4a660-9bd9-438f-a1c5-82a22c48fedf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea6910f3-e291-4228-8e49-67fd0f2af155",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac7f0435-66c0-4ef9-8cd6-a5af0717bedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"running_pipeline\" not in globals():\n",
    "    write_complete_dataset = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e388e4ae-f454-4342-bd6f-04b9583802a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"20240101\"\n",
    "end_date = todaysdate\n",
    "write_complete_dataset = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a444b67-20ef-49ed-a823-4743182bfb15",
   "metadata": {},
   "source": [
    "### Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c1b4fc0-42eb-457e-9562-3fc39d0076cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df = create_games(start_date, end_date, team_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad9e9c20-a6bb-4085-9f38-b43077302024",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df = game_df[game_df['status'] != \"Postponed\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f308ec75-c581-4908-a6fb-1beb2e8a582a",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66cb519-2136-4190-979b-80ef52acc92e",
   "metadata": {},
   "source": [
    "##### Create Matchup File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "522388e3-aa51-4fcb-9b4b-cb62917e7f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matchup_file(game_df, row, complete_dataset, steamer_hitters_df, steamer_pitchers_df, team_map):\n",
    "    game_id = game_df['game_id'][row]\n",
    "    game_datetime = game_df['game_datetime'][row]\n",
    "    game_date = game_df['game_date'][row]\n",
    "    date = int(game_date.replace(\"-\", \"\"))\n",
    "    away_id = game_df['away_id'][row]\n",
    "    home_id = game_df['home_id'][row]\n",
    "    # Retrieve Baseball Reference team abbreviation\n",
    "    team_map_cut = team_map[['teamId', 'BBREFTEAM']].set_index('teamId')\n",
    "    \n",
    "    away_team = team_map_cut.loc[away_id]['BBREFTEAM']\n",
    "    home_team = team_map_cut.loc[home_id]['BBREFTEAM']\n",
    "    \n",
    "    for team in away_team, home_team:\n",
    "        # Read in rosters\n",
    "        roster_df = pd.read_csv(os.path.join(baseball_path, \"A05. Rosters\", \"2. Rosters\", f\"Rosters {date}\", f\"Roster {team} {date}.csv\"), encoding='iso-8859-1')\n",
    "\n",
    "        # Read in batting orders\n",
    "        order_df = pd.read_csv(os.path.join(baseball_path, \"A05. Rosters\", \"1. Batting Orders\", f\"Batting Orders {date}\", f\"Batting Order {team} {game_id}.csv\"), encoding='iso-8859-1')        \n",
    "        \n",
    "        # Read in bullpens\n",
    "        bullpen_df = pd.read_csv(os.path.join(baseball_path, \"A04. Bullpens\", f\"Bullpens {date}\", f\"Bullpen {team} {date}.csv\"), encoding='iso-8859-1')  \n",
    "        \n",
    "        # Merge batting order onto roster\n",
    "        team_df = pd.merge(roster_df, order_df[['id', 'fullName', 'position', 'status', 'order']], on='id', how='outer', suffixes=(\"\",\"2\"))\n",
    "        \n",
    "        # Fill in missings\n",
    "        team_df['batSide'].fillna('Right', inplace=True)\n",
    "        team_df['pitchHand'].fillna('Right', inplace=True)\n",
    "        team_df['fullName'].fillna(team_df['fullName2'], inplace=True)\n",
    "        team_df['position'].fillna(team_df['position2'], inplace=True)\n",
    "        \n",
    "        # Merge pitcher leverage onto roster\n",
    "        ### Testing\n",
    "        team_df['fullName'] = team_df['fullName'].apply(remove_accents)\n",
    "        ### Testing\n",
    "        team_df = pd.merge(team_df, bullpen_df[['Name', 'Leverage']], left_on='fullName', right_on='Name', how='left')\n",
    "        \n",
    "        # Add weather\n",
    "        box = create_box(game_id)\n",
    "        team_df['weather'] = box[0]\n",
    "        team_df['wind'] = box[1]\n",
    "        team_df['park'] = box[2]\n",
    "        team_df = clean_weather(team_df)\n",
    "\n",
    "        # Add venue\n",
    "        team_df['venue_id'] = game_df['venue_id'][row]\n",
    "        \n",
    "        # Add starters\n",
    "        team_df['away_starter'] = game_df['away_probable_pitcher'][row]\n",
    "        team_df['home_starter'] = game_df['home_probable_pitcher'][row]\n",
    "\n",
    "        team_df['away_starter'] = team_df['away_starter'].apply(remove_accents)\n",
    "        team_df['home_starter'] = team_df['home_starter'].apply(remove_accents)\n",
    "        \n",
    "        \n",
    "        # Assign Leverage of 1 to starting pitcher\n",
    "        team_df['Leverage'] = np.where((team_df['fullName'] == team_df['away_starter']) | (team_df['fullName'] == team_df['home_starter']), 1, team_df['Leverage'])\n",
    "\n",
    "        # Determine batting order\n",
    "        team_df['order'] = pd.to_numeric(team_df['order'], errors='coerce')\n",
    "        team_df['batting_order'] = np.nan\n",
    "        for i in range(9):\n",
    "            team_df['batting_order'] = np.where(team_df['order'] == (i+1)*100, i+1, team_df['batting_order'])\n",
    "\n",
    "        ### Batters\n",
    "        batter_df = team_df[team_df['position'] != \"Pitcher\"]\n",
    "\n",
    "        ## Dataset\n",
    "        # Vs. LHP\n",
    "        vs_l = complete_dataset[complete_dataset['date'] < int(date)]\n",
    "        vs_l = vs_l[vs_l['pitchHand'] == \"L\"]\n",
    "        vs_l.drop_duplicates(subset='batter', keep='last', inplace=True)\n",
    "\n",
    "        # Merge in stats\n",
    "        batter_df = pd.merge(batter_df, vs_l[['batter'] + batter_inputs + ['imp_b', 'pa_b', 'pa_b_long']], left_on='id', right_on='batter', how='left')\n",
    "\n",
    "        # Vs. RHP\n",
    "        vs_r = complete_dataset[complete_dataset['date'] < int(date)]\n",
    "        vs_r = vs_r[vs_r['pitchHand'] == \"R\"]\n",
    "        vs_r.drop_duplicates(subset='batter', keep='last', inplace=True)\n",
    "\n",
    "        # Merge in stats\n",
    "        batter_df = pd.merge(batter_df, vs_r[['batter'] + batter_inputs + ['imp_b', 'pa_b', 'pa_b_long']], left_on='id', right_on='batter', how='left', suffixes=(\"_l\", \"_r\"))\n",
    "\n",
    "        ## Steamer \n",
    "        # Keep last observation before date (may switch to <= if I find projections are up early)\n",
    "        steamer_hitters_last_df = steamer_hitters_df[steamer_hitters_df['date'] <= int(date)]\n",
    "        steamer_hitters_last_df.drop_duplicates(subset='mlbamid', keep='last', inplace=True)\n",
    "\n",
    "        # Merge\n",
    "        batter_df = pd.merge(batter_df, steamer_hitters_last_df, left_on='id', right_on='mlbamid', how='left', suffixes=(\"\", \"_fg\"))\n",
    "\n",
    "        # Remove redundant variables\n",
    "        batter_df.drop(columns={'batter_l', 'batter_r', 'firstname', 'lastname', 'mlbamid', 'fullName2', 'position2'}, inplace=True)\n",
    "\n",
    "        # Clean\n",
    "        # batter_df = clean_order(batter_df)\n",
    "\n",
    "        # Move 'batting_order' to the desired position\n",
    "        batter_df.insert(batter_df.columns.get_loc('order') + 1, 'batting_order', batter_df.pop('batting_order'))\n",
    "\n",
    "        # Sort\n",
    "        batter_df.sort_values('batting_order', inplace=True)\n",
    "\n",
    "\n",
    "        ### Pitchers\n",
    "        pitcher_df = team_df[(team_df['position'] == \"Pitcher\") | (team_df['position'] == \"Two-Way Player\")]\n",
    "\n",
    "        ## Dataset\n",
    "        # Vs. LHB\n",
    "        vs_l = complete_dataset[complete_dataset['date'] < int(date)]\n",
    "        vs_l = vs_l[vs_l['batSide'] == \"L\"]\n",
    "        vs_l.drop_duplicates(subset='pitcher', keep='last', inplace=True)\n",
    "\n",
    "        # Merge in stats\n",
    "        pitcher_df = pd.merge(pitcher_df, vs_l[['pitcher'] + pitcher_inputs + ['imp_p', 'pa_p', 'pa_p_long']], left_on='id', right_on='pitcher', how='left')\n",
    "\n",
    "        # Vs. RHB\n",
    "        vs_r = complete_dataset[complete_dataset['date'] < int(date)]\n",
    "        vs_r = vs_r[vs_r['batSide'] == \"R\"]\n",
    "        vs_r.drop_duplicates(subset='pitcher', keep='last', inplace=True)\n",
    "\n",
    "        # Merge in stats\n",
    "        pitcher_df = pd.merge(pitcher_df, vs_r[['pitcher'] + pitcher_inputs + ['imp_p', 'pa_p', 'pa_p_long']], left_on='id', right_on='pitcher', how='left', suffixes=(\"_l\", \"_r\"))\n",
    "\n",
    "        ## Steamer \n",
    "        # Keep last observation before date (may switch to <= if I find projections are up early)\n",
    "        steamer_pitchers_last_df = steamer_pitchers_df[steamer_pitchers_df['date'] <= int(date)]\n",
    "        steamer_pitchers_last_df.drop_duplicates(subset='mlbamid', keep='last', inplace=True)\n",
    "\n",
    "        # Merge\n",
    "        pitcher_df = pd.merge(pitcher_df, steamer_pitchers_last_df, left_on='id', right_on='mlbamid', how='left', suffixes=(\"\", \"_fg\"))\n",
    "\n",
    "        # Remove redundant variables\n",
    "        pitcher_df.drop(columns={'pitcher_l', 'pitcher_r', 'firstname', 'lastname', 'mlbamid', 'fullName2', 'position2'}, inplace=True)\n",
    "\n",
    "        # Move 'batting_order' to the desired position\n",
    "        pitcher_df.insert(pitcher_df.columns.get_loc('order') + 1, 'batting_order', pitcher_df.pop('batting_order'))\n",
    "\n",
    "        # Sort\n",
    "        pitcher_df.sort_values('Leverage', inplace=True)\n",
    "\n",
    "        if team == away_team:\n",
    "            away_batter_df = batter_df.copy()\n",
    "            away_pitcher_df = pitcher_df.copy()\n",
    "        else:\n",
    "            home_batter_df = batter_df.copy()\n",
    "            home_pitcher_df = pitcher_df.copy()\n",
    "\n",
    "    # Drop duplicates: \n",
    "    away_batter_df.drop_duplicates('id', keep='last', inplace=True)\n",
    "    away_batter_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    home_batter_df.drop_duplicates('id', keep='last', inplace=True)\n",
    "    home_batter_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    away_pitcher_df.drop_duplicates('id', keep='last', inplace=True)\n",
    "    away_pitcher_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    home_pitcher_df.drop_duplicates('id', keep='last', inplace=True)\n",
    "    home_pitcher_df.reset_index(drop=True, inplace=True)\n",
    "       \n",
    "        \n",
    "    return away_batter_df, away_pitcher_df, home_batter_df, home_pitcher_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a18cd04-b548-4a64-95fc-1059bae92f64",
   "metadata": {},
   "source": [
    "##### Create Matchup Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f803b624-5b13-4af6-ab8f-3276035da579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matchup_files(game_df, row, complete_dataset, steamer_hitters_df, steamer_pitchers_df, team_map):\n",
    "\n",
    "    # Extract IDs\n",
    "    game_id = game_df['game_id'][row]\n",
    "    away_id = game_df['away_id'][row]\n",
    "    home_id = game_df['home_id'][row]\n",
    "\n",
    "    # Retrieve Baseball Reference team abbreviation\n",
    "    team_map_cut = team_map[['teamId', 'BBREFTEAM']].set_index('teamId')\n",
    "    away_team = team_map_cut.loc[away_id]['BBREFTEAM']\n",
    "    home_team = team_map_cut.loc[home_id]['BBREFTEAM']    \n",
    "\n",
    "    # Extract date\n",
    "    game_date = game_df['game_date'][row]\n",
    "    game_date = game_date.replace(\"-\", \"\")\n",
    "    game_datetime = game_df['game_datetime'][row]\n",
    "\n",
    "    # Convert string to datetime object\n",
    "    utc_datetime = datetime.datetime.strptime(game_datetime, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "    # Define the UTC timezone\n",
    "    utc_timezone = pytz.timezone(\"UTC\")\n",
    "\n",
    "    # Set the UTC timezone for the datetime object\n",
    "    utc_datetime = utc_timezone.localize(utc_datetime)\n",
    "\n",
    "    # Convert to Eastern Standard Time (EST)\n",
    "    est_timezone = pytz.timezone(\"US/Eastern\")\n",
    "    est_datetime = utc_datetime.astimezone(est_timezone)\n",
    "\n",
    "    # Format the result\n",
    "    formatted_time = est_datetime.strftime(\"%H%M\")\n",
    "\n",
    "\n",
    "    # Create position dfs\n",
    "    away_batter_df, away_pitcher_df, home_batter_df, home_pitcher_df = create_matchup_file(game_df, row, complete_dataset, steamer_hitters_df, steamer_pitchers_df, team_map)\n",
    "\n",
    "    \n",
    "    # Create folder, if it doesn't exist\n",
    "    os.makedirs(os.path.join(baseball_path, \"B01. Matchups\", f'Matchups {game_date}'), exist_ok=True)\n",
    "\n",
    "    # File name\n",
    "    matchup_file = f\"{away_team}@{home_team} {game_id} {formatted_time}\"\n",
    "\n",
    "    # Write to Excel\n",
    "    away_batter_df.to_excel(os.path.join(baseball_path, \"B01. Matchups\", f'Matchups {game_date}', f'{matchup_file}.xlsx'), sheet_name=\"AwayBatters\", engine='openpyxl', index=False)\n",
    "\n",
    "    with pd.ExcelWriter(os.path.join(baseball_path, \"B01. Matchups\", f'Matchups {game_date}', f'{matchup_file}.xlsx'), mode='a', engine='openpyxl') as writer:  \n",
    "        home_batter_df.to_excel(writer, sheet_name='HomeBatters', index=False)\n",
    "\n",
    "    with pd.ExcelWriter(os.path.join(baseball_path, \"B01. Matchups\", f'Matchups {game_date}', f'{matchup_file}.xlsx'), mode='a', engine='openpyxl') as writer:  \n",
    "        away_pitcher_df.to_excel(writer, sheet_name='AwayPitchers', index=False)\n",
    "\n",
    "    with pd.ExcelWriter(os.path.join(baseball_path, \"B01. Matchups\", f'Matchups {game_date}', f'{matchup_file}.xlsx'), mode='a', engine='openpyxl') as writer:  \n",
    "        home_pitcher_df.to_excel(writer, sheet_name='HomePitchers', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f210150f-f4c2-47ef-918d-bf4d1deba9bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae3e2d03-1d8e-4c30-910f-ec08162cd440",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5b58351-d1b9-4e03-addc-430b64196f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"C:\\Users\\james\\Documents\\MLB\\Code\\U4. Datasets.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fee73dc2-29c1-4422-a57f-c031f24e6554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in park factors\n",
    "multiplier_df = pd.read_csv(os.path.join(baseball_path, \"Multiplier Dataset.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa5989b7-f686-4506-b88c-6e59e878f6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 25s\n",
      "Wall time: 3min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if write_complete_dataset == True:\n",
    "    # # Read in dataset \n",
    "    # complete_dataset = create_pa_inputs(multiplier_df, 2015, 2024, 50, 300, True)\n",
    "    complete_dataset = pd.read_csv(os.path.join(baseball_path, \"nn_dataset.csv\"))\n",
    "    \n",
    "    # Subset\n",
    "    complete_dataset = complete_dataset.query('date > 20210301')\n",
    "\n",
    "    # Read in Steamer hitters\n",
    "    steamer_hitters_df = pd.read_csv(os.path.join(baseball_path, \"A03. Steamer\", \"steamer_hitters_weekly_log.csv\"), encoding='iso-8859-1')\n",
    "    steamer_hitters_df_current = pd.read_csv(os.path.join(baseball_path, \"A03. Steamer\", \"steamer_hitters.csv\"), encoding='iso-8859-1')\n",
    "    steamer_hitters_df = pd.concat([steamer_hitters_df, steamer_hitters_df_current], axis=0)\n",
    "    steamer_hitters_df['proj_year'].fillna(2024, inplace=True)\n",
    "    steamer_hitters_df['proj_date'].fillna(todaysdate_dash, inplace=True)\n",
    "    steamer_hitters_df = clean_steamer_hitters(steamer_hitters_df)\n",
    "\n",
    "    # Read in Steamer pitchers\n",
    "    steamer_pitchers_df = pd.read_csv(os.path.join(baseball_path, \"A03. Steamer\", \"steamer_pitchers_weekly_log.csv\"), encoding='iso-8859-1')\n",
    "    steamer_pitchers_df_current = pd.read_csv(os.path.join(baseball_path, \"A03. Steamer\", \"steamer_pitchers.csv\"), encoding='iso-8859-1')\n",
    "    steamer_pitchers_df = pd.concat([steamer_pitchers_df, steamer_pitchers_df_current], axis=0)\n",
    "    steamer_pitchers_df['proj_year'].fillna(2024, inplace=True)\n",
    "    steamer_pitchers_df['proj_date'].fillna(todaysdate_dash, inplace=True)\n",
    "    steamer_pitchers_df = clean_steamer_pitchers(steamer_pitchers_df)\n",
    "\n",
    "    # Write to CSV (we'll read these later in B.)\n",
    "    complete_dataset.to_csv(os.path.join(baseball_path, \"Complete Dataset.csv\"), index=False)\n",
    "    steamer_hitters_df.to_csv(os.path.join(baseball_path, \"Steamer Hitters.csv\"), index=False)\n",
    "    steamer_pitchers_df.to_csv(os.path.join(baseball_path, \"Steamer Pitchers.csv\"), index=False)\n",
    "    \n",
    "else:\n",
    "    complete_dataset = pd.read_csv(os.path.join(baseball_path, \"Complete Dataset.csv\"))\n",
    "    steamer_hitters_df = pd.read_csv(os.path.join(baseball_path, \"Steamer Hitters.csv\"))\n",
    "    steamer_pitchers_df = pd.read_csv(os.path.join(baseball_path, \"Steamer Pitchers.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f0b3da-ca40-46f2-a193-25c6ad8d8ed9",
   "metadata": {},
   "source": [
    "Shrink datasets for faster processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40bb6b04-b27c-4041-beea-7fe06885af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset.drop(columns={'description', 'batterName', 'pitcherName', 'postOnFirst', 'postOnSecond', 'postOnThird', 'preOnFirst', 'preOnSecond', 'preOnThird', 'pitch_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1033c32-7b5e-4a23-86de-ea4f8d1fd116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shrink datasets for faster processing\n",
    "# complete_dataset.drop(columns={'description', 'batterName', 'pitcherName', 'postOnFirst', 'postOnSecond', 'postOnThird', 'preOnFirst', 'preOnSecond', 'preOnThird', 'pitch_name'}, inplace=True)\n",
    "complete_dataset = complete_dataset[complete_dataset['date'].astype(int) > game_df[\"date\"].astype(int).min()-10000]\n",
    "steamer_hitters_df = steamer_hitters_df[steamer_hitters_df['date'].astype(int) > game_df[\"date\"].astype(int).min()-10000]\n",
    "steamer_pitchers_df = steamer_pitchers_df[steamer_pitchers_df['date'].astype(int) > game_df[\"date\"].astype(int).min()-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b755de9-07c5-4a95-8641-83ce821569f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed: 25.5min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed: 41.5min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed: 63.7min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed: 96.0min\n",
      "[Parallel(n_jobs=4)]: Done 2472 out of 2472 | elapsed: 97.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 25min 20s\n",
      "Wall time: 1h 37min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(len(game_df))\n",
    "empty_list = Parallel(n_jobs=4, verbose=True)(delayed(create_matchup_files)(game_df, row, complete_dataset, steamer_hitters_df, steamer_pitchers_df, team_map) for row in range(len(game_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113bc735-68e0-4098-b42f-86876e63010b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f869c1-2b36-4d67-b0d4-e24027ba56a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
