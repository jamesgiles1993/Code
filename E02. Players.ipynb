{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f955d08b-7da5-4b5e-b23d-2ea450f0b242",
   "metadata": {},
   "source": [
    "# C02. Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51c1bfeb-97ac-47e7-9a97-b71d1763d3d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run \"C:\\Users\\james\\Documents\\MLB\\Code\\U1. Imports.ipynb\"\n",
    "%run \"C:\\Users\\james\\Documents\\MLB\\Code\\U2. Utilities.ipynb\"\n",
    "%run \"C:\\Users\\james\\Documents\\MLB\\Code\\U3. Classes.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68bf4c5-7a97-40d0-83ff-f33e68ad3ae2",
   "metadata": {},
   "source": [
    "### Goals:\n",
    "- Compare my FP projections to actual FP scored\n",
    "    - Main breakdowns\n",
    "        - Batters\n",
    "            - Overall\n",
    "            - Lefty*\n",
    "            - Righty*\n",
    "            - Unimputed\n",
    "            - Imputed\n",
    "            - Unsubbed\n",
    "        - Pitchers (SP only)\n",
    "            - Overall\n",
    "            - Lefty*\n",
    "            - Righty*\n",
    "            - Unimputed\n",
    "            - Imputed\n",
    "    - By projection quantile\n",
    "        - Batters\n",
    "        - Pitchers (SP only)\n",
    "    - By park\n",
    "        - Batters\n",
    "        - Pitchers (SP only)\n",
    "    - By year\n",
    "        - Batters\n",
    "        - Pitchers (SP only)\n",
    "\n",
    "- Compare my scoring component projections to actual scoring component scoring (projected singles vs. actual singles, etc...) (mean)\n",
    "    - Batters\n",
    "    - Pitchers (SP only)\n",
    "    \n",
    "- Compare my FP projections to other FP projections (mean, MSE)\n",
    "    - Batters\n",
    "    - Pitchers (SP only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322f3978-c96e-4bbb-b4f0-913636611288",
   "metadata": {},
   "source": [
    "### Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaf4e9c7-dfaa-45a6-b08e-0bdaeca641cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"20240318\"\n",
    "# end_date = yesterdaysdate\n",
    "end_date = \"20240930\"\n",
    "\n",
    "start_date = todaysdate\n",
    "end_date = todaysdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d5017b-4acb-4645-9349-3e9cbd5d2af3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4aaae491-d555-4264-b7fd-2d66a37aed60",
   "metadata": {},
   "source": [
    "### Games"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdc1267-a3a6-4adc-b3e8-5311715afa62",
   "metadata": {},
   "source": [
    "Games played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46a32558-b12f-4bd6-994f-0175fe63b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df = create_games(start_date, end_date, team_map)\n",
    "# game_df = pd.read_pickle(os.path.join(baseball_path, \"game_df.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3774d5-e235-4010-8376-252162285a6c",
   "metadata": {},
   "source": [
    "Dates and games with my projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e690fe7-e131-42ac-b0e5-903b77907ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_mask = (game_df['date'] >= start_date) & (game_df['date'] <= end_date) \n",
    "date_list = list(game_df[date_mask]['date'].unique())\n",
    "date_folders = [f\"Matchups {date}\" for date in date_list]\n",
    "date_folders = [date_folder for date_folder in os.listdir(r\"C:\\Users\\james\\Documents\\MLB\\Database\\B02. Simulations\\2. Player Sims\") and date_folders]\n",
    "\n",
    "game_list = list(game_df[date_mask]['game_id'].unique())\n",
    "player_folders = [f\"Players {game}\" for game in game_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8f0869-8bae-46ed-9de4-46f7f85eb9a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5367efe-b695-4c33-9bfe-a83091a4144c",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81fcb31-1a20-4634-8f5e-1cf5f411735d",
   "metadata": {},
   "source": [
    "Extract date, teams, and gamePk from folder names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a7c7236-0ecd-4bca-b7e5-c8cf0833ccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_from_folder(date_folder, matchup_folder):\n",
    "    # Extract date from date folder\n",
    "    date = date_folder.split(' ')[1]\n",
    "    \n",
    "    # Extract teams and gamePK from matchup folder\n",
    "    parts = matchup_folder.split(' ')\n",
    "    away_team, home_team = parts[0].split('@')\n",
    "    gamePk = parts[1]\n",
    "    \n",
    "    return date, away_team, home_team, gamePk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a35c55-e6b4-4e67-9437-eb166630fef4",
   "metadata": {},
   "source": [
    "Average player stats for a given position group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc35a2b9-2419-4580-ac3e-390753bc8f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_averages(date_folder, matchup_folder, position='pitchers'):\n",
    "    date, away_team, home_team, gamePk = extract_info_from_folder(date_folder, matchup_folder)\n",
    "    \n",
    "    # Initialize an empty list to store DataFrames\n",
    "    dfs = []\n",
    "    \n",
    "    # Get a list of all CSV files in the matchup folder\n",
    "    csv_files = [file for file in os.listdir(os.path.join(baseball_path, \"B02. Simulations\", \"2. Player Sims\", date_folder, matchup_folder)) \n",
    "                 if file.startswith(position) and file.endswith('.csv')]\n",
    "    \n",
    "    # Iterate over each CSV file\n",
    "    for csv_file in csv_files:\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(os.path.join(baseball_path, \"B02. Simulations\", \"2. Player Sims\", date_folder, matchup_folder, csv_file))\n",
    "        \n",
    "        # Append date, away_team, home_team, and gamePk columns\n",
    "        df['date'] = date\n",
    "        df['away_team'] = away_team\n",
    "        df['home_team'] = home_team\n",
    "        df['gamePk'] = gamePk\n",
    "        \n",
    "        # Append the DataFrame to the list\n",
    "        dfs.append(df)\n",
    "    \n",
    "    # Concatenate all DataFrames in the list\n",
    "    combined_df = pd.concat(dfs)\n",
    "    \n",
    "    # Select numeric columns\n",
    "    numeric_cols = combined_df.select_dtypes(include='number')\n",
    "    \n",
    "    # Group by fullName and calculate the mean for numeric columns\n",
    "    averaged_numeric_cols = numeric_cols.groupby(combined_df['fullName'], sort=False).mean()\n",
    "    \n",
    "    # Select team and additional columns\n",
    "    additional_cols = combined_df[['fullName', 'team', 'date', 'away_team', 'home_team', 'gamePk']].drop_duplicates('fullName').set_index('fullName')\n",
    "    \n",
    "    # Concatenate numeric and additional columns\n",
    "    averaged_df = pd.concat([additional_cols, averaged_numeric_cols], axis=1).reset_index()\n",
    "\n",
    "    averaged_df['team_abbrev'] = np.where(averaged_df['team'] == \"away\", averaged_df['away_team'], averaged_df['home_team'])\n",
    "\n",
    "    averaged_df['starter'] = (~averaged_df['team'].duplicated()).astype(int)\n",
    "\n",
    "    return averaged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428e49a9-4b80-4e74-a185-2a6273d606e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3603832-c19f-46b7-989c-8783829261e2",
   "metadata": {},
   "source": [
    "### Player Sim Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fe4fa3-bd6d-4b3f-aa4a-da5395099887",
   "metadata": {},
   "source": [
    "Calculate averages for player stats in simulations by game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42dfdd4-4ce5-4c2f-8200-150d5f302a8b",
   "metadata": {},
   "source": [
    "##### Batters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f65139-41dd-42e3-abfb-454bb093d650",
   "metadata": {},
   "source": [
    "Calculate averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c83d11d1-eae1-4b5d-bb92-81fe94f5d6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 172 ms\n",
      "Wall time: 1.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "position = 'batters'\n",
    "\n",
    "# Parallelize the loop using joblib and directly return df_list\n",
    "batter_df_list = Parallel(n_jobs=-1)(\n",
    "    delayed(game_averages)(date_folder, matchup_folder, position) \n",
    "    for date_folder in date_folders \n",
    "    for matchup_folder in os.listdir(os.path.join(baseball_path, \"B02. Simulations\", \"2. Player Sims\", date_folder)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c058968b-bca8-432f-ac0f-e8b76628ff94",
   "metadata": {},
   "source": [
    "Write to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2340be8-e6b1-47d9-874c-d0fcdbe1abbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in batter_df_list:\n",
    "    gamePk = df['gamePk'][0]\n",
    "    away_df = df.query('team == \"away\"')\n",
    "    home_df = df.query('team == \"home\"')\n",
    "    \n",
    "    # Create folder\n",
    "    os.makedirs(os.path.join(baseball_path, \"C04. Players\", f\"Players {gamePk}\"), exist_ok=True)\n",
    "\n",
    "    # Write to csv\n",
    "    away_df.to_csv(os.path.join(baseball_path, \"C04. Players\", f\"Players {gamePk}\", f\"away batters projections {gamePk}.csv\"), index=False)\n",
    "    home_df.to_csv(os.path.join(baseball_path, \"C04. Players\", f\"Players {gamePk}\", f\"home batters projections {gamePk}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f84ee4d-70d3-4b9d-bbc5-5d7d223b2920",
   "metadata": {},
   "source": [
    "##### Pitchers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9983e1-8db1-4304-8719-93ebb9573495",
   "metadata": {},
   "source": [
    "Calculate averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "993e3ecc-8e16-41a9-b15f-4d2e4ec9032c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 789 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "position = 'pitchers'\n",
    "\n",
    "# Parallelize the loop using joblib and directly return df_list\n",
    "pitcher_df_list = Parallel(n_jobs=-1)(\n",
    "    delayed(game_averages)(date_folder, matchup_folder, position) \n",
    "    for date_folder in date_folders \n",
    "    for matchup_folder in os.listdir(os.path.join(baseball_path, \"B02. Simulations\", \"2. Player Sims\", date_folder)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1627337d-36d0-43d4-8d7a-b0abbb1c71dc",
   "metadata": {},
   "source": [
    "Write to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2dd4cf72-a02c-4b42-8704-7e0e2fc037fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in pitcher_df_list:\n",
    "    gamePk = df['gamePk'][0]\n",
    "    away_df = df.query('team == \"away\"')\n",
    "    home_df = df.query('team == \"home\"')\n",
    "    \n",
    "    # Create folder\n",
    "    os.makedirs(os.path.join(baseball_path, \"C04. Players\", f\"Players {gamePk}\"), exist_ok=True)\n",
    "\n",
    "    # Write to csv\n",
    "    away_df.to_csv(os.path.join(baseball_path, \"C04. Players\", f\"Players {gamePk}\", f\"away pitchers projections {gamePk}.csv\"), index=False)\n",
    "    home_df.to_csv(os.path.join(baseball_path, \"C04. Players\", f\"Players {gamePk}\", f\"home pitchers projections {gamePk}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518db8a2-5896-494c-93c8-43e7ab2cd224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e16b8c6b-6935-40e8-9a7b-86cf8f9f1493",
   "metadata": {},
   "source": [
    "### Player Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5b1bad-2878-4e53-b760-30e063ede081",
   "metadata": {},
   "source": [
    "Add players' actual scoring onto simulated projections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb1f11c-d501-4281-b938-97272e6ca9fc",
   "metadata": {},
   "source": [
    "##### Batters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a42cc0a-9c0e-4c5a-843d-d511fbce1074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to process each folder\n",
    "def process_batters(folder):\n",
    "    # Extract gamePk\n",
    "    gamePk = folder.split(\" \")[1]\n",
    "\n",
    "    ### Batters\n",
    "    ## Away\n",
    "    # Read in projections\n",
    "    away_batter_projected_results_df = pd.read_csv(os.path.join(baseball_path, \"C04. Players\", f\"Players {gamePk}\", f\"away batters projections {gamePk}.csv\"))\n",
    "    # Read in results\n",
    "    away_batter_actual_results_df = pd.read_csv(os.path.join(baseball_path, \"A10. Player Results\", f\"Player Results {gamePk}\", f\"away batters {gamePk}.csv\"))\n",
    "\n",
    "    # Merge\n",
    "    away_batters_merged = away_batter_projected_results_df[['fullName', 'id', 'imp_b_l', 'imp_b_r', 'PA', 'HBP', 'BB', 'B1', 'B2', 'B3', 'HR', 'SB', 'R', 'RBI', 'FP', 'gamePk']].merge(away_batter_actual_results_df, left_on=['id', 'gamePk'], right_on=['personId', 'gamePk'], how='outer')\n",
    "\n",
    "    ## Home\n",
    "    # Read in projections\n",
    "    home_batter_projected_results_df = pd.read_csv(os.path.join(baseball_path, \"C04. Players\", f\"Players {gamePk}\", f\"home batters projections {gamePk}.csv\"))\n",
    "    # Read in results\n",
    "    home_batter_actual_results_df = pd.read_csv(os.path.join(baseball_path, \"A10. Player Results\", f\"Player Results {gamePk}\", f\"home batters {gamePk}.csv\"))\n",
    "\n",
    "    # Merge\n",
    "    home_batters_merged = home_batter_projected_results_df[['fullName', 'id', 'imp_b_l', 'imp_b_r', 'PA', 'HBP', 'BB', 'B1', 'B2', 'B3', 'HR', 'SB', 'R', 'RBI', 'FP', 'gamePk']].merge(home_batter_actual_results_df, left_on=['id', 'gamePk'], right_on=['personId', 'gamePk'], how='outer')\n",
    "\n",
    "    # Append them together\n",
    "    batters_merged = pd.concat([away_batters_merged, home_batters_merged], axis=0)\n",
    "\n",
    "    \n",
    "    return batters_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0627e5fb-9bd9-4ec5-87b1-9b417f3b8daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batters2(folder):\n",
    "    try:\n",
    "        batters_merged = process_batters(folder)    \n",
    "        return batters_merged   \n",
    "    except:\n",
    "        pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c153050e-6415-456d-89d7-7baf32c0e67f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All objects passed were None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:3\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    383\u001b[0m     objs,\n\u001b[0;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    385\u001b[0m     ignore_index\u001b[38;5;241m=\u001b[39mignore_index,\n\u001b[0;32m    386\u001b[0m     join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[0;32m    387\u001b[0m     keys\u001b[38;5;241m=\u001b[39mkeys,\n\u001b[0;32m    388\u001b[0m     levels\u001b[38;5;241m=\u001b[39mlevels,\n\u001b[0;32m    389\u001b[0m     names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[0;32m    390\u001b[0m     verify_integrity\u001b[38;5;241m=\u001b[39mverify_integrity,\n\u001b[0;32m    391\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    393\u001b[0m )\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clean_keys_and_objs(objs, keys)\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:541\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[1;34m(self, objs, keys)\u001b[0m\n\u001b[0;32m    538\u001b[0m         keys \u001b[38;5;241m=\u001b[39m Index(clean_keys, name\u001b[38;5;241m=\u001b[39mname, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(keys, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 541\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll objects passed were None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m objs_list, keys\n",
      "\u001b[1;31mValueError\u001b[0m: All objects passed were None"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run the loop in parallel\n",
    "batters_merged_list = Parallel(n_jobs=-1)(delayed(process_batters2)(folder) for folder in player_folders)\n",
    "batters_merged_df = pd.concat(batters_merged_list, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594f51cd-8c15-4091-977d-fdf22fb211bd",
   "metadata": {},
   "source": [
    "##### Pitchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c1169c7-3fd3-4387-a887-fd2efb20d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pitchers(folder):\n",
    "    # Extract gamePk\n",
    "    gamePk = folder.split(\" \")[1]\n",
    "    \n",
    "    ### Pitchers\n",
    "    ## Away\n",
    "    # Read in projections\n",
    "    away_pitcher_projected_results_df = pd.read_csv(os.path.join(baseball_path, \"C04. Players\", f\"Players {gamePk}\", f\"away pitchers projections {gamePk}.csv\"))\n",
    "    away_pitcher_projected_results_df['team'] = \"away\"\n",
    "    # Read in results\n",
    "    away_pitcher_actual_results_df = pd.read_csv(os.path.join(baseball_path, \"A10. Player Results\", f\"Player Results {gamePk}\", f\"away pitchers {gamePk}.csv\"))\n",
    "\n",
    "    # Merge\n",
    "    away_pitchers_merged = away_pitcher_projected_results_df[['fullName', 'id', 'imp_p_l', 'imp_p_r', 'OUT', 'PA', 'SO', 'HBP', 'BB', 'B1', 'B2', 'B3', 'HR', 'H', 'R', 'ER', 'W', 'CG', 'CGSO', 'NH', 'FP', 'team', 'gamePk']].merge(away_pitcher_actual_results_df, left_on=['id', 'gamePk', 'team'], right_on=['personId', 'gamePk', 'team'], how='outer')\n",
    "    \n",
    "    ## Home\n",
    "    # Read in projections\n",
    "    home_pitcher_projected_results_df = pd.read_csv(os.path.join(baseball_path, \"C04. Players\", f\"Players {gamePk}\", f\"home pitchers projections {gamePk}.csv\"))\n",
    "    home_pitcher_projected_results_df['team'] = \"home\"\n",
    "    # Read in results\n",
    "    home_pitcher_actual_results_df = pd.read_csv(os.path.join(baseball_path, \"A10. Player Results\", f\"Player Results {gamePk}\", f\"home pitchers {gamePk}.csv\"))\n",
    "\n",
    "    # Merge\n",
    "    home_pitchers_merged = home_pitcher_projected_results_df[['fullName', 'id', 'imp_p_l', 'imp_p_r', 'OUT', 'PA', 'SO', 'HBP', 'BB', 'B1', 'B2', 'B3', 'HR', 'H', 'R', 'ER', 'W', 'CG', 'CGSO', 'NH', 'FP', 'team', 'gamePk']].merge(home_pitcher_actual_results_df, left_on=['id', 'gamePk', 'team'], right_on=['personId', 'gamePk', 'team'], how='outer')\n",
    "\n",
    "    # Append them together\n",
    "    pitchers_merged = pd.concat([away_pitchers_merged, home_pitchers_merged], axis=0)\n",
    "\n",
    "    \n",
    "    return pitchers_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7147efe8-c1fe-459a-ac83-b42abb667305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pitchers2(folder):\n",
    "    try:\n",
    "        pitchers_merged = process_pitchers(folder)    \n",
    "        return pitchers_merged   \n",
    "    except:\n",
    "        pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf8caac1-fbde-4f5f-b9a0-50fd4d47b878",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All objects passed were None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:3\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    383\u001b[0m     objs,\n\u001b[0;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    385\u001b[0m     ignore_index\u001b[38;5;241m=\u001b[39mignore_index,\n\u001b[0;32m    386\u001b[0m     join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[0;32m    387\u001b[0m     keys\u001b[38;5;241m=\u001b[39mkeys,\n\u001b[0;32m    388\u001b[0m     levels\u001b[38;5;241m=\u001b[39mlevels,\n\u001b[0;32m    389\u001b[0m     names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[0;32m    390\u001b[0m     verify_integrity\u001b[38;5;241m=\u001b[39mverify_integrity,\n\u001b[0;32m    391\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    393\u001b[0m )\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clean_keys_and_objs(objs, keys)\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:541\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[1;34m(self, objs, keys)\u001b[0m\n\u001b[0;32m    538\u001b[0m         keys \u001b[38;5;241m=\u001b[39m Index(clean_keys, name\u001b[38;5;241m=\u001b[39mname, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(keys, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 541\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll objects passed were None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m objs_list, keys\n",
      "\u001b[1;31mValueError\u001b[0m: All objects passed were None"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run the loop in parallel\n",
    "pitchers_merged_list = Parallel(n_jobs=-1)(delayed(process_pitchers2)(folder) for folder in player_folders)\n",
    "pitchers_merged_df = pd.concat(pitchers_merged_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c4e9b9-3463-4df0-a338-7f658eeb22ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d314997d-7b19-4a1f-9c15-d2ac1b8141d3",
   "metadata": {},
   "source": [
    "### 1. Player Stat Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156926eb-e7fd-4a03-ac15-bc5b2b8fbfb5",
   "metadata": {},
   "source": [
    "Compare simulated projections to player stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85341c6d-7810-45ed-b1fe-339f43fc60b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_stat_path = os.path.join(baseball_path, \"C02. Players\", \"1. Player Stat Evaluations\", f\"{todaysdate} Player Stat Evaluations.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acb422a-ff8b-4699-8180-408bafd5ae0d",
   "metadata": {},
   "source": [
    "##### Batters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8143c348-16cb-4dbd-b465-a2022bd89c90",
   "metadata": {},
   "source": [
    "Create New Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b169daf0-4788-400a-bf17-da3d815e8acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual singles\n",
    "batters_merged_df['singles'] = batters_merged_df['h'] - batters_merged_df['doubles'] - batters_merged_df['triples'] - batters_merged_df['hr']\n",
    "# Actual PA\n",
    "batters_merged_df['pa'] = batters_merged_df[['ab', 'bb', 'hbp']].sum(axis=1)\n",
    "# Projected hits\n",
    "batters_merged_df['H'] = batters_merged_df[['B1', 'B2', 'B3', 'HR']].sum(axis=1)\n",
    "# Reached\n",
    "batters_merged_df['ON'] = batters_merged_df[['H', 'BB', 'HBP']].sum(axis=1)\n",
    "batters_merged_df['on'] = batters_merged_df[['h', 'bb', 'hbp']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87923c33-d5a8-4c10-b508-dbbae4c08a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify number of batters that batted in a given spot in the order (we may only want those who were never subbed out or are subs)\n",
    "batters_merged_df['battingSpot'] = batters_merged_df['battingOrder'] // 100\n",
    "# Instance of batter in that spot\n",
    "# Example:\n",
    "# Three batters batted 4\n",
    "# All three would have battingSpot = 4\n",
    "# battingSpotInstance for starter would be 1, the first sub would be 2, second sub would be 3\n",
    "batters_merged_df['battingSpotInstance'] = batters_merged_df.groupby(['gamePk', 'team', 'battingSpot'])['battingSpot'].transform('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31480f7e-973a-4b07-9bf9-6cc050eb85b2",
   "metadata": {},
   "source": [
    "##### Starters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75940583-f2c7-4484-9a85-5931f0879b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_batters = batters_merged_df.query('battingSpotInstance == 1')[['PA', 'pa', 'ON', 'on', 'H', 'h', 'B1', 'singles', 'B2', 'doubles', 'B3', 'triples', 'HR', 'hr', 'BB', 'bb', 'SB', 'sb', 'FP', 'fp']].agg(['mean', 'sum'])\n",
    "\n",
    "# Split the dataframe into projected (even rows) and actual (odd rows)\n",
    "projected = all_batters.T.iloc[::2].reset_index()\n",
    "actual = all_batters.T.iloc[1::2].reset_index()\n",
    "\n",
    "# Concatenate the two dataframes side-by-side\n",
    "all_batters = pd.concat([projected, actual], axis=1)\n",
    "\n",
    "# Rename the columns\n",
    "all_batters.columns = [\"Projected\", \"Projected Mean\", 'Projected Sum', \"Actual\", \"Actual Mean\", 'Actual Sum']\n",
    "\n",
    "# Write to Excel\n",
    "all_batters.to_excel(player_stat_path, sheet_name='AllBatters', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d65fea-4ee4-4d2b-a966-df5cba403f7c",
   "metadata": {},
   "source": [
    "##### Starters - Unimputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd44f07a-3000-4dc2-ad18-dfb324c278be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def batter_stats(batters_merged_df, starters_only=False, imputation_status='both'):\n",
    "#     # Determine battingSpotInstance\n",
    "#     if starters_only == True:\n",
    "#         battingSpotInstance_mask = (df['battingSpotInstance'] == 1)\n",
    "#     if imputation_status == 'imputed':\n",
    "#         imputation_mask = (df['imp_b_l'] == 1 | df['imp_b_r'] == 1)\n",
    "        \n",
    "#     df = batters_merged_df.query('battingSpotInstance == 1').query('imp_b_l == 0 & imp_b_r == 0')[['PA', 'pa', 'ON', 'on', 'H', 'h', 'B1', 'singles', 'B2', 'doubles', 'B3', 'triples', 'HR', 'hr', 'BB', 'bb', 'SB', 'sb', 'FP', 'fp']].agg(['mean', 'sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15657d90-0a40-43ab-8c8e-32b4295a593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unimputed_batters = batters_merged_df.query('battingSpotInstance == 1').query('imp_b_l == 0 & imp_b_r == 0')[['PA', 'pa', 'ON', 'on', 'H', 'h', 'B1', 'singles', 'B2', 'doubles', 'B3', 'triples', 'HR', 'hr', 'BB', 'bb', 'SB', 'sb', 'FP', 'fp']].agg(['mean', 'sum'])\n",
    "# unimputed_batters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b685d4a-2676-41c5-9050-db82bbf8cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "unimputed_batters = batters_merged_df.query('battingSpotInstance == 1').query('imp_b_l == 0 & imp_b_r == 0')[['PA', 'pa', 'ON', 'on', 'H', 'h', 'B1', 'singles', 'B2', 'doubles', 'B3', 'triples', 'HR', 'hr', 'BB', 'bb', 'SB', 'sb', 'FP', 'fp']].agg(['mean', 'sum'])\n",
    "\n",
    "# Split the dataframe into projected (even rows) and actual (odd rows)\n",
    "projected = unimputed_batters.T.iloc[::2].reset_index()\n",
    "actual = unimputed_batters.T.iloc[1::2].reset_index()\n",
    "\n",
    "# Concatenate the two dataframes side-by-side\n",
    "unimputed_batters = pd.concat([projected, actual], axis=1)\n",
    "\n",
    "# Rename the columns\n",
    "unimputed_batters.columns = [\"Projected\", \"Projected Mean\", 'Projected Sum', \"Actual\", \"Actual Mean\", 'Actual Sum']\n",
    "\n",
    "# Set Projected Share\n",
    "unimputed_batters['Projected Share'] = 0.0\n",
    "unimputed_batters.loc[unimputed_batters['Projected'] == 'PA', 'Projected Share'] = 1\n",
    "unimputed_batters.loc[unimputed_batters['Projected'] == 'ON', 'Projected Share'] = (\n",
    "    unimputed_batters.loc[unimputed_batters['Projected'] == 'ON', 'Projected Mean'].values[0] /\n",
    "    unimputed_batters.loc[unimputed_batters['Projected'] == 'PA', 'Projected Mean'].values[0]\n",
    ")\n",
    "unimputed_batters.loc[~unimputed_batters['Projected'].isin(['PA', 'ON']), 'Projected Share'] = (\n",
    "    unimputed_batters.loc[~unimputed_batters['Projected'].isin(['PA', 'ON']), 'Projected Mean'] /\n",
    "    unimputed_batters.loc[unimputed_batters['Projected'] == 'ON', 'Projected Mean'].values[0]\n",
    ")\n",
    "\n",
    "# Set Actual Share\n",
    "unimputed_batters['Actual Share'] = 0.0\n",
    "unimputed_batters.loc[unimputed_batters['Actual'] == 'pa', 'Actual Share'] = 1\n",
    "unimputed_batters.loc[unimputed_batters['Actual'] == 'on', 'Actual Share'] = (\n",
    "    unimputed_batters.loc[unimputed_batters['Actual'] == 'on', 'Actual Mean'].values[0] /\n",
    "    unimputed_batters.loc[unimputed_batters['Actual'] == 'pa', 'Actual Mean'].values[0]\n",
    ")\n",
    "unimputed_batters.loc[~unimputed_batters['Actual'].isin(['pa', 'on']), 'Actual Share'] = (\n",
    "    unimputed_batters.loc[~unimputed_batters['Actual'].isin(['pa', 'on']), 'Actual Mean'] /\n",
    "    unimputed_batters.loc[unimputed_batters['Actual'] == 'on', 'Actual Mean'].values[0]\n",
    ")\n",
    "\n",
    "# Append the new DataFrame\n",
    "with pd.ExcelWriter(player_stat_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    unimputed_batters.to_excel(writer, sheet_name='UnimputedBatters', index=False)\n",
    "    \n",
    "unimputed_batters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105fe2ab-c5f6-4987-81e4-7a54f3cf65f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "1-unimputed_batters['Projected Mean'][1] / unimputed_batters['Projected Mean'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae8a644-2a95-4b25-9c1c-024575109e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "1-unimputed_batters['Actual Mean'][1] / unimputed_batters['Actual Mean'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101215b8-b0ff-4254-a565-7c227c9c87c5",
   "metadata": {},
   "source": [
    "##### Starters - Imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b2f77b-7736-4146-8e40-b6eb480488da",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_batters = batters_merged_df.query('battingSpotInstance == 1').query('imp_b_l == 1 | imp_b_r == 1')[['PA', 'pa', 'ON', 'on', 'H', 'h', 'B1', 'singles', 'B2', 'doubles', 'B3', 'triples', 'HR', 'hr', 'BB', 'bb', 'SB', 'sb', 'FP', 'fp']].agg(['mean', 'sum'])\n",
    "\n",
    "# Split the dataframe into projected (even rows) and actual (odd rows)\n",
    "projected = imputed_batters.T.iloc[::2].reset_index()\n",
    "actual = imputed_batters.T.iloc[1::2].reset_index()\n",
    "\n",
    "# Concatenate the two dataframes side-by-side\n",
    "imputed_batters = pd.concat([projected, actual], axis=1)\n",
    "\n",
    "# Rename the columns\n",
    "imputed_batters.columns = [\"Projected\", \"Projected Mean\", 'Projected Sum', \"Actual\", \"Actual Mean\", 'Actual Sum']\n",
    "\n",
    "# Append the new DataFrame\n",
    "with pd.ExcelWriter(player_stat_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    imputed_batters.to_excel(writer, sheet_name='ImputedBatters', index=False)\n",
    "    \n",
    "imputed_batters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f13ef3-68fa-43a3-ac23-9d8cac53f900",
   "metadata": {},
   "source": [
    "##### Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10013692-3f80-4bb1-9abf-b6397fa6104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_batters = batters_merged_df.groupby(['gamePk', 'team']).sum(numeric_only=True)[['PA', 'pa', 'ON', 'on', 'H', 'h', 'B1', 'singles', 'B2', 'doubles', 'B3', 'triples', 'HR', 'hr', 'BB', 'bb', 'HBP', 'hbp', 'R', 'r', 'RBI', 'rbi', 'SB', 'sb', 'FP', 'fp']].agg(['mean', 'sum'])\n",
    "\n",
    "# Split the dataframe into projected (even rows) and actual (odd rows)\n",
    "projected = team_batters.T.iloc[::2].reset_index()\n",
    "actual = team_batters.T.iloc[1::2].reset_index()\n",
    "\n",
    "# Concatenate the two dataframes side-by-side\n",
    "team_batters = pd.concat([projected, actual], axis=1)\n",
    "\n",
    "# Rename the columns\n",
    "team_batters.columns = [\"Projected\", \"Projected Mean\", 'Projected Sum', \"Actual\", \"Actual Mean\", 'Actual Sum']\n",
    "\n",
    "# Append the new DataFrame\n",
    "with pd.ExcelWriter(player_stat_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    team_batters.to_excel(writer, sheet_name='TeamBatters', index=False)\n",
    "    \n",
    "team_batters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90280d7c-0286-4dcb-be00-fd6ac49638e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9759ba-8512-4fea-ab2b-3d1f81bbdc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "1-team_batters['Projected Mean'][1] / team_batters['Projected Mean'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c7363c-5e4d-4750-a3e6-9ae80611121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "1-team_batters['Actual Mean'][1] / team_batters['Actual Mean'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c91510-aa23-41b8-b669-62e1f4942f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11fc376b-07d3-4692-aff2-189aa3856e61",
   "metadata": {},
   "source": [
    "##### Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174638d3-0266-4f92-9b31-99db45a5f035",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_pa_mean = batters_merged_df.groupby(['gamePk', 'team']).sum(numeric_only=True)['pa'].mean()\n",
    "projected_pa_mean = batters_merged_df.groupby(['gamePk', 'team']).sum(numeric_only=True)['PA'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b445e054-a2be-416d-9c2e-aa14de0d646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the fraction\n",
    "fraction = actual_pa_mean/projected_pa_mean\n",
    "\n",
    "# Select the columns you want to multiply and multiply them by the fraction\n",
    "columns_to_multiply = ['PA', 'H', 'B1', 'B2', 'B3', 'HR', 'BB', 'HBP', 'R', 'RBI', 'SB', 'FP']\n",
    "batters_merged_df_scaled = batters_merged_df.copy()\n",
    "batters_merged_df_scaled[columns_to_multiply] = batters_merged_df[columns_to_multiply] * fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c85fb2-0fb6-4520-a8f5-b2da17e0f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_batters = batters_merged_df_scaled.groupby(['gamePk', 'team']).sum(numeric_only=True)[['PA', 'pa', 'ON', 'on', 'H', 'h', 'B1', 'singles', 'B2', 'doubles', 'B3', 'triples', 'HR', 'hr', 'BB', 'bb', 'HBP', 'hbp', 'R', 'r', 'RBI', 'rbi', 'SB', 'sb', 'FP', 'fp']]\n",
    "\n",
    "# Convert to DF\n",
    "scaled_batters = pd.DataFrame(scaled_batters.mean().reset_index())\n",
    "\n",
    "# Split the dataframe into projected (even rows) and actual (odd rows)\n",
    "projected = scaled_batters.iloc[::2].reset_index(drop=True)\n",
    "actual = scaled_batters.iloc[1::2].reset_index(drop=True)\n",
    "\n",
    "# Concatenate the two dataframes side-by-side\n",
    "scaled_batters = pd.concat([projected, actual], axis=1)\n",
    "\n",
    "# Rename the columns\n",
    "scaled_batters.columns = [\"Projected\", \"Projected Value\", \"Actual\", \"Actual Value\"]\n",
    "\n",
    "# Append the new DataFrame\n",
    "with pd.ExcelWriter(player_stat_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    scaled_batters.to_excel(writer, sheet_name='ScaledBatters', index=False)\n",
    "\n",
    "scaled_batters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa3364e-9959-453c-b6a1-4e59a9a3656c",
   "metadata": {},
   "source": [
    "##### Park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da99a688-e86e-4f95-8ef1-49a888447c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "batter_park_fp = batters_merged_df.query('battingSpotInstance == 1').groupby('venue_id')[['FP', 'fp']].agg(['mean']).reset_index()\n",
    "batter_park_fp.columns = ['VENUE_ID', 'FP', 'fp']\n",
    "batter_park_fp = pd.merge(batter_park_fp, team_map[['VENUE_ID', 'BBREFTEAM']], on='VENUE_ID', how='left')\n",
    "\n",
    "# Append the new DataFrame\n",
    "with pd.ExcelWriter(player_stat_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    batter_park_fp.to_excel(writer, sheet_name='ParkBatters', index=False)\n",
    "    \n",
    "batter_park_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d2a266-0243-4213-ba34-519fb1c1c6ea",
   "metadata": {},
   "source": [
    "##### Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054b8abe-0b53-4ae8-a99f-6b417dc96c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batter_year_fp = batters_merged_df.query('battingSpotInstance == 1').groupby('year')[['FP', 'fp']].agg(['mean']).reset_index()\n",
    "batter_year_fp.columns = ['year', 'FP', 'fp']\n",
    "\n",
    "# Append the new DataFrame\n",
    "with pd.ExcelWriter(player_stat_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    batter_year_fp.to_excel(writer, sheet_name='YearBatters', index=False)\n",
    "    \n",
    "batter_year_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2a4553-83fc-4b85-af01-99577e2dd3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider tracking if players were never removed from game\n",
    "# Consider merging on innings and only looking at full games\n",
    "# Consider adding lefty/righty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ffcc05-8198-4ec7-b8a2-b72224379ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "032a240e-fca1-408e-8aad-23704fd61882",
   "metadata": {},
   "source": [
    "#### Pitchers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3fc010-1fb5-4fd1-9aa0-f79c049d11f1",
   "metadata": {},
   "source": [
    "##### Create New Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea2e99a-955e-468b-8f48-65ed03a852cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitchers_merged_df.sort_values(['gamePk', 'team', 'date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a37ed30-fe27-497c-93d8-caa92da21f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitchers_merged_df['personId'].fillna(pitchers_merged_df['id'], inplace=True)\n",
    "pitchers_merged_df['name'].fillna(pitchers_merged_df['fullName'], inplace=True)\n",
    "\n",
    "for col in ['starter', 'ip', 'outs', 'h', 'r', 'er', 'bb', 'k', 'hr', 'hbp', 'w', 'l', 'cg', 'cgso', 'nh', 'fp']:\n",
    "    pitchers_merged_df[col].fillna(0, inplace=True)\n",
    "    \n",
    "for col in ['date', 'year', 'venue_id', 'team', 'teamabbrev']:\n",
    "    # pitchers_merged_df.sort_values(['date', 'year', 'venue_id', 'team', 'teamabbrev'], ascending=False, inplace=True)\n",
    "    pitchers_merged_df[col].fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c13e4-6b8d-45b8-a607-427815487f3e",
   "metadata": {},
   "source": [
    "##### Starters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3136e4-bbf8-4d6c-9714-c2a0dffc51ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pitchers = pitchers_merged_df.dropna().query('starter == 1')[['OUT', 'outs', 'PA', 'pa', 'ER', 'er', 'R', 'r', 'H', 'h', 'SO', 'k', 'W', 'w', 'FP', 'fp']].agg(['mean', 'sum'])\n",
    "\n",
    "# Split the dataframe into projected (even rows) and actual (odd rows)\n",
    "projected = all_pitchers.T.iloc[::2].reset_index()\n",
    "actual = all_pitchers.T.iloc[1::2].reset_index()\n",
    "\n",
    "# Concatenate the two dataframes side-by-side\n",
    "all_pitchers = pd.concat([projected, actual], axis=1)\n",
    "\n",
    "# Rename the columns\n",
    "all_pitchers.columns = [\"Projected\", \"Projected Mean\", 'Projected Sum', \"Actual\", \"Actual Mean\", 'Actual Sum']\n",
    "\n",
    "# Append the new DataFrame\n",
    "with pd.ExcelWriter(player_stat_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    all_pitchers.to_excel(writer, sheet_name='AllPitchers', index=False)\n",
    "    \n",
    "all_pitchers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de87712-9caf-49a9-996d-6272d116499f",
   "metadata": {},
   "source": [
    "##### Starters - Unimputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78cc80a-5a67-4d99-93f9-5b9b0cd730d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unimputed_pitchers = pitchers_merged_df.dropna().query('starter == 1').query('imp_p_l == 0 & imp_p_r == 0')[['OUT', 'outs', 'PA', 'pa', 'ER', 'er', 'R', 'r', 'H', 'h', 'SO', 'k', 'W', 'w', 'FP', 'fp']].agg(['mean', 'sum'])\n",
    "\n",
    "# Split the dataframe into projected (even rows) and actual (odd rows)\n",
    "projected = unimputed_pitchers.T.iloc[::2].reset_index()\n",
    "actual = unimputed_pitchers.T.iloc[1::2].reset_index()\n",
    "\n",
    "# Concatenate the two dataframes side-by-side\n",
    "unimputed_pitchers = pd.concat([projected, actual], axis=1)\n",
    "\n",
    "# Rename the columns\n",
    "unimputed_pitchers.columns = [\"Projected\", \"Projected Mean\", 'Projected Sum', \"Actual\", \"Actual Mean\", \"Actual Sum\"]\n",
    "\n",
    "# Append the new DataFrame\n",
    "with pd.ExcelWriter(player_stat_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    unimputed_pitchers.to_excel(writer, sheet_name='UnimputedPitchers', index=False)\n",
    "\n",
    "unimputed_pitchers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b1b7b5-e793-4b9a-b22b-9d54137fe88f",
   "metadata": {},
   "source": [
    "##### Starters - Imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dafd25-a015-443a-b8ea-31c4f8e3458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_pitchers = pitchers_merged_df.dropna().query('starter == 1').query('imp_p_l == 1 | imp_p_r == 1')[['OUT', 'outs', 'PA', 'pa', 'ER', 'er', 'R', 'r', 'H', 'h', 'SO', 'k', 'W', 'w', 'FP', 'fp']].agg(['mean', 'sum'])\n",
    "\n",
    "# Split the dataframe into projected (even rows) and actual (odd rows)\n",
    "projected = imputed_pitchers.T.iloc[::2].reset_index()\n",
    "actual = imputed_pitchers.T.iloc[1::2].reset_index()\n",
    "\n",
    "# Concatenate the two dataframes side-by-side\n",
    "imputed_pitchers = pd.concat([projected, actual], axis=1)\n",
    "\n",
    "# Rename the columns\n",
    "imputed_pitchers.columns = [\"Projected\", \"Projected Mean\", 'Projected Sum', \"Actual\", \"Actual Mean\", \"Actual Sum\"]\n",
    "\n",
    "# Append the new DataFrame\n",
    "with pd.ExcelWriter(player_stat_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    imputed_pitchers.to_excel(writer, sheet_name='ImputedPitchers', index=False)\n",
    "\n",
    "imputed_pitchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f912ca-ef25-4567-9ef7-00d199577ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a5f2746-a929-4c3b-9410-685692e5274d",
   "metadata": {},
   "source": [
    "##### Scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c5874f-2344-4e95-ad1a-e2084b329612",
   "metadata": {},
   "source": [
    "This calculates how starting pitchers would do if they went as long as they were supposed to. <br>\n",
    "Note: outs should have a nonlinear relationship with wins, so this won't be exactly right, but close enough. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4187db7-f81a-4bb2-8660-d196f2187b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_outs_mean = pitchers_merged_df.dropna().query('starter == 1')['outs'].mean()\n",
    "projected_outs_mean = pitchers_merged_df.dropna().query('starter == 1')['OUT'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ecf2bc-6f7c-4195-9c09-cd90ca5a7841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the fraction\n",
    "fraction = actual_outs_mean/projected_outs_mean\n",
    "\n",
    "# Select the columns you want to multiply and multiply them by the fraction\n",
    "columns_to_multiply = ['OUT', 'ER', 'R', 'SO', 'FP']\n",
    "pitchers_merged_df_scaled = pitchers_merged_df.copy()\n",
    "pitchers_merged_df_scaled[columns_to_multiply] = pitchers_merged_df_scaled[columns_to_multiply] * fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fa8ff6-02c8-4c2a-97eb-1b7519894f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the DataFrame\n",
    "pitchers_scaled = pitchers_merged_df_scaled.dropna().query('starter == 1')[['OUT', 'outs', 'PA', 'pa', 'ER', 'er', 'R', 'r', 'SO', 'k', 'W', 'w', 'FP', 'fp']].agg(['mean', 'sum'])\n",
    "\n",
    "# Split the dataframe into projected (even rows) and actual (odd rows)\n",
    "projected = pitchers_scaled.T.iloc[::2].reset_index()\n",
    "actual = pitchers_scaled.T.iloc[1::2].reset_index()\n",
    "\n",
    "# Concatenate the two dataframes side-by-side\n",
    "pitchers_scaled = pd.concat([projected, actual], axis=1)\n",
    "\n",
    "# Rename the columns\n",
    "pitchers_scaled.columns = [\"Projected\", \"Projected Mean\", 'Projected Sum', \"Actual\", \"Actual Mean\", 'Actual Sum']\n",
    "\n",
    "# Append the new DataFrame\n",
    "with pd.ExcelWriter(player_stat_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    pitchers_scaled.to_excel(writer, sheet_name='ScaledPitchers', index=False)\n",
    "\n",
    "pitchers_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49551f7e-2b11-437d-be15-908eb873260e",
   "metadata": {},
   "source": [
    "##### Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bd2d12-c4b5-4f0e-af39-2fc15ebc6a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_pitchers = pitchers_merged_df.groupby(['gamePk', 'team']).sum(numeric_only=True).query('outs >= 24')[['OUT', 'outs', 'PA', 'pa', 'ER', 'er', 'R', 'r', 'SO', 'k', 'H', 'h', 'BB', 'bb', 'HR', 'hr', 'FP', 'fp']].agg(['mean'])\n",
    "\n",
    "# Convert to DF\n",
    "team_pitchers = pd.DataFrame(team_pitchers.mean().reset_index())\n",
    "\n",
    "# Split the dataframe into projected (even rows) and actual (odd rows)\n",
    "projected = team_pitchers.iloc[::2].reset_index(drop=True)\n",
    "actual = team_pitchers.iloc[1::2].reset_index(drop=True)\n",
    "\n",
    "# Concatenate the two dataframes side-by-side\n",
    "team_pitchers = pd.concat([projected, actual], axis=1)\n",
    "\n",
    "# Rename the columns\n",
    "team_pitchers.columns = [\"Projected\", \"Projected Value\", \"Actual\", \"Actual Value\"]\n",
    "\n",
    "# Append the new DataFrame\n",
    "with pd.ExcelWriter(player_stat_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    team_pitchers.to_excel(writer, sheet_name='TeamPitchers', index=False)\n",
    "\n",
    "team_pitchers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f684d3a-251a-4dca-a956-02a1dc31c6f0",
   "metadata": {},
   "source": [
    "##### Park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70afe9be-db68-43e7-acb9-ab9954f80c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitcher_park_fp = pitchers_merged_df.query('starter == 1').groupby('venue_id')[['FP', 'fp']].agg(['mean']).reset_index()\n",
    "pitcher_park_fp.columns = ['VENUE_ID', 'FP', 'fp']\n",
    "pitcher_park_fp = pd.merge(pitcher_park_fp, team_map[['VENUE_ID', 'BBREFTEAM']], on='VENUE_ID', how='left')\n",
    "\n",
    "# Append the new DataFrame\n",
    "with pd.ExcelWriter(player_stat_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    pitcher_park_fp.to_excel(writer, sheet_name='ParkPitchers', index=False)\n",
    "\n",
    "pitcher_park_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81290f3b-97c6-465e-b045-a5d08b635276",
   "metadata": {},
   "source": [
    "##### Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488bcfca-3b83-4103-81ce-8942e846f4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitcher_year_fp = pitchers_merged_df.query('starter == 1').groupby('year')[['FP', 'fp']].agg(['mean']).reset_index()\n",
    "pitcher_year_fp.columns = ['year', 'FP', 'fp']\n",
    "\n",
    "# Append the new DataFrame\n",
    "with pd.ExcelWriter(player_stat_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    pitcher_year_fp.to_excel(writer, sheet_name='YearPitchers', index=False)\n",
    "    \n",
    "pitcher_year_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e737129-a3be-4670-9802-1021d036b234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a68c51f-f70b-4bd5-bf30-db00bcb55e20",
   "metadata": {},
   "source": [
    "### 2. Competitor Projection Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3045a3-c62b-4278-bd97-af95f2f3b8e7",
   "metadata": {},
   "source": [
    "Compare my simulated projections to other source(s) of player fantasy point projections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f8fa90-2cdb-42a4-b086-b851054acc3b",
   "metadata": {},
   "source": [
    "##### Read in projections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cefabe-7bae-41a4-978c-0dd6903126f4",
   "metadata": {},
   "source": [
    "DFF - Date-Based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcead1db-1b00-46b2-98ad-2cd55d1baa31",
   "metadata": {},
   "source": [
    "DFF projections from when I extracted only one set of projections per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0383aef2-ebda-4263-97f7-97ba21278579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory path\n",
    "directory = r'C:\\Users\\james\\Documents\\MLB\\Database\\A07. Projections\\1. DFF\\2. Projections\\Date'\n",
    "\n",
    "# Initialize an empty list to store dataframes\n",
    "dfs = []\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):  # Check if the file is a CSV file\n",
    "        # Read the CSV file into a pandas dataframe\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        dfs.append(df)  # Append the dataframe to the list\n",
    "\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "dff_date_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Drop duplicates based on \"First Name\", \"Last Name\", and \"date\"\n",
    "dff_date_df.drop_duplicates(subset=[\"first_name\", \"last_name\", \"game_date\"], inplace=True)\n",
    "\n",
    "# Print the resulting dataframe\n",
    "print(dff_date_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cf2bd7-c88b-43f6-bf38-25b02d91a647",
   "metadata": {},
   "source": [
    "DFF - Slate-Based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63825cb8-d89a-43a1-8af3-1bd942f7f275",
   "metadata": {},
   "source": [
    "DFF projections from when I extract one set of projections per slate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a935b2d3-7025-4d25-84ff-6008d4f51709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory path\n",
    "directory = r'C:\\Users\\james\\Documents\\MLB\\Database\\A07. Projections\\1. DFF\\2. Projections'\n",
    "\n",
    "# Initialize an empty list to store dataframes\n",
    "dfs = []\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):  # Check if the file is a CSV file\n",
    "        # Read the CSV file into a pandas dataframe\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        dfs.append(df)  # Append the dataframe to the list\n",
    "\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "dff_slate_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Drop duplicates based on \"First Name\", \"Last Name\", and \"date\"\n",
    "dff_slate_df.drop_duplicates(subset=[\"First Name\", \"Last Name\", \"date\"], inplace=True)\n",
    "\n",
    "# Print the resulting dataframe\n",
    "print(dff_slate_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e2411b-4983-4b87-9241-fb99d90415d7",
   "metadata": {},
   "source": [
    "Clean name and date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7536ba6c-76ac-4e15-9b75-fe34e1253280",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_date_df.rename(columns={'first_name':'First Name', 'last_name':'Last Name', 'ppg_projection':'FP', 'team':'Team'}, inplace=True)\n",
    "dff_date_df['date'] = dff_date_df['game_date'].str.replace(\"-\", \"\").astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd36f2b-8cdf-4100-a1be-2802efe132a6",
   "metadata": {},
   "source": [
    "Combine DFF dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33a4e2d-658a-4a3c-b18c-94a9f888f283",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_df = pd.concat([dff_date_df[['First Name', 'Last Name', 'Team', 'FP', 'date']], dff_slate_df[['First Name', 'Last Name', 'FP', 'Team', 'date']]], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e1d33a-31a1-4483-a53e-6fe6f21e5e8f",
   "metadata": {},
   "source": [
    "Clean name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7175d04e-ac81-4df4-beee-4764c92abe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_df['fullName'] = dff_df['First Name'] + \" \" + dff_df['Last Name']\n",
    "dff_df.rename(columns={'FP': 'FP_DFF'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6796f0af-3d86-41cd-a12d-369497fb1098",
   "metadata": {},
   "source": [
    "Only keep one instance per player per game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d125cbe-5f2d-43b3-aaa1-7b9aa42108b5",
   "metadata": {},
   "source": [
    "Note: doubleheaders could be confused here - consider dropping both?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db032e99-6240-4efe-a854-2650a587126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_df.drop_duplicates(['fullName', 'date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68911a70-335b-4556-99f6-1d0b9bf9140c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec8cb30e-289b-4b01-8ba7-e3baf1f8b85f",
   "metadata": {},
   "source": [
    "##### Batters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b05420-9c9a-47e6-a4bf-803e9697c1f6",
   "metadata": {},
   "source": [
    "Merge DFF projections onto my projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd175e48-be5e-47fe-bb1b-4211452f0646",
   "metadata": {},
   "outputs": [],
   "source": [
    "batters_with_dff = batters_merged_df.drop_duplicates(['fullName', 'date']).merge(dff_df, on=['fullName', 'date'], how='inner', validate='one_to_one')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72764611-fe80-41a9-946b-2568d92ff612",
   "metadata": {},
   "source": [
    "Create error and success measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a82cdcb-367b-437a-93a8-0e4c7f4b4087",
   "metadata": {},
   "outputs": [],
   "source": [
    "batters_with_dff['error_me'] = (batters_with_dff['fp'] - batters_with_dff['FP'])\n",
    "batters_with_dff['error_dff'] = (batters_with_dff['fp'] - batters_with_dff['FP_DFF'])\n",
    "\n",
    "batters_with_dff['error_me2'] = batters_with_dff['error_me'] ** 2\n",
    "batters_with_dff['error_dff2'] = batters_with_dff['error_dff'] ** 2\n",
    "\n",
    "batters_with_dff['beat_dff'] = (batters_with_dff['error_me2'] < batters_with_dff['error_dff2']).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865e9cf4-b0d9-45c1-896f-aa2074881c64",
   "metadata": {},
   "source": [
    "##### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c97ff26-d464-4031-807d-e36871096e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "batter_summary_stats = pd.DataFrame(batters_with_dff.query('FP > 4 and FP_DFF > 4')[['FP', 'FP_DFF', 'fp', 'error_me', 'error_dff', 'error_me2', 'error_dff2', 'beat_dff']].mean())\n",
    "batter_summary_stats.columns=['Batters']\n",
    "batter_summary_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d4a41b-3dca-4fcb-be56-bca4da2d42cc",
   "metadata": {},
   "source": [
    "##### Quantiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24efa3f3-5d37-4623-bb6d-85e2dbc0a903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of quantiles\n",
    "quantiles = 20\n",
    "\n",
    "# Filter the dataframe\n",
    "batters_filtered_df = batters_with_dff.query('FP > 4 and FP_DFF > 4')\n",
    "\n",
    "# Create deciles based on FP\n",
    "batters_filtered_df['FP_quantile'] = pd.qcut(batters_filtered_df['fp'], quantiles, labels=False, duplicates='drop') + 1\n",
    "\n",
    "# Group by deciles and calculate averages for FP and FP_DFF\n",
    "batters_quantile_averages = (batters_filtered_df.groupby('FP_quantile').agg(Avg_FP=('FP', 'mean'), Avg_FP_DFF=('FP_DFF', 'mean'), Avg_fp=('fp', 'mean')).reset_index())\n",
    "\n",
    "print(batters_quantile_averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989d99bb-ed39-46c0-b44e-cf9b3fa59171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the averages\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot FP averages\n",
    "plt.plot(batters_quantile_averages['FP_quantile'], batters_quantile_averages['Avg_FP'], marker='o', label='FP - Me')\n",
    "\n",
    "# Plot FP_DFF averages\n",
    "plt.plot(batters_quantile_averages['FP_quantile'], batters_quantile_averages['Avg_FP_DFF'], marker='o', label='FP - DFF')\n",
    "\n",
    "# Plot fp averages\n",
    "plt.plot(batters_quantile_averages['FP_quantile'], batters_quantile_averages['Avg_fp'], marker='o', label='FP - Actual')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Average FP by Decile', fontsize=16)\n",
    "plt.xlabel('FP Quantile', fontsize=14)\n",
    "plt.ylabel('Average Value', fontsize=14)\n",
    "plt.xticks(batters_quantile_averages['FP_quantile'])\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fdbbde-9d31-45cc-ba1c-93a99d20a68c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7006db2-e84a-4753-a40d-710c7b14fa5a",
   "metadata": {},
   "source": [
    "##### Pitchers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a4ea99-06f9-413f-a881-018b58614ccd",
   "metadata": {},
   "source": [
    "Merge DFF projections onto my projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2474a2-fa31-4956-81b0-cae99a96cf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitchers_with_dff = pitchers_merged_df.drop_duplicates(['fullName', 'date']).merge(dff_df, on=['fullName', 'date'], how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e390ca7-7ec6-498a-b4e5-a1416c146668",
   "metadata": {},
   "source": [
    "Create error and success measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203631e3-9e4a-426b-92ab-e5f33a084c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitchers_with_dff['error_me'] = (pitchers_with_dff['fp'] - pitchers_with_dff['FP'])\n",
    "pitchers_with_dff['error_dff'] = (pitchers_with_dff['fp'] - pitchers_with_dff['FP_DFF'])\n",
    "\n",
    "pitchers_with_dff['error_me2'] = pitchers_with_dff['error_me'] ** 2\n",
    "pitchers_with_dff['error_dff2'] = pitchers_with_dff['error_dff'] ** 2\n",
    "\n",
    "pitchers_with_dff['beat_dff'] = (pitchers_with_dff['error_me2'] < pitchers_with_dff['error_dff2']).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743b1166-e292-4870-a743-1bab050657b8",
   "metadata": {},
   "source": [
    "##### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8eb7cc-a230-435b-b41d-73f0b0e45aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitcher_summary_stats = pd.DataFrame(pitchers_with_dff.dropna().query('starter == 1')[['FP', 'FP_DFF', 'fp', 'error_me', 'error_dff', 'error_me2', 'error_dff2', 'beat_dff']].mean())\n",
    "pitcher_summary_stats.columns = ['Pitchers']\n",
    "pitcher_summary_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f324bf-c272-43c7-b4d2-98a5525115fe",
   "metadata": {},
   "source": [
    "##### Quantiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb39bbc-784d-49cc-a7c3-1706be032b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of quantiles\n",
    "quantiles = 20\n",
    "\n",
    "# Filter the dataframe\n",
    "pitchers_filtered_df = pitchers_with_dff.query('FP > 4 and FP_DFF > 4')\n",
    "\n",
    "# Create deciles based on FP\n",
    "pitchers_filtered_df['FP_quantile'] = pd.qcut(pitchers_filtered_df['fp'], quantiles, labels=False) + 1\n",
    "\n",
    "# Group by deciles and calculate averages for FP and FP_DFF\n",
    "pitchers_quantile_averages = (pitchers_filtered_df.groupby('FP_quantile').agg(Avg_FP=('FP', 'mean'), Avg_FP_DFF=('FP_DFF', 'mean'), Avg_fp=('fp', 'mean')).reset_index())\n",
    "\n",
    "pitchers_quantile_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e821c528-ad1c-4657-9640-d576be528d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the averages\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot FP averages\n",
    "plt.plot(pitchers_quantile_averages['FP_quantile'], pitchers_quantile_averages['Avg_FP'], marker='o', label='FP - Me')\n",
    "\n",
    "# Plot FP_DFF averages\n",
    "plt.plot(pitchers_quantile_averages['FP_quantile'], pitchers_quantile_averages['Avg_FP_DFF'], marker='o', label='FP - DFF')\n",
    "\n",
    "# Plot fp averages\n",
    "plt.plot(pitchers_quantile_averages['FP_quantile'], pitchers_quantile_averages['Avg_fp'], marker='o', label='FP - Actual ')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Average FP by Quantile', fontsize=16)\n",
    "plt.xlabel('FP Quantile', fontsize=14)\n",
    "plt.ylabel('Average Value', fontsize=14)\n",
    "plt.xticks(pitchers_quantile_averages['FP_quantile'])\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7207bc82-6767-4f75-921d-3f02bd12d582",
   "metadata": {},
   "source": [
    "Write to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1990a95-8356-440d-bc36-3a3e0130d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_evaluation_path = os.path.join(baseball_path, \"C02. Players\", \"2. Competitor Projection Evaluations\", f\"{todaysdate} Competitor Projection Evaluation.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cc6e31-266f-4c44-91ef-9f8d5fcd218a",
   "metadata": {},
   "source": [
    "Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fd1f71-2442-461c-be89-63e280e10131",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_stats = pd.concat([batter_summary_stats, pitcher_summary_stats], axis=1)\n",
    "summary_stats.to_excel(projection_evaluation_path, sheet_name='Summary Stats')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bbb8e7-4da3-493f-bd82-5541ee4061bf",
   "metadata": {},
   "source": [
    "Quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c7b996-3bef-41bd-8d96-1b29a7d7a47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the new DataFrame\n",
    "with pd.ExcelWriter(projection_evaluation_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    batters_quantile_averages.to_excel(writer, sheet_name='BatterQuantiles', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c40e49-40ec-4dbc-a145-32bfdb9e54a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the new DataFrame\n",
    "with pd.ExcelWriter(projection_evaluation_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    pitchers_quantile_averages.to_excel(writer, sheet_name='PitcherQuantiles', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d58c91a-e811-4e04-bdbf-82577e643d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
