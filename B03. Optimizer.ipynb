{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# B03. Optimizer\n",
    "Sources: <br>\n",
    "\n",
    "Description: This optimizes lineups based on player projections and provided constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_player_sims(folder_path: str, position: str, n_jobs: int = -1) -> pd.DataFrame:\n",
    "    ### Read in data\n",
    "    # Select columns to read\n",
    "    if position == \"batter\":\n",
    "        columns = ['id', 'fullName', 'batting_order', 'imp_b_l', 'imp_b_r', 'confirmed', 'FP', 'team']\n",
    "    else:\n",
    "        columns = ['id', 'fullName', 'imp_p_l', 'imp_p_r', 'confirmed', 'FP', 'team']\n",
    "\n",
    "    # Specify files\n",
    "    folder = Path(folder_path)\n",
    "    file_paths = [file for file in folder.iterdir() if file.is_file() and file.suffix == '.csv' and file.name.startswith(position)]\n",
    "\n",
    "    # Read in CSVs, but only the specified columns \n",
    "    dfs = Parallel(n_jobs=n_jobs)(delayed(pd.read_csv)(file, usecols=columns) for file in file_paths)\n",
    "\n",
    "    # Concatenate dataframes together\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    ### Create new columns\n",
    "    # Identify home and away teams\n",
    "    away_team = folder_path.split(\"\\\\\")[-1].split(\"@\")[0]\n",
    "    home_team = (folder_path.split(\"\\\\\")[-1]).split(\"@\")[1].split(\" \")[0]\n",
    "    # Identify game_id\n",
    "    game_id = folder_path.split(\" \")[-2]\n",
    "\n",
    "    # Create team columns\n",
    "    df['away_team'] = away_team\n",
    "    df['home_team'] = home_team\n",
    "    df['TeamAbbrev'] = np.where(df['team'] == \"away\", df['away_team'], df['home_team'])\n",
    "    df['game_id'] = game_id\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_player_file(contestKey, guide, draftGroupId, roto_slate, max_exposure_pitchers, max_exposure_batters, projections='roto', rostership='roto', ownership_spread=0.25):\n",
    "    ### Step 1) Read in Draftables\n",
    "    draftable_df = pd.read_csv(os.path.join(baseball_path, \"A01. DraftKings\", \"2. Draftables\", f\"Draftables {draftGroupId}.csv\"), dtype='str', encoding='iso-8859-1')\n",
    "\n",
    "    # Create clean TEAM column\n",
    "    draftable_df['TEAM'] = draftable_df['TeamAbbrev'].map(team_dict)\n",
    "    \n",
    "    # Remove postponed games\n",
    "    if \"alertType\" in draftable_df.columns:\n",
    "        draftable_df = draftable_df[draftable_df['alertType'] != \"Postponed Game Alert\"].reset_index(drop=True)\n",
    "    \n",
    "    ### Step 2) Read in Sims\n",
    "    sim_dfs = []\n",
    "    for folder in os.listdir(os.path.join(baseball_path, \"B02. Simulations\", \"2. Player Sims\", f\"Matchups {guide['date'][0]}\")):\n",
    "        # Check if folder name contains any game_id\n",
    "        if not any(game in folder for game in list(guide['game_id'].astype(str))):\n",
    "            print(f\"Excluding: {folder}\")\n",
    "            continue\n",
    "\n",
    "        folder_path = os.path.join(baseball_path, \"B02. Simulations\", \"2. Player Sims\", f\"Matchups {guide['date'][0]}\", folder)\n",
    "        print(f\"Folder: {folder}\")\n",
    "        # Batters\n",
    "        position = 'batter'\n",
    "        batter_df = concat_player_sims(folder_path, position, n_jobs=-1)\n",
    "        batter_df['Position'] = position\n",
    "        batter_df.rename(columns={'imp_b_l': 'imp_l', 'imp_b_r': 'imp_r'}, inplace=True)\n",
    "        # Pitchers\n",
    "        position = 'pitcher'\n",
    "        pitcher_df = concat_player_sims(folder_path, position, n_jobs=-1)\n",
    "        pitcher_df['Position'] = position\n",
    "        pitcher_df.rename(columns={'imp_p_l': 'imp_l', 'imp_p_r': 'imp_r'}, inplace=True)\n",
    "        pitcher_df['batting_order'] = -99\n",
    "        pitcher_df['confirmed'].fillna(\"Y\", inplace=True)\n",
    "\n",
    "        df = pd.concat([batter_df, pitcher_df], ignore_index=True, axis=0)\n",
    "\n",
    "        sim_dfs.append(df)\n",
    "\n",
    "\n",
    "    # Concatenate all player sims together\n",
    "    sim_df = pd.concat(sim_dfs, ignore_index=True, axis=0)\n",
    "\n",
    "    # Pivot\n",
    "    # Create a new index for each FP instance within each `id`\n",
    "    sim_df['FP_index'] = sim_df.groupby('id').cumcount()\n",
    "\n",
    "    # Pivot the DataFrame, using the `FP_index` to spread `FP` values into columns\n",
    "    wide_df = sim_df.pivot_table(index=[col for col in sim_df.columns if col != 'FP' and col != 'FP_index'],\n",
    "                             columns='FP_index', \n",
    "                             values='FP', \n",
    "                             aggfunc='first')\n",
    "\n",
    "    # Rename the columns to FP_0, FP_1, etc.\n",
    "    wide_df.columns = [f\"FP_{col}\" for col in wide_df.columns]\n",
    "\n",
    "    # Reset index to get a flat DataFrame\n",
    "    wide_df.reset_index(inplace=True)\n",
    "\n",
    "    # Create clean TEAM variable\n",
    "    wide_df['TEAM'] = wide_df['TeamAbbrev'].map(team_dict)\n",
    "\n",
    "    ### Step 3) Read in RotoWire Projections\n",
    "    try:\n",
    "        roto_df = pd.read_csv(os.path.join(baseball_path, \"A07. Projections\", \"2. RotoWire\", \"2. Projections\", f\"RotoWire Projections {roto_slate}.csv\"))\n",
    "\n",
    "        # Create clean columns\n",
    "        roto_df['fullName'] = roto_df['firstName'] + \" \" + roto_df['lastName']\n",
    "        roto_df['roto_projection'] = roto_df['points']\n",
    "        roto_df['TEAM'] = roto_df['teamAbbr'].map(team_dict)\n",
    "\n",
    "        # Keep relevant columns\n",
    "        roto_df = roto_df[['fullName', 'TEAM', 'roto_projection', 'rostership']]\n",
    "    except:\n",
    "        print(\"No Roto file\")\n",
    "        rostership = None\n",
    "        roto_df = pd.DataFrame(columns=['fullName', 'TEAM', 'roto_projection', 'rostership'])\n",
    "\n",
    "\n",
    "    ### Step 4) Merge\n",
    "    # Merge draftables, sims (wide), and RotoWire dataframes\n",
    "    player_df = pd.merge(draftable_df, wide_df, left_on=['Name', 'TEAM'], right_on=['fullName', 'TEAM'], how='inner', suffixes=(\"\", \"2\"))\n",
    "    player_df = pd.merge(player_df, roto_df, on=['fullName', 'TEAM'], how='left')\n",
    "\n",
    "\n",
    "    ### Step 5) Create New Fields\n",
    "    ## Projections\n",
    "    # Identify FP columns\n",
    "    fp_columns = [col for col in player_df.columns if \"FP_\" in col]\n",
    "    # RotoWire\n",
    "    if projections == 'roto':\n",
    "        player_df['AvgPointsPerGame'] = player_df['roto_projection'].fillna(0)\n",
    "    # My projections\n",
    "    elif projections == \"robot\":\n",
    "        player_df['AvgPointsPerGame'] = player_df[fp_columns].mean(axis=1)\n",
    "    \n",
    "    ## Exposure\n",
    "    # Set exposure range\n",
    "    # RotoWire ownership projections   \n",
    "    if rostership == \"roto\":\n",
    "        # Multiplier\n",
    "        # Sometimes rostership doesn't add up to 1000\n",
    "        multiplier = 1000 / player_df['rostership'].sum(axis=0)\n",
    "        player_df['rostership'] = player_df['rostership'] * multiplier\n",
    "        player_df['rostership'].fillna(0, inplace=True)\n",
    "\n",
    "        # Minimum\n",
    "        # Shouldn't be below 0\n",
    "        player_df['Min Exposure'] = np.maximum(player_df['rostership'] * (1 - ownership_spread) / 100, 0)\n",
    "        # Very low values (0.01, for instance) make solving difficult. Replace with minimum of 0.\n",
    "        player_df['Min Exposure'] = np.where(player_df['Min Exposure'] < 0.1, 0, player_df['Min Exposure'])\n",
    "        # Maximum\n",
    "        player_df['Max Exposure'] = np.where(player_df['Position2'] == \"batter\",\n",
    "                                             np.minimum(player_df['rostership'] * (1 + ownership_spread) / 100, max_exposure_batters),\n",
    "                                             np.minimum(player_df['rostership'] * (1 + ownership_spread) / 100, max_exposure_pitchers))\n",
    "    # No ownership projections\n",
    "    else:\n",
    "        player_df['Min Exposure'] = 0\n",
    "        player_df['Max Exposure'] = np.where(player_df['Position2'] == \"batter\", max_exposure_batters, max_exposure_pitchers)\n",
    "\n",
    "    ## Roster information\n",
    "    player_df['Confirmed Starter'] = (player_df['confirmed'].isin([\"Y\",1])).astype(int)\n",
    "    player_df['Roster Order'] = player_df['batting_order'].astype(int)\n",
    "\n",
    "\n",
    "    # Relevant columns\n",
    "    player_columns = ['Position', 'Name + ID', 'Name', 'ID', 'Roster Position', 'Salary', 'Game Info', 'TeamAbbrev', 'AvgPointsPerGame', 'playerId', 'draftGroupId', 'game_id', 'Position2', 'imp_l', 'imp_r', 'confirmed', 'batting_order'] + fp_columns + ['rostership', 'roto_projection', 'Roster Order', 'Confirmed Starter', 'Min Exposure', 'Max Exposure']\n",
    "\n",
    "    \n",
    "    return player_df[player_columns].sort_values(['AvgPointsPerGame'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Lineups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_lineups(contestKey, min_salary=49000, min_projection=5, stack_list=[5, 2, 1], excluded_teams=[],\n",
    "                   min_starters=10, strategy=None, max_deviation=0.2, progressive_growth=0.01, num_lineups=200, parameters='Max'):\n",
    "\n",
    "    class GLPKPuLPSolver(PuLPSolver):\n",
    "        LP_SOLVER = GLPK_CMD(path='C:/Users/james/anaconda3/Library/bin/glpsol.exe', msg=False)\n",
    "    \n",
    "    ### Load in DraftKings baseball optimizer\n",
    "    optimizer = get_optimizer(Site.DRAFTKINGS, Sport.BASEBALL, solver=GLPKPuLPSolver)\n",
    "    \n",
    "    ### Load in player sims\n",
    "    optimizer.load_players_from_csv(os.path.join(baseball_path, \"B03. Lineups\", \"1. Players\", f\"Players {contestKey}.csv\"))\n",
    "\n",
    "    ### Settings\n",
    "    # Set minimum salary\n",
    "    optimizer.set_min_salary_cap(min_salary)\n",
    "    # Stacks\n",
    "    for stack in stack_list:\n",
    "        optimizer.add_stack(TeamStack(size=stack, for_positions=['C', '1B', '2B', '3B', 'SS', 'OF'])) # removed spacing= argument because it's slow\n",
    "    # Position Restrictions (may be incompatible with GLPK)\n",
    "    # optimizer.restrict_positions_for_opposing_team(['SP', 'RP'], ['C', '1B', '2B', '3B', 'SS', 'OF']) \n",
    "    # Team Exclusions\n",
    "    optimizer.player_pool.exclude_teams(excluded_teams)\n",
    "    # Confirmed Starters\n",
    "    optimizer.set_min_starters(min_starters)\n",
    "    # Minimum Projection\n",
    "    optimizer.player_pool.add_filters(PlayerFilter(from_value=min_projection),)\n",
    "    # Set strategy (default is to use the same projections each simulation)\n",
    "    if strategy == \"Random\":\n",
    "        optimizer.set_fantasy_points_strategy(RandomFantasyPointsStrategy(max_deviation=max_deviation))  # set random strategy with custom max_deviation\n",
    "    elif strategy == \"Progressive\":\n",
    "        optimizer.set_fantasy_points_strategy(ProgressiveFantasyPointsStrategy(progressive_growth))  # Set progressive strategy that increase player points by 1%\n",
    "\n",
    "    # Set exposure overwrite\n",
    "    for player in optimizer.player_pool.get_players():\n",
    "        player.min_exposure = 0\n",
    "        if parameters == 'Min':\n",
    "            player.max_exposure = 1\n",
    "\n",
    "    ### Optimizer\n",
    "    i = 0\n",
    "    for lineup_num in optimizer.optimize(num_lineups, exposure_strategy=AfterEachExposureStrategy):\n",
    "        if i % 50 == 0 or i in [1, num_lineups - 1]:\n",
    "            sys.stdout.write(f\"\\r{stack_list}: {i}/{num_lineups}   \")  # \\r moves to the beginning of the line\n",
    "            sys.stdout.flush()\n",
    "        i += 1\n",
    "\n",
    "    print(f\"{stack_list}: {num_lineups}/{num_lineups} - Finished!\")\n",
    "\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lineups2(params):\n",
    "    try:\n",
    "        optimizer = create_lineups(*params)\n",
    "    except Exception as e:\n",
    "        optimizer = str(params) + \" \" + str(e)\n",
    "\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_lineups(optimizers):\n",
    "    # Read the CSV contents into DataFrames and concatenate them\n",
    "    dataframes = []\n",
    "    for i, optimizer in enumerate(optimizers):\n",
    "        if type(optimizer) != str:\n",
    "            optimizer.export(f'optimizer_{i}.csv')\n",
    "            dataframes.append(pd.read_csv(f'optimizer_{i}.csv'))\n",
    "\n",
    "    combined_df = pd.concat(dataframes)\n",
    "    combined_df.drop_duplicates(inplace=True)\n",
    "    combined_df.sort_values('FPPG', inplace=True, ascending=False)\n",
    "\n",
    "    # Write the combined DataFrame to a new CSV file\n",
    "    combined_df.to_csv(os.path.join(baseball_path, \"B03. Lineups\", \"2. Lineups\", f\"Lineups {contestKey}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Lineups Ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def choose_lineups(contestKey, roto_slate, pareto_set, sense_list, sort_by, ascending_list):\n",
    "    # Read in players\n",
    "    player_sims = pd.read_csv(os.path.join(baseball_path, \"B03. Lineups\", \"1. Players\", f\"Players {contestKey}.csv\"))\n",
    "\n",
    "    # Keep relevant variables\n",
    "    player_sims.drop(columns={\"Position\", \"Name\", \"ID\", \"Roster Position\", \"Salary\", \"Game Info\", \"TeamAbbrev\", 'playerId', 'draftGroupId', 'game_id', 'Position2', 'imp_l', 'imp_r', \"AvgPointsPerGame\"}, inplace=True)\n",
    "\n",
    "\n",
    "    # Clean Name + ID variable to remove space (this is for consistency for merging)\n",
    "    player_sims['Name + ID'] = player_sims['Name + ID'].str.replace(r'\\s*\\(', '(', regex=True, flags=re.IGNORECASE)\n",
    "        \n",
    "    # Determine number of game simulations\n",
    "    num_sims = sum('FP_' in column_name for column_name in player_sims.columns)\n",
    "\n",
    "    \n",
    "    # Read in daily lineups\n",
    "    lineup_sims = pd.read_csv(os.path.join(baseball_path, \"B03. Lineups\", \"2. Lineups\", f\"Lineups {contestKey}.csv\"))\n",
    "    \n",
    "    # Merge stats onto lineups\n",
    "    lineup_sims = lineup_sims.merge(player_sims, left_on=\"P\", right_on=\"Name + ID\", how='left', validate=\"m:1\")\n",
    "    lineup_sims = lineup_sims.merge(player_sims, left_on=\"P.1\", right_on=\"Name + ID\", how='left', validate=\"m:1\", suffixes=(None, \"_P.1\"))\n",
    "    lineup_sims = lineup_sims.merge(player_sims, left_on=\"C\", right_on=\"Name + ID\", how='left', validate=\"m:1\", suffixes=(None, \"_C\"))\n",
    "    lineup_sims = lineup_sims.merge(player_sims, left_on=\"1B\", right_on=\"Name + ID\", how='left', validate=\"m:1\", suffixes=(None, \"_1B\"))\n",
    "    lineup_sims = lineup_sims.merge(player_sims, left_on=\"2B\", right_on=\"Name + ID\", how='left', validate=\"m:1\", suffixes=(None, \"_2B\"))\n",
    "    lineup_sims = lineup_sims.merge(player_sims, left_on=\"3B\", right_on=\"Name + ID\", how='left', validate=\"m:1\", suffixes=(None, \"_3B\"))\n",
    "    lineup_sims = lineup_sims.merge(player_sims, left_on=\"SS\", right_on=\"Name + ID\", how='left', validate=\"m:1\", suffixes=(None, \"_SS\"))\n",
    "    lineup_sims = lineup_sims.merge(player_sims, left_on=\"OF\", right_on=\"Name + ID\", how='left', validate=\"m:1\", suffixes=(None, \"_OF\"))\n",
    "    lineup_sims = lineup_sims.merge(player_sims, left_on=\"OF.1\", right_on=\"Name + ID\", how='left', validate=\"m:1\", suffixes=(None, \"_OF.1\"))\n",
    "    lineup_sims = lineup_sims.merge(player_sims, left_on=\"OF.2\", right_on=\"Name + ID\", how='left', validate=\"m:1\", suffixes=(None, \"_OF.2\"))\n",
    "    \n",
    "    # Add up player performances\n",
    "    i=0\n",
    "    # Where i is the number of simulations\n",
    "    while i < num_sims:\n",
    "        sim = f\"FP_{i}\"\n",
    "        P1 = sim\n",
    "        P2 = sim + \"_P.1\"\n",
    "        C = sim + \"_C\"\n",
    "        B1 = sim + \"_1B\"\n",
    "        B2 = sim + \"_2B\"\n",
    "        B3 = sim + \"_3B\"\n",
    "        SS = sim + \"_SS\"\n",
    "        OF1 = sim + \"_OF\"\n",
    "        OF2 = sim + \"_OF.1\"\n",
    "        OF3 = sim + \"_OF.2\"\n",
    "\n",
    "        game = f\"Sim {i}\"\n",
    "\n",
    "        lineup_sims[game] = lineup_sims[P1] + lineup_sims[P2] + lineup_sims[C] + lineup_sims[B1] + lineup_sims[B2] + lineup_sims[B3] + lineup_sims[SS] + lineup_sims[OF1] + lineup_sims[OF2] + lineup_sims[OF3]\n",
    "\n",
    "        i+=1\n",
    "\n",
    "    \n",
    "    lineup_sims.rename(columns={'FPPG':'AvgPointsPerGame'}, inplace=True)\n",
    "        \n",
    "    \n",
    "    ### Calculate summary statistics\n",
    "    column_list = [col for col in lineup_sims if col.startswith(\"Sim\")]\n",
    "\n",
    "    ### Points\n",
    "    lineup_sims['AVG'] = lineup_sims[column_list].mean(axis=1)\n",
    "    lineup_sims['P50'] = lineup_sims[column_list].median(axis=1)\n",
    "    lineup_sims['P75'] = lineup_sims[column_list].quantile(.75, axis=1)\n",
    "    lineup_sims['P90'] = lineup_sims[column_list].quantile(.90, axis=1)\n",
    "    lineup_sims['P95'] = lineup_sims[column_list].quantile(.95, axis=1)\n",
    "    lineup_sims['P99'] = lineup_sims[column_list].quantile(.99, axis=1)\n",
    "    lineup_sims['P100'] = lineup_sims[column_list].max(axis=1)\n",
    "\n",
    "    \n",
    "    ### Tail \n",
    "    lineup_sims['Tail'] = 0 \n",
    "    for column in column_list:\n",
    "        for i in range(len(lineup_sims)):\n",
    "            if lineup_sims[column][i] >= lineup_sims['P95'][i]:\n",
    "                lineup_sims['Tail'][i] = lineup_sims['Tail'][i] + lineup_sims[column][i]\n",
    "\n",
    "    lineup_sims['Sim STD'] = lineup_sims[lineup_sims.columns[lineup_sims.columns.str.startswith('Sim')]].std(axis=1)\n",
    "\n",
    "    # Standard deviations from mean \n",
    "    lineup_sims['Plus2'] = lineup_sims['AvgPointsPerGame'] + 2 * lineup_sims['Sim STD']\n",
    "    lineup_sims['Plus3'] = lineup_sims['AvgPointsPerGame'] + 3 * lineup_sims['Sim STD']\n",
    "    \n",
    "    \n",
    "    ### Ownership\n",
    "    # Pitcher ownership \n",
    "    lineup_sims.rename(columns={'rostership': 'rostership_P'}, inplace=True)\n",
    "    lineup_sims['pitcher rostership'] = lineup_sims[['rostership_P', 'rostership_P.1']].sum(axis=1)\n",
    "    # Batter ownership \n",
    "    lineup_sims['batter rostership'] = lineup_sims[['rostership_C', 'rostership_1B', 'rostership_2B', 'rostership_3B', 'rostership_SS', 'rostership_OF', 'rostership_OF.1', 'rostership_OF.2']].sum(axis=1)\n",
    "    # Total\n",
    "    lineup_sims['rostership'] = lineup_sims[['pitcher rostership', 'batter rostership']].sum(axis=1)\n",
    "\n",
    "\n",
    "    # Identify pareto optimal lineups\n",
    "    lineup_sims['pareto'] = paretoset(lineup_sims[pareto_set], sense=sense_list).astype('int')\n",
    "\n",
    "\n",
    "    # Filter columns starting with 'Sim '\n",
    "    sim_columns = [col for col in lineup_sims.columns if col.startswith('Sim ')]\n",
    "\n",
    "    # Initialize the Wins and Top1% columns\n",
    "    lineup_sims['Wins'] = 0\n",
    "    lineup_sims['Top1%'] = 0\n",
    "    lineup_sims['Top5%'] = 0\n",
    "    lineup_sims['Top10%'] = 0\n",
    "    lineup_sims['Top20%'] = 0\n",
    "    lineup_sims['Top50%'] = 0\n",
    "\n",
    "    # Iterate over each 'Sim ' column\n",
    "    for col in sim_columns:\n",
    "        # Find the maximum value in the column\n",
    "        max_value = lineup_sims[col].max()\n",
    "        # Increment the 'Wins' count for rows with the maximum value in this column\n",
    "        lineup_sims.loc[lineup_sims[col] == max_value, 'Wins'] += 1\n",
    "\n",
    "        # Calculate the top 1% threshold for the current column\n",
    "        top_1_percent_threshold = lineup_sims[col].quantile(0.99)\n",
    "        top_5_percent_threshold = lineup_sims[col].quantile(0.95)\n",
    "        top_10_percent_threshold = lineup_sims[col].quantile(0.90)\n",
    "        top_20_percent_threshold = lineup_sims[col].quantile(0.80)\n",
    "        top_50_percent_threshold = lineup_sims[col].quantile(0.50)\n",
    "        # Increment the 'Top1%' count for rows with values in the top 1%\n",
    "        lineup_sims.loc[lineup_sims[col] >= top_1_percent_threshold, 'Top1%'] += 1\n",
    "        lineup_sims.loc[lineup_sims[col] >= top_5_percent_threshold, 'Top5%'] += 1\n",
    "        lineup_sims.loc[lineup_sims[col] >= top_10_percent_threshold, 'Top10%'] += 1\n",
    "        lineup_sims.loc[lineup_sims[col] >= top_20_percent_threshold, 'Top20%'] += 1\n",
    "        lineup_sims.loc[lineup_sims[col] >= top_50_percent_threshold, 'Top50%'] += 1\n",
    "\n",
    "    # Convert the Top1% count to a percentage\n",
    "    lineup_sims['Top1%'] = (lineup_sims['Top1%'] / len(sim_columns)) * 100\n",
    "    lineup_sims['Top5%'] = (lineup_sims['Top5%'] / len(sim_columns)) * 100\n",
    "    lineup_sims['Top10%'] = (lineup_sims['Top10%'] / len(sim_columns)) * 100\n",
    "    lineup_sims['Top20%'] = (lineup_sims['Top20%'] / len(sim_columns)) * 100\n",
    "    lineup_sims['Top50%'] = (lineup_sims['Top50%'] / len(sim_columns)) * 100\n",
    "\n",
    "    # Sort (descending - Note that DK will read this the wrong way)\n",
    "    lineup_sims.sort_values(by=sort_by, ascending=ascending_list, inplace=True)\n",
    "\n",
    "\n",
    "    # Delete excess variables\n",
    "    lineup_sims = lineup_sims.loc[:, ~lineup_sims.columns.str.contains('FP', case=False)]\n",
    "    lineup_sims = lineup_sims.loc[:, ~lineup_sims.columns.str.contains('Name', case=False)]\n",
    "    lineup_sims = lineup_sims.loc[:, ~lineup_sims.columns.str.contains('Order', case=False)]\n",
    "    lineup_sims = lineup_sims.loc[:, ~lineup_sims.columns.str.contains('Exposure', case=False)]\n",
    "    lineup_sims = lineup_sims.loc[:, ~lineup_sims.columns.str.contains('onfirmed', case=False)]\n",
    "    lineup_sims = lineup_sims.loc[:, ~lineup_sims.columns.str.contains('rostership_', case=False)]\n",
    "    lineup_sims = lineup_sims.loc[:, ~lineup_sims.columns.str.contains('roto_projection', case=False)]\n",
    "\n",
    "    \n",
    "    return lineup_sims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Uploads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_upload_file(contestKey, sort_by='Plus3'):\n",
    "    # Read in lineup sims\n",
    "    lineup_ranked = pd.read_csv(os.path.join(baseball_path, \"B03. Lineups\", \"3. Lineups Ranked\", f\"Lineups Ranked {contestKey}.csv\"))\n",
    "    # # Sort (ascending because DK will put the bottom lineups at the top)\n",
    "    # lineup_ranked.sort_values(by=sort_by, ascending=True, inplace=True)\n",
    "    # Keep just the players\n",
    "    lineup_ranked = lineup_ranked[['P', 'P.1', 'C', '1B', '2B', '3B', 'SS', 'OF', 'OF.1', 'OF.2']]\n",
    "    \n",
    "    # Rename variables to appease DK's upload\n",
    "    lineup_ranked.rename(columns={'P.1':'P', 'OF.1':'OF', 'OF.2':'OF'}, inplace=True)\n",
    "    \n",
    "    return lineup_ranked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_entry_file(draftGroupId, contestKey):\n",
    "    # Download entry file for draftGroupId\n",
    "    url = f\"https://www.draftkings.com/bulkentryedit/getentriescsv?draftGroupId={draftGroupId}\"\n",
    "\n",
    "    javascript_code = f\"window.open('{url}', '_blank');\"\n",
    "    display(Javascript(javascript_code))\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Get the list of files in the downloads folder\n",
    "    files = os.listdir(download_path)\n",
    "\n",
    "    # Get the most recently modified file (entry sheet)\n",
    "    most_recent_file = max(files, key=lambda x: os.path.getctime(os.path.join(download_path, x)))\n",
    "    most_recent_file_path = os.path.join(download_path, most_recent_file)\n",
    "    df = pd.read_csv(most_recent_file_path, usecols=['Entry ID','Contest Name','Contest ID','Entry Fee'])\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Read in Upload file\n",
    "    lineup_sims = pd.read_csv(os.path.join(baseball_path, \"B03. Lineups\", \"4. Uploads\", f\"Upload {contestKey}.csv\"), encoding='iso-8859-1')\n",
    "\n",
    "    # Keep just the players\n",
    "    lineup_sims = lineup_sims[['P', 'P.1', 'C', '1B', '2B', '3B', 'SS', 'OF', 'OF.1', 'OF.2']]\n",
    "    # Rename variables to appease DK's upload\n",
    "    lineup_sims.rename(columns={'P.1':'P', 'OF.1':'OF', 'OF.2':'OF'}, inplace=True)\n",
    "    lineup_sims.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # Merge entry sheet with lineups\n",
    "    entry_df = df.merge(lineup_sims, how='inner', left_index=True, right_index=True)\n",
    "    \n",
    "    # Convert to numeric\n",
    "    entry_df['Entry ID'] = entry_df['Entry ID'].astype('int64')\n",
    "\n",
    "    return entry_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contest_lineups(contestKey, sort_by, min_salary, min_projection, major_stack, minor_stack, max_exposure_batters, max_exposure_pitchers, excluded_teams, min_starters, lineups, historic):\n",
    "    # Read in Contest Guide\n",
    "    guide = pd.read_csv(os.path.join(baseball_path, \"A09. Contest Guides\", f\"Contest Guide {contestKey}.csv\"))\n",
    "\n",
    "    # Identify draftGroupId\n",
    "    draftGroupId = guide['draftGroupId'][0]\n",
    "\n",
    "    # Identify date\n",
    "    date = guide['date'][0]\n",
    "\n",
    "    # Identify RotoWire slate\n",
    "    roto_slate = guide['roto_slate'][0]\n",
    "    \n",
    "    # 1. Players\n",
    "    # This creates player files to be used as inputs in optimizer\n",
    "    draftables_with_sims = create_player_file(contestKey, guide, draftGroupId, date, roto_slate)    \n",
    "    draftables_with_sims.to_csv(os.path.join(baseball_path, \"B03. Lineups\", \"1. Players\", f\"Players {contestKey}.csv\"), index=False, encoding='iso-8859-1')\n",
    "    \n",
    "    # 2. Lineups\n",
    "    # This creates optimal lineups\n",
    "    create_lineups(contestKey, min_salary, min_projection, major_stack, minor_stack, excluded_teams, min_starters, lineups)\n",
    "    \n",
    "    # 3. Lineups Ranked\n",
    "    # This adds stats based on score distributions to assess which lineups to choose\n",
    "    lineups_ranked = choose_lineups(contestKey, roto_slate, sort_by)\n",
    "    lineups_ranked.to_csv(os.path.join(baseball_path, \"B03. Lineups\", \"3. Lineups Ranked\", f\"Lineups Ranked {contestKey}.csv\"), index=False)\n",
    "    \n",
    "    # 4. Uploads\n",
    "    # This creates a file to upload lineups to DraftKings in the proper order\n",
    "    if historic == False:\n",
    "        # Create upload file\n",
    "        upload = create_upload_file(contestKey, sort_by)\n",
    "        upload.to_csv(os.path.join(baseball_path, \"B03. Lineups\", \"4. Uploads\", f\"Upload {contestKey}.csv\"), index=False)\n",
    "\n",
    "    # 5. Entries\n",
    "    # This creates a file to upload entry-specific lineups\n",
    "    if historic == False:\n",
    "        entry = create_entry_file(draftGroupId, contestKey)\n",
    "        entry.to_csv(os.path.join(baseball_path, \"B03. Lineups\", \"5. Entries\", f\"Entries {draftGroupId}.csv\"), index=False, encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This returns contestKeys that do not work\n",
    "def create_contest_lineups2(contestKey, sort_by, min_salary, min_projection, major_stack, minor_stack, max_exposure_batters, max_exposure_pitchers, excluded_teams, min_starters, lineups, historic):\n",
    "    try:\n",
    "        return create_contest_lineups(contestKey, sort_by, min_salary, min_projection, major_stack, minor_stack, max_exposure_batters, max_exposure_pitchers, excluded_teams, min_starters, lineups, historic)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing contestKey: {contestKey}. Exception: {e}\")\n",
    "        return contestKey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_upload_file(draftGroupId, contestKey, contestTime):    \n",
    "    message = f\"\"\"\\\n",
    "    contestTime: {contestTime}\n",
    "    draftGroupId: {draftGroupId}\n",
    "    contestKey: {contestKey}\n",
    "\n",
    "    Entries: https://www.draftkings.com/entry/upload\n",
    "    Uploads: https://www.draftkings.com/lineup/upload\n",
    "    \"\"\"\n",
    "\n",
    "    sender_email = 'jamesgiles1993@gmail.com'\n",
    "    receiver_emails = ['jamesgiles1993@gmail.com'] #, 'ayman.a.usmani@gmail.com']\n",
    "    smtp_server = 'smtp.gmail.com'\n",
    "    port = 465  # Port for SSL\n",
    "    password = 'neik ktcl nhyc pdxx'\n",
    "\n",
    "    # Create a multipart message object\n",
    "    msg = MIMEMultipart()\n",
    "    msg['Subject'] = f'Lineups: {contestKey}'\n",
    "    msg['From'] = sender_email\n",
    "    msg['To'] = ', '.join(receiver_emails)  # Join list into comma-separated string\n",
    "\n",
    "    # Attach the message to the email\n",
    "    msg.attach(MIMEText(message, 'plain'))\n",
    "\n",
    "    # Add Entry and Upload files as attachments\n",
    "    entry_path = os.path.join(baseball_path, \"B03. Lineups\", \"5. Entries\", f\"Entries {draftGroupId}.csv\")\n",
    "    upload_path = os.path.join(baseball_path, \"B03. Lineups\", \"4. Uploads\", f\"Upload {contestKey}.csv\")\n",
    "\n",
    "    def attach_file(file_path):\n",
    "        with open(file_path, 'rb') as attachment:\n",
    "            part = MIMEBase('application', 'octet-stream')\n",
    "            part.set_payload(attachment.read())\n",
    "            encoders.encode_base64(part)\n",
    "            filename = os.path.basename(file_path)\n",
    "            part.add_header('Content-Disposition', f'attachment; filename=\"{filename}\"')\n",
    "            msg.attach(part)\n",
    "\n",
    "    attach_file(entry_path)\n",
    "    attach_file(upload_path)\n",
    "\n",
    "    # Create a secure SSL context\n",
    "    context = ssl.create_default_context()\n",
    "\n",
    "    # Send the email\n",
    "    try:\n",
    "        with smtplib.SMTP_SSL(smtp_server, port, context=context) as server:\n",
    "            server.login(sender_email, password)\n",
    "            server.sendmail(sender_email, receiver_emails, msg.as_string())\n",
    "        print(\"Email sent successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_entries(draftGroupId):\n",
    "    # Open entry page\n",
    "    webbrowser.open(f\"https://www.draftkings.com/entry/upload\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Search for \"UPLOAD CSV\" and get its position\n",
    "    upload_csv_button = pyautogui.locateOnScreen(r\"C:\\Users\\james\\Documents\\MLB\\UPLOAD CSV.png\", confidence=0.8)\n",
    "    \n",
    "    # Check if the button is found\n",
    "    if upload_csv_button is not None:\n",
    "        # If found, click on it\n",
    "        pyautogui.click(upload_csv_button)\n",
    "    else:\n",
    "        print(\"Button not found.\")\n",
    "    \n",
    "    # Access directory bar\n",
    "    pyautogui.hotkey('alt', 'd')\n",
    "    time.sleep(3)\n",
    "\n",
    "    # # Type filepath\n",
    "    # pyautogui.write(rf\"C:\\Users\\james\\Documents\\MLB\\Database\\B03. Lineups\\5. Entries\\Entries {draftGroupId}.csv\", interval=0.025)\n",
    "    # time.sleep(3)\n",
    "    # pyautogui.press('enter')\n",
    "\n",
    "    # Copy and paste the file path\n",
    "    filepath = rf\"C:\\Users\\james\\Documents\\MLB\\Database\\B03. Lineups\\5. Entries\\Entries {draftGroupId}.csv\"\n",
    "    pyperclip.copy(filepath)\n",
    "    pyautogui.hotkey(\"ctrl\", \"v\")\n",
    "    time.sleep(3)\n",
    "    pyautogui.press(\"enter\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda-base)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
