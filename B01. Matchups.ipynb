{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c333deb8-8bf3-4890-a652-0eee019ab5f8",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfd4f0ff-0070-4710-b2b9-caccc2aa1f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports executed\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if not hasattr(sys.modules['__main__'], '__file__'):\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U1. Imports.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U2. Utilities.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U3. Classes.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U4. Datasets.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U5. Models.ipynb\"\n",
    "    print(\"Imports executed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a4a660-9bd9-438f-a1c5-82a22c48fedf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a444b67-20ef-49ed-a823-4743182bfb15",
   "metadata": {},
   "source": [
    "### Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa13292b-b463-44d4-936a-8f98fb940a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not hasattr(sys.modules['__main__'], '__file__'):\n",
    "    # Set date range \n",
    "    start_date = \"20240328\"\n",
    "    end_date = yesterdaysdate\n",
    "    all_game_df = pd.read_csv(os.path.join(baseball_path, \"game_df.csv\"))\n",
    "    game_df = all_game_df[(all_game_df['date'].astype(str) >= start_date) & (all_game_df['date'].astype(str) <= end_date)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a407da39-28e4-478f-a07d-b3427f86043f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2079d2c-37f7-4380-b81c-b8bf8232f268",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d507a8-008c-4be2-a9e1-9ad851cd1baf",
   "metadata": {},
   "source": [
    "Create PA model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f068fd7-517a-4898-bb61-610ff39c0f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 50.2 s\n",
      "Wall time: 54.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "complete_dataset = pd.read_csv(os.path.join(baseball_path, \"Final Dataset.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea077468-110c-47f4-bb06-f770852a2bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset = complete_dataset.replace([float('inf'), float('-inf')], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "810f2091-ebf9-4c9a-bdaa-704de3ccd510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1698399    20250417.0\n",
       "1698400    20250417.0\n",
       "1698401    20250417.0\n",
       "1698402    20250417.0\n",
       "1698403           NaN\n",
       "Name: date, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_dataset['date'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d458aef9-eb8f-4908-851f-ee387fae4f9d",
   "metadata": {},
   "source": [
    "Read in Steamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6706069a-9918-483b-a685-08dced4b926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "steamer_hitters_df = pd.read_csv(os.path.join(baseball_path, \"A03. Steamer\", \"steamer_hitters_weekly_log.csv\"), encoding='iso-8859-1')\n",
    "steamer_hitters_df_current = pd.read_csv(os.path.join(baseball_path, \"A03. Steamer\", \"steamer_hitters.csv\"), encoding='iso-8859-1')\n",
    "steamer_hitters_df_current['proj_year'] = steamer_hitters_df_current['proj_season'].copy()\n",
    "steamer_hitters_df = pd.concat([steamer_hitters_df, steamer_hitters_df_current], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7604b53d-c85a-429c-ab0c-cfd2276d7e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "steamer_pitchers_df = pd.read_csv(os.path.join(baseball_path, \"A03. Steamer\", \"steamer_pitchers_weekly_log.csv\"), encoding='iso-8859-1')\n",
    "steamer_pitchers_df_current = pd.read_csv(os.path.join(baseball_path, \"A03. Steamer\", \"steamer_pitchers.csv\"), encoding='iso-8859-1')\n",
    "steamer_pitchers_df_current['proj_year'] = steamer_pitchers_df_current['proj_season'].copy()\n",
    "steamer_pitchers_df = pd.concat([steamer_pitchers_df, steamer_pitchers_df_current], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27285005-72eb-4581-8b91-66e6eec53354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68ff7ea8-d23c-48fe-8776-26008a5827fa",
   "metadata": {},
   "source": [
    "### Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab9095e-a312-49cc-af21-528d92f9d42e",
   "metadata": {},
   "source": [
    "Clean Steamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5989b7-f686-4506-b88c-6e59e878f6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hitters\n",
    "steamer_hitters_df['proj_year'].fillna(2025, inplace=True) # Shouldn't happen\n",
    "steamer_hitters_df['proj_date'].fillna(todaysdate_dash, inplace=True)\n",
    "steamer_hitters_df = clean_steamer_hitters(steamer_hitters_df)\n",
    "\n",
    "# Pitchers\n",
    "steamer_pitchers_df['proj_year'].fillna(2025, inplace=True) # Shouldn't happen\n",
    "steamer_pitchers_df['proj_date'].fillna(todaysdate_dash, inplace=True)\n",
    "steamer_pitchers_df = clean_steamer_pitchers(steamer_pitchers_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a3c5d9-822d-4066-9a31-68cc9b319802",
   "metadata": {},
   "source": [
    "Shrink for faster processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad04eb2-a613-4527-bc27-aebb8c42a91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset.drop(columns={'description', 'batterName', 'pitcherName', 'postOnFirst', 'postOnSecond', 'postOnThird', \n",
    "                               'preOnFirst', 'preOnSecond', 'preOnThird', 'pitch_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431df294-3043-4c04-ae44-3b92af9ff65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset = complete_dataset[complete_dataset['date'].astype(int) > game_df[\"date\"].astype(int).min()-10000]\n",
    "steamer_hitters_df = steamer_hitters_df[steamer_hitters_df['date'].astype(int) > game_df[\"date\"].astype(int).min()-10000]\n",
    "steamer_pitchers_df = steamer_pitchers_df[steamer_pitchers_df['date'].astype(int) > game_df[\"date\"].astype(int).min()-10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7281fc60-729f-46f4-b4a9-6d37f47be768",
   "metadata": {},
   "source": [
    "Create vs subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20c84f3-11d4-466b-b7d3-f3c10e2e8477",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_lhp = complete_dataset[complete_dataset['pitchHand'] == \"L\"].copy()\n",
    "vs_rhp = complete_dataset[complete_dataset['pitchHand'] == \"R\"].copy()\n",
    "vs_lhp['id'] = vs_lhp['batter'].astype(str) # note, this won't match what's in id field already\n",
    "vs_rhp['id'] = vs_rhp['batter'].astype(str)\n",
    "vs_lhp.drop_duplicates(subset=['id', 'date'], keep='last', inplace=True)\n",
    "vs_lhp.drop_duplicates(subset=['id', 'date'], keep='last', inplace=True)\n",
    "vs_lhp['date_time'] = pd.to_datetime(vs_lhp['date'], format='%Y%m%d')\n",
    "vs_rhp['date_time'] = pd.to_datetime(vs_rhp['date'], format='%Y%m%d')\n",
    "vs_lhp.sort_values('date_time', inplace=True)\n",
    "vs_rhp.sort_values('date_time', inplace=True)\n",
    "\n",
    "vs_lhb = complete_dataset[complete_dataset['batSide'] == \"L\"].copy()\n",
    "vs_rhb = complete_dataset[complete_dataset['batSide'] == \"R\"].copy()\n",
    "vs_lhb['id'] = vs_lhb['pitcher'].astype(str)\n",
    "vs_rhb['id'] = vs_rhb['pitcher'].astype(str)\n",
    "vs_lhb.drop_duplicates(subset=['id', 'date'], keep='last', inplace=True)\n",
    "vs_lhb.drop_duplicates(subset=['id', 'date'], keep='last', inplace=True)\n",
    "vs_lhb['date_time'] = pd.to_datetime(vs_lhb['date'], format='%Y%m%d')\n",
    "vs_rhb['date_time'] = pd.to_datetime(vs_rhb['date'], format='%Y%m%d')\n",
    "vs_lhb.sort_values('date_time', inplace=True)\n",
    "vs_rhb.sort_values('date_time', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409dccda-fcd5-4ee8-86e8-7d72e3afbe2c",
   "metadata": {},
   "source": [
    "Prep for merge_asof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed92f88-79f3-4ff2-b61e-4326d91b564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_hitters_df['date_time'] = pd.to_datetime(steamer_hitters_df['date'], format='%Y%m%d')\n",
    "steamer_pitchers_df['date_time'] = pd.to_datetime(steamer_pitchers_df['date'], format='%Y%m%d')\n",
    "steamer_hitters_df.sort_values('date_time', inplace=True)\n",
    "steamer_pitchers_df.sort_values('date_time', inplace=True)\n",
    "steamer_hitters_df['id'] = steamer_hitters_df['mlbamid'].astype(int).astype(str)\n",
    "steamer_pitchers_df['id'] = steamer_pitchers_df['mlbamid'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e3bc9c-6656-49e5-a7cd-305f03784a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f308ec75-c581-4908-a6fb-1beb2e8a582a",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66cb519-2136-4190-979b-80ef52acc92e",
   "metadata": {},
   "source": [
    "##### Create Matchup File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d994557-b9c9-433d-8554-717a7974a9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matchup_file(game_df, row, vs_lhp, vs_rhp, vs_rhb, vs_lhb, steamer_hitters_df, steamer_pitchers_df, team_dict):\n",
    "    game_id = game_df['game_id'][row]\n",
    "    game_datetime = game_df['game_datetime'][row]\n",
    "    game_date = game_df['game_date'][row]\n",
    "    date = int(game_date.replace(\"-\", \"\"))\n",
    "    away_id = game_df['away_id'][row]\n",
    "    home_id = game_df['home_id'][row]\n",
    "    \n",
    "    # Retrieve Baseball Reference team abbreviation\n",
    "    away_team = team_dict[away_id]\n",
    "    home_team = team_dict[home_id]\n",
    "\n",
    "\n",
    "    for team in away_team, home_team:\n",
    "        # Read in rosters\n",
    "        roster_df = pd.read_csv(os.path.join(baseball_path, \"A05. Rosters\", \"2. Rosters\", f\"Rosters {date}\", f\"Roster {team} {date}.csv\"), encoding='iso-8859-1', dtype='str')\n",
    "\n",
    "        # Read in batting orders\n",
    "        order_df = pd.read_csv(os.path.join(baseball_path, \"A05. Rosters\", \"1. Batting Orders\", f\"Batting Orders {date}\", f\"Batting Order {team} {game_id}.csv\"), encoding='iso-8859-1', dtype='str')        \n",
    "        \n",
    "        # Read in bullpens\n",
    "        bullpen_df = pd.read_csv(os.path.join(baseball_path, \"A04. Bullpens\", f\"Bullpens {date}\", f\"Bullpen {team} {date}.csv\"), encoding='iso-8859-1', dtype='str')  \n",
    "        bullpen_df['id'] = bullpen_df['id'].apply(lambda x: x.replace('.0', '') if isinstance(x, str) else x)\n",
    "        \n",
    "        # Drop if missing id\n",
    "        bullpen_df = bullpen_df[(bullpen_df['id'].notna()) & (bullpen_df['id'] != \"\")].reset_index(drop=True)\n",
    "        \n",
    "        # Merge batting order onto roster\n",
    "        team_df = pd.merge(roster_df, order_df[['id', 'fullName', 'position', 'status', 'order']], on='id', how='outer', suffixes=(\"\",\"2\"))\n",
    "        \n",
    "        # Fill in missings\n",
    "        team_df['batSide'].fillna('Right', inplace=True)\n",
    "        team_df['pitchHand'].fillna('Right', inplace=True)\n",
    "        team_df['fullName'].fillna(team_df['fullName2'], inplace=True)\n",
    "        team_df['position'].fillna(team_df['position2'], inplace=True)\n",
    "\n",
    "        # Clean name\n",
    "        team_df['fullName'] = team_df['fullName'].apply(remove_accents)\n",
    "        \n",
    "        # Merge pitcher leverage onto roster\n",
    "        team_df = pd.merge(team_df, bullpen_df[['id', 'Leverage']], on=['id'], how='left')\n",
    "        \n",
    "        # Add weather\n",
    "        box = create_box(game_id)\n",
    "        team_df['weather'] = box[0]\n",
    "        team_df['wind'] = box[1]\n",
    "        team_df['park'] = box[2]\n",
    "        team_df = clean_weather(team_df)\n",
    "\n",
    "        # Add venue\n",
    "        team_df['venue_id'] = game_df['venue_id'][row]\n",
    "        \n",
    "        # Add starters\n",
    "        team_df['away_starter'] = game_df['away_probable_pitcher'][row]\n",
    "        team_df['home_starter'] = game_df['home_probable_pitcher'][row]\n",
    "        team_df['away_starter'] = team_df['away_starter'].apply(remove_accents)\n",
    "        team_df['home_starter'] = team_df['home_starter'].apply(remove_accents)\n",
    "        \n",
    "        # Assign Leverage of 1 to starting pitcher\n",
    "        team_df['Leverage'] = np.where((team_df['fullName'] == team_df['away_starter']) | (team_df['fullName'] == team_df['home_starter']), 1, team_df['Leverage'])\n",
    "\n",
    "        # Determine batting order\n",
    "        team_df['order'] = pd.to_numeric(team_df['order'], errors='coerce')\n",
    "        team_df['batting_order'] = np.nan\n",
    "        for i in range(9):\n",
    "            team_df['batting_order'] = np.where(team_df['order'] == (i+1)*100, i+1, team_df['batting_order'])\n",
    "\n",
    "        ### Batters\n",
    "        batter_df = team_df[team_df['position'] != \"Pitcher\"]\n",
    "        batter_df['date_time'] = pd.to_datetime(batter_df['date'], format='%Y%m%d')\n",
    "        batter_df['date_time'].fillna(batter_df['date_time'].min(), inplace=True)\n",
    "            \n",
    "        ## Dataset\n",
    "        # Merge in stats\n",
    "        # # Merge LHP stats\n",
    "        batter_df = pd.merge_asof(\n",
    "            batter_df,\n",
    "            vs_lhp[['id', 'date_time'] + batter_inputs + ['imp_b', 'pa_b', 'pa_b_long']],\n",
    "            on='date_time',\n",
    "            by='id',\n",
    "            direction='backward',\n",
    "            # suffixes=('', '_l')\n",
    "        )\n",
    "\n",
    "        # Merge RHP stats\n",
    "        batter_df = pd.merge_asof(\n",
    "            batter_df,\n",
    "            vs_rhp[['id', 'date_time'] + batter_inputs + ['imp_b', 'pa_b', 'pa_b_long']],\n",
    "            on='date_time',\n",
    "            by='id',\n",
    "            direction='backward',\n",
    "            suffixes=('_l', '_r')\n",
    "        )\n",
    "\n",
    "        # Merge Steamer\n",
    "        batter_df = pd.merge_asof(\n",
    "            batter_df,\n",
    "            steamer_hitters_df,\n",
    "            on='date_time',\n",
    "            by='id',\n",
    "            direction='backward',\n",
    "            suffixes=('', '_steamer')\n",
    "        )\n",
    "\n",
    "        # Remove redundant variables\n",
    "        batter_df.drop(columns={'firstname', 'lastname', 'mlbamid', 'fullName2', 'position2'}, inplace=True)\n",
    "\n",
    "        # Move 'batting_order' to the desired position\n",
    "        batter_df.insert(batter_df.columns.get_loc('order') + 1, 'batting_order', batter_df.pop('batting_order'))\n",
    "        \n",
    "        # Sort\n",
    "        batter_df['batting_order'] = pd.to_numeric(batter_df['batting_order'], errors='coerce')\n",
    "        batter_df.sort_values('batting_order', inplace=True)\n",
    "\n",
    "\n",
    "        ### Pitchers\n",
    "        pitcher_df = team_df[(team_df['position'] == \"Pitcher\") | (team_df['position'] == \"Two-Way Player\")]\n",
    "        pitcher_df['date_time'] = pd.to_datetime(pitcher_df['date'], format='%Y%m%d')\n",
    "        pitcher_df['date_time'].fillna(pitcher_df['date_time'].min(), inplace=True)\n",
    "\n",
    "        ## Dataset\n",
    "        # Merge in stats\n",
    "        # # Merge LHP stats\n",
    "        pitcher_df = pd.merge_asof(\n",
    "            pitcher_df,\n",
    "            vs_lhb[['id', 'date_time'] + pitcher_inputs + ['imp_p', 'pa_p', 'pa_p_long']],\n",
    "            on='date_time',\n",
    "            by='id',\n",
    "            direction='backward',\n",
    "            # suffixes=('', '_l')\n",
    "        )\n",
    "\n",
    "        # Merge RHP stats\n",
    "        pitcher_df = pd.merge_asof(\n",
    "            pitcher_df,\n",
    "            vs_rhb[['id', 'date_time'] + pitcher_inputs + ['imp_p', 'pa_p', 'pa_p_long']],\n",
    "            on='date_time',\n",
    "            by='id',\n",
    "            direction='backward',\n",
    "            suffixes=('_l', '_r')\n",
    "        )\n",
    "\n",
    "        # Merge Steamer\n",
    "        pitcher_df = pd.merge_asof(\n",
    "            pitcher_df,\n",
    "            steamer_pitchers_df,\n",
    "            on='date_time',\n",
    "            by='id',\n",
    "            direction='backward',\n",
    "            suffixes=('', '_steamer')\n",
    "        )\n",
    "\n",
    "        # Remove redundant variables\n",
    "        pitcher_df.drop(columns={'firstname', 'lastname', 'mlbamid', 'fullName2', 'position2'}, inplace=True)\n",
    "\n",
    "        # Move 'batting_order' to the desired position\n",
    "        pitcher_df.insert(pitcher_df.columns.get_loc('order') + 1, 'batting_order', pitcher_df.pop('batting_order'))\n",
    "\n",
    "        # Sort\n",
    "        pitcher_df['Leverage'] = pd.to_numeric(pitcher_df['Leverage'], errors='coerce')\n",
    "        pitcher_df.sort_values('Leverage', inplace=True)\n",
    "\n",
    "        # Assign team\n",
    "        if team == away_team:\n",
    "            away_batter_df = batter_df.copy()\n",
    "            away_pitcher_df = pitcher_df.copy()\n",
    "        else:\n",
    "            home_batter_df = batter_df.copy()\n",
    "            home_pitcher_df = pitcher_df.copy()\n",
    "\n",
    "    # Drop duplicates: \n",
    "    away_batter_df.drop_duplicates('id', keep='last', inplace=True)\n",
    "    away_batter_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    home_batter_df.drop_duplicates('id', keep='last', inplace=True)\n",
    "    home_batter_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    away_pitcher_df.drop_duplicates('id', keep='last', inplace=True)\n",
    "    away_pitcher_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    home_pitcher_df.drop_duplicates('id', keep='last', inplace=True)\n",
    "    home_pitcher_df.reset_index(drop=True, inplace=True)\n",
    "       \n",
    "    return away_batter_df, away_pitcher_df, home_batter_df, home_pitcher_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a18cd04-b548-4a64-95fc-1059bae92f64",
   "metadata": {},
   "source": [
    "##### Create Matchup Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a60fbfb-bdd0-440c-9f1e-efe5e9c2a98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matchup_files(game_df, row, vs_lhp, vs_rhp, vs_rhb, vs_lhb, steamer_hitters_df, steamer_pitchers_df, team_dict):\n",
    "    # Extract IDs\n",
    "    game_id = game_df['game_id'][row]\n",
    "    away_id = game_df['away_id'][row]\n",
    "    home_id = game_df['home_id'][row]\n",
    "\n",
    "    # Retrieve Baseball Reference team abbreviation\n",
    "    away_team = team_dict[away_id]\n",
    "    home_team = team_dict[home_id]\n",
    "\n",
    "    # Extract date\n",
    "    game_date = game_df['game_date'][row]\n",
    "    game_date = game_date.replace(\"-\", \"\")\n",
    "    game_datetime = game_df['game_datetime'][row]\n",
    "\n",
    "    # Convert string to datetime object\n",
    "    utc_datetime = datetime.datetime.strptime(game_datetime, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "    # Define the UTC timezone\n",
    "    utc_timezone = pytz.timezone(\"UTC\")\n",
    "\n",
    "    # Set the UTC timezone for the datetime object\n",
    "    utc_datetime = utc_timezone.localize(utc_datetime)\n",
    "\n",
    "    # Convert to Eastern Standard Time (EST)\n",
    "    est_timezone = pytz.timezone(\"US/Eastern\")\n",
    "    est_datetime = utc_datetime.astimezone(est_timezone)\n",
    "\n",
    "    # Format the result\n",
    "    formatted_time = est_datetime.strftime(\"%H%M\")\n",
    "\n",
    "    \n",
    "    # Create position dfs\n",
    "    away_batter_df, away_pitcher_df, home_batter_df, home_pitcher_df = create_matchup_file(game_df, row, vs_lhp, vs_rhp, vs_rhb, vs_lhb, steamer_hitters_df, steamer_pitchers_df, team_dict)\n",
    "\n",
    "    \n",
    "    # Create folder, if it doesn't exist\n",
    "    os.makedirs(os.path.join(baseball_path, \"B01. Matchups\", f'Matchups {game_date}'), exist_ok=True)\n",
    "\n",
    "    # File name\n",
    "    matchup_file = f\"{away_team}@{home_team} {game_id} {formatted_time}\"\n",
    "\n",
    "    # Write to Excel\n",
    "    away_batter_df.to_excel(os.path.join(baseball_path, \"B01. Matchups\", f'Matchups {game_date}', f'{matchup_file}.xlsx'), sheet_name=\"AwayBatters\", engine='openpyxl', index=False)\n",
    "\n",
    "    with pd.ExcelWriter(os.path.join(baseball_path, \"B01. Matchups\", f'Matchups {game_date}', f'{matchup_file}.xlsx'), mode='a', engine='openpyxl') as writer:  \n",
    "        home_batter_df.to_excel(writer, sheet_name='HomeBatters', index=False)\n",
    "\n",
    "    with pd.ExcelWriter(os.path.join(baseball_path, \"B01. Matchups\", f'Matchups {game_date}', f'{matchup_file}.xlsx'), mode='a', engine='openpyxl') as writer:  \n",
    "        away_pitcher_df.to_excel(writer, sheet_name='AwayPitchers', index=False)\n",
    "\n",
    "    with pd.ExcelWriter(os.path.join(baseball_path, \"B01. Matchups\", f'Matchups {game_date}', f'{matchup_file}.xlsx'), mode='a', engine='openpyxl') as writer:  \n",
    "        home_pitcher_df.to_excel(writer, sheet_name='HomePitchers', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176bc79f-574c-4667-bc13-dc1e76265ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df[['home_probable_pitcher', 'away_probable_pitcher']] = game_df[['home_probable_pitcher', 'away_probable_pitcher']].fillna(\"Missing Starter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3e2d03-1d8e-4c30-910f-ec08162cd440",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b755de9-07c5-4a95-8641-83ce821569f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(len(game_df))\n",
    "empty_list = Parallel(n_jobs=5, verbose=True)(delayed(create_matchup_files)(game_df, row, vs_lhp, vs_rhp, vs_rhb, vs_lhb, steamer_hitters_df, steamer_pitchers_df, team_dict) for row in range(len(game_df)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda-base)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
