{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c333deb8-8bf3-4890-a652-0eee019ab5f8",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfd4f0ff-0070-4710-b2b9-caccc2aa1f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports executed\n"
     ]
    }
   ],
   "source": [
    "if not hasattr(sys.modules['__main__'], '__file__'):\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U1. Imports.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U2. Utilities.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U3. Classes.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U4. Datasets.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U5. Models.ipynb\"\n",
    "    print(\"Imports executed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62ce8847-cc30-4293-80cd-959d4e608a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is run in the morning and at night. \n",
    "# Concern is that we don't want to have to run create_dataset right before. (steamer runtime is trivial)\n",
    "# This isn't necessarily a problem. Just never generate here. \n",
    "# Generate in the AM in morning dashboard but don't generate in the PM.\n",
    "# If it's only being generated here, you can generate in morning dashboard separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a4a660-9bd9-438f-a1c5-82a22c48fedf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea6910f3-e291-4228-8e49-67fd0f2af155",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e388e4ae-f454-4342-bd6f-04b9583802a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not hasattr(sys.modules['__main__'], '__file__'):\n",
    "    generate = True # Probably should always be False because this needs to run right before game time\n",
    "    write = True # Probably should always be False because this needs to run right before game time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52003aba-57ab-4e76-892b-a8682020f0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a444b67-20ef-49ed-a823-4743182bfb15",
   "metadata": {},
   "source": [
    "### Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa13292b-b463-44d4-936a-8f98fb940a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not hasattr(sys.modules['__main__'], '__file__'):\n",
    "    # Set date range \n",
    "    start_date = \"20240808\"\n",
    "    end_date = \"20240808\"\n",
    "    game_df = create_games(start_date, end_date, team_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a407da39-28e4-478f-a07d-b3427f86043f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2079d2c-37f7-4380-b81c-b8bf8232f268",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066ba00a-4d5a-48a6-ab73-d9eadc9ab542",
   "metadata": {},
   "source": [
    "Read in Park x Weather Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd9eadee-5f5b-4556-8a00-8f4de020fb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplier_df = pd.read_csv(os.path.join(baseball_path, \"Multiplier Dataset.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d507a8-008c-4be2-a9e1-9ad851cd1baf",
   "metadata": {},
   "source": [
    "Create PA model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f068fd7-517a-4898-bb61-610ff39c0f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 52.6 s\n",
      "Wall time: 57.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# complete_dataset = create_pa_inputs(multiplier_df, 2015, 2024, 50, 300, adjust=True, generate=generate, write=write)\n",
    "complete_dataset = pd.read_csv(os.path.join(baseball_path, \"Complete Dataset - Adjusted.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d458aef9-eb8f-4908-851f-ee387fae4f9d",
   "metadata": {},
   "source": [
    "Read in Steamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6706069a-9918-483b-a685-08dced4b926e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.66 s\n",
      "Wall time: 3.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "steamer_hitters_df = pd.read_csv(os.path.join(baseball_path, \"A03. Steamer\", \"steamer_hitters_weekly_log.csv\"), encoding='iso-8859-1')\n",
    "steamer_hitters_df_current = pd.read_csv(os.path.join(baseball_path, \"A03. Steamer\", \"steamer_hitters.csv\"), encoding='iso-8859-1')\n",
    "steamer_hitters_df_current['proj_year'] = steamer_hitters_df_current['proj_season'].copy()\n",
    "steamer_hitters_df = pd.concat([steamer_hitters_df, steamer_hitters_df_current], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7604b53d-c85a-429c-ab0c-cfd2276d7e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 6.22 s\n",
      "Wall time: 6.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "steamer_pitchers_df = pd.read_csv(os.path.join(baseball_path, \"A03. Steamer\", \"steamer_pitchers_weekly_log.csv\"), encoding='iso-8859-1')\n",
    "steamer_pitchers_df_current = pd.read_csv(os.path.join(baseball_path, \"A03. Steamer\", \"steamer_pitchers.csv\"), encoding='iso-8859-1')\n",
    "steamer_pitchers_df_current['proj_year'] = steamer_pitchers_df_current['proj_season'].copy()\n",
    "steamer_pitchers_df = pd.concat([steamer_pitchers_df, steamer_pitchers_df_current], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ff7ea8-d23c-48fe-8776-26008a5827fa",
   "metadata": {},
   "source": [
    "### Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab9095e-a312-49cc-af21-528d92f9d42e",
   "metadata": {},
   "source": [
    "Clean Steamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa5989b7-f686-4506-b88c-6e59e878f6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hitters\n",
    "steamer_hitters_df['proj_year'].fillna(2025, inplace=True) # Shouldn't happen\n",
    "steamer_hitters_df['proj_date'].fillna(todaysdate_dash, inplace=True)\n",
    "steamer_hitters_df = clean_steamer_hitters(steamer_hitters_df)\n",
    "\n",
    "# Pitchers\n",
    "steamer_pitchers_df['proj_year'].fillna(2025, inplace=True) # Shouldn't happen\n",
    "steamer_pitchers_df['proj_date'].fillna(todaysdate_dash, inplace=True)\n",
    "steamer_pitchers_df = clean_steamer_pitchers(steamer_pitchers_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a3c5d9-822d-4066-9a31-68cc9b319802",
   "metadata": {},
   "source": [
    "Shrink for faster processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dad04eb2-a613-4527-bc27-aebb8c42a91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset.drop(columns={'description', 'batterName', 'pitcherName', 'postOnFirst', 'postOnSecond', 'postOnThird', \n",
    "                               'preOnFirst', 'preOnSecond', 'preOnThird', 'pitch_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "431df294-3043-4c04-ae44-3b92af9ff65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset = complete_dataset[complete_dataset['date'].astype(int) > game_df[\"date\"].astype(int).min()-10000]\n",
    "steamer_hitters_df = steamer_hitters_df[steamer_hitters_df['date'].astype(int) > game_df[\"date\"].astype(int).min()-10000]\n",
    "steamer_pitchers_df = steamer_pitchers_df[steamer_pitchers_df['date'].astype(int) > game_df[\"date\"].astype(int).min()-10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae2b24a-2ef4-44f8-82cd-47a381cea717",
   "metadata": {},
   "source": [
    "Write to CSV (Should be unnecessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f606fbd-f542-4842-98dc-87f403b52f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# steamer_hitters_df.to_csv(os.path.join(baseball_path, \"Steamer Hitters.csv\"), index=False)\n",
    "# steamer_pitchers_df.to_csv(os.path.join(baseball_path, \"Steamer Pitchers.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20c84f3-11d4-466b-b7d3-f3c10e2e8477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f308ec75-c581-4908-a6fb-1beb2e8a582a",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66cb519-2136-4190-979b-80ef52acc92e",
   "metadata": {},
   "source": [
    "##### Create Matchup File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "522388e3-aa51-4fcb-9b4b-cb62917e7f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matchup_file(game_df, row, complete_dataset, steamer_hitters_df, steamer_pitchers_df, team_map):\n",
    "    game_id = game_df['game_id'][row]\n",
    "    game_datetime = game_df['game_datetime'][row]\n",
    "    game_date = game_df['game_date'][row]\n",
    "    date = int(game_date.replace(\"-\", \"\"))\n",
    "    away_id = game_df['away_id'][row]\n",
    "    home_id = game_df['home_id'][row]\n",
    "    # Retrieve Baseball Reference team abbreviation\n",
    "    team_map_cut = team_map[['teamId', 'BBREFTEAM']].set_index('teamId')\n",
    "    \n",
    "    away_team = team_map_cut.loc[away_id]['BBREFTEAM']\n",
    "    home_team = team_map_cut.loc[home_id]['BBREFTEAM']\n",
    "    \n",
    "    for team in away_team, home_team:\n",
    "        # Read in rosters\n",
    "        roster_df = pd.read_csv(os.path.join(baseball_path, \"A05. Rosters\", \"2. Rosters\", f\"Rosters {date}\", f\"Roster {team} {date}.csv\"), encoding='iso-8859-1')\n",
    "\n",
    "        # Read in batting orders\n",
    "        order_df = pd.read_csv(os.path.join(baseball_path, \"A05. Rosters\", \"1. Batting Orders\", f\"Batting Orders {date}\", f\"Batting Order {team} {game_id}.csv\"), encoding='iso-8859-1')        \n",
    "        \n",
    "        # Read in bullpens\n",
    "        bullpen_df = pd.read_csv(os.path.join(baseball_path, \"A04. Bullpens\", f\"Bullpens {date}\", f\"Bullpen {team} {date}.csv\"), encoding='iso-8859-1')  \n",
    "        \n",
    "        # Merge batting order onto roster\n",
    "        team_df = pd.merge(roster_df, order_df[['id', 'fullName', 'position', 'status', 'order']], on='id', how='outer', suffixes=(\"\",\"2\"))\n",
    "        \n",
    "        # Fill in missings\n",
    "        team_df['batSide'].fillna('Right', inplace=True)\n",
    "        team_df['pitchHand'].fillna('Right', inplace=True)\n",
    "        team_df['fullName'].fillna(team_df['fullName2'], inplace=True)\n",
    "        team_df['position'].fillna(team_df['position2'], inplace=True)\n",
    "        \n",
    "        # Merge pitcher leverage onto roster\n",
    "        ### Testing\n",
    "        team_df['fullName'] = team_df['fullName'].apply(remove_accents)\n",
    "        ### Testing\n",
    "        team_df = pd.merge(team_df, bullpen_df[['Name', 'Leverage']], left_on='fullName', right_on='Name', how='left')\n",
    "        \n",
    "        # Add weather\n",
    "        box = create_box(game_id)\n",
    "        team_df['weather'] = box[0]\n",
    "        team_df['wind'] = box[1]\n",
    "        team_df['park'] = box[2]\n",
    "        team_df = clean_weather(team_df)\n",
    "\n",
    "        # Add venue\n",
    "        team_df['venue_id'] = game_df['venue_id'][row]\n",
    "        \n",
    "        # Add starters\n",
    "        team_df['away_starter'] = game_df['away_probable_pitcher'][row]\n",
    "        team_df['home_starter'] = game_df['home_probable_pitcher'][row]\n",
    "\n",
    "        team_df['away_starter'] = team_df['away_starter'].apply(remove_accents)\n",
    "        team_df['home_starter'] = team_df['home_starter'].apply(remove_accents)\n",
    "        \n",
    "        \n",
    "        # Assign Leverage of 1 to starting pitcher\n",
    "        team_df['Leverage'] = np.where((team_df['fullName'] == team_df['away_starter']) | (team_df['fullName'] == team_df['home_starter']), 1, team_df['Leverage'])\n",
    "\n",
    "        # Determine batting order\n",
    "        team_df['order'] = pd.to_numeric(team_df['order'], errors='coerce')\n",
    "        team_df['batting_order'] = np.nan\n",
    "        for i in range(9):\n",
    "            team_df['batting_order'] = np.where(team_df['order'] == (i+1)*100, i+1, team_df['batting_order'])\n",
    "\n",
    "        ### Batters\n",
    "        batter_df = team_df[team_df['position'] != \"Pitcher\"]\n",
    "\n",
    "        ## Dataset\n",
    "        # Vs. LHP\n",
    "        vs_l = complete_dataset[complete_dataset['date'] < int(date)]\n",
    "        vs_l = vs_l[vs_l['pitchHand'] == \"L\"]\n",
    "        vs_l.drop_duplicates(subset='batter', keep='last', inplace=True)\n",
    "\n",
    "        # Merge in stats\n",
    "        batter_df = pd.merge(batter_df, vs_l[['batter'] + batter_inputs + ['imp_b', 'pa_b', 'pa_b_long']], left_on='id', right_on='batter', how='left')\n",
    "\n",
    "        # Vs. RHP\n",
    "        vs_r = complete_dataset[complete_dataset['date'] < int(date)]\n",
    "        vs_r = vs_r[vs_r['pitchHand'] == \"R\"]\n",
    "        vs_r.drop_duplicates(subset='batter', keep='last', inplace=True)\n",
    "\n",
    "        # Merge in stats\n",
    "        batter_df = pd.merge(batter_df, vs_r[['batter'] + batter_inputs + ['imp_b', 'pa_b', 'pa_b_long']], left_on='id', right_on='batter', how='left', suffixes=(\"_l\", \"_r\"))\n",
    "\n",
    "        ## Steamer \n",
    "        # Keep last observation before date \n",
    "        steamer_hitters_last_df = steamer_hitters_df[steamer_hitters_df['date'] <= int(date)]\n",
    "        steamer_hitters_last_df.drop_duplicates(subset='mlbamid', keep='last', inplace=True)\n",
    "\n",
    "        # Merge\n",
    "        batter_df = pd.merge(batter_df, steamer_hitters_last_df, left_on='id', right_on='mlbamid', how='left', suffixes=(\"\", \"_fg\"))\n",
    "\n",
    "        # Remove redundant variables\n",
    "        batter_df.drop(columns={'batter_l', 'batter_r', 'firstname', 'lastname', 'mlbamid', 'fullName2', 'position2'}, inplace=True)\n",
    "\n",
    "        # Clean\n",
    "        # batter_df = clean_order(batter_df)\n",
    "\n",
    "        # Move 'batting_order' to the desired position\n",
    "        batter_df.insert(batter_df.columns.get_loc('order') + 1, 'batting_order', batter_df.pop('batting_order'))\n",
    "\n",
    "        # Sort\n",
    "        batter_df.sort_values('batting_order', inplace=True)\n",
    "\n",
    "\n",
    "        ### Pitchers\n",
    "        pitcher_df = team_df[(team_df['position'] == \"Pitcher\") | (team_df['position'] == \"Two-Way Player\")]\n",
    "\n",
    "        ## Dataset\n",
    "        # Vs. LHB\n",
    "        vs_l = complete_dataset[complete_dataset['date'] < int(date)]\n",
    "        vs_l = vs_l[vs_l['batSide'] == \"L\"]\n",
    "        vs_l.drop_duplicates(subset='pitcher', keep='last', inplace=True)\n",
    "\n",
    "        # Merge in stats\n",
    "        pitcher_df = pd.merge(pitcher_df, vs_l[['pitcher'] + pitcher_inputs + ['imp_p', 'pa_p', 'pa_p_long']], left_on='id', right_on='pitcher', how='left')\n",
    "\n",
    "        # Vs. RHB\n",
    "        vs_r = complete_dataset[complete_dataset['date'] < int(date)]\n",
    "        vs_r = vs_r[vs_r['batSide'] == \"R\"]\n",
    "        vs_r.drop_duplicates(subset='pitcher', keep='last', inplace=True)\n",
    "\n",
    "        # Merge in stats\n",
    "        pitcher_df = pd.merge(pitcher_df, vs_r[['pitcher'] + pitcher_inputs + ['imp_p', 'pa_p', 'pa_p_long']], left_on='id', right_on='pitcher', how='left', suffixes=(\"_l\", \"_r\"))\n",
    "\n",
    "        ## Steamer \n",
    "        # Keep last observation before date (may switch to <= if I find projections are up early)\n",
    "        steamer_pitchers_last_df = steamer_pitchers_df[steamer_pitchers_df['date'] <= int(date)]\n",
    "        steamer_pitchers_last_df.drop_duplicates(subset='mlbamid', keep='last', inplace=True)\n",
    "\n",
    "        # Merge\n",
    "        pitcher_df = pd.merge(pitcher_df, steamer_pitchers_last_df, left_on='id', right_on='mlbamid', how='left', suffixes=(\"\", \"_fg\"))\n",
    "\n",
    "        # Remove redundant variables\n",
    "        pitcher_df.drop(columns={'pitcher_l', 'pitcher_r', 'firstname', 'lastname', 'mlbamid', 'fullName2', 'position2'}, inplace=True)\n",
    "\n",
    "        # Move 'batting_order' to the desired position\n",
    "        pitcher_df.insert(pitcher_df.columns.get_loc('order') + 1, 'batting_order', pitcher_df.pop('batting_order'))\n",
    "\n",
    "        # Sort\n",
    "        pitcher_df.sort_values('Leverage', inplace=True)\n",
    "\n",
    "        if team == away_team:\n",
    "            away_batter_df = batter_df.copy()\n",
    "            away_pitcher_df = pitcher_df.copy()\n",
    "        else:\n",
    "            home_batter_df = batter_df.copy()\n",
    "            home_pitcher_df = pitcher_df.copy()\n",
    "\n",
    "    # Drop duplicates: \n",
    "    away_batter_df.drop_duplicates('id', keep='last', inplace=True)\n",
    "    away_batter_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    home_batter_df.drop_duplicates('id', keep='last', inplace=True)\n",
    "    home_batter_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    away_pitcher_df.drop_duplicates('id', keep='last', inplace=True)\n",
    "    away_pitcher_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    home_pitcher_df.drop_duplicates('id', keep='last', inplace=True)\n",
    "    home_pitcher_df.reset_index(drop=True, inplace=True)\n",
    "       \n",
    "        \n",
    "    return away_batter_df, away_pitcher_df, home_batter_df, home_pitcher_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a18cd04-b548-4a64-95fc-1059bae92f64",
   "metadata": {},
   "source": [
    "##### Create Matchup Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f803b624-5b13-4af6-ab8f-3276035da579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matchup_files(game_df, row, complete_dataset, steamer_hitters_df, steamer_pitchers_df, team_map):\n",
    "    # Extract IDs\n",
    "    game_id = game_df['game_id'][row]\n",
    "    away_id = game_df['away_id'][row]\n",
    "    home_id = game_df['home_id'][row]\n",
    "\n",
    "    # Retrieve Baseball Reference team abbreviation\n",
    "    team_map_cut = team_map[['teamId', 'BBREFTEAM']].set_index('teamId')\n",
    "    away_team = team_map_cut.loc[away_id]['BBREFTEAM']\n",
    "    home_team = team_map_cut.loc[home_id]['BBREFTEAM']    \n",
    "\n",
    "    # Extract date\n",
    "    game_date = game_df['game_date'][row]\n",
    "    game_date = game_date.replace(\"-\", \"\")\n",
    "    game_datetime = game_df['game_datetime'][row]\n",
    "\n",
    "    # Convert string to datetime object\n",
    "    utc_datetime = datetime.datetime.strptime(game_datetime, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "    # Define the UTC timezone\n",
    "    utc_timezone = pytz.timezone(\"UTC\")\n",
    "\n",
    "    # Set the UTC timezone for the datetime object\n",
    "    utc_datetime = utc_timezone.localize(utc_datetime)\n",
    "\n",
    "    # Convert to Eastern Standard Time (EST)\n",
    "    est_timezone = pytz.timezone(\"US/Eastern\")\n",
    "    est_datetime = utc_datetime.astimezone(est_timezone)\n",
    "\n",
    "    # Format the result\n",
    "    formatted_time = est_datetime.strftime(\"%H%M\")\n",
    "\n",
    "\n",
    "    # Create position dfs\n",
    "    away_batter_df, away_pitcher_df, home_batter_df, home_pitcher_df = create_matchup_file(game_df, row, complete_dataset, steamer_hitters_df, steamer_pitchers_df, team_map)\n",
    "\n",
    "    \n",
    "    # Create folder, if it doesn't exist\n",
    "    os.makedirs(os.path.join(baseball_path, \"B01. Matchups\", f'Matchups {game_date}'), exist_ok=True)\n",
    "\n",
    "    # File name\n",
    "    matchup_file = f\"{away_team}@{home_team} {game_id} {formatted_time}\"\n",
    "\n",
    "    # Write to Excel\n",
    "    away_batter_df.to_excel(os.path.join(baseball_path, \"B01. Matchups\", f'Matchups {game_date}', f'{matchup_file}.xlsx'), sheet_name=\"AwayBatters\", engine='openpyxl', index=False)\n",
    "\n",
    "    with pd.ExcelWriter(os.path.join(baseball_path, \"B01. Matchups\", f'Matchups {game_date}', f'{matchup_file}.xlsx'), mode='a', engine='openpyxl') as writer:  \n",
    "        home_batter_df.to_excel(writer, sheet_name='HomeBatters', index=False)\n",
    "\n",
    "    with pd.ExcelWriter(os.path.join(baseball_path, \"B01. Matchups\", f'Matchups {game_date}', f'{matchup_file}.xlsx'), mode='a', engine='openpyxl') as writer:  \n",
    "        away_pitcher_df.to_excel(writer, sheet_name='AwayPitchers', index=False)\n",
    "\n",
    "    with pd.ExcelWriter(os.path.join(baseball_path, \"B01. Matchups\", f'Matchups {game_date}', f'{matchup_file}.xlsx'), mode='a', engine='openpyxl') as writer:  \n",
    "        home_pitcher_df.to_excel(writer, sheet_name='HomePitchers', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f210150f-f4c2-47ef-918d-bf4d1deba9bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae3e2d03-1d8e-4c30-910f-ec08162cd440",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b755de9-07c5-4a95-8641-83ce821569f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:   17.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.59 s\n",
      "Wall time: 18.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(len(game_df))\n",
    "empty_list = Parallel(n_jobs=4, verbose=True)(delayed(create_matchup_files)(game_df, row, complete_dataset, steamer_hitters_df, steamer_pitchers_df, team_map) \n",
    "                                              for row in range(len(game_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4511bda-1edf-4d2a-8335-b92a8ab6129e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055b4c50-ea69-4971-8cc2-acd059927099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c792a0-4199-447f-8995-68a674dd9126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef5729d-092d-4969-ac2c-f59dd9564341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392fdaab-63b0-4512-92ce-6ec318218df1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
