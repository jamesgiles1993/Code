{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "979729d9-6cbc-49e6-b1f9-1ed4752677c1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# M00. Expected Events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87f428d-fca4-4ef3-a971-3ffb018c9271",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ff0bfd-7406-4d5f-94c2-fd55848b29f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if not hasattr(sys.modules['__main__'], '__file__'):\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U1. Imports.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U2. Utilities.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U3. Classes.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U4. Datasets.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U5. Models.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea8d7ee-374e-4e41-ae92-6fb846c28972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39c846f6-f4bd-4907-addc-3591f2d5e7a7",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b17e9d-8046-49d5-96c5-3f208dd40a34",
   "metadata": {},
   "source": [
    "##### MLB Stats API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f04543a-92ca-4260-9d83-9dac3c9c4db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year, end_year = 2015, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8577881e-1443-43ba-b36b-9a8d55d0ea80",
   "metadata": {},
   "source": [
    "Merge MLB Stats API and Statcast data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefd9f75-7287-4028-a443-d41e849419a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = merge_datasets(start_year, end_year)\n",
    "df = clean_weather(df)\n",
    "df = create_events(df)\n",
    "df = create_variables(df)\n",
    "df = start_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57545c85-c4df-4ac1-a981-c7ccec24474e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be631e83-1ffc-489f-b7d8-600332cbf744",
   "metadata": {},
   "source": [
    "##### Open Meteo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb82074-b8b9-4e23-9e78-d9dd454d06fb",
   "metadata": {},
   "source": [
    "Read in Open Meteo weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aff0e1-0630-4ef0-8edf-924930b6fd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "weather_df = pd.concat(map(pd.read_csv, glob.glob(r\"C:\\Users\\james\\Documents\\MLB\\Database\\A06. Weather\\1. Open Meteo\\*.csv\")), ignore_index=True)[\n",
    "       ['game_id', 'year', 'venue_name', 'location.defaultCoordinates.latitude', 'location.defaultCoordinates.longitude', \n",
    "        'fieldInfo.leftLine', 'fieldInfo.center', 'fieldInfo.rightLine', 'fieldInfo.leftCenter', 'fieldInfo.rightCenter', 'location.elevation', 'location.azimuthAngle', 'fieldInfo.roofType', 'active', \n",
    "        'temperature_2m', 'relative_humidity_2m', 'dew_point_2m', 'surface_pressure', 'wind_speed_10m', 'wind_direction_10m', 'weather_code', 'precipitation_probability']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64524c4-f4c3-4e76-a651-3a426d1add0b",
   "metadata": {},
   "source": [
    "Calculate wind vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d7349a-419d-49a8-8742-c2c59a070add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vectors(row, azimuth_column, wind_column, speed_column):\n",
    "    angle = row[wind_column] - row[azimuth_column]\n",
    "    \n",
    "    # Calculate vectors\n",
    "    x_vect = round(math.sin(math.radians(angle)), 5) * row[speed_column] * -1\n",
    "    y_vect = round(math.cos(math.radians(angle)), 5) * row[speed_column] * -1\n",
    "\n",
    "    return pd.Series([x_vect, y_vect], index=['x_vect', 'y_vect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af97e4de-f49c-4fa9-a9ee-155e099500e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df[['meteo_x_vect', 'meteo_y_vect']] = weather_df.apply(lambda row: calculate_vectors(row, 'location.azimuthAngle', 'wind_direction_10m', 'wind_speed_10m'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef2918d-8ff6-49e3-9ab9-64b0daf13423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6acdcd6e-e422-47b6-a85e-e0153ac5c751",
   "metadata": {},
   "source": [
    "##### Baserunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b285dc8-0196-4126-bc7a-5a9395622d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_hitters_df = pd.read_csv(os.path.join(baseball_path, \"A03. Steamer\", \"steamer_hitters_weekly_log.csv\"), encoding='iso-8859-1', usecols=['proj_date', 'mlbamid', 'PA', 'UBR'], dtype='str')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d24144c-28a7-4960-9860-b0d30caa7630",
   "metadata": {},
   "source": [
    "Convert data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b7eb49-f974-420f-9882-39c3127aa527",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_hitters_df[['PA', 'UBR']] = steamer_hitters_df[['PA', 'UBR']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adf4318-29af-4665-a825-3d4e939c3b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_hitters_df['proj_date'] = pd.to_datetime(steamer_hitters_df['proj_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c80d7a-37ce-43c3-991b-dae3d5b161eb",
   "metadata": {},
   "source": [
    "Calculate UBR per 600 Plate Appearances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0c96a0-8aa6-4e03-a5e1-689eff99ff65",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_hitters_df['UBR600'] = steamer_hitters_df['UBR'] / steamer_hitters_df['PA'] * 600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7692fdd-8b50-4934-8257-4e22ab608845",
   "metadata": {},
   "source": [
    "##### Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5725ff67-53b9-4714-9a1b-bda074902278",
   "metadata": {},
   "source": [
    "Weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aeeb6a-5473-4095-aff2-1e737bf709c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset = df.merge(weather_df.drop(columns=['year']), left_on=['gamePk'], right_on=['game_id'], how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f3558a-b20b-4d35-856d-dc2a106a2bc5",
   "metadata": {},
   "source": [
    "Use weather column from MLB data to adjust for domes/roofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98307d00-947e-4c6e-b8c3-14add6ca1bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = complete_dataset['weather'].str.contains('Roof|Dome', case=False, na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248c58b5-d2a5-49c3-b158-5d4d5b88e82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset.loc[mask, 'temperature'] = 70\n",
    "complete_dataset.loc[mask, 'x_vect'] = 0\n",
    "complete_dataset.loc[mask, 'y_vect'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508a40be-8923-46fa-89b2-5318321403c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset.loc[mask, 'temperature_2m'] = 70\n",
    "complete_dataset.loc[mask, 'meteo_x_vect'] = 0\n",
    "complete_dataset.loc[mask, 'meteo_y_vect'] = 0\n",
    "complete_dataset.loc[mask, 'relative_humidity_2m'] = 60\n",
    "complete_dataset.loc[mask, 'dew_point_2m'] = 57"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63ab710-b0ca-4da4-91cf-e693154f3b1a",
   "metadata": {},
   "source": [
    "Baserunning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81749564-0d32-4019-89c1-7f3b93b294b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset['proj_date'] = pd.to_datetime(complete_dataset['date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb06cfbd-5b30-4319-9b43-e54cfdbc2128",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset['mlbamid'] = complete_dataset['batter'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143fc2d1-3ada-4454-ac94-4fb381edaddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset = pd.merge_asof(\n",
    "    complete_dataset.sort_values('proj_date'),\n",
    "    steamer_hitters_df.sort_values('proj_date'),\n",
    "    by='mlbamid',\n",
    "    on='proj_date',\n",
    "    direction='backward'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8447bed-44eb-4a96-a0d6-5bb1d8fd0c60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b29a01cc-191b-4c07-8aab-ae19bb621c89",
   "metadata": {},
   "source": [
    "Note:\n",
    "- if y > 198.27 and x < 125.42), it's actually to left\n",
    "- if y > 198.27 and x > 125.42), it's actually to right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd146420-5276-4e4a-b0a7-3d5263a65fef",
   "metadata": {},
   "source": [
    "### Model #1. Expected Outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae33de55-4d6d-4406-aacd-0dff4564303b",
   "metadata": {},
   "source": [
    "Probability of events given how the baseball was launched, where it was launched to, and some information about the batter, including handedness and base running. Notably excluded park and weather."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8728c479-4554-43be-b920-e8aaa2c1472a",
   "metadata": {},
   "source": [
    "$ \\hat{\\text{eventsModel}} = launch\\_angle + launch\\_speed + to\\_l + to\\_lc + to\\_c + to\\_rc + to\\_r + b\\_L + UBR600 $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c4b643-304b-426c-b517-792e875ae4ff",
   "metadata": {},
   "source": [
    "##### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f2ecad-c36d-43e0-9ff3-d75390649f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_inputs = ['launch_angle', 'launch_speed', 'to_l', 'to_lc', 'to_c', 'to_rc', 'to_r', 'b_L', 'UBR600'] + ['bb', 'hbp', 'so']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0adbc9-85f6-4fa6-9a30-e9898e554dab",
   "metadata": {},
   "source": [
    "##### Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a69c238-6d8e-4a6f-b9ab-158b76f3b856",
   "metadata": {},
   "source": [
    "Sent launch data to 0 if not batted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2c1f3e-30e9-49df-b504-5ced13a6acde",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset[['launch_angle', 'launch_speed']] = complete_dataset[['launch_angle', 'launch_speed']].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed38b6f-af3a-4b2e-bc77-e1cd4dacbe2d",
   "metadata": {},
   "source": [
    "Remove atypical events and missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a8eff8-6cbf-4750-8013-915e0d8bdbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset = complete_dataset[~complete_dataset['eventsModel'].isin([\"Cut\"])].dropna(subset=outcome_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2562a9ac-3e6e-43e7-b624-0a5de43237d8",
   "metadata": {},
   "source": [
    "Define model input and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170509c2-00fe-46a4-8a19-14be3aecbbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = complete_dataset[outcome_inputs].values\n",
    "y = complete_dataset[['eventsModel']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c186089-661b-453d-986b-8db8eb552fb2",
   "metadata": {},
   "source": [
    "##### Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a2f490-7f40-4bf3-b689-63d51086068f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not hasattr(sys.modules['__main__'], '__file__'):\n",
    "    # One-hot encode the target\n",
    "    encode_outcome = OneHotEncoder(sparse_output=False)\n",
    "    # Fit and transform\n",
    "    y_encoded = encode_outcome.fit_transform(y)\n",
    "    # Save\n",
    "    pickle.dump(encode_outcome, open(os.path.join(model_path, \"M00. Expected Events\", \"encode_outcome.pkl\"), 'wb'))\n",
    "else:\n",
    "    y_encoded = encode_outcome.transform(y)\n",
    "\n",
    "# Calculate number of classes (used for model inputs)\n",
    "num_classes = y_encoded.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d158b352-5aa6-4b0f-a720-a91b8df0851c",
   "metadata": {},
   "source": [
    "##### Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ed7df9-6d79-42ab-bb15-82f83b5eefac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not hasattr(sys.modules['__main__'], '__file__'):\n",
    "    # Scale\n",
    "    scale_outcome = StandardScaler()\n",
    "    # Fit and transform\n",
    "    X_scaled = scale_outcome.fit_transform(X)\n",
    "    # Save\n",
    "    pickle.dump(scale_outcome, open(os.path.join(model_path, \"M00. Expected Events\", \"scale_outcome.pkl\"), 'wb'))\n",
    "else:\n",
    "    X_scaled = scale_outcome.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ae0b5a-b6b1-470c-a98e-5db04cffb09f",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71f7752-3414-4e9e-824b-2944dbe3ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not hasattr(sys.modules['__main__'], '__file__'):\n",
    "    predict_outcome = Sequential([\n",
    "        Dense(32, input_shape=(X_scaled.shape[1],), activation='relu'),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')  # softmax for multi-class classification\n",
    "    ])\n",
    "    \n",
    "    predict_outcome.compile(optimizer=Adam(learning_rate=0.00001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',      # watch validation loss\n",
    "        patience=5,              # stop if no improvement after 5 epochs\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    predict_outcome.fit(\n",
    "        X_scaled, y_encoded,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "\n",
    "    predict_outcome.save(os.path.join(model_path, \"M00. Expected Events\", 'predict_outcome.keras'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96f1228-6cd3-4b99-ab98-014fd1d3dcd1",
   "metadata": {},
   "source": [
    "##### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301431d2-a5f6-43d1-b159-af1edfadaf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_outcome.predict(X_scaled)\n",
    "\n",
    "prediction_df = pd.DataFrame(predictions, columns=encode_outcome.categories_[0])\n",
    "prediction_df = prediction_df.add_suffix('_pred')\n",
    "\n",
    "prediction_df = pd.concat([complete_dataset.reset_index(drop=True), prediction_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bbb416-db3e-45a4-b804-c8c8751d095e",
   "metadata": {},
   "source": [
    "##### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7113ce42-7b1c-48f2-933c-a9f967168cc6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adjust the number of rows and columns\n",
    "n_events = len(events_list)\n",
    "n_cols = 3\n",
    "n_rows = (n_events + n_cols - 1) // n_cols  # Ceiling division\n",
    "\n",
    "# Set square plots: each subplot is 5x5 inches\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 5 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, event in enumerate(events_list):\n",
    "    ax = axes[i]\n",
    "    pred_col = f\"{event}_pred\"\n",
    "    \n",
    "    if pred_col not in prediction_df.columns:\n",
    "        continue\n",
    "\n",
    "    # Bucket the predicted values into quantiles\n",
    "    prediction_df['bucket'] = pd.qcut(prediction_df[pred_col], q=20, duplicates='drop')\n",
    "\n",
    "    # Compute averages\n",
    "    bucket_avg = prediction_df.groupby('bucket').agg(\n",
    "        avg_pred=(pred_col, 'mean'),\n",
    "        avg_actual=(event, 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Plot\n",
    "    ax.plot(bucket_avg['avg_pred'], label='Predicted')\n",
    "    ax.plot(bucket_avg['avg_actual'], label='Actual')\n",
    "    ax.set_title(f\"{event.upper()} Prediction vs Actual\")\n",
    "    ax.set_xlabel(\"Quantile Bucket\")\n",
    "    ax.set_ylabel(\"Rate\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "# Remove extra axes if any\n",
    "for j in range(n_events, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b26eba8-4df2-4a1b-91cf-801951af40fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3775400-5c1f-4762-ac22-1c8bb1aabfe5",
   "metadata": {},
   "source": [
    "### Calculate PFX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7d1b63-e7fa-4afd-8b44-f41611891a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_list_pred = [f\"{event}_pred\" for event in events_list]\n",
    "pfx_list = [f\"{event}_pfx\" for event in events_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6d4e76-6b13-4652-afc5-31e32260c620",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_pfx_df = prediction_df.groupby(['venue_id', 'gamePk', 'batSide', 'date'])[events_list + events_list_pred].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16813f82-bf9f-4955-b958-2f233a5fa3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_games = 243"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e9bcb4-5850-46e6-b0ff-8e4d287312ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the data is sorted appropriately for rolling\n",
    "game_pfx_df = game_pfx_df.sort_values(['venue_id', 'date', 'batSide'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd4e3f2-8cd9-47d6-8f91-7465fab4aaaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c951081-5a59-4e60-be80-2217ef98200a",
   "metadata": {},
   "source": [
    "##### Unshifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285b2814-b9bd-4586-90ef-511179d5805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the rolling average of the last num_games *including* the current row\n",
    "rolling_avgs = (\n",
    "    game_pfx_df\n",
    "    .groupby(['venue_id', 'batSide'], group_keys=False)\n",
    "    .apply(lambda group: group[events_list + events_list_pred].shift(0).rolling(num_games, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "# Rename columns to indicate they are rolling averages\n",
    "rolling_avgs.columns = [f'{col}_rolling' for col in events_list + events_list_pred]\n",
    "\n",
    "# Concatenate with the original dataframe\n",
    "unshifted_game_pfx_df = pd.concat([game_pfx_df, rolling_avgs], axis=1)\n",
    "\n",
    "for event in events_list:\n",
    "    unshifted_game_pfx_df[f'{event}_pfx'] = unshifted_game_pfx_df[f'{event}_rolling'] / unshifted_game_pfx_df[f'{event}_pred_rolling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c612c3-cc75-4bfc-92d4-534be19b700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unshifted_game_pfx_df[['venue_id', 'batSide'] + [col for col in unshifted_game_pfx_df if col.endswith(\"pfx\")]].drop_duplicates(subset=['venue_id', 'batSide'], keep='last').to_csv(os.path.join(baseball_path, \"Park Latest.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3926c55a-e86c-4e9c-8a09-d693b58168f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5865847-227c-4e04-ad86-b8e28b9c3eab",
   "metadata": {},
   "source": [
    "##### Shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62d0eff-e9bb-4802-a05b-fd95c8bb3028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the rolling average of the last num_games *including* the current row\n",
    "rolling_avgs = (\n",
    "    game_pfx_df\n",
    "    .groupby(['venue_id', 'batSide'], group_keys=False)\n",
    "    .apply(lambda group: group[events_list + events_list_pred].shift(1).rolling(num_games, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "# Rename columns to indicate they are rolling averages\n",
    "rolling_avgs.columns = [f'{col}_rolling' for col in events_list + events_list_pred]\n",
    "\n",
    "# Concatenate with the original dataframe\n",
    "shifted_game_pfx_df = pd.concat([game_pfx_df, rolling_avgs], axis=1)\n",
    "\n",
    "for event in events_list:\n",
    "    shifted_game_pfx_df[f'{event}_pfx'] = shifted_game_pfx_df[f'{event}_rolling'] / shifted_game_pfx_df[f'{event}_pred_rolling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2909911c-bd8b-4966-be50-9e469f67fbc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1284a047-897c-47dc-8e1f-e4b5edb4e741",
   "metadata": {},
   "source": [
    "### Model #2. Weather Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f068fb-18bb-473d-8bb7-084d0f26c28b",
   "metadata": {},
   "source": [
    "$ \\hat{\\text{eventsModel2}} = \\hat{\\text{eventsModel}} + pfx + meteo\\_x\\_vect + meteo\\_y\\_vect + temperature\\_2m + relative\\_humidity\\_2m + dew\\_point\\_2m + surface\\_pressure + venue\\_id $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70325a82-52d2-41ea-90a1-feffc8f9a587",
   "metadata": {},
   "source": [
    "##### Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4774653-6605-44b4-ba74-352f5357b75a",
   "metadata": {},
   "source": [
    "Meteo weather inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da575162-d402-460b-a580-f01c803618aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_weather_list = ['meteo_x_vect', 'meteo_y_vect', 'temperature_2m', 'relative_humidity_2m', 'dew_point_2m', 'surface_pressure']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728a7d69-ba13-4811-9d17-26f170c3dab8",
   "metadata": {},
   "source": [
    "Parks with sufficient samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dfe8cf-caf3-487f-ae3d-9a278838bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_dummy_list = [f'venue_{id}' for id in sorted(prediction_df['venue_id'].value_counts()[lambda x: x > 20000].index.tolist())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc175b7-8580-42cc-9b3e-ef4fbed95a9a",
   "metadata": {},
   "source": [
    "Select inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5587b1cb-cfb1-4ef3-9cfa-6df6e2e7349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wfx_inputs = events_list_pred + pfx_list + meteo_weather_list + venue_dummy_list + ['b_L']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c41b96-d57f-4eb6-a13b-e60a5ebd8e5b",
   "metadata": {},
   "source": [
    "##### Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e808e87-ebc3-47f3-925a-e412caae499d",
   "metadata": {},
   "source": [
    "Merge in park factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd02fa0-4e95-44b6-8774-c46bce8c8fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df2 = prediction_df.merge(shifted_game_pfx_df[['gamePk', 'batSide'] + pfx_list], on=['gamePk', 'batSide'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f94483b-87e0-4bb0-bac3-c059b246a830",
   "metadata": {},
   "source": [
    "Create venue dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864b750f-e27b-49b6-a806-3ce5f023c28d",
   "metadata": {},
   "source": [
    "Note: not all venue dummies may be included in venue_dummy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab8d608-c4f1-4cc3-8e3c-a196a67dad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df2['venue_id2'] = sample_df2['venue_id'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0364ec90-f0bd-4fc2-ba7b-995023ffb1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df2 = pd.get_dummies(sample_df2, columns=['venue_id2'], prefix='venue', drop_first=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be669683-d7de-4838-ad6b-43bb24057a52",
   "metadata": {},
   "source": [
    "Set pfx to 1 if not in venue sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bf312c-1c00-44ff-95fd-6489c5d66577",
   "metadata": {},
   "source": [
    "Note: we may want to set this in shifted_game_pfx_df and default to a rolling value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9463340-14d9-4b4b-8d51-2923c7d73bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df2['sample_venue'] = sample_df2[venue_dummy_list].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72b4644-845d-4658-8215-82d556517e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pfx in pfx_list:\n",
    "    sample_df2[pfx] = np.where(sample_df2['sample_venue'] == 0, 1, sample_df2[pfx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1406fb3a-d19b-43c4-bfc6-5ddb899919ff",
   "metadata": {},
   "source": [
    "Drop if missing inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc25f0a7-0b1d-4cb0-b817-11e1af8771eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df2.dropna(subset=wfx_inputs, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3967b47d-8734-439a-aab6-397142c0ecb6",
   "metadata": {},
   "source": [
    "Group by game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4198b83-ebf5-42b2-b041-97f92faf8f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df2 = sample_df2.groupby(['gamePk', 'date', 'venue_id', 'batSide'])[wfx_inputs + events_list].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0283694-8e6a-45bb-a9c2-b973caa63d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df2['b_L'] = (sample_df2['batSide'] == \"L\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb4db6d-f7da-40b3-9dd3-661266a590ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df2 = sample_df2[sample_df2['date'] > 20180101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2812e92a-3c3f-46fe-9dd3-a752f4b519c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "X = sample_df2[wfx_inputs].values\n",
    "y = sample_df2[events_list].values\n",
    "\n",
    "# Number of classes\n",
    "num_classes = y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c685868e-0a6a-4e87-b0f3-f0c4bee1f23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df2[wfx_inputs].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783b3ac3-5534-4fc1-9707-ddd0c8883bc6",
   "metadata": {},
   "source": [
    "###### Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b06b545-6099-412b-8141-25847fcc4e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not hasattr(sys.modules['__main__'], '__file__'):\n",
    "    # Scale\n",
    "    scale_wfx = StandardScaler()\n",
    "    # Fit and transform\n",
    "    X_scaled = scale_wfx.fit_transform(X)\n",
    "    # Save\n",
    "    pickle.dump(scale_wfx, open(os.path.join(model_path, \"M00. Expected Events\", \"scale_wfx.pkl\"), 'wb'))\n",
    "else:\n",
    "    X_scaled = scale_wfx.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4cb291-ee37-477c-b637-cdc3698dfdbe",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96680804-a161-4271-870e-99d046a21d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import KLDivergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96009bd6-5591-48db-be15-ad970ba242d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if not hasattr(sys.modules['__main__'], '__file__'):\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "    from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "\n",
    "    import numpy as np\n",
    "    import os\n",
    "\n",
    "    class VotingEnsemble:\n",
    "        def __init__(self, models):\n",
    "            self.models = models\n",
    "\n",
    "        def predict(self, X):\n",
    "            predictions = np.array([model.predict(X, verbose=0) for model in self.models])\n",
    "            return np.mean(predictions, axis=0)\n",
    "\n",
    "    ensemble_size = 3\n",
    "    ensemble_models = []\n",
    "    model_dir = os.path.join(model_path, \"M00. Expected Events\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    for i in range(ensemble_size):\n",
    "        model = Sequential([\n",
    "            Dense(128, input_shape=(X_scaled.shape[1],), activation='relu'),\n",
    "            Dropout(0.3),\n",
    "            Dense(256, activation='relu'),\n",
    "            Dropout(0.3),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                      # loss='categorical_crossentropy',\n",
    "                      loss=keras.losses.KLDivergence(),\n",
    "                      metrics=[KLDivergence()])\n",
    "\n",
    "        early_stop = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            X_scaled, y,\n",
    "            epochs=100,\n",
    "            batch_size=32,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[early_stop],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        model_path_i = os.path.join(model_dir, f'predict_wfx_{i}.keras')\n",
    "        model.save(model_path_i)\n",
    "        ensemble_models.append(model)\n",
    "\n",
    "    # Wrap ensemble in predict_wfx for compatibility\n",
    "    predict_wfx = VotingEnsemble(ensemble_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f353999-b9e4-4d7e-a181-eda915931906",
   "metadata": {},
   "source": [
    "##### Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7a2f32-db44-4056-91cb-6f36a325a767",
   "metadata": {},
   "source": [
    "Save event averages for use in predictions in A06. Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f298e6d-547c-4b09-85b2-8c61a77a2c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_df = pd.DataFrame(sample_df2[events_list].mean()).T\n",
    "# average_df.to_csv(os.path.join(baseball_path, \"Event Averages.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91663ac-cab6-4c20-94ed-b4c4e7aad828",
   "metadata": {},
   "source": [
    "Before predicting, replace with mean predicted event rates to determine how weather would affect an average batted-ball game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1212e6-1502-49f5-a765-36885a4404bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df3 = sample_df2.copy()\n",
    "for event in events_list:\n",
    "    sample_df3[f'{event}_pred'] = sample_df3[event].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a44d785-ee00-4611-8e1b-00bae5fe9f00",
   "metadata": {},
   "source": [
    "Now actually predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e73aca2-a8e0-4151-874c-508520a7a242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "X2 = sample_df3[wfx_inputs].values\n",
    "y2 = sample_df3[events_list].values\n",
    "\n",
    "# Scale the features\n",
    "X2_scaled = scale_wfx.transform(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe382813-f734-441c-a4d1-7a1b19c48ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bf8e8e-05f0-43d5-962a-20e5b9ffe8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = predict_wfx.predict(X2_scaled)\n",
    "prediction_df2 = pd.DataFrame(predictions2, columns=events_list)\n",
    "\n",
    "prediction_df2 = prediction_df2.add_suffix('_pred2')\n",
    "\n",
    "prediction_df2 = pd.concat([prediction_df2, sample_df3.reset_index()], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adff36da-0aa5-40c3-a840-cd4948395166",
   "metadata": {},
   "source": [
    "Calculate WFX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4f6739-dcfd-4f9f-a7b4-e48b1d216c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbe2e17-2206-4a3a-a33a-9ef07ed37413",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in events_list:\n",
    "    prediction_df2[f'{event}_wfx'] = prediction_df2[f'{event}_pred2'] / prediction_df2[f'{event}_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04b6715-6e18-49a9-b0a2-90661d0ccd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df2[['hr_pred', 'hr_pred2', 'hr']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7340814-0cee-45c2-9f03-3ac14e55818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_df = prediction_df2.groupby('venue_id')[['hr_pred2', 'hr']].mean()\n",
    "hr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b00ef55-98eb-4749-ae7e-65f4c67bb7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_df['squared_error'] = (hr_df['hr_pred2'] - hr_df['hr']) ** 2\n",
    "hr_df['squared_error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44687b9-ce3e-4808-9692-ea39c8556629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort and get top/bottom 500\n",
    "top_500 = prediction_df2.nlargest(500, 'hr_wfx')\n",
    "bottom_500 = prediction_df2.nsmallest(500, 'hr_wfx')\n",
    "\n",
    "# Get value counts\n",
    "top_counts = top_500['venue_id'].value_counts().head(5)\n",
    "bottom_counts = bottom_500['venue_id'].value_counts().head(5)\n",
    "\n",
    "# Combine into a 5x4 DataFrame\n",
    "result_df = pd.DataFrame({\n",
    "    'Top Venue': top_counts.index,\n",
    "    'Top Count': top_counts.values,\n",
    "    'Bottom Venue': bottom_counts.index,\n",
    "    'Bottom Count': bottom_counts.values\n",
    "})\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda9b526-f824-4efe-85ed-873cd3b927aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df2.sort_values('hr_wfx', ascending=False).head(100)[['meteo_y_vect', 'temperature_2m']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc8a297-6145-40cd-8e4d-96e81f90860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df2.sort_values('hr_wfx', ascending=False).tail(100)[['meteo_y_vect', 'temperature_2m']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee20131-0a48-4b9d-9f1e-e5f1b9f5e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the number of rows and columns\n",
    "n_events = len(events_list)\n",
    "n_cols = 3\n",
    "n_rows = (n_events + n_cols - 1) // n_cols  # Ceiling division\n",
    "\n",
    "# Set square plots: each subplot is 5x5 inches\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 5 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, event in enumerate(events_list):\n",
    "    ax = axes[i]\n",
    "    pred_col = f\"{event}_pred2\"\n",
    "    \n",
    "    if pred_col not in prediction_df2.columns:\n",
    "        continue\n",
    "\n",
    "    # Bucket the predicted values into quantiles\n",
    "    prediction_df2['bucket'] = pd.qcut(prediction_df2[pred_col], q=10, duplicates='drop')\n",
    "\n",
    "    # Compute averages\n",
    "    bucket_avg = prediction_df2.groupby('bucket').agg(\n",
    "        avg_pred=(pred_col, 'mean'),\n",
    "        avg_actual=(event, 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Plot\n",
    "    ax.plot(bucket_avg['avg_pred'], label='Predicted')\n",
    "    ax.plot(bucket_avg['avg_actual'], label='Actual')\n",
    "    ax.set_title(f\"{event.upper()} Prediction vs Actual\")\n",
    "    ax.set_xlabel(\"Quantile Bucket\")\n",
    "    ax.set_ylabel(\"Rate\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Set y-axis limits: from 1/3 of the max to the max\n",
    "    y_max = max(bucket_avg['avg_pred'].max(), bucket_avg['avg_actual'].max())\n",
    "    y_min = y_max / 2\n",
    "\n",
    "    # Create 10 evenly spaced ticks from y_min to y_max\n",
    "    ticks = np.linspace(y_min, y_max, 10)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_yticks(np.round(ticks, 5))  # round for cleaner labels\n",
    "\n",
    "# Remove extra axes if any\n",
    "for j in range(n_events, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6225ea4a-6024-448a-832e-286f4ecacc05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82c3212-e2b7-4b38-89fd-d7f7d4bb95c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a454580-31c2-4754-9a09-a43d1ac19be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acee279-2ea6-4cdb-b0dd-ce15fce44d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U4. Datasets.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5b1f9a-f060-416f-9a70-da60112bc016",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df[events_list_pred].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eef4af8-d2de-495c-853a-230cd3074336",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df[events_list] = prediction_df[events_list_pred].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656874bb-1b6e-4c64-a3d9-38016a7ab241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5f9f9f-56f3-47fe-9daa-03c0fa4bc083",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'bucket' in list(prediction_df.columns):\n",
    "    prediction_df.drop(columns=['bucket'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272c54d4-9a01-4b5d-abc8-6511adc48eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rolling stats\n",
    "short, long = 50, 300\n",
    "\n",
    "# Short\n",
    "start_time = time.time()\n",
    "df_short = rolling_pas(prediction_df, short, events_list)\n",
    "print(f\"Short took {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0ebd3d-1c04-498d-92e6-e2b2ca4df51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long\n",
    "start_time = time.time()\n",
    "df_long = rolling_pas(prediction_df, long, events_list)\n",
    "df_long = df_long.add_suffix(\"_long\")\n",
    "print(f\"Long took {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2df331-f936-448a-ad7f-fe79d283fef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short[batter_stats_short].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6d3999-4224-48a7-b9d7-60dd8c7aeed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "# We only need the rolling stats \n",
    "long_stats = batter_stats_long + pitcher_stats_long\n",
    "df_long = df_long[long_stats]\n",
    "\n",
    "# Dataset\n",
    "final_dataset = pd.concat([df_short, df_long], axis=1)\n",
    "\n",
    "\n",
    "# Reset index\n",
    "final_dataset.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Sort\n",
    "final_dataset.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2837fb9-985e-4c5d-b788-72fc054b7c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.drop(columns=events_list + ['Cut'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8144d0e-45d9-424a-9dac-e16b77199ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dummies = pd.get_dummies(final_dataset['eventsModel']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668c6799-d9c8-4248-a4ad-2790853d4e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fd2fae-3989-4076-9419-680e56537aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = pd.concat([final_dataset, event_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a62456-5e08-4122-a601-c73c38099a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = final_dataset.replace([float('inf'), float('-inf')], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9769aa93-0cf0-4482-b7f7-b45136e99283",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "final_dataset.to_csv(os.path.join(baseball_path, \"Final Dataset.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6e7be0-ce55-43e9-b1e0-9fbd5f6e054d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "l_shifted_game_wfx_df = prediction_df2[prediction_df2['batSide'] == \"L\"]\n",
    "r_shifted_game_wfx_df = prediction_df2[prediction_df2['batSide'] == \"R\"]\n",
    "\n",
    "wfx_df = pd.merge(l_shifted_game_wfx_df, r_shifted_game_wfx_df, on=['venue_id', 'gamePk', 'date'], how='left', suffixes=(\"_l\", \"_r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5df586-df91-454b-b889-f4d710f2fecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wfx_df[['venue_id', 'gamePk', 'date'] + [col for col in wfx_df if \"wfx\" in col]].to_csv(os.path.join(baseball_path, \"Park and Weather Factors.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d358df03-a62d-40b4-a318-ce76d8198fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in wfx_df['date'].unique():\n",
    "    wfx_df[wfx_df['date'] == date][['venue_id', 'gamePk', 'date'] + [col for col in wfx_df if \"wfx\" in col]].to_csv(os.path.join(baseball_path, \"A06. Weather\", \"3. Park and Weather Factors\", f\"Park and Weather Factors {date}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2128019-78ea-49ec-bb59-59aa23db229b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
