{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b3b5eba-437e-4bad-98dd-7f82ecfa6124",
   "metadata": {},
   "source": [
    "# A7. Matchups\n",
    "Source: DKSalaries, A5. Stats <br>\n",
    "\n",
    "Description: This uses DKSalaries and A5. Stats to create matchup Excel files as simulation input <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9431cf06-1049-49a2-9ad7-a1b7ca6a84b7",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "774b3e91-8e43-4932-8324-abde3eae6fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import xlrd\n",
    "import unidecode\n",
    "import datetime\n",
    "from datetime import date\n",
    "from pathlib import Path\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import time\n",
    "\n",
    "# import import_ipynb\n",
    "# from Utilities import *\n",
    "\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\james\\Documents\\MLB\\Code\")\n",
    "from Utilities import *\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\")\n",
    "\n",
    "from distutils.dir_util import copy_tree\n",
    "\n",
    "baseball_path = r\"C:\\Users\\james\\Documents\\MLB\\Data\"\n",
    "download_path = r\"C:\\Users\\james\\Downloads\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "434a13e2-9942-441c-9fa1-b61644a7e3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Today's Date\n",
    "# YYYY-MM-DD (datetime)\n",
    "todaysdate_dt = datetime.date.today()\n",
    "\n",
    "# YYYY-MM-DD (string)\n",
    "todaysdate_dash = str(todaysdate_dt)\n",
    "\n",
    "# MM/DD/YYYY\n",
    "todaysdate_slash = todaysdate_dash.split(\"-\")\n",
    "todaysdate_slash = todaysdate_slash[1] + \"/\" + todaysdate_slash[2] + \"/\" + todaysdate_slash[0]\n",
    "\n",
    "# YYYYMMDD\n",
    "todaysdate = todaysdate_dash.replace(\"-\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7cf8084-518f-430c-9590-e10bd9e825c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This reads in a map of team name, codes, and the number Fangraphs uses in their URLs\n",
    "team_map = pd.read_csv(os.path.join(baseball_path, \"Utilities\", \"Team Map.csv\"))\n",
    "\n",
    "# We just need teams right now\n",
    "team_map = team_map[['DKTEAM', 'BBREFTEAM', 'SFBBTEAM']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9f0609-dfe8-41af-9dd1-2addbcd96d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e00dd2e-202f-408e-bdfc-72c4de4c961c",
   "metadata": {},
   "source": [
    "### Lineups "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b752fa0-d60d-41c0-b852-37da7b787ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape team lineups\n",
    "def scrape_lineups(date=todaysdate_dash, early=False):\n",
    "    # Read in daily lineups from Baseball Monster\n",
    "    url = \"https://baseballmonster.com/Lineups.aspx?csv=1&d=\" + date\n",
    "    lineups = pd.read_csv(url)\n",
    "\n",
    "    # Merge with team map to get proper team code\n",
    "    lineups = lineups.merge(team_map, left_on='team code', right_on='SFBBTEAM', how='inner') \n",
    "\n",
    "    # Fill missings\n",
    "    lineups[' mlb id'] = np.where(lineups[' player name'] == \"Masataka Yoshida\", 807799, lineups[' mlb id'])\n",
    "\n",
    "    # Check missings\n",
    "    lineups[' mlb id'].fillna(999999, inplace=True)\n",
    "    for i in range(len(lineups)):\n",
    "        if lineups[' mlb id'][i] == 999999:\n",
    "            print(lineups[' player name'][i])\n",
    "\n",
    "    # Determine if it's the first or second game of a double header\n",
    "    lineups['count'] = lineups.groupby('BBREFTEAM').cumcount()+1\n",
    "    lineups['game'] = np.where(lineups['count'] <= 10, 1, 2)\n",
    "    lineups['games'] = lineups.groupby('BBREFTEAM')['game'].transform('max')\n",
    "    \n",
    "    # If it's early, keep the first game\n",
    "    if early == True:\n",
    "        lineups = lineups[lineups['game'] == 1]\n",
    "    # If it's not, keep the last game\n",
    "    else:\n",
    "        lineups = lineups[lineups['game'] == lineups['games']]\n",
    "\n",
    "    # Keep relevant variables\n",
    "    lineups = lineups[[' mlb id', ' batting order', 'BBREFTEAM']]\n",
    "    lineups.rename(columns={' mlb id': 'key_mlbam', ' batting order':'batting_order_fill'}, inplace=True)\n",
    "    \n",
    "    \n",
    "    return lineups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f8b1163-544c-482e-ade6-bb031f05ae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save today's lineups as a CSV\n",
    "todaysdate_dash = todaysdate[:4] + \"-\" + todaysdate[4:6] + \"-\" + todaysdate[6:]\n",
    "lineups = scrape_lineups(date=todaysdate_dash, early=False)\n",
    "lineups.to_csv(os.path.join(baseball_path, \"A7. Matchups - 1. Lineups\", \"Lineups \" + todaysdate_dash + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a9278c-39ba-43d9-8db3-f1ebea8dc945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be599c30-5e0d-4a23-8164-f797b7bcf904",
   "metadata": {},
   "source": [
    "### DK Salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b815914e-7f0d-422e-b68e-1fc320900ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This reads in the most recently downloaded salary file and saves it \n",
    "def create_dk_salaries(date=todaysdate):\n",
    "    # Find all DK downloads\n",
    "    dk_files = glob.glob(os.path.join(download_path, 'DKSalaries*.csv'))\n",
    "    dk_files.sort(key=os.path.getmtime)\n",
    "\n",
    "    latest = dk_files[-1]\n",
    "\n",
    "    # Clean DK salaries for merge\n",
    "    dk_salaries = pd.read_csv(os.path.join(download_path, latest))\n",
    "    \n",
    "    dk_salaries = dk_salaries[dk_salaries['Name'] != \"Caleb Smith\"] # There are two Ca Smiths on Pit. Kept Canaan\n",
    "    \n",
    "    dk_salaries['ID'] = np.where(dk_salaries['Name'] == \"Shohei Ohtani\", 134045, dk_salaries['ID'])\n",
    "    \n",
    "    dk_salaries.to_csv(os.path.join(baseball_path, \"A7. Matchups - 1. Salaries\", \"DKSalaries_\" + date + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7293ea1b-8d4c-4b21-876f-33fd5c720072",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dk_salaries(todaysdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "800fa9d9-0b7f-4b15-b01f-5ec339967b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This reads in saves salary files and keeps relevant variables. It also creates a list of games.\n",
    "def clean_dk_salaries(date=todaysdate):\n",
    "    # Read in DK Salaries\n",
    "    dk_salaries = pd.read_csv(os.path.join(baseball_path, \"A7. Matchups - 1. Salaries\", \"DKSalaries_\" + date + \".csv\"))\n",
    "    \n",
    "    \n",
    "    # Clean game info\n",
    "    # For scraped, we already fix the names - make this better universally\n",
    "    dk_salaries['Game Info'] = dk_salaries['Game Info'].replace({\"CWS\":\"CHW\", \"KC\": \"KCR\", \"SD\": \"SDP\", \"SF\":\"SFG\", \"TB\":\"TBR\", \"WAS\":\"WSN\", \"@\": \"_\", \":\": \"\", \"/\": \"\"}, regex=True)\n",
    "    dk_salaries['Game Info'] = dk_salaries['Game Info'].replace({\"SDPP\": \"SDP\", 'TBRR':'TBR', 'KCRR':'KCR'}, regex=True)\n",
    "    dk_salaries['Game Info'] = dk_salaries['Game Info'].replace({\"@\": \"_\", \":\": \"\", \"/\": \"\"}, regex=True)\n",
    "    # Merge with team map to get baseball reference names\n",
    "    dk_salaries = dk_salaries.merge(team_map, left_on='TeamAbbrev', right_on='DKTEAM', how='left')\n",
    "\n",
    "    # Convert to Baseball Reference team code\n",
    "    dk_salaries['TeamAbbrev'] = dk_salaries['BBREFTEAM']\n",
    "\n",
    "    # Change Ohtani's number\n",
    "    dk_salaries['ID'] = np.where((dk_salaries['Name'] == \"Shohei Ohtani\"), 134045, dk_salaries['ID'])\n",
    "   \n",
    "    # Clean names\n",
    "    dk_salaries = name_clean(dk_salaries)\n",
    "\n",
    "    # This is all we need to merge. \n",
    "    dk_salaries_cut = dk_salaries[['First2', 'Last5', 'BBREFTEAM', 'Salary', 'ID']]\n",
    "\n",
    "\n",
    "    # We also want a separate game info df with teams, time, who's home, date\n",
    "    game_info = dk_salaries[['Game Info']]\n",
    "\n",
    "    # This is the list of all matchups\n",
    "    matchups = game_info['Game Info'].unique()\n",
    "    matchups = matchups.tolist()\n",
    "    \n",
    "    print(matchups)\n",
    "\n",
    "    # Define a custom sorting key function that extracts the numbers from characters 17-20 in each string (the game time)\n",
    "    # Note: AM games can mess this up a bit\n",
    "    def sort_key(string):\n",
    "        return int(string[17:21])\n",
    "\n",
    "    \n",
    "    try:\n",
    "        matchups.remove('Postponed')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        matchups.remove('Cancelled')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        # Sort matchups on game time\n",
    "        matchups.sort(key=sort_key)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return dk_salaries_cut, matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ab9792e-2bfa-425d-9477-8913b08527d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_ins(df):\n",
    "    # Take first two characters of first name\n",
    "    df['First2_fill'] = df['firstName'].str.slice(0,2)\n",
    "    # And first 5 characters of last name\n",
    "    df['Last5_fill'] = df['lastName'].str.slice(0,5)\n",
    "\n",
    "    # Make lower case\n",
    "    df['First2_fill'] = df['First2_fill'].str.lower()\n",
    "    df['Last5_fill'] = df['Last5_fill'].str.lower()\n",
    "\n",
    "    # Make string (this makes the f_remove_accents function work properly\n",
    "    df['First2_fill'] = df['First2_fill'].astype(str) # this one is necessary\n",
    "    df['Last5_fill'] = df['Last5_fill'].astype(str) # this one is not\n",
    "\n",
    "    # Remove accents\n",
    "    df['First2_fill'] = df.apply(lambda x: remove_accents(x['First2_fill']), axis=1)  # remove accents\n",
    "    df['Last5_fill'] = df.apply(lambda x: remove_accents(x['Last5_fill']), axis=1)  # remove accents\n",
    "\n",
    "    # Remove abnormal characters\n",
    "    df['First2_fill'] = df['First2_fill'].str.replace('[^a-zA-Z0-9 ]', '')\n",
    "    df['Last5_fill'] = df['Last5_fill'].str.replace('[^a-zA-Z0-9 ]', '')\n",
    "    \n",
    "    df['First2'].fillna(df['First2_fill'],inplace=True)\n",
    "    df['Last5'].fillna(df['Last5_fill'],inplace=True)\n",
    "    \n",
    "    try:\n",
    "        df['outs'].fillna(9, inplace=True)\n",
    "        df['avgFaced'].fillna(15, inplace=True)\n",
    "        df['starter_api'].fillna(1, inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    df.drop(columns=['First2_fill', 'Last5_fill'], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5efa5ef-a508-40af-bd95-44d005856c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05e680a9-a608-4036-a920-7df859b79c94",
   "metadata": {},
   "source": [
    "### Matchup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d1d9745-5499-413e-b650-407466653a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_matchups(df):\n",
    "    # Add RP leverage to starting pitcher leverage (1 if starter)\n",
    "    df['Leverage'] = np.where(df['starter'] == 1, 1, df['Leverage'])\n",
    "    \n",
    "    # Determine batting order\n",
    "    df['batting_order'] = np.nan\n",
    "    for i in range(9):\n",
    "        df['batting_order'] = np.where(df['order'] == (i+1)*100, i+1, df['batting_order'])\n",
    "    \n",
    "    # Imputed flag\n",
    "    try:\n",
    "        df['imp'] = np.where(df['pa_b_long_r'] < 40, 1, 0)\n",
    "    except:\n",
    "        df['imp'] = np.where(df['pa_p_long_r'] < 40, 1, 0)\n",
    "        \n",
    "    # Delete unnamed columns\n",
    "    df = df.loc[:,~df.columns.str.startswith('Unnamed')]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "596f72f6-1ffa-492a-835a-2ce47904c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matchups(date=todaysdate, backtest=False, early=False):        \n",
    "    # Read in clean DK Salaries data\n",
    "    dk_salaries_cut, matchups = clean_dk_salaries(date)\n",
    "    \n",
    "    # Scrape lineups \n",
    "    date_dash = date[:4] + \"-\" + date[4:6] + \"-\" + date[6:]\n",
    "    print(date_dash)\n",
    "    lineups = scrape_lineups(date=date_dash, early=early)\n",
    "    \n",
    "    daily_folder = \"Daily\" + date\n",
    "    \n",
    "    for matchup in matchups:\n",
    "        # Create new folder with daily rosters\n",
    "        matchup_folder = \"Matchups\" + date\n",
    "        try:\n",
    "            os.mkdir(os.path.join(baseball_path, \"A7. Matchups - 2. Matchups\", matchup_folder))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        away = matchup[0:3]\n",
    "        home = matchup[4:7]\n",
    "        \n",
    "        away_file = away + date + \".xlsx\"\n",
    "        home_file = home + date + \".xlsx\"\n",
    "        \n",
    "        # Read in away data\n",
    "        away_batters = pd.read_excel(os.path.join(baseball_path, \"A5. Stats - 2. Teams\", daily_folder, away_file), sheet_name='Batters')\n",
    "        away_pitchers = pd.read_excel(os.path.join(baseball_path, \"A5. Stats - 2. Teams\", daily_folder, away_file), sheet_name='Pitchers')\n",
    "        \n",
    "        # Read in home data\n",
    "        home_batters = pd.read_excel(os.path.join(baseball_path, \"A5. Stats - 2. Teams\", daily_folder, home_file), sheet_name='Batters')\n",
    "        home_pitchers = pd.read_excel(os.path.join(baseball_path, \"A5. Stats - 2. Teams\", daily_folder, home_file), sheet_name='Pitchers')\n",
    "            \n",
    "        \n",
    "        # Fill in missings\n",
    "        away_batters = fill_ins(away_batters)\n",
    "        away_pitchers = fill_ins(away_pitchers)\n",
    "        home_batters = fill_ins(home_batters)\n",
    "        home_pitchers = fill_ins(home_pitchers)\n",
    "    \n",
    "        # Merge with DK Salaries\n",
    "        away_batters = away_batters.merge(dk_salaries_cut, on=['First2', 'Last5', 'BBREFTEAM'], how='left')\n",
    "        away_pitchers = away_pitchers.merge(dk_salaries_cut, on=['First2', 'Last5', 'BBREFTEAM'], how='left')\n",
    "        \n",
    "        home_batters = home_batters.merge(dk_salaries_cut, on=['First2', 'Last5', 'BBREFTEAM'], how='left')\n",
    "        home_pitchers = home_pitchers.merge(dk_salaries_cut, on=['First2', 'Last5', 'BBREFTEAM'], how='left')\n",
    "        \n",
    "        # Create name variable so Sims reads in right objects\n",
    "        away_batters['Name'] = away_batters['fullName']\n",
    "        away_pitchers['Name'] = away_pitchers['fullName']\n",
    "        home_batters['Name'] = home_batters['fullName']\n",
    "        home_pitchers['Name'] = home_pitchers['fullName']\n",
    "             \n",
    "        # Clean\n",
    "        away_batters = clean_matchups(away_batters)\n",
    "        away_pitchers = clean_matchups(away_pitchers)\n",
    "        \n",
    "        home_batters = clean_matchups(home_batters)\n",
    "        home_pitchers = clean_matchups(home_pitchers)   \n",
    "        \n",
    "        # Since they're getting fixed, we can make imp all 0, eventually get rid of it\n",
    "        away_batters['imp'] = 0\n",
    "        away_pitchers['imp'] = 0\n",
    "        home_batters['imp'] = 0\n",
    "        home_pitchers['imp'] = 0\n",
    "        \n",
    "        \n",
    "        # Add lineups\n",
    "        away_batters = away_batters.merge(lineups, on=['key_mlbam', 'BBREFTEAM'], how='left')\n",
    "        home_batters = home_batters.merge(lineups, on=['key_mlbam', 'BBREFTEAM'], how='left')\n",
    "        away_pitchers = away_pitchers.merge(lineups, on=['key_mlbam', 'BBREFTEAM'], how='left')\n",
    "        home_pitchers = home_pitchers.merge(lineups, on=['key_mlbam', 'BBREFTEAM'], how='left')\n",
    "        \n",
    "        # If backtesting, use statsapi order\n",
    "        if backtest == True:\n",
    "            away_batters['batting_order'] = np.nan\n",
    "            home_batters['batting_order'] = np.nan\n",
    "            for i in range(1, 10):\n",
    "                away_batters['batting_order'] = np.where(away_batters['order'] == i * 100, i, away_batters['batting_order'])\n",
    "                home_batters['batting_order'] = np.where(home_batters['order'] == i * 100, i, home_batters['batting_order'])\n",
    "                \n",
    "        if backtest == False:\n",
    "            # Fill in batting orders\n",
    "            away_batters['batting_order_fill'].fillna(\"-1\", inplace=True)\n",
    "            away_batters['batting_order'] = away_batters['batting_order_fill'].astype('int')\n",
    "            away_batters['batting_order'] = np.where(away_batters['batting_order'] == -1, np.nan, away_batters['batting_order'])\n",
    "            away_batters.drop(columns={'batting_order_fill'}, inplace=True)\n",
    "\n",
    "            home_batters['batting_order_fill'].fillna(\"-1\", inplace=True)\n",
    "            home_batters['batting_order'] = home_batters['batting_order_fill'].astype('int')\n",
    "            home_batters['batting_order'] = np.where(home_batters['batting_order'] == -1, np.nan, home_batters['batting_order'])\n",
    "            home_batters.drop(columns={'batting_order_fill'}, inplace=True)\n",
    "\n",
    "            away_pitchers['batting_order'] = away_pitchers['batting_order_fill']\n",
    "            away_pitchers['starter'] = np.where(away_pitchers['batting_order'] == \"SP\", 1, 0)\n",
    "            away_pitchers['Leverage'] = np.where(away_pitchers['batting_order'] == \"SP\", 1, away_pitchers['Leverage'])\n",
    "            away_pitchers.drop(columns={'batting_order_fill'}, inplace=True)\n",
    "\n",
    "            home_pitchers['batting_order'] = home_pitchers['batting_order_fill']\n",
    "            home_pitchers['starter'] = np.where(home_pitchers['batting_order'] == \"SP\", 1, 0)\n",
    "            home_pitchers['Leverage'] = np.where(home_pitchers['batting_order'] == \"SP\", 1, home_pitchers['Leverage'])\n",
    "            home_pitchers.drop(columns={'batting_order_fill'}, inplace=True)\n",
    "        \n",
    "        \n",
    "        batter_info = ['fullName', 'firstName', 'lastName', 'Salary', 'batting_order', 'starter', 'Leverage', 'batSide', 'pitchHand', \n",
    "         'position', 'BBREFTEAM', \n",
    "         'ID', 'id', 'key_mlbam', 'key_fangraphs', 'key_bbref_minors', 'key_bbref', \n",
    "         'name_first', 'name_last', 'First2', 'Last5', 'Name', 'order',        \n",
    "         'status', 'venue_id', 'game_date', 'game_type', 'game_num', 'summary', \n",
    "         'weather', 'wind', 'missing']\n",
    "        \n",
    "        batter_stat = [               \n",
    "         'b_L', 'batSide_l', \n",
    "         'b1_b_l', 'b2_b_l', 'b3_b_l', 'hr_b_l', 'bb_b_l', 'hbp_b_l',               \n",
    "         'so_b_l', 'lo_b_l', 'po_b_l', 'go_b_l', 'fo_b_l', \n",
    "         'woba_b_l', 'slg_b_l', 'obp_b_l', 'iso_b_l', \n",
    "         'to_left_b_l', 'to_middle_b_l', 'to_right_b_l',                      \n",
    "         'hard_hit_b_l', 'totalDistance_b_l', 'launchSpeed_b_l', \n",
    "         'maxSpeed_b_l', 'maxSpin_b_l',\n",
    "         'pa_b_l', 'ab_b_l', \n",
    "                       \n",
    "         'b1_b_long_l', 'b2_b_long_l', 'b3_b_long_l', 'hr_b_long_l', 'bb_b_long_l', 'hbp_b_long_l',              \n",
    "         'so_b_long_l', 'lo_b_long_l', 'po_b_long_l', 'go_b_long_l', 'fo_b_long_l', \n",
    "         'woba_b_long_l', 'slg_b_long_l', 'obp_b_long_l', 'iso_b_long_l',\n",
    "         'to_left_b_long_l', 'to_middle_b_long_l', 'to_right_b_long_l',                      \n",
    "         'hard_hit_b_long_l', 'totalDistance_b_long_l', 'launchSpeed_b_long_l', \n",
    "         'maxSpeed_b_long_l', 'maxSpin_b_long_l',                       \n",
    "         'pa_b_long_l', 'ab_b_long_l', \n",
    "                       \n",
    "                       \n",
    "         'batSide_r', \n",
    "         'b1_b_r', 'b2_b_r', 'b3_b_r', 'hr_b_r', 'bb_b_r', 'hbp_b_r',\n",
    "         'so_b_r', 'lo_b_r', 'po_b_r', 'go_b_r', 'fo_b_r', \n",
    "         'woba_b_r', 'slg_b_r', 'obp_b_r', 'iso_b_r', \n",
    "         'to_left_b_r', 'to_middle_b_r', 'to_right_b_r',                      \n",
    "         'hard_hit_b_r', 'totalDistance_b_r', 'launchSpeed_b_r',\n",
    "         'maxSpeed_b_r', 'maxSpin_b_r',        \n",
    "         'pa_b_r', 'ab_b_r', \n",
    "                       \n",
    "         'b1_b_long_r', 'b2_b_long_r', 'b3_b_long_r', 'hr_b_long_r', 'bb_b_long_r', 'hbp_b_long_r', \n",
    "         'so_b_long_r', 'lo_b_long_r', 'po_b_long_r', 'go_b_long_r', 'fo_b_long_r', \n",
    "         'woba_b_long_r', 'slg_b_long_r', 'obp_b_long_r','iso_b_long_r', \n",
    "         'to_left_b_long_r', 'to_middle_b_long_r', 'to_right_b_long_r',                      \n",
    "         'hard_hit_b_long_r', 'totalDistance_b_long_r', 'launchSpeed_b_long_r',\n",
    "         'maxSpeed_b_long_r', 'maxSpin_b_long_r',\n",
    "         'pa_b_long_r', 'ab_b_long_r', \n",
    "                       \n",
    "         'b1_rate', 'b2_rate', 'b3_rate', 'hr_rate', 'bb_rate', 'hbp_rate', 'so_rate', 'obp', 'slg', 'woba', \n",
    "         'sba_imp', 'sbr', 'sba_2b', 'sba_3b', 'sb_2b', 'sb_3b', \n",
    "         'imp']\n",
    "        \n",
    "        pitcher_info = ['fullName', 'firstName', 'lastName', 'Salary', 'batting_order', 'starter', 'Leverage', 'batSide', 'pitchHand', \n",
    "         'position', 'BBREFTEAM', \n",
    "         'ID', 'id', 'key_mlbam', 'key_fangraphs', 'key_bbref_minors', 'key_bbref',  \n",
    "         'name_first', 'name_last', 'First2', 'Last5', 'Name', 'order',               \n",
    "         'status', 'venue_id', 'game_date', 'game_type', 'game_num', 'summary', \n",
    "         'weather', 'wind', 'missing']\n",
    "          \n",
    "        pitcher_stat = [\n",
    "         'p_L', 'pitchHand_l', \n",
    "         'b1_p_l', 'b2_p_l', 'b3_p_l', 'hr_p_l', 'bb_p_l', 'hbp_p_l', \n",
    "         'so_p_l', 'lo_p_l', 'po_p_l', 'go_p_l', 'fo_p_l', \n",
    "         'woba_p_l', 'slg_p_l', 'obp_p_l', 'iso_p_l', \n",
    "         'to_left_p_l', 'to_middle_p_l', 'to_right_p_l', \n",
    "         'hard_hit_p_l', 'totalDistance_p_l', 'launchSpeed_p_l',\n",
    "         'maxSpeed_p_l', 'maxSpin_p_l', \n",
    "         'pa_p_l', 'ab_p_l',\n",
    "                        \n",
    "         'b1_p_long_l', 'b2_p_long_l', 'b3_p_long_l', 'hr_p_long_l', 'bb_p_long_l', 'hbp_p_long_l',                \n",
    "         'so_p_long_l', 'lo_p_long_l', 'po_p_long_l', 'go_p_long_l', 'fo_p_long_l', \n",
    "         'woba_p_long_l', 'slg_p_long_l', 'obp_p_long_l', 'iso_p_long_l', \n",
    "         'to_left_p_long_l', 'to_middle_p_long_l', 'to_right_p_long_l', \n",
    "         'hard_hit_p_long_l', 'totalDistance_p_long_l', 'launchSpeed_p_long_l',\n",
    "         'maxSpeed_p_long_l', 'maxSpin_p_long_l',                        \n",
    "         'pa_p_long_l', 'ab_p_long_l', \n",
    "                        \n",
    "         'pitchHand_r', \n",
    "         'b1_p_r', 'b2_p_r', 'b3_p_r', 'hr_p_r', 'bb_p_r', 'hbp_p_r',               \n",
    "         'so_p_r', 'lo_p_r', 'po_p_r', 'go_p_r', 'fo_p_r', \n",
    "         'woba_p_r', 'slg_p_r', 'obp_p_r', 'iso_p_r', \n",
    "         'to_left_p_r', 'to_middle_p_r', 'to_right_p_r', \n",
    "         'hard_hit_p_r', 'totalDistance_p_r', 'launchSpeed_p_r',\n",
    "         'maxSpeed_p_r', 'maxSpin_p_r', \n",
    "         'pa_p_r', 'ab_p_r', \n",
    "                        \n",
    "         'b1_p_long_r', 'b2_p_long_r', 'b3_p_long_r', 'hr_p_long_r', 'bb_p_long_r', 'hbp_p_long_r',                \n",
    "         'so_p_long_r', 'lo_p_long_r', 'po_p_long_r', 'go_p_long_r', 'fo_p_long_r', \n",
    "         'woba_p_long_r', 'slg_p_long_r', 'obp_p_long_r', 'iso_p_long_r', \n",
    "         'to_left_p_long_r', 'to_middle_p_long_r', 'to_right_p_long_r', \n",
    "         'hard_hit_p_long_r', 'totalDistance_p_long_r', 'launchSpeed_p_long_r',\n",
    "         'maxSpeed_p_long_r', 'maxSpin_p_long_r',          \n",
    "         'pa_p_long_r', 'ab_p_long_r', \n",
    "                        \n",
    "         'H9', 'HR9', 'K9', 'BB9',                \n",
    "         'outs', 'avgFaced',\n",
    "         'imp']\n",
    "        \n",
    "        batter_list = batter_info + batter_stat\n",
    "        pitcher_list = pitcher_info + pitcher_stat \n",
    "            \n",
    "        # Keep relevant variables\n",
    "        away_batters = away_batters[batter_list]\n",
    "        home_batters = home_batters[batter_list]\n",
    "        away_pitchers = away_pitchers[pitcher_list]\n",
    "        home_pitchers = home_pitchers[pitcher_list]\n",
    "        \n",
    "        away_batters.sort_values('batting_order', inplace=True)\n",
    "        home_batters.sort_values('batting_order', inplace=True)\n",
    "        away_pitchers.sort_values('Leverage', inplace=True)\n",
    "        home_pitchers.sort_values('Leverage', inplace=True)\n",
    "        \n",
    "        print(matchup)\n",
    "        if away_batters['batting_order'].sum() != 45:\n",
    "            print(\"The sum of the away team's batting order is {}.\".format(away_batters['batting_order'].sum()))\n",
    "        if home_batters['batting_order'].sum() != 45:\n",
    "            print(\"The sum of the home team's batting order is {}.\".format(home_batters['batting_order'].sum()))\n",
    "        if 1 not in list(away_pitchers['Leverage']):\n",
    "            print(\"The away team is missing a starting pitcher.\")\n",
    "        if 4 not in list(away_pitchers['Leverage']):\n",
    "            print(\"The away team is missing a closer.\")\n",
    "        if 1 not in list(home_pitchers['Leverage']):\n",
    "            print(\"The home team is missing a starting pitcher.\")\n",
    "        if 4 not in list(home_pitchers['Leverage']):\n",
    "            print(\"The home team is missing a closer.\")\n",
    "        \n",
    "        # Create file named after matchup\n",
    "        matchup_file = matchup + \".xlsx\"\n",
    "        \n",
    "        # Fill in missings with team averages\n",
    "        for stat in batter_stat:\n",
    "            try:\n",
    "                stat_mean = away_batters[stat].mean()\n",
    "                away_batters[stat].fillna(stat_mean, inplace=True)\n",
    "            except:\n",
    "                away_batters[stat].fillna(\"R\", inplace=True)\n",
    "                \n",
    "            try:\n",
    "                stat_mean = home_batters[stat].mean()\n",
    "                home_batters[stat].fillna(stat_mean, inplace=True)\n",
    "            except:\n",
    "                home_batters[stat].fillna(\"R\", inplace=True)\n",
    "                \n",
    "        for stat in pitcher_stat:\n",
    "            try:\n",
    "                stat_mean = away_pitchers[stat].mean()\n",
    "                away_pitchers[stat].fillna(stat_mean, inplace=True)\n",
    "            except:\n",
    "                away_pitchers[stat].fillna(\"R\", inplace=True)\n",
    "                \n",
    "            try:\n",
    "                stat_mean = home_pitchers[stat].mean()\n",
    "                home_pitchers[stat].fillna(stat_mean, inplace=True)\n",
    "            except:\n",
    "                home_pitchers[stat].fillna(\"R\", inplace=True)\n",
    "                        \n",
    "                \n",
    "        away_batters.fillna(-99, inplace=True)\n",
    "        away_pitchers.fillna(-99, inplace=True)\n",
    "        home_batters.fillna(-99, inplace=True)\n",
    "        home_pitchers.fillna(-99, inplace=True)\n",
    "        \n",
    "        # Maybe print out players that are imputed and starting\n",
    "        away_batters['imp'] = np.where(away_batters['name_last'] == -99, 1, 0)\n",
    "        away_pitchers['imp'] = np.where(away_pitchers['name_last'] == -99, 1, 0)\n",
    "        home_batters['imp'] = np.where(home_batters['name_last'] == -99, 1, 0)\n",
    "        home_pitchers['imp'] = np.where(home_pitchers['name_last'] == -99, 1, 0)\n",
    "        \n",
    "        # Write to Excel\n",
    "        away_batters.to_excel(os.path.join(baseball_path, \"A7. Matchups - 2. Matchups\", matchup_folder, matchup_file), sheet_name=\"AwayBatters\", engine='openpyxl')\n",
    "\n",
    "        with pd.ExcelWriter(os.path.join(baseball_path, \"A7. Matchups - 2. Matchups\", matchup_folder, matchup_file), mode='a', engine='openpyxl') as writer:  \n",
    "            away_pitchers.to_excel(writer, sheet_name='AwayPitchers')\n",
    "\n",
    "        with pd.ExcelWriter(os.path.join(baseball_path, \"A7. Matchups - 2. Matchups\", matchup_folder, matchup_file), mode='a', engine='openpyxl') as writer:  \n",
    "            home_batters.to_excel(writer, sheet_name='HomeBatters')\n",
    "\n",
    "        with pd.ExcelWriter(os.path.join(baseball_path, \"A7. Matchups - 2. Matchups\", matchup_folder, matchup_file), mode='a', engine='openpyxl') as writer:  \n",
    "            home_pitchers.to_excel(writer, sheet_name='HomePitchers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64f73e5-e04b-4504-89a8-062886b1f1c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a19ff23-0f72-4de1-ad08-8df9afade7a2",
   "metadata": {},
   "source": [
    "### Run One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "734980f7-8d3e-43c6-84db-52297f53b451",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TOR_BAL 06142023 0705PM ET', 'LAA_TEX 06142023 0805PM ET', 'NYY_NYM 06142023 0710PM ET', 'WSN_HOU 06142023 0810PM ET', 'CHW_LAD 06142023 1010PM ET', 'TBR_OAK 06142023 0940PM ET', 'PHI_ARI 06142023 0940PM ET', 'MIA_SEA 06142023 0940PM ET', 'CLE_SDP 06142023 0940PM ET', 'PIT_CHC 06142023 0805PM ET', 'COL_BOS 06142023 0710PM ET', 'CIN_KCR 06142023 0810PM ET']\n",
      "2023-06-14\n",
      "TOR_BAL 06142023 0705PM ET\n",
      "NYY_NYM 06142023 0710PM ET\n",
      "COL_BOS 06142023 0710PM ET\n",
      "LAA_TEX 06142023 0805PM ET\n",
      "PIT_CHC 06142023 0805PM ET\n",
      "WSN_HOU 06142023 0810PM ET\n",
      "CIN_KCR 06142023 0810PM ET\n",
      "TBR_OAK 06142023 0940PM ET\n",
      "PHI_ARI 06142023 0940PM ET\n",
      "MIA_SEA 06142023 0940PM ET\n",
      "CLE_SDP 06142023 0940PM ET\n",
      "CHW_LAD 06142023 1010PM ET\n"
     ]
    }
   ],
   "source": [
    "# Create daily matchups:\n",
    "# Note: early should default to false, although it only matters in double headers\n",
    "create_matchups(date=todaysdate, backtest=False, early=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5de793d-3a07-46f9-a05b-7a7d3feab875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e26ba02-7530-42d5-9d30-3951563219f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76624d87-463e-4a4a-958c-227404a58fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for filename in os.listdir(r\"C:\\Users\\james\\Documents\\MLB\\Data\\A7. Matchups - 1. Salaries\"): \n",
    "#     # 2023 \n",
    "#     if filename.endswith(\".csv\") and filename.startswith(\"DKSalaries_2023\"):\n",
    "#         # Pull out date\n",
    "#         date = filename[11:19]\n",
    "#         print(date)\n",
    "#         try:\n",
    "#             create_matchups(date=date, backtest=False, early=False)\n",
    "#         except:\n",
    "#             print(\"It ain't work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5abf8b66-fdc6-4d31-aaa9-f3d6f59b4ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code was last run on: 2023-06-14 at 23:46:59.\n"
     ]
    }
   ],
   "source": [
    "print(\"Code was last run on: {} at {}.\".format(datetime.date.today(), datetime.datetime.now().strftime(\"%H:%M:%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc68cc9-4bd3-4a3d-a339-db8f7b186bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dadd97-28e9-442f-811a-26ca0f799ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4c87f0-98b2-4732-9d38-ae82e4c5d4be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
