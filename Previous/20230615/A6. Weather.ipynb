{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A6. Weather\n",
    "Source: Swish Analytics <br>\n",
    "\n",
    "Description: This scrapes Swish Analytics for daily weather data <br>\n",
    "Historic data can be found using the stats API <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import requests\n",
    "import datetime\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, Request\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "baseball_path = r\"C:\\Users\\james\\Documents\\MLB\\Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Today's Date\n",
    "# YYYY-MM-DD (datetime)\n",
    "todaysdate_dt = datetime.date.today()\n",
    "\n",
    "# YYYY-MM-DD (string)\n",
    "todaysdate_dash = str(todaysdate_dt)\n",
    "\n",
    "# MM/DD/YYYY\n",
    "todaysdate_slash = todaysdate_dash.split(\"-\")\n",
    "todaysdate_slash = todaysdate_slash[1] + \"/\" + todaysdate_slash[2] + \"/\" + todaysdate_slash[0]\n",
    "\n",
    "# YYYYMMDD\n",
    "todaysdate = todaysdate_dash.replace(\"-\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This reads in a map of team name, codes, and the number Fangraphs uses in their URLs\n",
    "team_map = pd.read_csv(os.path.join(baseball_path, \"Utilities\", \"Team Map.csv\"))\n",
    "\n",
    "# We just need teams right now\n",
    "team_map = team_map[['FANGRAPHSTEAM', 'BBREFTEAM', 'FULLNAME', 'VENUE_ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This reverses winds so that they're named for where they're going, not where they're from. This is so vectors make more sense logically.\n",
    "def wind_reverser(direction):\n",
    "    direction = direction.replace(\"N\", \"s\")\n",
    "    direction = direction.replace(\"S\", \"n\")\n",
    "    direction = direction.replace(\"E\", \"w\")\n",
    "    direction = direction.replace(\"W\", \"e\")\n",
    "    \n",
    "    return direction.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This calculates number of degrees for each direction\n",
    "def find_degree(direction):\n",
    "    if direction == \"N\":\n",
    "        degree = 0\n",
    "    elif direction == \"NNE\":\n",
    "        degree = 1\n",
    "    elif direction == \"NE\":\n",
    "        degree = 2\n",
    "    elif direction == \"ENE\":\n",
    "        degree = 3\n",
    "    elif direction == \"E\":\n",
    "        degree = 4\n",
    "    elif direction == \"ESE\":\n",
    "        degree = 5\n",
    "    elif direction == \"SE\":\n",
    "        degree = 6\n",
    "    elif direction == \"SSE\":\n",
    "        degree = 7\n",
    "    elif direction == \"S\":\n",
    "        degree = 8\n",
    "    elif direction == \"SSW\":\n",
    "        degree = 9\n",
    "    elif direction == \"SW\":\n",
    "        degree = 10\n",
    "    elif direction == \"WSW\":\n",
    "        degree = 11\n",
    "    elif direction == \"W\":\n",
    "        degree = 12\n",
    "    elif direction == \"WNW\":\n",
    "        degree = 13\n",
    "    elif direction == \"NW\":\n",
    "        degree = 14\n",
    "    elif direction == \"NNW\":\n",
    "        degree = 15\n",
    "        \n",
    "    degree = degree * 22.5 \n",
    "\n",
    "    return degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This calculates the x and y vectors given the park's orientation and the wind's direction\n",
    "def calculate_vectors(row):\n",
    "    # Determines degree of centerfield\n",
    "    park_angle = find_degree(row['CF'])\n",
    "    # Determine degree of wind\n",
    "    row['Direction'] = wind_reverser(row['Direction'])\n",
    "    wind_angle = find_degree(row['Direction']) \n",
    "    \n",
    "    # Determine angle between them\n",
    "    angle = wind_angle - park_angle \n",
    "\n",
    "    # Calculate vectors\n",
    "    x_vect = round(math.sin(math.radians(angle)), 5) * row['Speed']\n",
    "    y_vect = round(math.cos(math.radians(angle)), 5) * row['Speed']\n",
    "\n",
    "    return x_vect, y_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape, scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape swishanalytics for weather date\n",
    "# Create the URL \n",
    "url = \"https://swishanalytics.com/mlb/weather?date=\" + todaysdate_dash\n",
    "\n",
    "# Use this to spoof a browser\n",
    "hdr = {'User-Agent':'Mozilla/5.0'}\n",
    "\n",
    "# I don't know what any of this does\n",
    "req = urllib.request.Request(url, headers=hdr)\n",
    "response = urlopen(req)\n",
    "soup = BeautifulSoup(response, \"html.parser\")\n",
    "\n",
    "# So this create a list of matchups in the order of the weather tables\n",
    "matchup_list = []\n",
    "text = soup.find_all(text=True)\n",
    "for t in text: \n",
    "    if \"\\xa0\\xa0@\\xa0\\xa0\" in t:\n",
    "        if t.parent.name != \"small\":\n",
    "            matchup_list.append(t.parent)\n",
    "\n",
    "matchup_list_clean = []\n",
    "for matchup in matchup_list:\n",
    "    matchup_clean = str(matchup)\n",
    "    matchup_clean = matchup_clean.replace('<h4 class=\"lato inline vert-mid bold\">\\xa0\\xa0', \"\")\n",
    "    matchup_clean = matchup_clean.replace('\\xa0\\xa0', \"\")\n",
    "    matchup_clean = matchup_clean.replace('</h4>', \"\")\n",
    "    matchup_list_clean.append(matchup_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes with weather by park\n",
    "# If a df_weather exists, get rid of it\n",
    "try:\n",
    "    del df_weather\n",
    "except:\n",
    "    pass\n",
    "\n",
    "r = requests.get(url, headers=hdr)\n",
    "\n",
    "# Loop over every weather table (one for each item in the matchup list)   \n",
    "i = 0\n",
    "while i < len(matchup_list_clean):\n",
    "    # This is the table number\n",
    "    table = 3 + (i * 2)\n",
    "    # Make the table\n",
    "    df = pd.read_html(r.text)[table]\n",
    "       \n",
    "    # Rename columns so they'll be consistent when they're appended together (they're usually hours)\n",
    "    num_col = len(df.columns)\n",
    "    \n",
    "    df.rename(columns={df.columns[num_col-5]:\"Start\", df.columns[num_col-4]:\"Plus1\", df.columns[num_col-3]:\"Plus2\", df.columns[num_col-2]:\"Plus3\", df.columns[num_col-1]:\"Plus4\"}, inplace=True)\n",
    "    \n",
    "    # Create a column with the matchup\n",
    "    df['Matchup'] = matchup_list_clean[i]\n",
    "    \n",
    "    # Try to append if you can, if not, create the weather dataframe\n",
    "    try: \n",
    "        df_weather = df_weather.append(df)\n",
    "    except:\n",
    "        df_weather = df\n",
    "        \n",
    "    i += 1\n",
    "\n",
    "# Clean up a bit\n",
    "df_weather = df_weather.reset_index()\n",
    "df_weather['Start'] = df_weather['Start'].str.replace(u\"°\", \"\")\n",
    "df_weather['Start'] = df_weather['Start'].str.replace(\" mph\", \"\")\n",
    "df_weather['Plus1'] = df_weather['Plus1'].str.replace(u\"°\", \"\")\n",
    "df_weather['Plus1'] = df_weather['Plus1'].str.replace(\" mph\", \"\")\n",
    "\n",
    "# Create temperature, wind speed, and wind direction dataframes\n",
    "df_temp = df_weather[df_weather['Unnamed: 0'] == \"Temp\"]\n",
    "df_speed = df_weather[df_weather['Unnamed: 0'] == \"Wind Speed\"]\n",
    "df_dir = df_weather[df_weather['Unnamed: 0'] == \"Wind Dir\"]\n",
    "\n",
    "# Only keep relevant variables and label them appropriately\n",
    "df_temp = df_temp[['Matchup', 'Plus1']]\n",
    "df_temp.rename(columns={'Plus1': 'TEMP_PARK_CT'}, inplace=True)\n",
    "\n",
    "df_speed = df_speed[['Matchup', 'Plus1']]\n",
    "df_speed.rename(columns={'Plus1': 'Speed'}, inplace=True)\n",
    "\n",
    "df_dir = df_dir[['Matchup', 'Plus1']]\n",
    "df_dir.rename(columns={'Plus1': 'Direction'}, inplace=True)\n",
    "\n",
    "# Merge them all together to get the weather data\n",
    "df_weather_inputs = df_temp.merge(df_speed, on='Matchup', how='inner')\n",
    "df_weather_inputs = df_weather_inputs.merge(df_dir, on='Matchup', how='inner')\n",
    "\n",
    "# Choose the home team \n",
    "df_weather_inputs['FANGRAPHSTEAM'] = df_weather_inputs['Matchup'].str.split(\"@\").str[1]\n",
    "df_weather_inputs = pd.merge(df_weather_inputs, team_map, on='FANGRAPHSTEAM', how='left')\n",
    "df_weather_inputs.rename(columns={'BBREFTEAM':'Team'}, inplace=True)\n",
    "\n",
    "# Convert to numeric\n",
    "df_weather_inputs['Speed'] = df_weather_inputs['Speed'].astype('float')\n",
    "df_weather_inputs['TEMP_PARK_CT'] = df_weather_inputs['TEMP_PARK_CT'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in ballpark orientations (which direction center field is in relation to home plate)\n",
    "orientations = pd.read_excel(os.path.join(baseball_path, \"Utilities\", \"Park Orientations.xlsx\"))\n",
    "\n",
    "# Merge with weather data\n",
    "weather = orientations.merge(df_weather_inputs, on='Team', how='inner')\n",
    "\n",
    "# Calculate wind vectors\n",
    "weather[['x_vect', 'y_vect']] = weather.apply(calculate_vectors, axis=1, result_type='expand')\n",
    "\n",
    "# Only keep second game of a double header\n",
    "weather = weather.drop_duplicates(subset='Matchup', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BBREFTEAM</th>\n",
       "      <th>x_vect</th>\n",
       "      <th>y_vect</th>\n",
       "      <th>TEMP_PARK_CT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>OAK</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LAD</td>\n",
       "      <td>3.329316</td>\n",
       "      <td>8.037756</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOS</td>\n",
       "      <td>-3.176244</td>\n",
       "      <td>7.668204</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HOU</td>\n",
       "      <td>7.071100</td>\n",
       "      <td>7.071100</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SEA</td>\n",
       "      <td>2.181276</td>\n",
       "      <td>5.266116</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NYM</td>\n",
       "      <td>11.640888</td>\n",
       "      <td>4.821768</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAL</td>\n",
       "      <td>10.901784</td>\n",
       "      <td>4.515624</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DET</td>\n",
       "      <td>1.722060</td>\n",
       "      <td>4.157460</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARI</td>\n",
       "      <td>8.776860</td>\n",
       "      <td>3.635460</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MIN</td>\n",
       "      <td>6.467160</td>\n",
       "      <td>2.678760</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TEX</td>\n",
       "      <td>-6.374772</td>\n",
       "      <td>2.640492</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>STL</td>\n",
       "      <td>5.173728</td>\n",
       "      <td>2.143008</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KCR</td>\n",
       "      <td>-3.695520</td>\n",
       "      <td>-1.530720</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHC</td>\n",
       "      <td>-5.912832</td>\n",
       "      <td>-2.449152</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SDP</td>\n",
       "      <td>7.668204</td>\n",
       "      <td>-3.176244</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BBREFTEAM     x_vect    y_vect  TEMP_PARK_CT\n",
       "17       OAK   0.000000  9.600000            61\n",
       "14       LAD   3.329316  8.037756            62\n",
       "2        BOS  -3.176244  7.668204            64\n",
       "12       HOU   7.071100  7.071100            87\n",
       "19       SEA   2.181276  5.266116            59\n",
       "16       NYM  11.640888  4.821768            64\n",
       "1        BAL  10.901784  4.515624            73\n",
       "11       DET   1.722060  4.157460            72\n",
       "0        ARI   8.776860  3.635460            91\n",
       "15       MIN   6.467160  2.678760            83\n",
       "21       TEX  -6.374772  2.640492            88\n",
       "20       STL   5.173728  2.143008            87\n",
       "13       KCR  -3.695520 -1.530720            78\n",
       "3        CHC  -5.912832 -2.449152            63\n",
       "18       SDP   7.668204 -3.176244            64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in list of parks\n",
    "all_parks = pd.read_csv(os.path.join(baseball_path, \"Utilities\", \"All Parks.csv\"))\n",
    "# Create dummies for each park (set = 0)\n",
    "venue_dummies = pd.get_dummies(all_parks['venue_id'], prefix='venue')\n",
    "for col in venue_dummies.columns:\n",
    "    weather[col] = 0\n",
    "# Look over VENUE_ID, set venue_ dummy = 1 if it corresponds to VENUE_ID\n",
    "for venue in weather['VENUE_ID'].unique().tolist():\n",
    "    venue_dummy = \"venue_\" + str(venue)\n",
    "    weather[venue_dummy] = np.where(weather['VENUE_ID'] == venue, 1, 0)\n",
    "\n",
    "# Create variables\n",
    "# More variables exist in backtest data (from API) that aren't needed when scraping day-of\n",
    "weather['game_date'] = todaysdate\n",
    "weather['venue_id'] = weather['VENUE_ID']\n",
    "weather['BBREFTEAM'] = weather['Team']\n",
    "weather['weather'] = \"Missing\"\n",
    "weather['Speed'] = \"Missing\"\n",
    "weather['CF_angle'] = \"Missing\"\n",
    "weather['wind_angle'] = \"Missing\"\n",
    "weather['angle'] = \"Missing\"\n",
    "\n",
    "# Keep relevant variables\n",
    "weather = weather[['venue_id', 'game_date', 'weather', 'Speed', 'BBREFTEAM', 'CF', \n",
    "         'TEMP_PARK_CT', 'Speed', 'CF_angle', 'wind_angle', 'angle', 'x_vect', \n",
    "         'y_vect',\n",
    "         'venue_1',    'venue_2',    'venue_3',    'venue_4',    'venue_5', 'venue_7', \n",
    "         'venue_10',   'venue_12',   'venue_13',   'venue_14',   'venue_15',   \n",
    "         'venue_16',   'venue_17',   'venue_19',   'venue_22',   'venue_31',\n",
    "         'venue_32',   'venue_680',  'venue_2392', 'venue_2394', 'venue_2395',\n",
    "         'venue_2535', 'venue_2536', 'venue_2602', 'venue_2680', 'venue_2681',\n",
    "         'venue_2701', 'venue_2735', 'venue_2756', 'venue_2889', 'venue_3289',\n",
    "         'venue_3309', 'venue_3312', 'venue_3313', 'venue_4169', 'venue_4705',\n",
    "         'venue_5010', 'venue_5325', 'venue_5365', 'venue_5381', 'venue_5445']]\n",
    "    \n",
    "    \n",
    "# Create daily weather file\n",
    "weather.to_excel(os.path.join(baseball_path, \"A6. Weather\", \"Daily_Weather_\" + todaysdate + \".xlsx\"), index=False)\n",
    "\n",
    "\n",
    "weather[['BBREFTEAM', 'x_vect', 'y_vect', 'TEMP_PARK_CT']].sort_values('y_vect', ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code was last run on: 2023-06-14 at 18:28:54.\n"
     ]
    }
   ],
   "source": [
    "print(\"Code was last run on: {} at {}.\".format(datetime.date.today(), datetime.datetime.now().strftime(\"%H:%M:%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
