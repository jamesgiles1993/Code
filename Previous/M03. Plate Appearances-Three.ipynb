{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "246dcb35-a0f2-4ce2-a46e-f6b8c1053bf2",
   "metadata": {},
   "source": [
    "# M03. Predict PAs\n",
    "- This predicts the outcome of plate appearances\n",
    "- Type: Model\n",
    "- Run Frequency: Irregular\n",
    "- Sources:\n",
    "    - MLB API\n",
    "    - Steamer\n",
    "- Dates:\n",
    "    - Created: 4/19/2024\n",
    "    - Updated: 4/21/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72339d03-2fb3-4067-97eb-994324eb3c21",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4534de56-4550-4dce-99fc-73d526095998",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"U1. Imports.ipynb\"\n",
    "%run \"U2. Utilities.ipynb\"\n",
    "%run \"U3. Classes.ipynb\"\n",
    "%run \"U4. Datasets.ipynb\"\n",
    "%run \"U5. Models.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67afe9b9-2ede-417d-873a-acfb5e5e7ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set option to display numbers without scientific notation\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034975ab-8382-4a5b-988d-64745d11cec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81a6014a-eb27-4083-9537-1ec7e127de15",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb08ca5-c5d6-4660-b5b7-3d9296d116ad",
   "metadata": {},
   "source": [
    "##### Park x Weather Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8c4a68-63ea-4fc3-aeb8-f24391e9887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplier_df = pd.read_csv(os.path.join(baseball_path, \"Multiplier Dataset.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bd9517-fc3e-4366-bd46-2dfce7c7c7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3da3950c-f72c-489f-8d4c-58e39ffe3a89",
   "metadata": {},
   "source": [
    "##### Stats API and Statcast Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d2ebfd-f97e-4f95-a307-f6ee176bd478",
   "metadata": {},
   "source": [
    "Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862dd887-6a8c-491e-9272-2583b9d239b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# complete_dataset = create_pa_inputs(multiplier_df, 2015, 2024, short=50, long=300, adjust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11183e5a-182f-4640-ae17-d4591b516c97",
   "metadata": {},
   "source": [
    "Write to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f5512d-d06a-4dd6-8909-08aa909e47a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_dataset.to_csv(os.path.join(baseball_path, \"nn_dataset.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc189ba-7baa-46f6-84af-52a00c19c8f0",
   "metadata": {},
   "source": [
    "Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08d1bc6-54b9-46b5-b93d-5d0ee40cae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset = pd.read_csv(os.path.join(baseball_path, \"nn_dataset.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee27de4-ce5b-47c5-a4cf-c830466c46c8",
   "metadata": {},
   "source": [
    "Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52508861-52f1-4d58-8c14-f481006a1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "complete_dataset[batter_inputs] = scale_batter_stats.transform(complete_dataset[batter_inputs])\n",
    "complete_dataset[pitcher_inputs] = scale_pitcher_stats.transform(complete_dataset[pitcher_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b866ef9-6f8c-4e06-a7ed-e592704bbe89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31af98da-c1d1-43f0-a38d-7992b6b96f0a",
   "metadata": {},
   "source": [
    "##### Steamer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c57230d-cd56-4185-80d5-175e339ff5b7",
   "metadata": {},
   "source": [
    "Read in hitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef91c4c-14d8-4e8d-98d1-fcc3d34333d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_hitters_df = pd.read_csv(os.path.join(baseball_path, \"A03. Steamer\", \"steamer_hitters_weekly_log.csv\"), encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb08b20-1f0d-4272-868a-a071205b819a",
   "metadata": {},
   "source": [
    "Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4194d026-dbb6-43c7-aed1-0ba7f2dcc416",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_hitters_df2 = clean_steamer_hitters(steamer_hitters_df)\n",
    "steamer_hitters_df2.dropna(subset=batter_stats_fg, inplace=True)\n",
    "steamer_hitters_df2[batter_stats_fg] = scale_batter_stats_steamer.transform(steamer_hitters_df2[batter_stats_fg])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bc62f8-205d-4fca-8fe7-77090575ca6f",
   "metadata": {},
   "source": [
    "Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ecadf9-e251-4390-819a-ab4133a8e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_hitters_df2[batter_stats_fg] = scale_batter_stats_steamer.transform(steamer_hitters_df2[batter_stats_fg])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ba419a-58da-4569-a47f-81f42e99c149",
   "metadata": {},
   "source": [
    "Read in pitchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe7d409-3aba-4c26-b7ff-4e0bac53dd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_pitchers_df = pd.read_csv(os.path.join(baseball_path, \"A03. Steamer\", \"steamer_pitchers_weekly_log.csv\"), encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e7bc1b-2165-40de-b18a-5ce4a5eeda4d",
   "metadata": {},
   "source": [
    "Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc05c0e-a762-4dd1-b624-0a3eef35f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_pitchers_df2 = clean_steamer_pitchers(steamer_pitchers_df)\n",
    "steamer_pitchers_df2.dropna(subset=pitcher_stats_fg2, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2d3acf-0351-4fe4-8c58-324a41c7ffc7",
   "metadata": {},
   "source": [
    "Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96034fe3-b3ea-4798-a317-14644903ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_pitchers_df2[pitcher_stats_fg] = scale_pitcher_stats_steamer.transform(steamer_pitchers_df2[pitcher_stats_fg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ed059a-3722-4a35-89f9-29a67c57e0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c115569b-2eb1-4689-976b-2bec2de41de2",
   "metadata": {},
   "source": [
    "##### Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23ab6f4-8ad4-4553-b652-dc309cd750f4",
   "metadata": {},
   "source": [
    "Format dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83073ed4-4a17-4a52-818f-68aef1fc6f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset['date_time'] = pd.to_datetime(complete_dataset['date'], format='%Y%m%d')\n",
    "complete_dataset['date_time_copy'] = complete_dataset['date_time'].copy()\n",
    "steamer_hitters_df2['date_time'] = pd.to_datetime(steamer_hitters_df2['date'], format='%Y%m%d')\n",
    "steamer_pitchers_df2['date_time'] = pd.to_datetime(steamer_pitchers_df2['date'], format='%Y%m%d')\n",
    "\n",
    "steamer_hitters_df2.rename(columns={'mlbamid': 'batter'}, inplace=True)\n",
    "steamer_pitchers_df2.rename(columns={'mlbamid': 'pitcher'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f30dd3-3af8-4091-aa85-0ce10d34cc21",
   "metadata": {},
   "source": [
    "Sort to prep for merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6487f3-2d3a-4610-9f93-2c9df6513a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset.sort_values('date_time', inplace=True)\n",
    "steamer_hitters_df2.sort_values('date_time', inplace=True)\n",
    "steamer_pitchers_df2.sort_values('date_time', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821f1b85-e5c8-4b0f-b14d-b74aa8ae8963",
   "metadata": {},
   "source": [
    "Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b979390c-a523-4916-887e-da6066b32fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_hitters_df2.drop(columns=['date', 'firstname', 'lastname', 'steamerid'], inplace=True)\n",
    "steamer_pitchers_df2.drop(columns=['date', 'firstname', 'lastname', 'steamerid'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11525c81-34ac-4b5e-b4be-93e480287dfb",
   "metadata": {},
   "source": [
    "Remove missing pitchers (occurs occassionally in 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58197e4-5412-4374-be94-7431061c3d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_pitchers_df2 = steamer_pitchers_df2[~steamer_pitchers_df2['pitcher'].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94389ba7-2be4-401e-8010-0d9aa3f2acd5",
   "metadata": {},
   "source": [
    "Set data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0352f70a-489f-4ad8-a38b-4f9e1d0dfa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset['batter'] = complete_dataset['batter'].astype(int).astype(str)\n",
    "complete_dataset['pitcher'] = complete_dataset['pitcher'].astype(int).astype(str)\n",
    "steamer_hitters_df2['batter'] = steamer_hitters_df2['batter'].astype(int).astype(str)\n",
    "steamer_pitchers_df2['pitcher'] = steamer_pitchers_df2['pitcher'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27529d5a-52e6-4ab1-b1de-c0ff138312aa",
   "metadata": {},
   "source": [
    "Merge asof most recent date in Steamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c448db-edaf-4259-9de4-641528042799",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df = pd.merge_asof(\n",
    "    complete_dataset,\n",
    "    steamer_hitters_df2,\n",
    "    on='date_time',\n",
    "    by='batter',  # Group by 'batter'\n",
    "    direction='backward'  # Use 'backward', 'forward', or 'nearest' as appropriate\n",
    ")\n",
    "# Correct datetime (might be unnecessary, but I'm not sure which date_time it takes after the merge)\n",
    "complete_merged_df['date_time'] = complete_merged_df['date_time_copy'].copy()\n",
    "\n",
    "complete_merged_df = pd.merge_asof(\n",
    "    complete_merged_df,\n",
    "    steamer_pitchers_df2,\n",
    "    on='date_time',\n",
    "    by='pitcher',  # Group by 'batter'\n",
    "    direction='backward'  # Use 'backward', 'forward', or 'nearest' as appropriate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c062496f-1cb1-42d2-bc85-1a505271bcfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "455ace11-7229-4b30-bf8f-d39d3d778dc5",
   "metadata": {},
   "source": [
    "##### Impute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf31f9e-9599-42f5-a2fd-57cabeb86a21",
   "metadata": {},
   "source": [
    "For players with insufficient sample sizes, stats are imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e123af-6012-4391-b253-5d6aadd9d5c5",
   "metadata": {},
   "source": [
    "Option 1: Steamer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded33168-3847-4abb-b652-3ef67fa1bfb1",
   "metadata": {},
   "source": [
    "First, remove from dataset if ever missing FG/Steamer stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dbca98-3a4a-4644-80ef-9d5623791ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df = complete_merged_df[~complete_merged_df['b1_rate'].isna()]\n",
    "complete_merged_df = complete_merged_df[~complete_merged_df['H9'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500f4ca2-ffde-4601-90d1-44826dc538f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add hands to use in imputation\n",
    "batter_stats_fg_imp = batter_stats_fg + ['b_L', 'p_L']\n",
    "pitcher_stats_fg_imp = pitcher_stats_fg + ['b_L', 'p_L']\n",
    "\n",
    "### Batters\n",
    "# Use Steamer stats to predict API/Statcast stats for those with limited samples\n",
    "batter_predictions = impute_batter_stats.predict(complete_merged_df.loc[complete_merged_df['pa_b'] < 40, batter_stats_fg_imp])\n",
    "\n",
    "# Impute inputs with limited sample size with predicted values\n",
    "complete_merged_df.loc[complete_merged_df['pa_b'] < 40, batter_inputs] = batter_predictions\n",
    "\n",
    "### Pitchers\n",
    "# Use Steamer stats to predict API/Statcast stats for those with limited samples\n",
    "pitcher_predictions = impute_pitcher_stats.predict(complete_merged_df.loc[complete_merged_df['pa_p'] < 40, pitcher_stats_fg_imp])\n",
    "\n",
    "# Impute inputs with limited sample size with predicted values\n",
    "complete_merged_df.loc[complete_merged_df['pa_p'] < 40, pitcher_inputs] = pitcher_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95462618-9051-4892-a8ff-89c721fcfd94",
   "metadata": {},
   "source": [
    "Option 2: 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6348bdb-6a17-4c4f-9e5f-96ca3143a06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing instead of imputing, just weighting with 0s\n",
    "# complete_merged_df[batter_inputs].fillna(0, inplace=True)\n",
    "# complete_merged_df[pitcher_inputs].fillna(0, inplace=True)\n",
    "\n",
    "# # Calculate the weighted average for each column in pitcher_stats\n",
    "# # Could be simplified, but I wanted to show the steps\n",
    "# # Weighted average of provided value and 0. PAs and 50-PAs are weights. \n",
    "# for col in batter_inputs:\n",
    "#     complete_merged_df[col] = (complete_merged_df[col] * complete_merged_df['pa_b'] + 0 * (50-complete_merged_df['pa_b']))/50\n",
    "\n",
    "# # Calculate the weighted average for each column in pitcher_stats\n",
    "# for col in pitcher_inputs:\n",
    "#     complete_merged_df[col] = (complete_merged_df[col] * complete_merged_df['pa_p'] + 0 * (50-complete_merged_df['pa_p']))/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4efb4e-3b69-40eb-bf50-41ff56292730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7ddb37c-4952-4f64-8adf-2041ee2d1fb4",
   "metadata": {},
   "source": [
    "### Select Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477bd072-5b6a-4fd0-a1e8-a6684523b347",
   "metadata": {},
   "source": [
    "Drop early observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918584cf-b36e-4562-82e5-2a5de3f107b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df = complete_merged_df[complete_merged_df['game_date'] > '2015-07-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb32714-d856-448e-9cdd-1bbfe7c27a04",
   "metadata": {},
   "source": [
    "Drop atypical events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b16b03-1a40-4dd9-9ec4-f01c5e0519ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df = complete_merged_df.query('eventsModel != \"Cut\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e08a90-2b2d-467b-8445-1d8429866b83",
   "metadata": {},
   "source": [
    "Drop observations from inactive parks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6c585d-7a56-41bc-a08d-eea21df321c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_parks = list(team_map['VENUE_ID'].astype(int))\n",
    "complete_merged_df = complete_merged_df[complete_merged_df['venue_id'].astype(int).isin(active_parks)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb08877-624a-4fb9-800a-2383d63639d9",
   "metadata": {},
   "source": [
    "Venue dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4eab78-befd-4a87-adab-552915e74d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df['venue_id2'] = complete_merged_df['venue_id'].copy()\n",
    "complete_merged_df = pd.get_dummies(complete_merged_df, columns=['venue_id2'], prefix='venue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87917ec-f544-4827-96dc-8deeecdb6615",
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_dummy_list = [col for col in complete_merged_df.columns if col.startswith(\"venue_\") and col != \"venue_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1617541-f916-4c83-a5b1-2fff03b7f792",
   "metadata": {},
   "source": [
    "Park x weather multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b011c2b-b0b7-446e-bc1f-a1893183bf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in events_list:\n",
    "    # Assign multiplier for their \n",
    "    complete_merged_df[f'{event}_wfx'] = np.where(complete_merged_df['batSide'] == \"L\", complete_merged_df[f'{event}_wfx_l'], complete_merged_df[f'{event}_wfx_r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60285c38-348b-49d2-aa90-6b5c51fe5373",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplier_inputs = [f'{event}_wfx' for event in events_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef23881-52a4-4d5a-9424-919f3b76ffe1",
   "metadata": {},
   "source": [
    "Leading dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b42c6b-2ce7-4b1a-8927-3ab99ef7caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df['winning'] = (complete_merged_df['preBatterScore'] > complete_merged_df['prePitcherScore']).astype(int)\n",
    "complete_merged_df['winning_big'] = (complete_merged_df['preBatterScore'] > complete_merged_df['prePitcherScore'] + 3).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb871ab-93d1-4713-bf5a-c5c054a6f1c5",
   "metadata": {},
   "source": [
    "Inning dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d221d8-c785-470b-81ea-e76334285b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inning in range(1, 12):\n",
    "    complete_merged_df[f'inning_{inning}'] = (complete_merged_df['inning'] == inning).astype(int)\n",
    "complete_merged_df['inning_11'] = (complete_merged_df['inning'] >= 11).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caca2a2-47c9-40a6-abe3-283bb51b6c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "inning_dummy_list = [col for col in complete_merged_df.columns if col.startswith(\"inning_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaf70fd-d3ae-42ec-8d5b-02fa6b5a9135",
   "metadata": {},
   "source": [
    "Out dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5b608a-f155-4df1-88fe-e78c252690ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_merged_df[['description', 'outs', 'outs_pre', 'outs_pa', 'outs_pa_inning', 'outs_0', 'outs_1', 'outs_2']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afbd8f1-a5a8-4703-9990-e276f9042f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for out in range(0, 3):\n",
    "    complete_merged_df[f'outs_{out}'] = (complete_merged_df['outs_pre'] == out).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0572d99b-6624-4d63-92d1-8885b73f736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dummy_list = ['outs_0', 'outs_1', 'outs_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0302e663-9682-4a5f-91bd-6563ac42bdd3",
   "metadata": {},
   "source": [
    "Cumulative variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be619b5-4a50-40a5-b5ba-92d371347db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_inning_list = [col for col in complete_merged_df.columns if col.endswith(\"_inning\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759dce85-6a13-468d-843a-4233436e2427",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_inning_list.remove('rbi_inning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3efd012-4862-45ef-bb1d-c46c45543db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_game_list = [col for col in complete_merged_df.columns if col.endswith(\"_game\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ed7fe9-eedf-4b17-b50f-b063ac0a55b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_game_list.remove('rbi_game')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18e14f3-e49b-4e0b-9403-4bc722bb3047",
   "metadata": {},
   "source": [
    "All Test Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a187f5-a21d-40ff-a356-d8a88c013759",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = ['prePitcherScore', 'preBatterScore', 'winning', 'winning_big', 'times_faced'] + cumulative_inning_list + cumulative_game_list + venue_dummy_list + inning_dummy_list + out_dummy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af08b8fc-e202-44d4-aab1-fb5bf3b29eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d888da0-e487-48a5-a96e-6c86bedb3e25",
   "metadata": {},
   "source": [
    "### Shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12c7c0b-594f-4eab-ba8f-2198056b444a",
   "metadata": {},
   "source": [
    "Many batter and pitcher stats are calculated at the end of the plate appearance. For prediction purposes, we need these stats coming into the plate appearance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065f102b-3eab-4989-b453-206579c60fb8",
   "metadata": {},
   "source": [
    "##### Batter Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fea2bb1-777e-4181-a2a0-16cb7363bdab",
   "metadata": {},
   "source": [
    "Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd38ce01-6e7a-4027-a2d6-01ba978c9aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89923df4-805a-46d8-9027-7372749d0156",
   "metadata": {},
   "source": [
    "Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c180e3-f30f-4667-a6e0-a65a6a009c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df[batter_inputs + ['ab_b', 'pa_b', 'imp_b']] = complete_merged_df.groupby(['batter', 'pitchHand'])[batter_inputs + ['ab_b', 'pa_b', 'imp_b']].shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541793ed-0b9d-4a69-9e81-adba638bb0ed",
   "metadata": {},
   "source": [
    "##### Pitcher Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699542c3-f47b-4047-8eed-f232c73f6111",
   "metadata": {},
   "source": [
    "Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d45cce5-c6b9-4def-a41e-55e20d8332ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6aa9bb-1868-460d-aad3-b90f9bcfd748",
   "metadata": {},
   "source": [
    "Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e722928f-a6c7-41e6-b13a-fa802f830b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df[pitcher_inputs + ['ab_p', 'pa_p', 'imp_p']] = complete_merged_df.groupby(['pitcher', 'batSide'])[pitcher_inputs + ['ab_p', 'pa_p', 'imp_p']].shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c92d5b-f855-4e06-90ec-11fda6da6c54",
   "metadata": {},
   "source": [
    "##### Inning Sums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3cec77-5d6d-40f4-9729-d36b1fb0b233",
   "metadata": {},
   "source": [
    "Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0c8db5-1a52-4940-949a-13812a7d5856",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0edfd47-fdcf-45e6-9a49-1accd4623585",
   "metadata": {},
   "source": [
    "Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56a5edf-701c-4a1c-8cac-cb06d858fac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df[cumulative_inning_list] = complete_merged_df.groupby(['gamePk', 'inning', 'pitcher'])[cumulative_inning_list].shift(1)\n",
    "complete_merged_df[cumulative_inning_list] = complete_merged_df[cumulative_inning_list].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bd248a-dfae-4e01-8e99-5e787fde5c8b",
   "metadata": {},
   "source": [
    "##### Game Sums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe139353-6358-46bf-907a-8a9812b65b47",
   "metadata": {},
   "source": [
    "Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d656f8a-0193-4ac7-8267-113bedc83b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df[cumulative_game_list + ['times_faced']] = complete_merged_df.groupby(['gamePk', 'pitcher'])[cumulative_game_list + ['times_faced']].shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6474bf-3cad-4af6-9a1f-e04604695852",
   "metadata": {},
   "source": [
    "Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0f3c32-7ccd-48a4-86f1-45a2600c118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df[cumulative_game_list + ['times_faced']] = complete_merged_df[cumulative_game_list + ['times_faced']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd7acb7-4bdd-4092-9a15-600b61ccc9b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdd7d6e-e1a3-4360-8cd5-7989fa1c9930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_merged_df.query('date == 20240403').query('halfInning == \"top\"')[['gamePk', 'inning', 'inning_1', 'inning_2', 'outs_0', 'outs_1', 'outs_2', 'pitcherName', 'batterName', 'eventsModel', 'times_faced', 'faced_inning', 'faced_game', 'preBatterScore']].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f06117-35d7-4a97-b900-36dbe09881cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "706a9f38-ef35-43bb-8fae-605540c49b31",
   "metadata": {},
   "source": [
    "### Select Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c6d65b-2dc5-4532-9507-0b9b1a1d3270",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_inputs2 = batter_inputs + pitcher_inputs + hand_inputs + game_state_inputs + imp_inputs + starter_inputs + multiplier_inputs + test_inputs\n",
    "keep_list = pa_inputs2 + ['pa_b', 'pa_p', 'year', 'venue_id', 'is_out', 'eventsModel', 'batterName', 'pitcherName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742b9d1f-25fe-4ae2-8144-d73a99d3d582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep relevant variables\n",
    "model_dataset = complete_merged_df[keep_list]\n",
    "# Drop if missing information\n",
    "model_dataset.dropna(subset=pa_inputs2, inplace=True)\n",
    "model_dataset.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf781d0f-ba06-4dc8-a82b-157ad1fea64e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b97fce27-c7a7-4d62-86b2-264bf6ecbab1",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a55de2-d5b1-4083-ba23-64b8ecd7298e",
   "metadata": {},
   "source": [
    "Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21610309-387e-4a06-ad4b-63111f5c67c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "model_dataset['split'] = np.random.choice([0, 0, 1], size=len(model_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3a448c-5411-49f5-ba87-105cc2d1ca6e",
   "metadata": {},
   "source": [
    "Create masks to identify training and testing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb19a8-50f9-447f-b390-f860d3886435",
   "metadata": {},
   "source": [
    "Note: to train on the entire dataset, you can simply set split = 0 for the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa442b2-c628-461b-8c47-550e35edba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_mask = (model_dataset['split'] == 0)\n",
    "testing_mask = (model_dataset['split'] == 1)\n",
    "\n",
    "# training_out_mask = (model_dataset['is_out'] == 1) & (model_dataset['split'] == 0)\n",
    "# testing_out_mask = (model_dataset['is_out'] == 1) & (model_dataset['split'] == 1)\n",
    "\n",
    "# training_safe_mask = (model_dataset['is_out'] == 0) & (model_dataset['split'] == 0)\n",
    "# testing_safe_mask = (model_dataset['is_out'] == 0) & (model_dataset['split'] == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b04c8b-cda8-4cd7-8824-97a57d6c71aa",
   "metadata": {},
   "source": [
    "Free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb30e14-a7d8-4368-a39b-bca912c1d93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del complete_merged_df, complete_dataset, steamer_hitters_df, steamer_hitters_df2, steamer_pitchers_df, steamer_pitchers_df2, multiplier_df,  batter_predictions, pitcher_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1f221c-b6a6-41b8-b677-385dc1abf2d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a191091-9148-4aa5-8d4f-0ab347592f7b",
   "metadata": {},
   "source": [
    "### Outs vs. Safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae0dd16-2d43-490b-9d59-1f9964ea255b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "len(pa_inputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a95258-0999-4273-90f4-9fea096e3624",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Train a single model\n",
    "def train_model(i, training_dataset, pa_inputs2, target, layers, activation, alpha, learning_rate, early_stopping, random_state, iters, batch_size):\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=layers,\n",
    "        activation=activation,\n",
    "        verbose=False,\n",
    "        alpha=alpha,\n",
    "        learning_rate_init=learning_rate,\n",
    "        early_stopping=early_stopping,\n",
    "        random_state=random_state + i,\n",
    "        max_iter=iters,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    model.fit(training_dataset[pa_inputs2], training_dataset[target].values.ravel())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7330b0b-b984-411c-aa20-2e9f4a430e8b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Neural Network Layers\n",
    "layers = (196,196,196)\n",
    "\n",
    "\n",
    "# To string\n",
    "layers_str = ''.join(str(x) for x in layers)\n",
    "binary_filename = f\"predict_binary_{layers_str}_{todaysdate}.sav\"\n",
    "print(binary_filename)\n",
    "\n",
    "activation='relu' # Other models have been deemed worse than relu\n",
    "iters = 100\n",
    "learning_rate = 0.00001\n",
    "alpha = 0.0001\n",
    "early_stopping = True\n",
    "random_state = 100\n",
    "batch_size='auto'\n",
    "# batch_size = 32\n",
    "number_of_models = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be04605a-1ee0-4ae7-86ee-2341026be7e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "##### %%time\n",
    "# List to store model performance stats\n",
    "model_stats = []\n",
    "model_list = []\n",
    "\n",
    "for i in range(number_of_models):\n",
    "    # Train the model\n",
    "    model = train_model(i, model_dataset[training_mask], pa_inputs2, 'is_out', layers, activation, alpha, learning_rate, early_stopping, random_state, iters, batch_size)\n",
    "    model_list.append(model)\n",
    "    \n",
    "    # Predict probabilities\n",
    "    model_dataset.loc[testing_mask, [f'model_{i}_is_safe_pred', f'model_{i}_is_out_pred']] = model.predict_proba(model_dataset.loc[testing_mask, pa_inputs2].astype(float))\n",
    "\n",
    "    # Create decile column for current model\n",
    "    model_dataset.loc[testing_mask, f'model_{i}_decile'] = pd.qcut(model_dataset[testing_mask][f'model_{i}_is_out_pred'], 20, labels=False)\n",
    "\n",
    "    # Group by decile\n",
    "    df = model_dataset[testing_mask].groupby(f'model_{i}_decile')[[f'model_{i}_is_out_pred', 'is_out']].mean().reset_index()\n",
    "\n",
    "    # Calculate projected mean\n",
    "    pred_mean = df[f'model_{i}_is_out_pred'].mean()\n",
    "    \n",
    "    # Calculate actual mean\n",
    "    act_mean = df['is_out'].mean()\n",
    "    \n",
    "    # Calculate mean squared error\n",
    "    df['error_sq'] = (df[f'model_{i}_is_out_pred'] - df['is_out']) ** 2\n",
    "    mse = np.mean(df['error_sq'])\n",
    "\n",
    "    \n",
    "    # Calculate difference from mean\n",
    "    df['diff_mean'] = abs(df[f'model_{i}_is_out_pred'] - pred_mean)\n",
    "    diff_mean = df['diff_mean'].sum()\n",
    "    \n",
    "\n",
    "    # Append model stats\n",
    "    model_stats.append({'model': f'model_{i}', 'index': i, 'mean': act_mean, 'predicted': pred_mean, 'mse': mse, 'diff_mean': diff_mean})\n",
    "    \n",
    "                        \n",
    "    # Graph results\n",
    "    plt.figure(figsize=(6, 6))  # Make the figure square\n",
    "    plt.plot(df[f'model_{i}_is_out_pred'], df['is_out'], marker='o', color='black', label='is_out')\n",
    "    plt.plot(df[f'model_{i}_is_out_pred'], df[f'model_{i}_is_out_pred'], linestyle='--', color='red', label='Ideal')\n",
    "\n",
    "    # Set limits for both axes\n",
    "    plt.xlim(.6, .75)\n",
    "    plt.ylim(.6, .75)\n",
    "\n",
    "    # plt.xlim(0, 1)\n",
    "    # plt.ylim(0, 1)\n",
    "\n",
    "    # Make the aspect ratio equal\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "    plt.xlabel('Predicted Probability of Out')\n",
    "    plt.ylabel('Actual Probability of Out')\n",
    "    plt.title(f'Model {i}: Decile Analysis')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "                        \n",
    "    # Print out stats\n",
    "    print(f\"model_{i}\", f\"index: {i}\", f\"mean: {act_mean}\", f\"predicted: {pred_mean}\", f\"MSE: {mse}\", f\"Integral: {diff_mean}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ccd7c9-2ed7-43b2-bda6-0ef628e939e4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Identify Pareto-optimal models\n",
    "pareto_optimal = []\n",
    "for current in model_stats:\n",
    "    dominated = False\n",
    "    for other in model_stats:\n",
    "        if (\n",
    "            other['mse'] <= current['mse'] and \n",
    "            other['diff_mean'] >= current['diff_mean'] and \n",
    "            (other['mse'] < current['mse'] or other['diff_mean'] > current['diff_mean'])\n",
    "        ):\n",
    "            dominated = True\n",
    "            break\n",
    "    if not dominated:\n",
    "        pareto_optimal.append(current)\n",
    "        \n",
    "# Output Pareto-optimal models\n",
    "print(\"\\nPareto-optimal models:\")\n",
    "for stats in pareto_optimal:\n",
    "    print(f\"Model: {stats['model']}, Mean: {stats['mean']}, Predicted: {stats['predicted']}, Multiplier : {stats['mean'] / stats['predicted']}, MSE: {stats['mse']}, Diff Mean: {stats['diff_mean']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88fe3e1-2527-4d0c-8c29-b3ad16319bc0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 10 relu\n",
    "mses = []\n",
    "diff_means = []\n",
    "\n",
    "for model in model_stats:\n",
    "    diff_means.append(model['diff_mean'])\n",
    "    mses.append(model['mse'])\n",
    "    \n",
    "np.mean(diff_means), np.mean(mses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c798abff-f01b-4d14-b8a4-fd785d23a9f5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(model_list[0], open(os.path.join(model_path, \"M03. Plate Appearances\", binary_filename), 'wb'))\n",
    "binary_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3783e976-c882-474f-b527-1d53a5833428",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model_dataset[testing_mask].query('year == 2024')[['is_out', 'model_14_is_out_pred']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e997e4-e8d0-4e33-8ddf-e3269f6a3622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3aa9d924-5ce5-41bc-8df3-fc2602fbad21",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f2e693-010a-432b-9648-6a69bf8670fb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Neural network layerss\n",
    "layers = (10,)\n",
    "# To string\n",
    "layers_str = ''.join(str(x) for x in layers)\n",
    "# Activation method\n",
    "activation = 'relu'\n",
    "# Iterations\n",
    "iters = 100\n",
    "\n",
    "outs_filename = f\"predict_outs_{layers_str}_{todaysdate}.sav\"\n",
    "print(outs_filename)\n",
    "\n",
    "# Define the individual models in the ensemble\n",
    "models = [\n",
    "    MLPClassifier(hidden_layer_sizes=layers, activation='relu', random_state=1, early_stopping=True, learning_rate_init=0.00001, alpha=0.00001, max_iter=iters),\n",
    "    MLPClassifier(hidden_layer_sizes=layers, activation='relu', random_state=2, early_stopping=True, learning_rate_init=0.00001, alpha=0.00001, max_iter=iters),\n",
    "    MLPClassifier(hidden_layer_sizes=layers, activation='relu', random_state=3, early_stopping=True, learning_rate_init=0.00001, alpha=0.00001, max_iter=iters),\n",
    "\n",
    "]\n",
    "\n",
    "# Create the ensemble classifier using VotingClassifier\n",
    "predict_outs = VotingClassifier(estimators=[('model'+str(i+1), model) for i, model in enumerate(models)], voting='soft', n_jobs=-2).fit(model_dataset[training_out_mask].reset_index(drop=True)[pa_inputs2], model_dataset[training_out_mask][['eventsModel']].values.ravel())\n",
    "\n",
    "# Save model\n",
    "pickle.dump(predict_outs, open(os.path.join(model_path, \"M03. Plate Appearances\", outs_filename), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97405dd2-7c8e-4fdd-af0d-95da09f878b9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Predict out types\n",
    "outs_outputs = list(predict_outs.classes_)\n",
    "outs_outputs_pred = [x + \"_pred\" for x in outs_outputs]\n",
    "\n",
    "model_dataset.loc[testing_out_mask, outs_outputs_pred] = predict_outs.predict_proba(model_dataset[testing_out_mask][pa_inputs2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afdedb5-bd7c-4b70-b3b6-eac6fa1aa748",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create deciles\n",
    "for var in outs_outputs:\n",
    "    # Create actual outcome column\n",
    "    model_dataset.loc[testing_out_mask, f'{var}_act'] = (model_dataset.loc[testing_out_mask, 'eventsModel'] == var).astype(int)\n",
    "    \n",
    "    # Create deciles\n",
    "    model_dataset.loc[testing_out_mask, f'{var}_decile'] = pd.qcut(model_dataset.loc[testing_out_mask, f'{var}_pred'], 10, labels=False)\n",
    "    \n",
    "    # Create aggregated dataframe\n",
    "    globals()[f\"{var}_df\"] = model_dataset.loc[testing_out_mask].groupby(f'{var}_decile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()\n",
    "    # globals()[f\"{var}_df\"] = testing_dataset.query('year >= 2022').loc[mask].groupby(f'{var}_decile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()\n",
    "    # globals()[f\"{var}_df\"] = testing_dataset.query('venue_id == 19').loc[mask].groupby(f'{var}_decile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea5a925-fe18-418c-b64b-cc635d59cf98",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create figures\n",
    "fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "for i, var in enumerate(outs_outputs):\n",
    "    row = i // 3  # Calculate the row index based on the iteration\n",
    "    col = i % 3   # Calculate the column index based on the iteration\n",
    "    axs[row, col].plot(globals()[f\"{var}_df\"][f'{var}_decile'], globals()[f\"{var}_df\"][f'{var}_pred'], color='red')\n",
    "    axs[row, col].plot(globals()[f\"{var}_df\"][f'{var}_decile'], globals()[f\"{var}_df\"][f'{var}_act'], color='black')\n",
    "    axs[row, col].set_title(var)\n",
    "    # axs[row, col].set_ylim(0,0.35)\n",
    "\n",
    "\n",
    "# Add some space between subplots to prevent overlapping\n",
    "fig.tight_layout(pad=.0)\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089ebf8b-1ba1-4a7a-86de-797adefd9adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fe77ff2-1518-4c0e-907a-a3706f86cae5",
   "metadata": {},
   "source": [
    "### Safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced6b458-2a2d-4a61-9780-c9c4943df704",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Neural network layers\n",
    "# layers = (174,174,174,174)\n",
    "# layers = (10,)\n",
    "# layers = (198,198,198,198,198,198)\n",
    "layers = (196,196,196,196,196)\n",
    "# To string\n",
    "layers_str = ''.join(str(x) for x in layers)\n",
    "# Activation method\n",
    "activation = 'relu'\n",
    "# Iterations\n",
    "iters = 100\n",
    "# Alpha\n",
    "alpha = 0.0001\n",
    "# Learning Rate\n",
    "learning_rate = 0.00001\n",
    "# Batch Size\n",
    "batch_size='auto'\n",
    "# batch_size=32\n",
    "# Random state\n",
    "random_state = 10\n",
    "# Number of models\n",
    "num_models = 3\n",
    "\n",
    "safe_filename = f\"predict_safe_{layers_str}_{todaysdate}.sav\"\n",
    "print(safe_filename)\n",
    "\n",
    "\n",
    "\n",
    "# Define the individual models in the ensemble\n",
    "models = [\n",
    "    MLPClassifier(hidden_layer_sizes=layers, activation=activation, verbose=True, alpha=alpha, learning_rate_init=learning_rate, early_stopping=True, random_state=random_state+i, max_iter=iters, batch_size=batch_size)\n",
    "    for i in range(num_models)\n",
    "]\n",
    "\n",
    "# Create the ensemble classifier using VotingClassifier\n",
    "predict_safe = VotingClassifier(estimators=[('model'+str(i+1), model) for i, model in enumerate(models)], voting='soft', n_jobs=-2).fit(model_dataset[training_safe_mask][pa_inputs2], model_dataset[training_safe_mask][['eventsModel']].values.ravel())\n",
    "\n",
    "# Save model\n",
    "pickle.dump(predict_safe, open(os.path.join(model_path, \"M03. Plate Appearances\", safe_filename), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7603c83-8f4c-4e72-a7c8-02355b8ba017",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Predict safe types\n",
    "safe_outputs = list(predict_safe.classes_)\n",
    "safe_outputs_pred = [x + \"_pred\" for x in safe_outputs]\n",
    "\n",
    "model_dataset.loc[testing_safe_mask, safe_outputs_pred] = predict_safe.predict_proba(model_dataset[testing_safe_mask][pa_inputs2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb77236-8a0a-49eb-b701-007078d47ff8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create deciles\n",
    "for var in safe_outputs:    \n",
    "    # Create actual outcome column\n",
    "    model_dataset.loc[testing_safe_mask, f'{var}_act'] = (model_dataset.loc[testing_safe_mask, 'eventsModel'] == var).astype(int)\n",
    "    \n",
    "    # Create deciles\n",
    "    model_dataset.loc[testing_safe_mask, f'{var}_decile'] = pd.qcut(model_dataset.loc[testing_safe_mask, f'{var}_pred'], 10, labels=False)\n",
    "    \n",
    "    # Create aggregated dataframe\n",
    "    globals()[f\"{var}_df\"] = model_dataset.loc[testing_safe_mask].groupby(f'{var}_decile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()\n",
    "    globals()[f\"{var}_df\"] = model_dataset.query('year >= 2022').loc[testing_safe_mask].groupby(f'{var}_decile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()\n",
    "    # globals()[f\"{var}_df\"] = model_dataset.query('venue_id == 19').loc[testing_safe_mask].groupby(f'{var}_decile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4271fdd-d465-4063-b1c6-e0cc266094c3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create figures\n",
    "fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "for i, var in enumerate(safe_outputs):\n",
    "    row = i // 3  # Calculate the row index based on the iteration\n",
    "    col = i % 3   # Calculate the column index based on the iteration\n",
    "    axs[row, col].plot(globals()[f\"{var}_df\"][f'{var}_decile'], globals()[f\"{var}_df\"][f'{var}_act'], color='black')\n",
    "    axs[row, col].plot(globals()[f\"{var}_df\"][f'{var}_decile'], globals()[f\"{var}_df\"][f'{var}_pred'], color='red')\n",
    "    axs[row, col].set_title(var)\n",
    "    # axs[row, col].set_ylim(globals()[df_name][f'{var}_act'].min(),globals()[df_name][f'{var}_act'].max())\n",
    "    \n",
    "\n",
    "# Add some space between subplots to prevent overlapping\n",
    "fig.tight_layout(pad=.0)\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a09a38-9a9b-4f3e-82a5-9c3786ec6e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e1bdc14-c6e1-4df4-b61c-9da997fd7fad",
   "metadata": {},
   "source": [
    "### All"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a00a7c-6b34-4d6c-9d0b-6a6b88d185bd",
   "metadata": {},
   "source": [
    "##### Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8b45df-e352-43aa-bc78-8c1494a0014d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Neural network layers\n",
    "# layers = (196,196,196,196,196,196)\n",
    "layers = (10,)\n",
    "# To string\n",
    "layers_str = ''.join(str(x) for x in layers)\n",
    "# Activation method\n",
    "activation = 'relu'\n",
    "# Iterations\n",
    "iters = 1000\n",
    "# Alpha\n",
    "alpha = 0.0001\n",
    "# Learning Rate\n",
    "learning_rate = 0.00001\n",
    "# Batch Size\n",
    "batch_size='auto'\n",
    "# batch_size=32\n",
    "# Random state\n",
    "random_state = 1000000000\n",
    "# Number of models\n",
    "num_models = 1\n",
    "\n",
    "all_filename = f\"predict_all_{layers_str}_{todaysdate}.sav\"\n",
    "print(all_filename)\n",
    "\n",
    "\n",
    "# Define the individual models in the ensemble\n",
    "models = [\n",
    "    MLPClassifier(hidden_layer_sizes=layers, activation=activation, verbose=True, alpha=alpha, learning_rate_init=learning_rate, early_stopping=True, \n",
    "                  random_state=random_state+i, max_iter=iters, batch_size=batch_size)\n",
    "    for i in range(num_models)]\n",
    "\n",
    "# Create the ensemble classifier using VotingClassifier\n",
    "predict_all = VotingClassifier(estimators=[('model'+str(i+1), model) for i, model in enumerate(models)], voting='soft', n_jobs=-2).fit(model_dataset[training_mask][pa_inputs2], model_dataset[training_mask][['eventsModel']].values.ravel())\n",
    "\n",
    "# Save model\n",
    "pickle.dump(predict_all, open(os.path.join(model_path, \"M03. Plate Appearances\", all_filename), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3655c20d-9d57-47f8-a625-520dd349b977",
   "metadata": {},
   "source": [
    "##### Stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f28fa8-e262-441f-8a9b-afb0a74dabc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Neural network layers\n",
    "# layers = (196,196,196,196,196,196)\n",
    "layers = (196,)\n",
    "layers = (10,)\n",
    "# To string\n",
    "layers_str = ''.join(str(x) for x in layers)\n",
    "# Activation method\n",
    "activation = 'relu'\n",
    "# Iterations\n",
    "iters = 1000\n",
    "# Alpha\n",
    "alpha = 0.0001\n",
    "# Learning Rate\n",
    "learning_rate = 0.00001\n",
    "# Batch Size\n",
    "batch_size='auto'\n",
    "# batch_size=32\n",
    "# Random state\n",
    "random_state = 1000\n",
    "# Number of models\n",
    "num_models = 5\n",
    "cv = 5\n",
    "\n",
    "all_filename = f\"predict_all_{layers_str}_{todaysdate}.sav\"\n",
    "print(all_filename)\n",
    "\n",
    "\n",
    "# Define the individual models in the ensemble\n",
    "models = [\n",
    "    MLPClassifier(hidden_layer_sizes=layers, activation=activation, verbose=True, alpha=alpha, learning_rate_init=learning_rate, early_stopping=True, \n",
    "                  random_state=random_state+i, max_iter=iters, batch_size=batch_size)\n",
    "    for i in range(num_models)]\n",
    "\n",
    "# Define the meta-model\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Create the ensemble classifier using StackingClassifier\n",
    "predict_all = StackingClassifier(\n",
    "    estimators=[('model'+str(i+1), model) for i, model in enumerate(models)], \n",
    "    final_estimator=meta_model, \n",
    "    n_jobs=2, cv=cv\n",
    ").fit(model_dataset[training_mask][pa_inputs2], model_dataset[training_mask][['eventsModel']].values.ravel())\n",
    "\n",
    "# Save model\n",
    "pickle.dump(predict_all, open(os.path.join(model_path, \"M03. Plate Appearances\", all_filename), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61696551-eb87-4361-a346-ca4fc5d395a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict all types\n",
    "all_outputs = list(predict_all.classes_)\n",
    "all_outputs_pred = [x + \"_pred\" for x in all_outputs]\n",
    "\n",
    "model_dataset.loc[testing_mask, all_outputs_pred] = predict_all.predict_proba(model_dataset[testing_mask][pa_inputs2])\n",
    "\n",
    "# Calculate predicted out rate\n",
    "model_dataset['is_out_pred'] = model_dataset[['so_pred', 'fo_pred', 'go_pred', 'lo_pred', 'po_pred']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6854fc43-b351-41c1-a0ab-a825e0ca2251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f2d7d5-e962-4184-8ec3-f19ca8650b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set quantiles\n",
    "quantiles = 40\n",
    "\n",
    "# Create quantiles\n",
    "for var in all_outputs + ['is_out']:    \n",
    "    # Create actual outcome column\n",
    "    model_dataset.loc[testing_mask, f'{var}_act'] = (model_dataset.loc[testing_mask, 'eventsModel'] == var).astype(int)\n",
    "\n",
    "    # Create actual is_out value\n",
    "    if var == \"is_out\":\n",
    "        model_dataset.loc[testing_mask, f'{var}_act'] = model_dataset.loc[testing_mask, 'eventsModel'].isin(['so', 'lo', 'po', 'go', 'fo']).astype(int)\n",
    "    \n",
    "    # Create deciles\n",
    "    model_dataset.loc[testing_mask, f'{var}_quantile'] = pd.qcut(model_dataset.loc[testing_mask, f'{var}_pred'], quantiles, labels=False)\n",
    "    \n",
    "    # Create aggregated dataframe\n",
    "    globals()[f\"{var}_df\"] = model_dataset.loc[testing_mask].groupby(f'{var}_quantile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()\n",
    "    # globals()[f\"{var}_df\"] = model_dataset.query('year >= 2022').loc[testing_mask].groupby(f'{var}_quantile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()\n",
    "    # globals()[f\"{var}_df\"] = model_dataset.query('venue_id == 19').loc[testing_mask].groupby(f'{var}_quantile')[[f'{var}_act', f'{var}_pred']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2b80fd-ddc0-4269-8030-c6d9add60a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figures\n",
    "fig, axs = plt.subplots(4, 3, figsize=(12, 16))\n",
    "\n",
    "for i, var in enumerate(all_outputs + ['is_out']):\n",
    "    row = i // 3  # Calculate the row index based on the iteration\n",
    "    col = i % 3   # Calculate the column index based on the iteration\n",
    "    axs[row, col].plot(globals()[f\"{var}_df\"][f'{var}_quantile'], globals()[f\"{var}_df\"][f'{var}_act'], color='black')\n",
    "    axs[row, col].plot(globals()[f\"{var}_df\"][f'{var}_quantile'], globals()[f\"{var}_df\"][f'{var}_pred'], color='red')\n",
    "    axs[row, col].set_title(var)\n",
    "    # axs[row, col].set_ylim(globals()[df_name][f'{var}_act'].min(),globals()[df_name][f'{var}_act'].max())\n",
    "    \n",
    "\n",
    "# Add some space between subplots to prevent overlapping\n",
    "fig.tight_layout(pad=.0)\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc95693e-032e-4405-abac-f905fe979647",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset['total_bases_act'] = (model_dataset['b1_act'] +\n",
    "                                                  model_dataset['bb_act'] + \n",
    "                                                  model_dataset['hbp_act'] +\n",
    "                                                  model_dataset['b2_act'] * 2 +\n",
    "                                                  model_dataset['b3_act'] * 3 + \n",
    "                                                  model_dataset['hr_act'] * 4\n",
    "                                                 )\n",
    "\n",
    "model_dataset['total_bases_pred'] = (model_dataset['b1_pred'] +\n",
    "                                                  model_dataset['bb_pred'] + \n",
    "                                                  model_dataset['hbp_pred'] +\n",
    "                                                  model_dataset['b2_pred'] * 2 +\n",
    "                                                  model_dataset['b3_pred'] * 3 + \n",
    "                                                  model_dataset['hr_pred'] * 4\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9521a9b4-ee6d-48bc-969b-14dfbe8198bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset[testing_mask][['total_bases_act', 'total_bases_pred']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c302a8-cb90-450f-a65e-c6726399152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_lists = []\n",
    "for event in events_list + ['is_out']:\n",
    "    globals()[f\"{event}_df\"]['se'] = (globals()[f\"{event}_df\"][f'{event}_act'] - globals()[f\"{event}_df\"][f'{event}_pred']) ** 2\n",
    "    stat_list = [event, model_dataset[testing_mask][f'{event}_act'].mean(), model_dataset[testing_mask][f'{event}_pred'].mean(), globals()[f\"{event}_df\"]['se'].mean(), model_dataset[testing_mask][f'{event}_pred'].std()]\n",
    "    stat_lists.append(stat_list)\n",
    "stat_df = pd.DataFrame(stat_lists, columns=['Event', 'Actual', 'Predicted', 'MSE', 'STDev'])\n",
    "pd.options.display.float_format = '{:.3e}'.format\n",
    "\n",
    "print(f\"Layers: {layers}, num_models {num_models}, cv: {cv}, file_name: {all_filename}\")\n",
    "stat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2383c2a-16b2-4e14-bab3-74a554d14c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_lists = []\n",
    "for event in events_list + ['is_out']:\n",
    "    globals()[f\"{event}_df\"]['se'] = (globals()[f\"{event}_df\"][f'{event}_act'] - globals()[f\"{event}_df\"][f'{event}_pred']) ** 2\n",
    "    stat_list = [event, model_dataset[testing_mask][f'{event}_act'].mean(), model_dataset[testing_mask][f'{event}_pred'].mean(), globals()[f\"{event}_df\"]['se'].mean(), model_dataset[testing_mask][f'{event}_pred'].std()]\n",
    "    stat_lists.append(stat_list)\n",
    "stat_df = pd.DataFrame(stat_lists, columns=['Event', 'Actual', 'Predicted', 'MSE', 'STDev'])\n",
    "pd.options.display.float_format = '{:.3e}'.format\n",
    "\n",
    "print(f\"Layers: {layers}, num_models {num_models}, cv: {cv}, file_name: {all_filename}\")\n",
    "stat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d5ddfa-a9ce-4598-b84b-2eccabce6e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_lists = []\n",
    "for event in events_list + ['is_out']:\n",
    "    globals()[f\"{event}_df\"]['se'] = (globals()[f\"{event}_df\"][f'{event}_act'] - globals()[f\"{event}_df\"][f'{event}_pred']) ** 2\n",
    "    stat_list = [event, model_dataset[testing_mask][f'{event}_act'].mean(), model_dataset[testing_mask][f'{event}_pred'].mean(), globals()[f\"{event}_df\"]['se'].mean(), model_dataset[testing_mask][f'{event}_pred'].std()]\n",
    "    stat_lists.append(stat_list)\n",
    "stat_df = pd.DataFrame(stat_lists, columns=['Event', 'Actual', 'Predicted', 'MSE', 'STDev'])\n",
    "pd.options.display.float_format = '{:.3e}'.format\n",
    "\n",
    "print(f\"Layers: {layers}, num_models {num_models}, cv: {cv}, file_name: {all_filename}\")\n",
    "stat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aaeed2-3f8e-4bbd-82a6-1d8f7ecc7238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6e6f84-5188-4601-8874-dc9bf72eacab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset[testing_mask][['total_bases_act', 'total_bases_pred']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77f5538-221b-4f46-9cea-410dd9285839",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_lists = []\n",
    "for event in events_list + ['is_out']:\n",
    "    globals()[f\"{event}_df\"]['se'] = (globals()[f\"{event}_df\"][f'{event}_act'] - globals()[f\"{event}_df\"][f'{event}_pred']) ** 2\n",
    "    stat_list = [event, \n",
    "                 model_dataset[testing_mask][f'{event}_act'].mean(), \n",
    "                 model_dataset[testing_mask][f'{event}_pred'].mean(), \n",
    "                 globals()[f\"{event}_df\"]['se'].mean(), \n",
    "                 model_dataset[testing_mask][f'{event}_pred'].std()\n",
    "                 \n",
    "                ]\n",
    "    stat_lists.append(stat_list)\n",
    "stat_df = pd.DataFrame(stat_lists, columns=['Event', 'Actual', 'Predicted', 'MSE', 'STDev'])\n",
    "pd.options.display.float_format = '{:.3e}'.format\n",
    "\n",
    "print(f\"Layers: {layers}, num_models {num_models}, cv: {cv}, file_name: {all_filename}\")\n",
    "stat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e8ad92-bc4a-412f-b8e8-ad0faf96efd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset[testing_mask][['total_bases_act', 'total_bases_pred']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741b54f2-d743-4f41-9d74-f1cdfb761cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound; winsound.MessageBeep()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
