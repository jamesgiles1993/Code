{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d81b1d7-f86e-400c-8656-cceccfa9c5df",
   "metadata": {},
   "source": [
    "# C02. Projections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14fe0b0-0b8e-448d-96a2-27f5c9950a20",
   "metadata": {},
   "source": [
    "### Sims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f83926-7476-4ba8-bc27-0dc6f68300fe",
   "metadata": {},
   "source": [
    "Merge together game sims for a given stat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8ff46a0-df68-4690-acb4-b8fe680e7985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_game_player_sims(date, matchup, position=\"Both\", stat=\"FP\"):\n",
    "    # Identify simulation folder\n",
    "    simulation_folder = os.path.join(baseball_path, \"B02. Simulations\", \"2. Player Sims\", f\"Matchups {date}\", matchup)\n",
    "    \n",
    "    # Read in file names\n",
    "    player_game_sim_list = os.listdir(simulation_folder)\n",
    "\n",
    "    # Sort the file names numerically (by the number after the underscore)\n",
    "    sorted_file_names = sorted(player_game_sim_list, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "    \n",
    "    # Identify the number of the last sim    \n",
    "    max_sim = int(sorted_file_names[-1].replace(\".csv\", \"\").split(\"_\")[1])\n",
    "    \n",
    "    # Initialize merged_df outside the loop\n",
    "    merged_df = None\n",
    "    \n",
    "    \n",
    "    # List of single game sim results\n",
    "    df_list = []\n",
    "    \n",
    "    # Loop over sims\n",
    "    for sim_num in range(max_sim+1):\n",
    "        if position in [\"Both\", \"Batters\"]:\n",
    "            ### Batters\n",
    "            # If it's the first sim,\n",
    "            if sim_num == 0:\n",
    "                # Read in batters, keeping imputation flags\n",
    "                batter_df = pd.read_csv(os.path.join(simulation_folder, f\"batters_{sim_num}.csv\"), encoding='iso-8859-1', usecols=['fullName', 'imp_b_l', 'imp_b_r', 'confirmed', 'batting_order', f'{stat}'])\n",
    "                # Assign position\n",
    "                batter_df['Position'] = \"batter\"\n",
    "                # Rearrange\n",
    "                batter_df = batter_df[['fullName', 'Position', 'imp_b_l', 'imp_b_r', 'confirmed', 'batting_order', f'{stat}']]\n",
    "                # Rename \n",
    "                batter_df.rename(columns={'imp_b_l':'imp_l', 'imp_b_r':'imp_r'}, inplace=True)\n",
    "            else:\n",
    "                # Read in batters (only need stat because it's always in the same order)\n",
    "                batter_df = pd.read_csv(os.path.join(simulation_folder, f\"batters_{sim_num}.csv\"), encoding='iso-8859-1', usecols=[f'{stat}'])\n",
    "\n",
    "            # Rename to be sim-specific\n",
    "            batter_df.rename(columns={f'{stat}':f'{stat}_{sim_num}'}, inplace=True)\n",
    "\n",
    "        \n",
    "        if position in [\"Both\", \"Pitchers\"]:\n",
    "            ### Pitchers\n",
    "            # If it's the first sim,\n",
    "            if sim_num == 0:\n",
    "                # Read in pitchers, keeping imputation flags\n",
    "                pitcher_df = pd.read_csv(os.path.join(simulation_folder, f\"pitchers_{sim_num}.csv\"), encoding='iso-8859-1', usecols=['fullName', 'imp_p_l', 'imp_p_r', 'confirmed', f'{stat}'])\n",
    "                # Assign position\n",
    "                pitcher_df['Position'] = \"pitcher\"\n",
    "                # Rearrange\n",
    "                pitcher_df = pitcher_df[['fullName', 'Position', 'imp_p_l', 'imp_p_r', 'confirmed', f'{stat}']]\n",
    "                # Rename \n",
    "                pitcher_df.rename(columns={'imp_p_l':'imp_l', 'imp_p_r':'imp_r'}, inplace=True)\n",
    "            else:\n",
    "                # Read in pitchers (only need stat because it's always in the same order)\n",
    "                pitcher_df = pd.read_csv(os.path.join(simulation_folder, f\"pitchers_{sim_num}.csv\"), encoding='iso-8859-1', usecols=[f'{stat}'])\n",
    "\n",
    "            # Rename to be sim-specific\n",
    "            pitcher_df.rename(columns={f'{stat}':f'{stat}_{sim_num}'}, inplace=True)\n",
    "        \n",
    "        if position == \"Both\":\n",
    "            # Concatenate batters and pitchers together \n",
    "            player_df = pd.concat([batter_df, pitcher_df], axis=0)\n",
    "        elif position == \"Batters\":\n",
    "            player_df = batter_df.copy()\n",
    "        else:\n",
    "            player_df = pitcher_df.copy()\n",
    "            \n",
    "        # Add to list of dataframes\n",
    "        df_list.append(player_df)\n",
    "        \n",
    "    # Concatenate all dataframes together\n",
    "    merged_df = pd.concat(df_list, axis=1)\n",
    "    \n",
    "    # Drop duplicates (this is Ohtani)\n",
    "    merged_df.drop_duplicates('fullName', keep='last', inplace=True)\n",
    "        \n",
    "    # If you want to fill missing values with 0\n",
    "    merged_df.fillna(-99, inplace=True)\n",
    "    \n",
    "    # Free up memory\n",
    "    del player_game_sim_list, sorted_file_names, max_sim, simulation_folder\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8742dfe4-1b82-418f-91bc-1fe8b24aeefb",
   "metadata": {},
   "source": [
    "Merge together all player sims for a given contest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8989e786-19b3-41d7-a31f-b8b2a0532e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contest_player_sims(guide, contestKey, position=\"Both\", stat=\"FP\"):\n",
    "    # Pick date\n",
    "    date = guide['date'][0]\n",
    "    \n",
    "    # Identify matchup folder\n",
    "    matchup_folder = os.path.join(baseball_path, \"B02. Simulations\", \"2. Player Sims\", f\"Matchups {date}\")\n",
    "    \n",
    "    # Game simulations\n",
    "    game_player_sims_list = []\n",
    "    \n",
    "    # Loop over matchups\n",
    "    for matchup in os.listdir(matchup_folder):\n",
    "        # Identify gamePk\n",
    "        gamePk = matchup.split(\" \")[1]\n",
    "    \n",
    "        # If it's in the slate,\n",
    "        if int(gamePk) in list(guide['game_id'].unique()):\n",
    "            # Merge together all sim dataframes\n",
    "            game_player_sims = create_game_player_sims(date, matchup, position, stat)\n",
    "            \n",
    "            game_player_sims['gamePk'] = gamePk\n",
    "            \n",
    "            game_player_sims_list.append(game_player_sims)\n",
    "            del game_player_sims, gamePk\n",
    "            \n",
    "            \n",
    "            \n",
    "    # Concatenate all together\n",
    "    player_sims = pd.concat(game_player_sims_list, axis=0)\n",
    "    \n",
    "    del game_player_sims_list, guide, date, matchup_folder\n",
    "        \n",
    "    return player_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f386f574-04fb-40fe-aeb6-90de6ccaea22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f219634d-d85d-4754-83a3-f445948698f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Projections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1a5294-549c-477e-9282-a4902cd3d52f",
   "metadata": {},
   "source": [
    "##### Me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35701d41-0fe8-49d7-b012-54b11a3b0c19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_my_projections(guide, contestKey, stat=\"FP\"):\n",
    "    # Read in player sims\n",
    "    player_sims = create_contest_player_sims(guide, contestKey, stat=\"FP\")\n",
    "    \n",
    "    # Create universal name variable\n",
    "    my_projections = name_clean(player_sims, \"fullName\")\n",
    "\n",
    "    # Create a new column to average sim score\n",
    "    my_projections['Projection_Me'] = my_projections.filter(regex=f'^{stat}_').mean(axis=1)\n",
    "    \n",
    "    return my_projections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eba027e-e18a-4f3e-a2dd-88f344ca23f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### DFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63b404ba-ce5a-4397-92f7-069846eecfd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_dff_projections(guide):\n",
    "    # Identify slate\n",
    "    dff_slate = guide['dff_slate'][0]\n",
    "    \n",
    "    # Identify date\n",
    "    date = guide['date'][0]\n",
    "\n",
    "    # If slate is missing,\n",
    "    if pd.isna(dff_slate) or dff_slate == \"\" or dff_slate is None:\n",
    "        # Use date\n",
    "        dff_slate = date\n",
    "        # Add dashes to match file names\n",
    "        dff_slate = str(dff_slate)\n",
    "        dff_slate = f'{dff_slate[0:4]}-{dff_slate[4:6]}-{dff_slate[6:8]}'\n",
    "        # Read in projections\n",
    "        dff_projections = pd.read_csv(os.path.join(baseball_path, \"A07. Projections\", \"1. DFF\", \"2. Projections\", \"Date\", f\"DFF_MLB_cheatsheet_{dff_slate}.csv\"))\n",
    "\n",
    "    else:\n",
    "        # Read in projections\n",
    "        dff_projections = pd.read_csv(os.path.join(baseball_path, \"A07. Projections\", \"1. DFF\", \"2. Projections\", f\"DFF Projections {dff_slate}.csv\"))\n",
    "\n",
    "    print(dff_projections.head())\n",
    "    try:\n",
    "        dff_projections['Name'] = dff_projections['first_name'] + \" \" + dff_projections['last_name'] \n",
    "        dff_projections.rename(columns={'ppg_projection':'Projection_DFF'}, inplace=True)\n",
    "\n",
    "    except:\n",
    "        dff_projections['Name'] = dff_projections['First Name'] + \" \" + dff_projections['Last Name']    \n",
    "        dff_projections.rename(columns={'PPG':'Projection_DFF'}, inplace=True)\n",
    "        \n",
    "    dff_projections = dff_projections[['Name', 'Projection_DFF']]\n",
    "    # dff_projections.rename(columns={'ppg_projection':'Projection_DFF'}, inplace=True)\n",
    "    dff_projections = name_clean(dff_projections, \"Name\")\n",
    "    \n",
    "    return dff_projections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e7dda0-3dab-4472-8ae3-49332a8298c5",
   "metadata": {},
   "source": [
    "##### RotoWire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0fb337f-9ffe-47b0-b9d3-b2e0c9b97c7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_roto_projections(guide):\n",
    "    # Identify slate\n",
    "    roto_slate = guide['roto_slate'][0]\n",
    "\n",
    "    # Read in projections\n",
    "    roto_projections = pd.read_csv(os.path.join(baseball_path, \"A07. Projections\", \"2. RotoWire\", \"2. Projections\", f\"RotoWire Projections {roto_slate}.csv\"))\n",
    "\n",
    "    roto_projections['Name'] = roto_projections['firstName'] + \" \" + roto_projections['lastName'] \n",
    "    roto_projections = roto_projections[['Name', 'points', 'rostership']]\n",
    "    roto_projections.rename(columns={'points':'Projection_Roto'}, inplace=True)\n",
    "    roto_projections = name_clean(roto_projections, \"Name\")\n",
    "    \n",
    "    return roto_projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044a74d7-6844-45f1-b6c1-06d9468c6aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dce5626e-d433-4ccb-b425-9c23db5f05c6",
   "metadata": {},
   "source": [
    "### Pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27eb6ebd-6c55-4658-8bef-03b4a5139ebb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_projections_pre(daily, quietly=False):\n",
    "    ### Correlations\n",
    "    # My projections with DFF\n",
    "    dff_corr = daily['Projection_Me'].corr(daily['Projection_DFF'])\n",
    "    # My projections with RotoWire\n",
    "    roto_corr = daily['Projection_Me'].corr(daily['Projection_Roto'])\n",
    "    # DFF's projections with Rotowire's\n",
    "    their_corr = daily['Projection_DFF'].corr(daily['Projection_Roto'])\n",
    "    \n",
    "    if quietly == False:\n",
    "        print(f\"Correlations: Me and DFF {round(dff_corr, 3)}, Me and Roto {round(roto_corr, 3)}, DFF and Roto {round(their_corr, 3)}\")\n",
    "\n",
    "    \n",
    "    ### Outliers\n",
    "    # DFF\n",
    "    daily['Diff_DFF'] = daily['Projection_Me'] - daily['Projection_DFF']\n",
    "    daily.sort_values(by='Diff_DFF', ascending=True, inplace=True)\n",
    "    \n",
    "    print(\"I'm lower than DFF on:\")\n",
    "    print(daily[['Name', 'Projection_Me', 'Projection_DFF']].head(10))\n",
    "\n",
    "    daily.sort_values(by='Diff_DFF', ascending=False, inplace=True)\n",
    "    \n",
    "    print(\"I'm higher than DFF on:\")\n",
    "    print(daily[['Name', 'Projection_Me', 'Projection_DFF']].head(10))\n",
    "\n",
    "    \n",
    "    # RotoWire\n",
    "    daily['Diff_Roto'] = daily['Projection_Me'] - daily['Projection_Roto']\n",
    "    daily.sort_values(by='Diff_Roto', ascending=True, inplace=True)\n",
    "    \n",
    "    print(\"I'm lower than RotoWire on:\")\n",
    "    print(daily[['Name', 'Projection_Me', 'Projection_Roto']].head(10))\n",
    "\n",
    "    daily.sort_values(by='Diff_Roto', ascending=False, inplace=True)\n",
    "    \n",
    "    print(\"I'm higher than RotoWire on:\")\n",
    "    print(daily[['Name', 'Projection_Me', 'Projection_Roto']].head(10))\n",
    "\n",
    "    return daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa20e6fb-fab2-42c3-9223-83051d77ff86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2057f00-a3b0-42e4-a482-518f68c030b5",
   "metadata": {},
   "source": [
    "### Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "646992f8-1097-4937-b44b-b60a08b82f40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_projections_post(projections_and_results_df):    \n",
    "    # My errors\n",
    "    projections_and_results_df['error_Me'] = projections_and_results_df['Projection_Me'] - projections_and_results_df['FPTS']\n",
    "    projections_and_results_df['MSE_Me'] = projections_and_results_df['error_Me'] ** 2\n",
    "    \n",
    "    # DFF's errors\n",
    "    projections_and_results_df['error_DFF'] = projections_and_results_df['Projection_DFF'] - projections_and_results_df['FPTS']\n",
    "    projections_and_results_df['MSE_DFF'] = projections_and_results_df['error_DFF'] ** 2\n",
    "    \n",
    "    # RotoWire's errors\n",
    "    projections_and_results_df['error_Roto'] = projections_and_results_df['Projection_Roto'] - projections_and_results_df['FPTS']\n",
    "    projections_and_results_df['MSE_Roto'] = projections_and_results_df['error_Roto'] ** 2\n",
    "    \n",
    "    # Closer on player \n",
    "    projections_and_results_df['beat_DFF'] = (projections_and_results_df['MSE_DFF'] > projections_and_results_df['MSE_Me']).astype('int')\n",
    "    projections_and_results_df['beat_DFF'] = np.where(pd.isna(projections_and_results_df['MSE_DFF']), np.nan, projections_and_results_df['beat_DFF']) \n",
    "    projections_and_results_df['beat_Roto'] = (projections_and_results_df['MSE_Roto'] > projections_and_results_df['MSE_Me']).astype('int')    \n",
    "    projections_and_results_df['beat_Roto'] = np.where(pd.isna(projections_and_results_df['MSE_Roto']), np.nan, projections_and_results_df['beat_Roto']) \n",
    "                               \n",
    "    # May want to add RotoWire's ownership error\n",
    "    \n",
    "    return projections_and_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4563ac51-fe1d-4e74-9dcc-0d5f6cde1a64",
   "metadata": {},
   "source": [
    "Run evaluations from just contestKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10923a8-ec26-4d2a-8420-fedc7cfe13ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_contest_evaluation(contestKey):\n",
    "    # Read in guide\n",
    "    guide = pd.read_csv(os.path.join(baseball_path, \"A09. Contest Guides\", f\"Contest Guide {contestKey}.csv\"))\n",
    "    \n",
    "    # Read in projections\n",
    "    my_projections = read_my_projections(guide, contestKey)\n",
    "    try:\n",
    "        dff_projections = read_dff_projections(guide)\n",
    "    except:\n",
    "        print(\"No DFF Projections\")\n",
    "    roto_projections = read_roto_projections(guide)\n",
    "    \n",
    "        \n",
    "    # Merge projections\n",
    "    try:\n",
    "        projections_df = pd.merge(my_projections[['Name', 'Position', 'imp_l', 'imp_r', 'Projection_Me']], dff_projections, on='Name', how='outer')\n",
    "    except:\n",
    "        projections_df = my_projections[['Name', 'Position', 'imp_l', 'imp_r', 'Projection_Me']]\n",
    "        projections_df['Projection_DFF'] = np.nan\n",
    "    projections_df = pd.merge(projections_df, roto_projections, on='Name', how='outer')\n",
    "    valid_projections_df = projections_df.dropna().query('Projection_Me > 0 and Projection_DFF > 0 and Projection_Roto > 0')\n",
    "    \n",
    "    # Read in results\n",
    "    player_results_df = pd.read_csv(os.path.join(baseball_path, \"A01. DraftKings\", \"6. Player Results\", f\"Player Results {contestKey}.csv\"), encoding='iso-8859-1')\n",
    "    results_df = name_clean(player_results_df, \"Player\")\n",
    "    results_df = results_df[['Name', 'FPTS']]\n",
    "    \n",
    "    # Merge onto projections\n",
    "    projections_and_results_df = projections_df.merge(results_df, on='Name', how='left')\n",
    "    \n",
    "    # Run evaluations\n",
    "    projections_and_results_df = evaluate_projections_post(projections_and_results_df)\n",
    "\n",
    "    # Extract \n",
    "    date = guide['date'][0]\n",
    "    \n",
    "    # Add date and contestKey\n",
    "    projections_and_results_df['date'] = date\n",
    "    projections_and_results_df['contestKey'] = contestKey\n",
    "    \n",
    "    # Drop all instances of a duplicate (Luises Garcia)\n",
    "    projections_and_results_df.drop_duplicates(subset='Name', keep=False)\n",
    "    \n",
    "    return projections_and_results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
