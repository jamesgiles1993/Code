{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff5685da-6e8a-4101-9857-765d27dd3041",
   "metadata": {},
   "source": [
    "# M06. Park and Weather Factors\n",
    "This creates estimate of event rate multipliers based on park and weather conditions\n",
    "- Type: Model\n",
    "- Run Frequency: Irregular\n",
    "- Sources:\n",
    "    - MLB API\n",
    "- Dates:\n",
    "    - Created: 4/19/2024\n",
    "    - Updated: 4/21/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc96e937-bf3b-4468-9fb4-c70783972981",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b739e2c-e6cf-400b-a0b6-c6af1fac5f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"U1. Imports.ipynb\"\n",
    "%run \"U2. Utilities.ipynb\"\n",
    "%run \"U3. Classes.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c68dbeb-d94d-4866-93c7-1db7cb2f18ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"A02. MLB API.ipynb\"\n",
    "%run \"A03. Steamer.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0b4351-c7cd-4dce-a246-c99a604fb9df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e1d0fe9-5ee1-4a76-ba77-1cd6faca3193",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7ab00c-8f93-4c82-b5fe-9523275965a2",
   "metadata": {},
   "source": [
    "Create dataset of plays with rolling stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3333a8-e158-4e43-bfe3-5bb110280d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset = create_pa_inputs(park_factors, team_map, 2015, 2024, short=50, long=300, adjust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e24c6a2-7a1d-413b-81ad-4d9df721e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE IN IMPORTS\n",
    "year_inputs = [f\"year_{year}\" for year in range(2015,2025)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59550925-e4da-433c-bd75-ec104d283489",
   "metadata": {},
   "source": [
    "Remove imputed players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd74a85-8a84-431c-a3e5-32d65e671f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unimputed_df = complete_dataset.query('imp_b == 0 and imp_p == 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ccda54-254e-4551-9e31-4c41505c38a3",
   "metadata": {},
   "source": [
    "Remove park adjustments from outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abd0752-f36f-4834-ab9a-46c78965af32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for stat in events_list:\n",
    "    unimputed_df[stat] = (unimputed_df[stat] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4a69cc-ae1a-463e-9c29-f21231c6bd76",
   "metadata": {},
   "source": [
    "Create game averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1884f73-1c0e-4adc-b41b-6429b66a0131",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_list_b = [f\"{event}_b\" for event in events_list]\n",
    "events_list_p = [f\"{event}_p\" for event in events_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e752843-9313-4333-863f-c98c6f4f7069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group stats by game/venue/batSide to get model inputs\n",
    "game_df = unimputed_df.groupby(['gamePk', 'venue_id', 'batSide'])[events_list + events_list_b + events_list_p + ['x_vect', 'y_vect', 'temperature'] + year_inputs].mean().reset_index()\n",
    "\n",
    "# Add in venue dummies, only keeping active parks\n",
    "venue_dummies = pd.get_dummies(game_df['venue_id']).astype(int)\n",
    "active_parks = list(team_map['VENUE_ID'].astype(str))\n",
    "venue_dummies = venue_dummies[active_parks]\n",
    "game_df = pd.concat([game_df, venue_dummies], axis=1)\n",
    "\n",
    "# Only keep games in active parks\n",
    "game_df['active_park'] = game_df[active_parks].sum(axis=1)\n",
    "game_df = game_df.query('active_park == 1')\n",
    "game_df = game_df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Create a mapping dictionary for renaming columns\n",
    "active_venues = [f\"venue_{park}\" for park in active_parks]\n",
    "column_mapping = {col: 'venue_' + col for col in active_parks}\n",
    "\n",
    "# Rename only the columns present in active_parks\n",
    "game_df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# Add lefty dummy\n",
    "game_df['lefty'] = (game_df['batSide'] == \"L\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d39a4b9-8db9-4e7d-a091-91310cb6ca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create interaction terms\n",
    "interaction_terms = []\n",
    "# Weather x Park\n",
    "for col1 in ['x_vect', 'y_vect', 'temperature']:\n",
    "    for col2 in active_venues:\n",
    "        interaction_name = col1 + '_' + col2\n",
    "        game_df[interaction_name] = game_df[col1] * game_df[col2]\n",
    "        interaction_terms.append(interaction_name)\n",
    "# Weather x Park x batSide\n",
    "for col1 in ['x_vect', 'y_vect', 'temperature']:\n",
    "    for col2 in active_venues:\n",
    "        for col3 in ['lefty']:\n",
    "            interaction_name = col1 + '_' + col2 + '_' + col3\n",
    "            game_df[interaction_name] = game_df[col1] * game_df[col2] * game_df[col3]\n",
    "            interaction_terms.append(interaction_name)\n",
    "# Year x Park\n",
    "for col1 in year_inputs:\n",
    "    for col2 in active_venues:\n",
    "        interaction_name = col1 + '_' + col2\n",
    "        game_df[interaction_name] = game_df[col1] * game_df[col2]\n",
    "        interaction_terms.append(interaction_name)\n",
    "# Year x Park x batSide\n",
    "for col1 in year_inputs:\n",
    "    for col2 in active_venues:\n",
    "        for col3 in ['lefty']:\n",
    "            interaction_name = col1 + '_' + col2 + '_' + col3\n",
    "            game_df[interaction_name] = game_df[col1] * game_df[col2] * game_df[col3]\n",
    "            interaction_terms.append(interaction_name)\n",
    "# batSide x Park\n",
    "for col1 in ['lefty']:\n",
    "    for col2 in active_venues:\n",
    "        interaction_name = col1 + '_' + col2\n",
    "        game_df[interaction_name] = game_df[col1] * game_df[col2]\n",
    "        interaction_terms.append(interaction_name)\n",
    "game_df['x_vect_temperature'] = np.abs(game_df['x_vect']) * game_df['temperature']\n",
    "game_df['y_vect_temperature'] = game_df['y_vect'] * game_df['temperature']\n",
    "game_df['x_vect_y_vect'] = np.abs(game_df['x_vect']) * game_df['y_vect']\n",
    "interaction_terms.extend(['x_vect_temperature', 'y_vect_temperature', 'x_vect_y_vect'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97929308-c49f-4ab2-899a-a81624a9504d",
   "metadata": {},
   "source": [
    "park x weather\n",
    "park x weather x lefty\n",
    "park x year \n",
    "park x year x lefty\n",
    "park x lefty\n",
    "weather x weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855a13de-155d-4cfe-b533-db9c8942520f",
   "metadata": {},
   "source": [
    "### Regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e845b1-5c7c-4443-a832-5c50c5f9c06f",
   "metadata": {},
   "source": [
    "##### 1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2e5f0d-1556-45f7-b954-7a2805065edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define features and target variable\n",
    "X = game_df[['b1_b', 'b1_p', 'x_vect', 'y_vect', 'temperature', 'lefty'] + year_inputs + interaction_terms] \n",
    "y = game_df['b1']\n",
    "\n",
    "# Step 4: Fit a linear regression model\n",
    "b1_model = LinearRegression()\n",
    "b1_model.fit(X, y)\n",
    "\n",
    "pickle.dump(b1_model, open(os.path.join(model_path, f\"Weather Model - b1 {todaysdate}\"), 'wb'))\n",
    "\n",
    "X_copy = X.copy()\n",
    "\n",
    "# Replace for predicting with average\n",
    "X_copy['b1_b'] = unimputed_df['b1_b'].mean()\n",
    "X_copy['b1_p'] = unimputed_df['b1_p'].mean()\n",
    "\n",
    "\n",
    "# Step 5: Make predictions\n",
    "predictions = b1_model.predict(X_copy)\n",
    "\n",
    "# Step 6: Calculate deciles based on predicted \n",
    "game_df['predicted_b1'] = predictions\n",
    "game_df['decile_b1'] = pd.qcut(game_df['predicted_b1'], 10, labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f10779-917c-4e69-8461-53b2c08360f7",
   "metadata": {},
   "source": [
    "##### 2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcae5fd-f189-4245-8bf2-cf8e90255f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define features and target variable\n",
    "X = game_df[['b2_b', 'b2_p', 'x_vect', 'y_vect', 'temperature', 'lefty'] + year_inputs + interaction_terms] \n",
    "y = game_df['b2']\n",
    "\n",
    "# Step 4: Fit a linear regression model\n",
    "b2_model = LinearRegression()\n",
    "b2_model.fit(X, y)\n",
    "\n",
    "pickle.dump(b2_model, open(os.path.join(model_path, f\"Weather Model - b2 {todaysdate}\"), 'wb'))\n",
    "\n",
    "\n",
    "X_copy = X.copy()\n",
    "\n",
    "# Replace for predicting with average\n",
    "X_copy['b2_b'] = unimputed_df['b2_b'].mean()\n",
    "X_copy['b2_p'] = unimputed_df['b2_p'].mean()\n",
    "\n",
    "# Step 5: Make predictions\n",
    "predictions = b2_model.predict(X_copy)\n",
    "\n",
    "# Step 6: Calculate deciles based on predicted \n",
    "game_df['predicted_b2'] = predictions\n",
    "game_df['decile_b2'] = pd.qcut(game_df['predicted_b2'], 10, labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fb9e83-3aab-4a3a-8789-4262ef2de67a",
   "metadata": {},
   "source": [
    "##### 3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c574a70-1216-471f-8e46-762cdf0a750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define features and target variable\n",
    "X = game_df[['b3_b', 'b3_p', 'x_vect', 'y_vect', 'temperature', 'lefty'] + year_inputs + interaction_terms] \n",
    "y = game_df['b3']\n",
    "\n",
    "# Step 4: Fit a linear regression model\n",
    "b3_model = LinearRegression()\n",
    "b3_model.fit(X, y)\n",
    "\n",
    "pickle.dump(b3_model, open(os.path.join(model_path, f\"Weather Model - b3 {todaysdate}\"), 'wb'))\n",
    "\n",
    "\n",
    "X_copy = X.copy()\n",
    "\n",
    "# Replace for predicting with average\n",
    "X_copy['b3_b'] = unimputed_df['b3_b'].mean()\n",
    "X_copy['b3_p'] = unimputed_df['b3_p'].mean()\n",
    "\n",
    "# Step 5: Make predictions\n",
    "predictions = b3_model.predict(X_copy)\n",
    "\n",
    "# Step 6: Calculate deciles based on predicted \n",
    "game_df['predicted_b3'] = predictions\n",
    "game_df['decile_b3'] = pd.qcut(game_df['predicted_b3'], 10, labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce71f755-4004-45a8-bba6-20cc2eede5b0",
   "metadata": {},
   "source": [
    "##### HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b672dbd6-a8b3-416e-bf52-85a40cd9c3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define features and target variable\n",
    "# X = game_df.drop(columns=['hr', 'batSide', 'gamePk'])\n",
    "X = game_df[['hr_b', 'hr_p', 'x_vect', 'y_vect', 'temperature', 'lefty'] + year_inputs + interaction_terms] \n",
    "y = game_df['hr']\n",
    "\n",
    "# Step 4: Fit a linear regression model\n",
    "hr_model = LinearRegression()\n",
    "hr_model.fit(X, y)\n",
    "\n",
    "pickle.dump(hr_model, open(os.path.join(model_path, f\"Weather Model - hr {todaysdate}\"), 'wb'))\n",
    "\n",
    "\n",
    "X_copy = X.copy()\n",
    "\n",
    "# Replace for predicting with average\n",
    "X_copy['hr_b'] = unimputed_df['hr_b'].mean()\n",
    "X_copy['hr_p'] = unimputed_df['hr_p'].mean()\n",
    "\n",
    "# Step 5: Make predictions\n",
    "predictions = hr_model.predict(X_copy)\n",
    "\n",
    "# Step 6: Calculate deciles based on predicted hr\n",
    "game_df['predicted_hr'] = predictions\n",
    "game_df['decile_hr'] = pd.qcut(game_df['predicted_hr'], 10, labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0b5e6b-31c9-41ee-b8b9-d9b5abf58c14",
   "metadata": {},
   "source": [
    "##### BB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2d7827-dfdf-46ee-a598-33dc810eb313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define features and target variable\n",
    "X = game_df[['bb_b', 'bb_p', 'x_vect', 'y_vect', 'temperature', 'lefty'] + year_inputs + interaction_terms] \n",
    "y = game_df['bb']\n",
    "\n",
    "# Step 4: Fit a linear regression model\n",
    "bb_model = LinearRegression()\n",
    "bb_model.fit(X, y)\n",
    "\n",
    "pickle.dump(bb_model, open(os.path.join(model_path, f\"Weather Model - bb {todaysdate}\"), 'wb'))\n",
    "\n",
    "\n",
    "X_copy = X.copy()\n",
    "\n",
    "# Replace for predicting with average\n",
    "X_copy['bb_b'] = unimputed_df['bb_b'].mean()\n",
    "X_copy['bb_p'] = unimputed_df['bb_p'].mean()\n",
    "\n",
    "# Step 5: Make predictions\n",
    "predictions = bb_model.predict(X_copy)\n",
    "\n",
    "# Step 6: Calculate deciles based on predicted \n",
    "game_df['predicted_bb'] = predictions\n",
    "game_df['decile_bb'] = pd.qcut(game_df['predicted_bb'], 10, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c700e3-03f1-45d1-b00f-161e3532713b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90fefa42-468e-4751-b384-38bf6e39a391",
   "metadata": {},
   "source": [
    "##### HBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9134a40f-5b3f-4c2b-a75c-b00cdad9a1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define features and target variable\n",
    "X = game_df[['hbp_b', 'hbp_p', 'x_vect', 'y_vect', 'temperature', 'lefty'] + year_inputs + interaction_terms] \n",
    "y = game_df['hbp']\n",
    "\n",
    "# Step 4: Fit a linear regression model\n",
    "hbp_model = LinearRegression()\n",
    "hbp_model.fit(X, y)\n",
    "\n",
    "pickle.dump(hbp_model, open(os.path.join(model_path, f\"Weather Model - hbp {todaysdate}\"), 'wb'))\n",
    "\n",
    "\n",
    "X_copy = X.copy()\n",
    "\n",
    "# Replace for predicting with average\n",
    "X_copy['hbp_b'] = unimputed_df['hbp_b'].mean()\n",
    "X_copy['hbp_p'] = unimputed_df['hbp_p'].mean()\n",
    "\n",
    "# Step 5: Make predictions\n",
    "predictions = hbp_model.predict(X_copy)\n",
    "\n",
    "# Step 6: Calculate deciles based on predicted \n",
    "game_df['predicted_hbp'] = predictions\n",
    "game_df['decile_hbp'] = pd.qcut(game_df['predicted_hbp'], 10, labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13edf36b-a024-4d71-aff9-552901e30d20",
   "metadata": {},
   "source": [
    "##### SO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34731b42-2ef8-4a35-b83f-0d3ac721184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define features and target variable\n",
    "X = game_df[['so_b', 'so_p', 'x_vect', 'y_vect', 'temperature', 'lefty'] + year_inputs + interaction_terms] \n",
    "y = game_df['so']\n",
    "\n",
    "# Step 4: Fit a linear regression model\n",
    "so_model = LinearRegression()\n",
    "so_model.fit(X, y)\n",
    "\n",
    "pickle.dump(so_model, open(os.path.join(model_path, f\"Weather Model - so {todaysdate}\"), 'wb'))\n",
    "\n",
    "\n",
    "X_copy = X.copy()\n",
    "\n",
    "# Replace sor predicting with average\n",
    "X_copy['so_b'] = unimputed_df['so_b'].mean()\n",
    "X_copy['so_p'] = unimputed_df['so_p'].mean()\n",
    "\n",
    "# Step 5: Make predictions\n",
    "predictions = so_model.predict(X_copy)\n",
    "\n",
    "# Step 6: Calculate deciles based on predicted \n",
    "game_df['predicted_so'] = predictions\n",
    "game_df['decile_so'] = pd.qcut(game_df['predicted_so'], 10, labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbd5ec0-6013-44ee-a24d-465f582d63bf",
   "metadata": {},
   "source": [
    "##### FO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f24005-4381-419a-98cc-c5be6e357503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define features and target variable\n",
    "X = game_df[['fo_b', 'fo_p', 'x_vect', 'y_vect', 'temperature', 'lefty'] + year_inputs + interaction_terms] \n",
    "y = game_df['fo']\n",
    "\n",
    "# Step 4: Fit a linear regression model\n",
    "fo_model = LinearRegression()\n",
    "fo_model.fit(X, y)\n",
    "\n",
    "pickle.dump(fo_model, open(os.path.join(model_path, f\"Weather Model - fo {todaysdate}\"), 'wb'))\n",
    "\n",
    "\n",
    "X_copy = X.copy()\n",
    "\n",
    "# Replace for predicting with average\n",
    "X_copy['fo_b'] = unimputed_df['fo_b'].mean()\n",
    "X_copy['fo_p'] = unimputed_df['fo_p'].mean()\n",
    "\n",
    "# Step 5: Make predictions\n",
    "predictions = fo_model.predict(X_copy)\n",
    "\n",
    "# Step 6: Calculate deciles based on predicted \n",
    "game_df['predicted_fo'] = predictions\n",
    "game_df['decile_fo'] = pd.qcut(game_df['predicted_fo'], 10, labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9fa82f-7bdd-4449-b70b-659cf8713c86",
   "metadata": {},
   "source": [
    "##### GO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c92bc6-1765-413e-aa58-51147d2b8448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define features and target variable\n",
    "X = game_df[['go_b', 'go_p', 'x_vect', 'y_vect', 'temperature', 'lefty'] + year_inputs + interaction_terms] \n",
    "y = game_df['go']\n",
    "\n",
    "# Step 4: Fit a linear regression model\n",
    "go_model = LinearRegression()\n",
    "go_model.fit(X, y)\n",
    "\n",
    "pickle.dump(go_model, open(os.path.join(model_path, f\"Weather Model - go {todaysdate}\"), 'wb'))\n",
    "\n",
    "\n",
    "X_copy = X.copy()\n",
    "\n",
    "# Replace for predicting with average\n",
    "X_copy['go_b'] = unimputed_df['go_b'].mean()\n",
    "X_copy['go_p'] = unimputed_df['go_p'].mean()\n",
    "\n",
    "# Step 5: Make predictions\n",
    "predictions = go_model.predict(X_copy)\n",
    "\n",
    "# Step 6: Calculate deciles based on predicted \n",
    "game_df['predicted_go'] = predictions\n",
    "game_df['decile_go'] = pd.qcut(game_df['predicted_go'], 10, labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c79dee4-f103-4c74-8b25-4d7e353b539f",
   "metadata": {},
   "source": [
    "##### LO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa96cd66-8ee0-4a7d-a8f4-d5a928ea9dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define features and target variable\n",
    "X = game_df[['lo_b', 'lo_p', 'x_vect', 'y_vect', 'temperature', 'lefty'] + year_inputs + interaction_terms] \n",
    "y = game_df['lo']\n",
    "\n",
    "# Step 4: Fit a linear regression model\n",
    "lo_model = LinearRegression()\n",
    "lo_model.fit(X, y)\n",
    "\n",
    "pickle.dump(lo_model, open(os.path.join(model_path, f\"Weather Model - lo {todaysdate}\"), 'wb'))\n",
    "\n",
    "\n",
    "X_copy = X.copy()\n",
    "\n",
    "# Replace for predicting with average\n",
    "X_copy['lo_b'] = unimputed_df['lo_b'].mean()\n",
    "X_copy['lo_p'] = unimputed_df['lo_p'].mean()\n",
    "\n",
    "# Step 5: Make predictions\n",
    "predictions = lo_model.predict(X_copy)\n",
    "\n",
    "# Step 6: Calculate deciles based on predicted \n",
    "game_df['predicted_lo'] = predictions\n",
    "game_df['decile_lo'] = pd.qcut(game_df['predicted_lo'], 10, labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc811fc-6111-4fe8-91dd-d0f8a27912f5",
   "metadata": {},
   "source": [
    "##### PO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bca004-2efe-46f0-b648-2f054df7f33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define features and target variable\n",
    "X = game_df[['po_b', 'po_p', 'x_vect', 'y_vect', 'temperature', 'lefty'] + year_inputs + interaction_terms] \n",
    "y = game_df['po']\n",
    "\n",
    "# Step 4: Fit a linear regression model\n",
    "po_model = LinearRegression()\n",
    "po_model.fit(X, y)\n",
    "\n",
    "pickle.dump(po_model, open(os.path.join(model_path, f\"Weather Model - po {todaysdate}\"), 'wb'))\n",
    "\n",
    "\n",
    "X_copy = X.copy()\n",
    "\n",
    "# Replace for predicting with average\n",
    "X_copy['po_b'] = unimputed_df['po_b'].mean()\n",
    "X_copy['po_p'] = unimputed_df['po_p'].mean()\n",
    "\n",
    "# Step 5: Make predictions\n",
    "predictions = po_model.predict(X_copy)\n",
    "\n",
    "# Step 6: Calculate deciles based on predicted \n",
    "game_df['predicted_po'] = predictions\n",
    "game_df['decile_po'] = pd.qcut(game_df['predicted_po'], 10, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6999e50-2f58-4eef-945b-51110cff901c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8378204e-17cc-4ee7-a68c-88982c2f0305",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e1a69c-9dec-4264-bba9-626860e78c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an event to graph and view park/weather factors\n",
    "event = 'b2'\n",
    "\n",
    "# Step 7: Calculate average predicted and actual hr for each decile\n",
    "decile_means = game_df.query('venue_id == \"3\"').groupby(f'decile_{event}').agg({f'predicted_{event}': 'mean', f'{event}': 'mean'})\n",
    "\n",
    "# Step 8: Plot actual hr vs predicted hr by decile\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(decile_means.index, decile_means[f'predicted_{event}'], label=f'Predicted {event}', marker='o')\n",
    "plt.plot(decile_means.index, decile_means[f'{event}'], label=f'Actual {event}', marker='o')\n",
    "\n",
    "plt.xlabel('Decile')\n",
    "plt.ylabel(f'{event}')\n",
    "plt.title(f'Actual vs Predicted {event} by Decile')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb70d3b7-6fbc-4193-8781-abc2b5f1def5",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df['is_out_pred'] = game_df[['predicted_so', 'predicted_go', 'predicted_lo', 'predicted_fo', 'predicted_po']].sum(axis=1)\n",
    "game_df['is_out'] = game_df[['so', 'go', 'lo', 'fo', 'po']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd1ba8d-0953-456a-b13f-32fa8a71524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an event to graph and view park/weather factors\n",
    "event = 'out'\n",
    "\n",
    "\n",
    "# game_df['decile_out'] = pd.qcut(game_df['is_out_pred'], 10, labels=False)\n",
    "# decile_means = game_df.groupby('decile_out').agg({'is_out_pred': 'mean', 'is_out': 'mean'})\n",
    "\n",
    "game_df['decile_out'] = pd.qcut(game_df.query('venue_id == \"3\"')['is_out_pred'], 10, labels=False)\n",
    "decile_means = game_df.query('venue_id == \"3\"').groupby('decile_out').agg({'is_out_pred': 'mean', 'is_out': 'mean'})\n",
    "\n",
    "\n",
    "# Step 8: Plot actual hr vs predicted hr by decile\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(decile_means.index, decile_means['is_out_pred'], label=f'Predicted {event}', marker='o')\n",
    "plt.plot(decile_means.index, decile_means['is_out'], label=f'Actual {event}', marker='o')\n",
    "\n",
    "# Set the y-axis limits\n",
    "plt.ylim(0.62, 0.72)\n",
    "\n",
    "plt.xlabel('Decile')\n",
    "plt.ylabel(f'{event}')\n",
    "plt.title(f'Actual vs Predicted {event} by Decile')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8d79c9-bb41-45f9-ae2a-18bb4259e90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df.query('venue_id == \"3\"').groupby('decile_out')[['is_out', 'x_vect', 'y_vect', 'temperature']].mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8a5fd7-f048-4a7a-ac3e-2483ec51ace6",
   "metadata": {},
   "source": [
    "### Display Park/Weather Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24cd298-93fd-4bb5-af11-419bdf58d5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "event = 'hr'\n",
    "\n",
    "# Calculate park factors (=predicted rate/average rate)\n",
    "game_df[f'{event}_factor'] = game_df[f'predicted_{event}'] / game_df[event].mean()\n",
    "\n",
    "# Calculate averages by park\n",
    "park_averages = game_df[game_df['venue_id'].isin(team_map['VENUE_ID'].astype(str))].groupby('venue_id')[[f'decile_{event}', f'{event}', f'predicted_{event}', f'{event}_b', f'{event}_p']].mean().sort_values(by=[f'decile_{event}'], ascending=False).reset_index()\n",
    "# Calculate factor summary statistics for parks for given state\n",
    "park_descriptions = game_df[game_df['venue_id'].isin(team_map['VENUE_ID'].astype(str))].groupby('venue_id')[f'{event}_factor'].describe().sort_values('mean', ascending=False)\n",
    "\n",
    "# Merge on team information\n",
    "merge_map = team_map[['BBREFTEAM', 'VENUE_ID']]\n",
    "merge_map['VENUE_ID'] = merge_map['VENUE_ID'].astype(str)\n",
    "park_descriptions = park_descriptions.merge(merge_map, left_on=['venue_id'], right_on=['VENUE_ID'], how='left')\n",
    "# Merge on park averages\n",
    "park_descriptions = park_descriptions.merge(park_averages, left_on=['VENUE_ID'], right_on=['venue_id'], how='left')\n",
    "\n",
    "# Calculate park factors\n",
    "park_descriptions[f'{event}_factor'] = park_descriptions[f'predicted_{event}'] / game_df[event].mean()\n",
    "park_descriptions = park_descriptions[['BBREFTEAM', 'VENUE_ID', f'{event}_factor', f'{event}', f'predicted_{event}', f'{event}_b', f'{event}_p', f'decile_{event}', 'mean', 'count', 'std', 'min', '25%', '50%', '75%', 'max']]\n",
    "\n",
    "park_descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6c6b9b-553b-4fde-9856-db2da126eb7a",
   "metadata": {},
   "source": [
    "Future Considerations:\n",
    "- Consider rolling park factors to avoid using year\n",
    "- Clean to remove certain anomalous games (wind at the Trop, for example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0a9eb5-989c-4bb8-b089-33c44e415374",
   "metadata": {},
   "outputs": [],
   "source": [
    "unimputed_df[events_list].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5924ba64-15b0-4482-bfd4-ee334d124b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "park_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a988bab-e579-43d6-baed-d98565278807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
