{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6116898-f0f1-4999-9359-c745ca7fb312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run \"U1. Imports.ipynb\"\n",
    "# %run \"U2. Utilities.ipynb\"\n",
    "# %run \"U3. Classes.ipynb\"\n",
    "\n",
    "# baseball_path = r'C:\\Users\\james\\Documents\\MLB\\Database'\n",
    "\n",
    "# db_path = r'C:\\Users\\james\\Documents\\MLB\\Database\\MLBDB.db'\n",
    "# engine = create_engine(f'sqlite:///{db_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902df45b-6232-454e-b3e7-f1cb0ccd2130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run \"A02. MLB API.ipynb\"\n",
    "# %run \"A03. Steamer.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66cb519-2136-4190-979b-80ef52acc92e",
   "metadata": {},
   "source": [
    "### 1. Read in Stats API Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0bb23c-c3aa-42b5-a612-367d99ec9928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_dataset = create_pa_inputs(park_factors, team_map, 2015, 2023, 50, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4a03ef-46b4-455c-b91a-dfad9b352ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_dataset = complete_dataset.query('date > 20220301')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450da260-7b9d-4a7d-81ec-e056c0a13d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in Steamer hitters \n",
    "# steamer_hitters_df = pd.read_csv(os.path.join(baseball_path, \"A03. Steamer\", \"steamer_hitters_weekly_log.csv\"), encoding='iso-8859-1')\n",
    "# steamer_hitters_df = clean_steamer_hitters(steamer_hitters_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c35ce02-8ad8-4019-a972-09e490301d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in Steamer pitchers\n",
    "# steamer_pitchers_df = pd.read_csv(os.path.join(baseball_path, \"A03. Steamer\", \"steamer_pitchers_weekly_log.csv\"), encoding='iso-8859-1')\n",
    "# steamer_pitchers_df = clean_steamer_pitchers(steamer_pitchers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9a8d39-92b5-4f1f-9897-108489fa28d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# team_map = pd.read_csv(os.path.join(baseball_path, \"Utilities\", \"Team Map.csv\"))[['teamId', 'BBREFTEAM']].set_index('teamId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522388e3-aa51-4fcb-9b4b-cb62917e7f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matchup_file(game_df, row, complete_dataset, steamer_hitters_df, steamer_pitchers_df, team_map):\n",
    "    game_id = game_df['game_id'][row]\n",
    "    game_datetime = game_df['game_datetime'][row]\n",
    "    game_date = game_df['game_date'][row]\n",
    "    date = int(game_date.replace(\"-\", \"\"))\n",
    "    away_id = game_df['away_id'][row]\n",
    "    home_id = game_df['home_id'][row]\n",
    "    # Retrieve Baseball Reference team abbreviation\n",
    "    team_map_cut = team_map[['teamId', 'BBREFTEAM']].set_index('teamId')\n",
    "    \n",
    "    away_team = team_map_cut.loc[away_id]['BBREFTEAM']\n",
    "    home_team = team_map_cut.loc[home_id]['BBREFTEAM']\n",
    "    \n",
    "    for team in away_team, home_team:\n",
    "        # Read in rosters\n",
    "        roster_df = pd.read_csv(os.path.join(baseball_path, \"A05. Rosters\", \"2. Rosters\", f\"Rosters {date}\", f\"Roster {team} {date}.csv\"), encoding='iso-8859-1')\n",
    "\n",
    "        # Read in batting orders\n",
    "        order_df = pd.read_csv(os.path.join(baseball_path, \"A05. Rosters\", \"1. Batting Orders\", f\"Batting Orders {date}\", f\"Batting Order {team} {game_id}.csv\"), encoding='iso-8859-1')        \n",
    "        \n",
    "        # Read in bullpens\n",
    "        bullpen_df = pd.read_csv(os.path.join(baseball_path, \"A04. Bullpens\", f\"Bullpens {date}\", f\"Bullpen {team} {date}.csv\"), encoding='iso-8859-1')  \n",
    "        \n",
    "        # Merge batting order onto roster\n",
    "        team_df = pd.merge(roster_df, order_df[['id', 'fullName', 'position', 'status', 'order']], on='id', how='outer', suffixes=(\"\",\"2\"))\n",
    "        \n",
    "        # Fill in missings\n",
    "        team_df['batSide'].fillna('Right', inplace=True)\n",
    "        team_df['pitchHand'].fillna('Right', inplace=True)\n",
    "        team_df['fullName'].fillna(team_df['fullName2'], inplace=True)\n",
    "        team_df['position'].fillna(team_df['position2'], inplace=True)\n",
    "        \n",
    "        # Merge pitcher leverage onto roster\n",
    "        ### Testing\n",
    "        team_df['fullName'] = team_df['fullName'].apply(remove_accents)\n",
    "        ### Testing\n",
    "        team_df = pd.merge(team_df, bullpen_df[['Name', 'Leverage']], left_on='fullName', right_on='Name', how='left')\n",
    "        \n",
    "        # Add weather\n",
    "        box = create_box(game_id)\n",
    "        team_df['weather'] = box[0]\n",
    "        team_df['wind'] = box[1]\n",
    "        team_df['park'] = box[2]\n",
    "        team_df = clean_weather(team_df)\n",
    "\n",
    "        # Add venue\n",
    "        team_df['venue_id'] = game_df['venue_id'][row]\n",
    "        \n",
    "        # Add starters\n",
    "        team_df['away_starter'] = game_df['away_probable_pitcher'][row]\n",
    "        team_df['home_starter'] = game_df['home_probable_pitcher'][row]\n",
    "\n",
    "        team_df['away_starter'] = team_df['away_starter'].apply(remove_accents)\n",
    "        team_df['home_starter'] = team_df['home_starter'].apply(remove_accents)\n",
    "        \n",
    "        \n",
    "        # Assign Leverage of 1 to starting pitcher\n",
    "        team_df['Leverage'] = np.where((team_df['fullName'] == team_df['away_starter']) | (team_df['fullName'] == team_df['home_starter']), 1, team_df['Leverage'])\n",
    "\n",
    "        # Determine batting order\n",
    "        team_df['order'] = pd.to_numeric(team_df['order'], errors='coerce')\n",
    "        team_df['batting_order'] = np.nan\n",
    "        for i in range(9):\n",
    "            team_df['batting_order'] = np.where(team_df['order'] == (i+1)*100, i+1, team_df['batting_order'])\n",
    "\n",
    "        ### Batters\n",
    "        batter_df = team_df[team_df['position'] != \"Pitcher\"]\n",
    "\n",
    "        ## Dataset\n",
    "        # Vs. LHP\n",
    "        vs_l = complete_dataset[complete_dataset['date'] < int(date)]\n",
    "        vs_l = vs_l[vs_l['pitchHand'] == \"L\"]\n",
    "        vs_l.drop_duplicates(subset='batter', keep='last', inplace=True)\n",
    "\n",
    "        # Merge in stats\n",
    "        batter_df = pd.merge(batter_df, vs_l[['batter'] + batter_inputs + ['imp_b', 'pa_b', 'pa_b_long']], left_on='id', right_on='batter', how='left')\n",
    "\n",
    "        # Vs. RHP\n",
    "        vs_r = complete_dataset[complete_dataset['date'] < int(date)]\n",
    "        vs_r = vs_r[vs_r['pitchHand'] == \"R\"]\n",
    "        vs_r.drop_duplicates(subset='batter', keep='last', inplace=True)\n",
    "\n",
    "        # Merge in stats\n",
    "        batter_df = pd.merge(batter_df, vs_r[['batter'] + batter_inputs + ['imp_b', 'pa_b', 'pa_b_long']], left_on='id', right_on='batter', how='left', suffixes=(\"_l\", \"_r\"))\n",
    "\n",
    "        ## Steamer \n",
    "        # Keep last observation before date (may switch to <= if I find projections are up early)\n",
    "        steamer_hitters_last_df = steamer_hitters_df[steamer_hitters_df['date'] <= int(date)]\n",
    "        steamer_hitters_last_df.drop_duplicates(subset='mlbamid', keep='last', inplace=True)\n",
    "\n",
    "        # Merge\n",
    "        batter_df = pd.merge(batter_df, steamer_hitters_last_df, left_on='id', right_on='mlbamid', how='left', suffixes=(\"\", \"_fg\"))\n",
    "\n",
    "        # Remove redundant variables\n",
    "        batter_df.drop(columns={'batter_l', 'batter_r', 'firstname', 'lastname', 'mlbamid', 'fullName2', 'position2'}, inplace=True)\n",
    "\n",
    "        # Clean\n",
    "        # batter_df = clean_order(batter_df)\n",
    "\n",
    "        # Move 'batting_order' to the desired position\n",
    "        batter_df.insert(batter_df.columns.get_loc('order') + 1, 'batting_order', batter_df.pop('batting_order'))\n",
    "\n",
    "        # Sort\n",
    "        batter_df.sort_values('batting_order', inplace=True)\n",
    "\n",
    "\n",
    "        ### Pitchers\n",
    "        pitcher_df = team_df[(team_df['position'] == \"Pitcher\") | (team_df['position'] == \"Two-Way Player\")]\n",
    "\n",
    "        ## Dataset\n",
    "        # Vs. LHB\n",
    "        vs_l = complete_dataset[complete_dataset['date'] < int(date)]\n",
    "        vs_l = vs_l[vs_l['batSide'] == \"L\"]\n",
    "        vs_l.drop_duplicates(subset='pitcher', keep='last', inplace=True)\n",
    "\n",
    "        # Merge in stats\n",
    "        pitcher_df = pd.merge(pitcher_df, vs_l[['pitcher'] + pitcher_inputs + ['imp_p', 'pa_p', 'pa_p_long']], left_on='id', right_on='pitcher', how='left')\n",
    "\n",
    "        # Vs. RHB\n",
    "        vs_r = complete_dataset[complete_dataset['date'] < int(date)]\n",
    "        vs_r = vs_r[vs_r['batSide'] == \"R\"]\n",
    "        vs_r.drop_duplicates(subset='pitcher', keep='last', inplace=True)\n",
    "\n",
    "        # Merge in stats\n",
    "        pitcher_df = pd.merge(pitcher_df, vs_r[['pitcher'] + pitcher_inputs + ['imp_p', 'pa_p', 'pa_p_long']], left_on='id', right_on='pitcher', how='left', suffixes=(\"_l\", \"_r\"))\n",
    "\n",
    "        ## Steamer \n",
    "        # Keep last observation before date (may switch to <= if I find projections are up early)\n",
    "        steamer_pitchers_last_df = steamer_pitchers_df[steamer_pitchers_df['date'] <= int(date)]\n",
    "        steamer_pitchers_last_df.drop_duplicates(subset='mlbamid', keep='last', inplace=True)\n",
    "\n",
    "        # Merge\n",
    "        pitcher_df = pd.merge(pitcher_df, steamer_pitchers_last_df, left_on='id', right_on='mlbamid', how='left', suffixes=(\"\", \"_fg\"))\n",
    "\n",
    "        # Remove redundant variables\n",
    "        pitcher_df.drop(columns={'pitcher_l', 'pitcher_r', 'firstname', 'lastname', 'mlbamid', 'fullName2', 'position2'}, inplace=True)\n",
    "\n",
    "        # Move 'batting_order' to the desired position\n",
    "        pitcher_df.insert(pitcher_df.columns.get_loc('order') + 1, 'batting_order', pitcher_df.pop('batting_order'))\n",
    "\n",
    "        # Sort\n",
    "        pitcher_df.sort_values('Leverage', inplace=True)\n",
    "\n",
    "        if team == away_team:\n",
    "            away_batter_df = batter_df.copy()\n",
    "            away_pitcher_df = pitcher_df.copy()\n",
    "        else:\n",
    "            home_batter_df = batter_df.copy()\n",
    "            home_pitcher_df = pitcher_df.copy()\n",
    "\n",
    "    # Drop duplicates: \n",
    "    away_batter_df.drop_duplicates('id', keep='last', inplace=True)\n",
    "    away_batter_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    home_batter_df.drop_duplicates('id', keep='last', inplace=True)\n",
    "    home_batter_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    away_pitcher_df.drop_duplicates('id', keep='last', inplace=True)\n",
    "    away_pitcher_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    home_pitcher_df.drop_duplicates('id', keep='last', inplace=True)\n",
    "    home_pitcher_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            \n",
    "        \n",
    "    return away_batter_df, away_pitcher_df, home_batter_df, home_pitcher_df        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f803b624-5b13-4af6-ab8f-3276035da579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matchup_files(game_df, row, complete_dataset, steamer_hitters_df, steamer_pitchers_df, team_map):\n",
    "    # Skip spring training games\n",
    "    if game_df['game_type'][row] not in [\"S\", \"A\"]:\n",
    "         \n",
    "        # Extract IDs\n",
    "        game_id = game_df['game_id'][row]\n",
    "        away_id = game_df['away_id'][row]\n",
    "        home_id = game_df['home_id'][row]\n",
    "\n",
    "        # Retrieve Baseball Reference team abbreviation\n",
    "        team_map_cut = team_map[['teamId', 'BBREFTEAM']].set_index('teamId')\n",
    "        away_team = team_map_cut.loc[away_id]['BBREFTEAM']\n",
    "        home_team = team_map_cut.loc[home_id]['BBREFTEAM']    \n",
    "\n",
    "        # Extract date\n",
    "        game_date = game_df['game_date'][row]\n",
    "        game_date = game_date.replace(\"-\", \"\")\n",
    "        game_datetime = game_df['game_datetime'][row]\n",
    "\n",
    "        # Convert string to datetime object\n",
    "        utc_datetime = datetime.datetime.strptime(game_datetime, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "        # Define the UTC timezone\n",
    "        utc_timezone = pytz.timezone(\"UTC\")\n",
    "\n",
    "        # Set the UTC timezone for the datetime object\n",
    "        utc_datetime = utc_timezone.localize(utc_datetime)\n",
    "\n",
    "        # Convert to Eastern Standard Time (EST)\n",
    "        est_timezone = pytz.timezone(\"US/Eastern\")\n",
    "        est_datetime = utc_datetime.astimezone(est_timezone)\n",
    "\n",
    "        # Format the result\n",
    "        formatted_time = est_datetime.strftime(\"%H%M\")\n",
    "\n",
    "\n",
    "        # Create position dfs\n",
    "        away_batter_df, away_pitcher_df, home_batter_df, home_pitcher_df = create_matchup_file(game_df, row, complete_dataset, steamer_hitters_df, steamer_pitchers_df, team_map)\n",
    "   \n",
    "        \n",
    "        # Create folder, if it doesn't exist\n",
    "        try:\n",
    "            os.mkdir(os.path.join(baseball_path, \"B01. Matchups\", f'Matchups {game_date}'))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # File name\n",
    "        matchup_file = f\"{away_team}@{home_team} {game_id} {formatted_time}\"\n",
    "\n",
    "        # Write to Excel\n",
    "        away_batter_df.to_excel(os.path.join(baseball_path, \"B01. Matchups\", f'Matchups {game_date}', f'{matchup_file}.xlsx'), sheet_name=\"AwayBatters\", engine='openpyxl', index=False)\n",
    "\n",
    "        with pd.ExcelWriter(os.path.join(baseball_path, \"B01. Matchups\", f'Matchups {game_date}', f'{matchup_file}.xlsx'), mode='a', engine='openpyxl') as writer:  \n",
    "            home_batter_df.to_excel(writer, sheet_name='HomeBatters', index=False)\n",
    "\n",
    "        with pd.ExcelWriter(os.path.join(baseball_path, \"B01. Matchups\", f'Matchups {game_date}', f'{matchup_file}.xlsx'), mode='a', engine='openpyxl') as writer:  \n",
    "            away_pitcher_df.to_excel(writer, sheet_name='AwayPitchers', index=False)\n",
    "\n",
    "        with pd.ExcelWriter(os.path.join(baseball_path, \"B01. Matchups\", f'Matchups {game_date}', f'{matchup_file}.xlsx'), mode='a', engine='openpyxl') as writer:  \n",
    "            home_pitcher_df.to_excel(writer, sheet_name='HomePitchers', index=False)\n",
    "\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b2862d-f6ea-41f7-88f7-bc2ed444e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# game_df = read_and_save_games(generate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20daa033-d23b-4aef-b959-d890ad33707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# game_df = game_df.query('date >= \"20221022\"').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecc7a5d-6431-4ca0-be10-f50fa17fb609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# print(len(game_df))\n",
    "# Parallel(n_jobs=-1, verbose=True)(delayed(process_game)(game_df, row) for row in range(len(game_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d2f7d1-c83e-434d-b8ff-d60abb20f13d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
