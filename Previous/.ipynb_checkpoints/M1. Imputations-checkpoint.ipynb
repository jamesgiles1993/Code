{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fac54bd7-8f81-483e-9497-9ce724e3bfaa",
   "metadata": {},
   "source": [
    "# Imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bd73237-db59-48b4-b1e1-2bb16a0de377",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"Imports.ipynb\"\n",
    "\n",
    "# import ast\n",
    "# import datetime\n",
    "# import dateutil.parser\n",
    "# import distutils.dir_util\n",
    "# import glob\n",
    "# import IPython.display\n",
    "# import json\n",
    "# import math\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import pathlib\n",
    "# import pickle\n",
    "# import pyautogui\n",
    "# import pytz\n",
    "# import re\n",
    "# import requests\n",
    "# import selenium\n",
    "# import shutil\n",
    "# import statsapi\n",
    "# import statsmodels.formula.api as smf\n",
    "# import time\n",
    "# import unidecode\n",
    "# import warnings\n",
    "# import webbrowser\n",
    "# import xlrd\n",
    "# import random\n",
    "# import urllib\n",
    "# from urllib.request import urlopen, Request\n",
    "# import zipfile\n",
    "\n",
    "# from bs4 import BeautifulSoup\n",
    "# from datetime import date\n",
    "# from IPython.display import display, Javascript\n",
    "# from joblib import Parallel, delayed\n",
    "# from pathlib import Path\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.common.keys import Keys\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium import webdriver\n",
    "# from openpyxl import load_workbook\n",
    "# from functools import partial\n",
    "\n",
    "# from statsapi import get\n",
    "# from pydfs_lineup_optimizer import get_optimizer, Site, Sport, Player, TeamStack, PlayerFilter, RandomFantasyPointsStrategy\n",
    "\n",
    "# os.chdir(r\"C:\\Users\\james\\Documents\\MLB\\Code\")\n",
    "\n",
    "# import smtplib\n",
    "# import ssl\n",
    "# from email.mime.text import MIMEText\n",
    "# from email.mime.multipart import MIMEMultipart\n",
    "# from email.mime.base import MIMEBase\n",
    "# from email import encoders\n",
    "\n",
    "# # Ensure the warning is ignored only once\n",
    "# warnings.simplefilter(action=\"ignore\")\n",
    "\n",
    "# # Display the DataFrame\n",
    "# pd.set_option(\"display.max_rows\", None)\n",
    "# pd.set_option(\"display.max_columns\", None)\n",
    "# pd.set_option(\"display.width\", None)\n",
    "# pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# # Set paths\n",
    "# model_path = r\"C:\\Users\\james\\Documents\\MLB\\Code\\Models\"\n",
    "# baseball_path = r\"C:\\Users\\james\\Documents\\MLB\\Data2\"\n",
    "# download_path = r\"C:\\Users\\james\\Downloads\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b31b503-b5c2-41e8-bb9d-2356cd789ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import log_loss, classification_report, f1_score, make_scorer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from tensorflow import keras\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b840b4b6-927e-4eaf-98a3-9174951beb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"Utilities.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "159faf23-0371-4cd0-838a-e93e91abda5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This reads in Chadwick register with player codes.\n",
    "keep_list = ['key_mlbam', 'key_fangraphs', 'key_bbref_minors', 'key_bbref', 'name_first', 'name_last']\n",
    "chadwick = read_chadwick(keep_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c9426c9-cb8f-410a-8f77-7cd9082b0d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This reads in a map of team name, codes, and the shorthand MLB uses in their URLs\n",
    "team_map = pd.read_csv(os.path.join(baseball_path, \"Utilities\", \"Team Map.csv\"))\n",
    "\n",
    "# We just need teams right now\n",
    "team_map = team_map[['FULLNAME', 'BBREFTEAM', 'MLBURL', 'FANGRAPHSTEAM', 'VENUE_ID', 'SFBBTEAM', 'DKTEAM', 'ROTOWIRETEAM', 'FANPROSTEAM']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586d160d-01e3-4900-9cb4-f3c06af94e82",
   "metadata": {},
   "source": [
    "# Create sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "806063e4-6d01-400a-bb54-0a69889b1359",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"04. Dataset.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b208a161-1069-4ca8-aad9-dfcf3ce4154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in sample, up until today's date\n",
    "sample = create_model_input(todaysdate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb5bcda-0f05-40ba-989a-746862bac8bb",
   "metadata": {},
   "source": [
    "### FanGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34d7168b-b42b-4936-956b-a71044601dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append all FanGraphs projections together and save it as a CSV\n",
    "batters_list = []\n",
    "# Loop over all FanGraphs files\n",
    "for filename in os.listdir(r\"C:\\Users\\james\\Documents\\MLB\\Data2\\7. Stats\\B. Clean FanGraphs\\Batters\"):\n",
    "    # Extract date\n",
    "    date = filename[12:20]\n",
    "    # Read in dataframe\n",
    "    df = pd.read_csv(os.path.join(baseball_path, \"7. Stats\", \"B. Clean FanGraphs\", \"Batters\", filename), encoding='iso-8859-1')\n",
    "    # Add date column\n",
    "    df['date'] = date\n",
    "    \n",
    "    # Append dataframe to list\n",
    "    batters_list.append(df)\n",
    "    \n",
    "# Create combined dataframe\n",
    "batters_fg_sample = pd.concat(batters_list, axis=0)\n",
    "\n",
    "# Write to CSV\n",
    "batters_fg_sample.to_csv(os.path.join(baseball_path, \"Inputs\", \"Batters FanGraphs.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5588e69-381e-4726-abfe-9bfbfd8e6d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append all FanGraphs projections together and save it as a CSV\n",
    "pitchers_list = []\n",
    "# Loop over all FanGraphs files\n",
    "for filename in os.listdir(r\"C:\\Users\\james\\Documents\\MLB\\Data2\\7. Stats\\B. Clean FanGraphs\\Pitchers\"):\n",
    "    # Extract date\n",
    "    date = filename[13:21]\n",
    "    # Read in dataframe\n",
    "    df = pd.read_csv(os.path.join(baseball_path, \"7. Stats\", \"B. Clean FanGraphs\", \"Pitchers\", filename), encoding='iso-8859-1')\n",
    "    # Create date column\n",
    "    df['date'] = date\n",
    "    \n",
    "    try:\n",
    "        # Depending on the origin of the file (Steamer vs. FanGraphs), you may need to rename certain variables\n",
    "        df.rename(columns={'H9':'H/9', 'HR9':'HR/9', 'K9':'K/9', 'BB9':'BB/9'}, inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Append dataframe to list\n",
    "    pitchers_list.append(df)\n",
    "    \n",
    "# Create combined dataframe\n",
    "pitchers_fg_sample = pd.concat(pitchers_list, axis=0)\n",
    "\n",
    "# Write to CSV\n",
    "pitchers_fg_sample.to_csv(os.path.join(baseball_path, \"Inputs\", \"Pitchers FanGraphs.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cc40a4a-ab18-49b5-ae33-590879f94a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in FanGraphs batter projections for each day\n",
    "batters_fg_sample = pd.read_csv(os.path.join(baseball_path, \"Inputs\", \"Batters FanGraphs.csv\"))\n",
    "# Convert date to string for merge\n",
    "batters_fg_sample['date'] = batters_fg_sample['date'].astype('str')\n",
    "\n",
    "# Merge sample data (Stats API and Statcast) with projections (Fangraphs)\n",
    "sample = sample.merge(batters_fg_sample, left_on=['batter', 'date'], right_on=['mlbamid', 'date'], how='inner', suffixes=(\"\", \"_b\"))\n",
    "# Delete to clear up space\n",
    "del batters_fg_sample\n",
    "\n",
    "# Read in FanGraphs pitcher projections for each day\n",
    "pitchers_fg_sample = pd.read_csv(os.path.join(baseball_path, \"Inputs\", \"Pitchers FanGraphs.csv\"))\n",
    "# Convert date to string for merge\n",
    "pitchers_fg_sample['date'] = pitchers_fg_sample['date'].astype('str')\n",
    "\n",
    "# Merge sample data (Stats API and Statcast) with projections (Fangraphs)\n",
    "sample = sample.merge(pitchers_fg_sample, left_on=['pitcher', 'date'], right_on=['mlbamid', 'date'], how='inner', suffixes=(\"\", \"_p\"))\n",
    "# Delete to clear up space\n",
    "del pitchers_fg_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442f35a0-8398-4fda-a00f-36f978c64b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2aefa65d-3c30-4085-b984-21ccf16dc0fc",
   "metadata": {},
   "source": [
    "# Model Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cb3aac7-bc65-4499-956b-0cc75c5e395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic stat prefixes\n",
    "stats = ['b1','b2','b3','hr','bb','hbp',\n",
    "         'so','fo','go','lo','po',\n",
    "         'iso','slg','obp','woba','estimated_woba_using_speedangle',\n",
    "         'to_left','to_middle','to_right',\n",
    "         'hard_hit','barrel','totalDistance','launchSpeed','maxSpeed','maxSpin',\n",
    "         'ab','pa']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5f2ac3-0497-4ae1-9b78-ff7560923ae6",
   "metadata": {},
   "source": [
    "### Batter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24429473-026e-4211-8301-97551f7a8a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create position/length-specific inputs from stats\n",
    "batter_stats_short = [f\"{stat}_b\" for stat in stats]\n",
    "batter_stats_long  = [f\"{stat}_b_long\" for stat in stats]\n",
    "\n",
    "# FanGraphs stats\n",
    "batter_stats_fg =     ['b1_rate','b2_rate','b3_rate','hr_rate','bb_rate','hbp_rate','so_rate', 'woba', 'slg', 'obp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef70f22-512a-43a4-a998-0db456cec555",
   "metadata": {},
   "source": [
    "### Pitcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a54cfd37-0a83-4992-a21d-6a7300f6a1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create position/length-specific inputs from stats\n",
    "pitcher_stats_short = [f\"{stat}_p\" for stat in stats]\n",
    "pitcher_stats_long  = [f\"{stat}_p_long\" for stat in stats]\n",
    "\n",
    "# FanGraphs stats\n",
    "pitcher_stats_fg =    ['H/9','HR/9','K/9','BB/9']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab88167d-794c-413d-bafc-beb1ceaba8d8",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a22bc81f-f243-4a53-b744-69697f5d8d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Venues\n",
    "venue_nums = ['1', '2', '3', '4', '5', '7', '10', '12', '13', '14', '15', '16', '17', '19', '22', '31', '32', \n",
    "              '680', '2392', '2394', '2395', '2535', '2536', '2602', '2680', '2681', '2701', '2735', '2756', \n",
    "              '2889', '3289', '3309', '3312', '3313', '4169', '4705', '5010', '5325', '5365', '5381', '5445']\n",
    "\n",
    "venues = [f\"venue_{num}\" for num in venue_nums]\n",
    "\n",
    "# Years\n",
    "years = [f\"year_{year}\" for year in range(2015,2024)]\n",
    "\n",
    "# Matchup, weather, and game stat\n",
    "other_list = ['p_L','b_L','x_vect','y_vect','temperature','onFirst','onSecond','onThird','inning','top','score_diff']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d481b260-118d-4c0c-9225-b7e21c39891e",
   "metadata": {},
   "source": [
    "### Exclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32bd805f-05bd-4d22-bdf1-5557642981db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats that do not apply to the position or we just don't want\n",
    "exclude = [\"maxSpeed_b\", \"maxSpin_b\", \"maxSpeed_b_long\", \"maxSpin_b_long\", \n",
    "           \"totalDistance_p\", \"totalDistance_p_long\", \"launchSpeed_p\", \"launchSpeed_p_long\",\n",
    "           \"ab_b\", \"pa_b\", \"ab_b_long\", \"pa_b_long\", \n",
    "           \"ab_p\", \"pa_p\", \"ab_p_long\", \"pa_p_long\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d990afd7-09f6-4e6b-bc96-65e23127fb58",
   "metadata": {},
   "source": [
    "### Input Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f204d7e7-e458-4ef7-a17b-da2b708044b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batter inputs (into final mode)\n",
    "batter_stats = batter_stats_short + batter_stats_long\n",
    "batter_stats = [item for item in batter_stats if item not in exclude]\n",
    "\n",
    "# Pitcher inputs (into final mode)\n",
    "pitcher_stats = pitcher_stats_short + pitcher_stats_long\n",
    "pitcher_stats = [item for item in pitcher_stats if item not in exclude]\n",
    "\n",
    "# All inputs into final model\n",
    "inputs = batter_stats + pitcher_stats + venues + years + other_list\n",
    "\n",
    "\n",
    "# Add additional variables for ease of use\n",
    "inputs_plus = inputs + ['batterName', 'pitcherName', 'batter', 'pitcher', 'batSide', 'pitchHand', 'eventsModel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca10902f-1b78-459d-86b6-ab4c6cc58b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00e3f24d-c10a-4d4d-b44d-22cb150d5652",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa16f35d-f94d-46f9-8d0f-990192b746fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of small samples when training\n",
    "# Important: Figure out if you want this!\n",
    "# sample = sample.query('pa_b_long >= 40').query('pa_p_long >= 40')\n",
    "\n",
    "# Get rid of PA outcomes that are not valid outputs\n",
    "sample = sample.query('eventsModel != \"Cut\"').reset_index(drop=True)\n",
    "\n",
    "# Count outs\n",
    "sample['is_out'] = sample[['so', 'fo', 'go', 'lo', 'po']].sum(axis=1)\n",
    "# Rounding is necessary because SOs are adjusted for park factors, so they might be just above or just below 1.\n",
    "# This isn't an amazing solution, so I could probably do this more cleanly\n",
    "sample['is_out'] = sample['is_out'].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1677c531-6b77-44fa-96fa-3a8f9e4afad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory to models folder \n",
    "os.chdir(r\"C:\\Users\\james\\Documents\\MLB\\Code\\Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "890883f0-e1e6-42d3-8fc0-47c20adeac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove early rows because they'll treat all players like rookies\n",
    "sample = sample.drop(index=sample.index[:10000])\n",
    "sample.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2247758c-610f-4367-8abe-a4486ac5c431",
   "metadata": {},
   "source": [
    "### Standardize FG Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "582af464-cd2a-4517-955b-e9ace4e9c785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "batter_stats_fg_scaled = scaler.fit_transform(sample[batter_stats_fg])\n",
    "batter_stats_fg_scaled = pd.DataFrame(batter_stats_fg_scaled, columns=batter_stats_fg)\n",
    "\n",
    "# Save the trained StandardScaler object\n",
    "scaler_filename = \"batter_stats_fg_scaler.pkl\"\n",
    "with open(scaler_filename, \"wb\") as file:\n",
    "    pickle.dump(scaler, file)\n",
    "    \n",
    "# Standardize the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "pitcher_stats_fg_scaled = scaler.fit_transform(sample[pitcher_stats_fg])\n",
    "pitcher_stats_fg_scaled = pd.DataFrame(pitcher_stats_fg_scaled, columns=pitcher_stats_fg)\n",
    "\n",
    "# Save the trained StandardScaler object\n",
    "scaler_filename = \"pitcher_stats_fg_scaler.pkl\"\n",
    "with open(scaler_filename, \"wb\") as file:\n",
    "    pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eab0281-4f00-407c-ac01-213b2972b008",
   "metadata": {},
   "source": [
    "### Standardize Stats API and Statcast Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "affd2561-d138-4899-9b33-e548762c4220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "batter_stats_scaled = scaler.fit_transform(sample[batter_stats])\n",
    "batter_stats_scaled = pd.DataFrame(batter_stats_scaled, columns=batter_stats)\n",
    "\n",
    "# Save the trained StandardScaler object\n",
    "scaler_filename = \"batter_stats_scaler.pkl\"\n",
    "with open(scaler_filename, \"wb\") as file:\n",
    "    pickle.dump(scaler, file)\n",
    "    \n",
    "# Standardize the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "pitcher_stats_scaled = scaler.fit_transform(sample[pitcher_stats])\n",
    "pitcher_stats_scaled = pd.DataFrame(pitcher_stats_scaled, columns=pitcher_stats)\n",
    "\n",
    "# Save the trained StandardScaler object\n",
    "scaler_filename = \"pitcher_stats_scaler.pkl\"\n",
    "with open(scaler_filename, \"wb\") as file:\n",
    "    pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0279eb90-a9f3-4961-bd10-05e188cd6c17",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cdbe187-dc34-4297-9552-a90dcb6a9c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create working dataset\n",
    "# Extra variables\n",
    "model_extra_vars = venues + years + other_list \n",
    "extra_variable_df = sample[model_extra_vars]\n",
    "\n",
    "# Event variables\n",
    "eventsModel_df = sample[['pa_b', 'pa_p', 'year', 'is_out', 'eventsModel']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9afa09c2-d04a-4fde-b353-4a6725f86f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all together\n",
    "df = pd.concat([batter_stats_scaled, pitcher_stats_scaled, batter_stats_fg_scaled, pitcher_stats_fg_scaled, extra_variable_df, eventsModel_df], axis=1)\n",
    "# Since stats are normalized, this should just assume league average when missing\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7d46ceb-0aac-4f4c-b28f-199e68457076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -2.856849\n",
       "1    3.278646\n",
       "2    1.288464\n",
       "3   -0.849955\n",
       "4    0.599671\n",
       "Name: b1_b, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitcher_stats_scaled['b1_b'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a20280-1565-436b-9fc3-23bbe878c1e6",
   "metadata": {},
   "source": [
    "### Imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fbdef358-0e4b-472a-9db6-a5912af4ab4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\james\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\james\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\james\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\james\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\james\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\james\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\james\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\james\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\james\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1470, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 46 and 92 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](sequential_1/dense_5/BiasAdd, Cast)' with input shapes: [?,46], [?,92].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Pickle\u001b[39;00m\n\u001b[0;32m     28\u001b[0m model_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatter_imputations.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filenecgmpdb.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\james\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\james\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\james\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\james\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\james\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\james\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\james\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\james\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\james\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1470, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 46 and 92 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](sequential_1/dense_5/BiasAdd, Cast)' with input shapes: [?,46], [?,92].\n"
     ]
    }
   ],
   "source": [
    "batter_stats_fg2 = batter_stats_fg + ['b_L', 'p_L']\n",
    "\n",
    "# Create a copy of the DataFrame with only relevant columns\n",
    "df_filtered = df[batter_stats_fg2 + batter_stats + ['pa_b']].copy()\n",
    "\n",
    "# Drop rows with missing values in the features or target columns\n",
    "df_filtered.dropna(subset=batter_stats_fg2 + batter_stats, inplace=True)\n",
    "\n",
    "# Separate the features (batter_stats_fg2) and target (batter_stats) columns\n",
    "features = df_filtered[batter_stats_fg2]\n",
    "target = df_filtered[batter_stats]\n",
    "\n",
    "# Create and fit the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(25, activation='relu', input_shape=(len(batter_stats_fg2),)),\n",
    "    # keras.layers.Dense(25, activation='relu'),\n",
    "    # keras.layers.Dense(25, activation='relu'),\n",
    "    keras.layers.Dense(len(batter_stats))  # Output layer with the same number of units as the target columns\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "model.fit(features, target, epochs=10, batch_size=32)\n",
    "\n",
    "# Pickle\n",
    "model_filename = \"batter_imputations.pkl\"\n",
    "with open(model_filename, \"wb\") as file:\n",
    "    pickle.dump(model, file)\n",
    "    \n",
    "# Use the trained model to make predictions\n",
    "prediction = model.predict(df.loc[df['pa_b'] < 40, batter_stats_fg2])\n",
    "\n",
    "# Impute missing values in batter_stats with the predicted values\n",
    "df.loc[df['pa_b'] < 40, batter_stats] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee3103d-25da-4412-8fe4-3d488c92c147",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitcher_stats_fg2 = pitcher_stats_fg + ['b_L', 'p_L']\n",
    "\n",
    "# Create a copy of the DataFrame with only relevant columns\n",
    "df_filtered = df[pitcher_stats_fg2 + pitcher_stats + ['pa_p']].copy()\n",
    "\n",
    "# Drop rows with missing values in the features or target columns\n",
    "df_filtered.dropna(subset=pitcher_stats_fg2 + pitcher_stats, inplace=True)\n",
    "\n",
    "# Separate the features (pitcher_stats_fg) and target (pitcher_stats) columns\n",
    "features = df_filtered[pitcher_stats_fg2]\n",
    "target = df_filtered[pitcher_stats]\n",
    "\n",
    "# Create and fit the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(25, activation='relu', input_shape=(len(pitcher_stats_fg2),)),\n",
    "    keras.layers.Dense(25, activation='relu'),\n",
    "    keras.layers.Dense(25, activation='relu'),\n",
    "    keras.layers.Dense(len(pitcher_stats))  # Output layer with the same number of units as the target columns\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "# model.fit(features_imputed, target, epochs=5, batch_size=32)\n",
    "model.fit(features, target, epochs=10, batch_size=32)\n",
    "\n",
    "# Use the trained model to make predictions\n",
    "prediction = model.predict(df.loc[df['pa_p'] < 40, pitcher_stats_fg2])\n",
    "\n",
    "# Pickle\n",
    "model_filename = \"pitcher_imputations.pkl\"\n",
    "with open(model_filename, \"wb\") as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "# Impute missing values in pitcher_stats with the predicted values\n",
    "df.loc[df['pa_p'] < 40, pitcher_stats] = prediction\n",
    "\n",
    "\n",
    "# I think what you want to do is add batter hand and pitcher hand. \n",
    "# For batters, batter hand will just be an input and pitcher hand will be entered twice in 7. Stats, once to figure out _l and then _r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d08be1-a64c-4c57-8a25-30e2ff9adaf3",
   "metadata": {},
   "source": [
    "# Impute (for re-running without retraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e785cf58-2b57-47cc-88d8-def2f18b29fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in batter imputation model\n",
    "kmeans_model_filename = \"batter_imputations.pkl\"\n",
    "with open(kmeans_model_filename, \"rb\") as file:\n",
    "    batter_kmeans = pickle.load(file)\n",
    "    \n",
    "# Add handedness to FanGraphs stats\n",
    "batter_stats_fg2 = batter_stats_fg + ['b_L', 'p_L']\n",
    "\n",
    "# Use FanGraphs stats to predict API/Statcast stats for those with limited samples\n",
    "prediction = batter_kmeans.predict(df.loc[df['pa_b'] < 40, batter_stats_fg2])\n",
    "\n",
    "# Impute missing values in batter_stats with the predicted values\n",
    "# df.loc[df['pa_b'] < 40, batter_stats] = prediction\n",
    "df.loc[df['pa_b'] < 40, batter_stats] = prediction[:sum(df['pa_b'] < 40)]\n",
    "\n",
    "\n",
    "\n",
    "# Read in pitcher imputation model\n",
    "kmeans_model_filename = \"pitcher_imputations.pkl\"\n",
    "with open(kmeans_model_filename, \"rb\") as file:\n",
    "    pitcher_kmeans = pickle.load(file)\n",
    "    \n",
    "# Add handedness to FanGraphs stats\n",
    "pitcher_stats_fg2 = pitcher_stats_fg + ['b_L', 'p_L']\n",
    "    \n",
    "# Use FanGraphs stats to predict API/Statcast stats for those with limited samples\n",
    "prediction = pitcher_kmeans.predict(df.loc[df['pa_p'] < 40, pitcher_stats_fg2])\n",
    "\n",
    "# Impute missing values in pitcher_stats with the predicted values\n",
    "# df.loc[df['pa_p'] < 40, pitcher_stats] = prediction\n",
    "df.loc[df['pa_p'] < 40, batter_stats] = prediction[:sum(df['pa_p'] < 40)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be6ddfd-3fed-4fae-867d-505c1ebed166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create imputation flags (could move this up, might make more sense)\n",
    "df['imp_b'] = (df['pa_b'] < 40).astype('int')\n",
    "df['imp_p'] = (df['pa_p'] < 40).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d756e1-8e2a-45c7-98df-b13bceff20eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e29871a-8523-4aac-ad8a-8fa0685b32bb",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219a42a3-972a-4803-a298-f2b2128136d8",
   "metadata": {},
   "source": [
    "##### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5881b5a-7972-4ba8-86ab-014162177881",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_list = batter_stats + pitcher_stats + venues + years + other_list + ['pa_b', 'pa_p', 'imp_b', 'imp_p', 'year', 'is_out', 'eventsModel']\n",
    "model_dataset = df[keep_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b2b29d-b5ab-4fb7-bad2-003a7e25eb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9601272a-37d8-4b71-b9c7-4cd6910e6426",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f350ba-18e3-436a-ba40-b00690e21ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_dataset = model_dataset[model_dataset['eventsModel'].isin(['so', 'lo', 'go', 'fo', 'po'])].copy()\n",
    "safe_dataset = model_dataset[~model_dataset['eventsModel'].isin(['so', 'lo', 'go', 'fo', 'po'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c69e01-dc78-4cfc-ab35-e048259c3fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing groups\n",
    "X_train = model_dataset.groupby(model_dataset['year']).apply(lambda x: x.head(int(len(x)*2/3)))\n",
    "X_test = model_dataset.groupby(model_dataset['year']).apply(lambda x: x.tail(int(len(x)*1/3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a19fa37-7906-4683-a424-b1becd7eb496",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_dataset_train = X_train[X_train['eventsModel'].isin(['so', 'lo', 'go', 'fo', 'po'])].copy()\n",
    "safe_dataset_train = X_train[~X_train['eventsModel'].isin(['so', 'lo', 'go', 'fo', 'po'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7127336-ef02-449f-b133-c0b12cf929c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_dataset_test = X_test[X_test['eventsModel'].isin(['so', 'lo', 'go', 'fo', 'po'])].copy()\n",
    "safe_dataset_test = X_test[~X_test['eventsModel'].isin(['so', 'lo', 'go', 'fo', 'po'])].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2e1a7f-3ded-4038-9651-7d5a9b267986",
   "metadata": {},
   "source": [
    "### Out vs. Safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abdf95a-a430-45d7-b43d-cef40cb970f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs + ['imp_b', 'imp_p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e8a9cf-6889-487f-a7ce-f9faa6c098da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs.remove('imp_b')\n",
    "# inputs.remove('imp_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15690e3d-991d-4a52-8a30-b37b9e9836ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502c5392-30b1-4531-9e62-44eb51034e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "solver = 'lbfgs'\n",
    "\n",
    "iters = 200\n",
    "\n",
    "filename = \"model_binary_\" + \"voting\" + \"_100_new.sav\"\n",
    "\n",
    "print(filename)\n",
    "\n",
    "# Define the individual models in the ensemble\n",
    "models = [\n",
    "    LogisticRegression(solver='lbfgs', max_iter=20),  \n",
    "    LogisticRegression(solver='saga', max_iter=20),   \n",
    "    MLPClassifier(hidden_layer_sizes=(100,100), activation='relu', random_state=1, max_iter=15),  \n",
    "]\n",
    "\n",
    "\n",
    "# Create the ensemble classifier using VotingClassifier\n",
    "# model_binary = VotingClassifier(estimators=[('model'+str(i+1), model) for i, model in enumerate(models)], voting='soft', n_jobs=-2).fit(model_dataset[inputs], model_dataset[['is_out']].values.ravel())\n",
    "model_binary = VotingClassifier(estimators=[('model'+str(i+1), model) for i, model in enumerate(models)], voting='soft', n_jobs=-2).fit(X_train[inputs], X_train[['is_out']].values.ravel())\n",
    "# model_binary = LogisticRegression(solver=solver, max_iter=iters).fit(X_train[inputs], X_train[['is_out']].values.ravel())\n",
    "\n",
    "\n",
    "# Save model\n",
    "pickle.dump(model_binary, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8fb18a-de6c-450c-a011-c10a70aba9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = model_binary.predict_proba(X_test[inputs])\n",
    "X_test['is_safe_pred'] = proba[:, 0]  # Assign the first column of probabilities\n",
    "X_test['is_out_pred'] = proba[:, 1]  # Assign the second column of probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e59feb-6d1b-40b8-aba7-613a317b1736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dataset['decile'] = pd.qcut(model_dataset['is_out_pred'], 10, labels=False)\n",
    "\n",
    "# df_name = \"is_out\" + \"_df\"\n",
    "# globals()[df_name] = model_dataset.groupby('decile').mean().reset_index()\n",
    "\n",
    "X_test['decile'] = pd.qcut(X_test['is_out_pred'], 5, labels=False)\n",
    "\n",
    "df_name = \"is_out\" + \"_df\"\n",
    "globals()[df_name] = X_test.query('imp_b == 0').query('imp_p == 0').groupby('decile').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9c7642-5d5b-4785-8852-d8fdcdc0ecde",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(is_out_df['decile'], is_out_df['is_out_pred'], color='red')\n",
    "plt.plot(is_out_df['decile'], is_out_df['is_out'], color='black')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1b3027-06c5-4fe5-8341-dc5480d2b503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281e471c-b55c-4ec7-ad3c-f204a54b6fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b00202a4-b193-4c7e-9ddf-63badbcb1fc0",
   "metadata": {},
   "source": [
    "### Outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c61bb5-4d2d-441e-97a6-f1754203b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "layers = (30,30,30,30,30)\n",
    "# layers = (25,25,25,25,25)\n",
    "layers_str = ''.join(str(x) for x in layers)\n",
    "\n",
    "iters = 20\n",
    "\n",
    "filename = \"model_outs_\" + layers_str + \"_\" + str(iters) + \"_100.sav\"\n",
    "print(filename)\n",
    "# Define the individual models in the ensemble\n",
    "models = [\n",
    "    MLPClassifier(hidden_layer_sizes=(layers), activation='relu', verbose=True, alpha=0.0001, early_stopping=True, validation_fraction=0.1, random_state=1, max_iter=iters),\n",
    "]\n",
    "\n",
    "# Create the ensemble classifier using VotingClassifier\n",
    "# model_outs = VotingClassifier(estimators=[('model'+str(i+1), model) for i, model in enumerate(models)], voting='soft', n_jobs=-2).fit(outs_dataset[inputs], outs_dataset[['eventsModel']].values.ravel())\n",
    "model_outs = VotingClassifier(estimators=[('model'+str(i+1), model) for i, model in enumerate(models)], voting='soft', n_jobs=-2).fit(outs_dataset_train[inputs], outs_dataset_train[['eventsModel']].values.ravel())\n",
    "\n",
    "# Save model\n",
    "pickle.dump(model_outs, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecbaf7e-5929-4b66-8bdc-5e81e2231936",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_outputs = list(model_outs.classes_)\n",
    "outs_outputs_pred = [x + \"_pred\" for x in outs_outputs]\n",
    "outs_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a517b9c-53bb-43a1-8735-894f671c431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outs_dataset[outs_outputs_pred] = model_outs.predict_proba(outs_dataset[inputs])\n",
    "# outs_dataset_test[outs_outputs_pred] = model_outs.predict_proba(outs_dataset_test[inputs])\n",
    "\n",
    "proba = model_outs.predict_proba(outs_dataset_test[inputs])\n",
    "for i, col in enumerate(outs_outputs_pred):\n",
    "    outs_dataset_test[f'{col}'] = proba[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ca7a3e-afd3-4823-a017-75317bb6b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create deciles\n",
    "# for var in outs_outputs:\n",
    "#     outs_dataset[f'{var}_act'] = (outs_dataset['eventsModel'] == var).astype('int')\n",
    "#     outs_dataset['decile'] = pd.qcut(outs_dataset[f'{var}_pred'], 10, labels=False)\n",
    "#     df_name = var + \"_df\"\n",
    "#     globals()[df_name] = outs_dataset.groupby('decile').mean().reset_index()\n",
    "    \n",
    "# Create deciles\n",
    "for var in outs_outputs:\n",
    "    outs_dataset_test[f'{var}_act'] = (outs_dataset_test['eventsModel'] == var).astype('int')\n",
    "    outs_dataset_test['decile'] = pd.qcut(outs_dataset_test[f'{var}_pred'], 10, labels=False)\n",
    "    df_name = var + \"_df\"\n",
    "    globals()[df_name] = outs_dataset_test.query('imp_b == 0').query('imp_p == 0').groupby('decile').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9f1793-f2e3-40df-86c1-e47b5f521c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figures\n",
    "fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "for i, var in enumerate(outs_outputs):\n",
    "    row = i // 3  # Calculate the row index based on the iteration\n",
    "    col = i % 3   # Calculate the column index based on the iteration\n",
    "    df_name = var + \"_df\"\n",
    "    axs[row, col].plot(globals()[df_name]['decile'], globals()[df_name][f'{var}_pred'], color='red')\n",
    "    axs[row, col].plot(globals()[df_name]['decile'], globals()[df_name][f'{var}_act'], color='black')\n",
    "    axs[row, col].set_title(var)\n",
    "    # axs[row, col].set_ylim(0,0.35)\n",
    "\n",
    "\n",
    "# Add some space between subplots to prevent overlapping\n",
    "fig.tight_layout(pad=.0)\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d92fe9f-3f15-4a09-85d1-bbd5e9ef45cb",
   "metadata": {},
   "source": [
    "### Safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8352dc-4265-4309-9878-77b69d5ee00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "layers = (30,30,30,30,30)\n",
    "# layers = (25,25,25,25,25)\n",
    "layers_str = ''.join(str(x) for x in layers)\n",
    "model = \"safe\"\n",
    "iters = 15\n",
    "alpha = 0.0001\n",
    "activation = 'relu'\n",
    "short = 100\n",
    "\n",
    "\n",
    "# inputs = batter_stats_safe + pitcher_stats_safe + batter_stats_safe_long + pitcher_stats_safe_long + venues + years + other_list\n",
    "\n",
    "filename = \"model_\" + model + \"_\" + activation + \"_\" + layers_str + \"_\" + str(iters) + \"_\" + str(short) + \".sav\"\n",
    "print(filename)\n",
    "# Define the individual models in the ensemble\n",
    "models = [\n",
    "    MLPClassifier(hidden_layer_sizes=(layers), activation=activation, verbose=True, alpha=0.0001, early_stopping=True, validation_fraction=0.1, random_state=1, max_iter=iters),\n",
    "    MLPClassifier(hidden_layer_sizes=(layers), activation=activation, verbose=True, alpha=0.0001, early_stopping=True, validation_fraction=0.1, random_state=2, max_iter=iters),\n",
    "    MLPClassifier(hidden_layer_sizes=(layers), activation=activation, verbose=True, alpha=0.0001, early_stopping=True, validation_fraction=0.1, random_state=3, max_iter=iters),\n",
    "    # MLPClassifier(hidden_layer_sizes=(layers), activation=activation, verbose=True, alpha=0.0001, early_stopping=True, validation_fraction=0.1, random_state=15, max_iter=iters),\n",
    "]\n",
    "\n",
    "# Create the ensemble classifier using VotingClassifier\n",
    "# model_safe = VotingClassifier(estimators=[('model'+str(i+1), model) for i, model in enumerate(models)], voting='soft', n_jobs=-2).fit(safe_dataset[inputs], safe_dataset[['eventsModel']].values.ravel())\n",
    "model_safe = VotingClassifier(estimators=[('model'+str(i+1), model) for i, model in enumerate(models)], voting='soft', n_jobs=-2).fit(safe_dataset_train[inputs], safe_dataset_train[['eventsModel']].values.ravel())\n",
    "# model_safe = MLPClassifier(hidden_layer_sizes=(layers), activation=activation, verbose=True, alpha=0.0001, early_stopping=True, validation_fraction=0.1, random_state=7, max_iter=iters).fit(safe_dataset_train[inputs], safe_dataset_train[['eventsModel']].values.ravel())\n",
    "\n",
    "# Save model\n",
    "pickle.dump(model_safe, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9b28dd-9413-4438-a7f1-2cba198202b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d4c180-0364-4838-be54-3e97e2c85d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_outputs = list(model_safe.classes_)\n",
    "safe_outputs_pred = [x + \"_pred\" for x in safe_outputs]\n",
    "safe_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5870f04-8377-4a70-a243-7994fbcc27c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# safe_dataset[safe_outputs_pred] = model_safe.predict_proba(safe_dataset[inputs])\n",
    "# safe_dataset_test[safe_outputs_pred] = model_safe.predict_proba(safe_dataset_test[inputs])\n",
    "\n",
    "proba = model_safe.predict_proba(safe_dataset_test[inputs])\n",
    "for i, col in enumerate(safe_outputs_pred):\n",
    "    safe_dataset_test[f'{col}'] = proba[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdb223d-6a80-4617-90a2-ffe5b597323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create deciles\n",
    "# for var in safe_outputs:\n",
    "#     safe_dataset[f'{var}_act'] = (safe_dataset['eventsModel'] == var).astype('int')\n",
    "#     safe_dataset['decile'] = pd.qcut(safe_dataset[f'{var}_pred'], 10, labels=False)\n",
    "#     df_name = var + \"_df\"\n",
    "#     globals()[df_name] = safe_dataset.groupby('decile').mean().reset_index()\n",
    "    \n",
    "# Create deciles\n",
    "for var in safe_outputs:\n",
    "    safe_dataset_test[f'{var}_act'] = (safe_dataset_test['eventsModel'] == var).astype('int')\n",
    "    safe_dataset_test['decile'] = pd.qcut(safe_dataset_test[f'{var}_pred'], 10, labels=False)\n",
    "    df_name = var + \"_df\"\n",
    "    globals()[df_name] = safe_dataset_test.query('imp_b == 0').query('imp_p == 0').groupby('decile').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f225da1-6003-408c-aafa-8c90ecd46400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figures\n",
    "fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "for i, var in enumerate(safe_outputs):\n",
    "    row = i // 3  # Calculate the row index based on the iteration\n",
    "    col = i % 3   # Calculate the column index based on the iteration\n",
    "    df_name = var + \"_df\"\n",
    "    axs[row, col].plot(globals()[df_name]['decile'], globals()[df_name][f'{var}_pred'], color='red')\n",
    "    axs[row, col].plot(globals()[df_name]['decile'], globals()[df_name][f'{var}_act'], color='black')\n",
    "    axs[row, col].set_title(var)\n",
    "    # axs[row, col].set_ylim(globals()[df_name][f'{var}_act'].min(),globals()[df_name][f'{var}_act'].max())\n",
    "\n",
    "\n",
    "# Add some space between subplots to prevent overlapping\n",
    "fig.tight_layout(pad=.0)\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48de560f-0208-4d47-9019-a1615e1ea564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1c8801-717b-43ff-99a6-f8d93b98fe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "breaksfadf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15b4a50-acaa-4ae7-8ed7-c586accf3c54",
   "metadata": {},
   "source": [
    "# Single Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3a6bfe-47d4-4852-87c8-78a6ea90d602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "layers = (25,25)\n",
    "layers_str = ''.join(str(x) for x in layers)\n",
    "model = \"full\"\n",
    "iters = 10\n",
    "alpha = 0.0001\n",
    "activation = 'relu'\n",
    "short = 100\n",
    "\n",
    "filename = \"model_\" + model + \"_\" + activation + \"_\" + layers_str + \"_\" + str(iters) + \"_\" + str(short) + \".sav\"\n",
    "print(filename)\n",
    "\n",
    "# # Define the individual models in the ensemble\n",
    "# models = [\n",
    "#     MLPClassifier(hidden_layer_sizes=(layers), activation='relu', verbose=True, alpha=0.0001, early_stopping=True, validation_fraction=0.1, random_state=1, max_iter=iters),\n",
    "# ]\n",
    "\n",
    "# # Create the ensemble classifier using VotingClassifier\n",
    "# # model_binary = VotingClassifier(estimators=[('model'+str(i+1), model) for i, model in enumerate(models)], voting='soft', n_jobs=-2).fit(model_dataset[inputs], model_dataset[['is_out']].values.ravel())\n",
    "# model_full = VotingClassifier(estimators=[('model'+str(i+1), model) for i, model in enumerate(models)], voting='soft', n_jobs=-2).fit(X_train[inputs], X_train[['eventsModel']].values.ravel())\n",
    "\n",
    "model_full = MLPClassifier(hidden_layer_sizes=(layers), activation='relu', verbose=True, alpha=0.0001, early_stopping=True, validation_fraction=0.1, random_state=1, max_iter=iters).fit(X_train[inputs], X_train[['eventsModel']].values.ravel())\n",
    "\n",
    "\n",
    "# Save model\n",
    "pickle.dump(model_full, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4c7b41-78be-468d-ac0b-aad8940005a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_outputs = list(model_full.classes_)\n",
    "full_outputs_pred = [x + \"_pred\" for x in full_outputs]\n",
    "full_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168ec30c-33b3-41f3-bc36-384c6472028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dataset[full_outsputs_pred] = model_full.predict_proba(model_dataset[inputs])\n",
    "X_test[full_outputs_pred] = model_full.predict_proba(X_test[inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e15d1bf-b6d6-4521-828a-15fd5aa1efcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create deciles\n",
    "# for var in full_outputs:\n",
    "#     model_dataset[f'{var}_act'] = (model_dataset['eventsModel'] == var).astype('int')\n",
    "#     model_dataset['decile'] = pd.qcut(model_dataset[f'{var}_pred'], 10, labels=False)\n",
    "#     df_name = var + \"_df\"\n",
    "#     globals()[df_name] = model_dataset.groupby('decile').mean().reset_index()\n",
    "    \n",
    "# Create deciles\n",
    "for var in full_outputs:\n",
    "    X_test[f'{var}_act'] = (X_test['eventsModel'] == var).astype('int')\n",
    "    X_test['decile'] = pd.qcut(X_test[f'{var}_pred'], 10, labels=False)\n",
    "    df_name = var + \"_df\"\n",
    "    globals()[df_name] = X_test.groupby('decile').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1497bf9b-936c-495a-97eb-cd42703e725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figures\n",
    "fig, axs = plt.subplots(4, 3, figsize=(12, 16))\n",
    "\n",
    "for i, var in enumerate(full_outputs):\n",
    "    row = i // 3  # Calculate the row index based on the iteration\n",
    "    col = i % 3   # Calculate the column index based on the iteration\n",
    "    df_name = var + \"_df\"\n",
    "    axs[row, col].plot(globals()[df_name]['decile'], globals()[df_name][f'{var}_pred'], color='red')\n",
    "    axs[row, col].plot(globals()[df_name]['decile'], globals()[df_name][f'{var}_act'], color='black')\n",
    "    axs[row, col].set_title(var)\n",
    "    # axs[row, col].set_ylim(0,0.67)\n",
    "\n",
    "\n",
    "# Add some space between subplots to prevent overlapping\n",
    "fig.tight_layout(pad=.0)\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63ff7bd-f979-46c4-a3e6-80d471a5df89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeaae94-b8d4-4d7e-81c5-1286ae3e26fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do: create a way to calculate probabilities for individual matchups so you can test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
