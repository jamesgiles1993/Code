{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d83c71d0-17db-4afe-878a-b21d02f23306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# baseball_path = r\"C:\\Users\\james\\Documents\\MLB\\Data2\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1ab949-f4d4-497d-a772-84f0aadf8330",
   "metadata": {},
   "source": [
    "# RotoWire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "61f4f975-3d32-48e7-b714-539161b873de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_slate(Name):\n",
    "    if \"(Early)\" in Name:\n",
    "        slate = \"Early\"\n",
    "    elif \"(Late Night)\" in Name:\n",
    "        slate = \"Late Night\"\n",
    "    elif \"Night\" in Name:\n",
    "        slate = \"Night\"\n",
    "    else:\n",
    "        slate = \"All\"\n",
    "        \n",
    "    return slate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8ce72bca-dea2-40e2-990c-d7b376e3aa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_slates(date):\n",
    "    date_dash = date[0:4] + \"-\" + date[4:6] + \"-\" + date[6:]\n",
    "    url = 'https://www.rotowire.com/daily/mlb/saved-lineups.php?date={}'.format(date_dash)\n",
    "    \n",
    "    def fetch_page_source(url):\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            return response.text\n",
    "        else:\n",
    "            raise Exception(f\"Failed to fetch page source. Status code: {response.status_code}\")\n",
    "\n",
    "    def extract_data_from_page(html_content):\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        slates_data = []\n",
    "        for slate in soup.find_all('a', class_='dfs-slate'):\n",
    "            date_fragment, time = [text.strip() for text in slate.find('div', class_='dfs-slate-desc').stripped_strings]\n",
    "            time = time.lower()\n",
    "\n",
    "            slate_name_parts = [text.strip() for text in slate.find('div', class_='dfs-slate-name').stripped_strings]\n",
    "            slate_name = slate_name_parts[0]\n",
    "            num_games = slate_name_parts[-1].split()[0]  # Extract the number of games from the last part\n",
    "\n",
    "            slate_id = slate['href'].split('slateID=')[1]\n",
    "\n",
    "            slates_data.append({'date': date, 'slateID': slate_id, 'name': slate_name, 'time': time, 'games': num_games})\n",
    "\n",
    "        return slates_data\n",
    "\n",
    "    page_source = fetch_page_source(url)\n",
    "    data = extract_data_from_page(page_source)\n",
    "    \n",
    "    # Create a pandas DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Games will be a string of one of the team abbreviations. Fix it.\n",
    "    df['games'] = pd.to_numeric(df['games'], errors='coerce')\n",
    "    df['games'].fillna(1, inplace=True)\n",
    "    df['games'] = df['games'].astype('int') \n",
    "        \n",
    "    df.to_csv(os.path.join(baseball_path, \"11. Projections\", \"RotoWire\", \"A. Slates\", \"Slates \" + date + \".csv\"), index=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "18a8b5df-7645-4a0e-a6d0-9025cfd930be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_points(slateID):\n",
    "    \n",
    "    url = f'https://www.rotowire.com/optimizer/api/mlb/players.php?slateID={slateID}'\n",
    "    \n",
    "    try:\n",
    "        # Fetch JSON data from the API\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an exception for unsuccessful responses\n",
    "        api_data = response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data from API: {e}\")\n",
    "        return None\n",
    "\n",
    "    if not api_data:\n",
    "        print(\"No data found in API response.\")\n",
    "        return None\n",
    "\n",
    "    extracted_data = []\n",
    "\n",
    "    for entry in api_data:\n",
    "        rwID = entry.get('rwID')\n",
    "        slate_id = entry.get('slateID')\n",
    "        first_name = entry.get('firstName')\n",
    "        last_name = entry.get('lastName')\n",
    "        roto_pos = entry.get('rotoPos')\n",
    "        position = ','.join(entry.get('pos', []))\n",
    "        throws = entry.get('throws')\n",
    "        bats = entry.get('bats')\n",
    "        is_pitcher = entry.get('isPitcher')\n",
    "        is_batter = entry.get('isBatter')\n",
    "        team_abbr = entry.get('team', {}).get('abbr')\n",
    "        team_city = entry.get('team', {}).get('city')\n",
    "        team_nickname = entry.get('team', {}).get('nickname')\n",
    "        game_date_time = entry.get('game', {}).get('dateTime')\n",
    "        game_is_dome = entry.get('game', {}).get('isDome')\n",
    "        salary = entry.get('salary')\n",
    "        points = entry.get('pts')\n",
    "        rostership = entry.get('rostership')\n",
    "\n",
    "        row = {\n",
    "            'rwID': rwID,\n",
    "            'slateID': slate_id,\n",
    "            'firstName': first_name,\n",
    "            'lastName': last_name,\n",
    "            'rotoPos': roto_pos,\n",
    "            'position': position,\n",
    "            'throws': throws,\n",
    "            'bats': bats,\n",
    "            'isPitcher': is_pitcher,\n",
    "            'isBatter': is_batter,\n",
    "            'teamAbbr': team_abbr,\n",
    "            'teamCity': team_city,\n",
    "            'teamNickname': team_nickname,\n",
    "            'gameDateTime': game_date_time,\n",
    "            'gameIsDome': game_is_dome,\n",
    "            'salary': salary,\n",
    "            'points': points, \n",
    "            'rostership': rostership\n",
    "        }\n",
    "\n",
    "        extracted_data.append(row)\n",
    "\n",
    "    # Create a pandas DataFrame\n",
    "    df = pd.DataFrame(extracted_data)\n",
    "    \n",
    "    df.to_csv(os.path.join(baseball_path, \"11. Projections\", \"RotoWire\", \"B. Projections\", \"Slate \" + str(slateID) + \".csv\"), index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e960d23a-24ae-47ef-896e-9181277297d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_rotowire(contestKey):\n",
    "    # Identify index of contest\n",
    "    history_index = history_full.loc[history_full['contestKey'] == contestKey].index[0]\n",
    "    \n",
    "    # Extract name and date\n",
    "    name = history_full.loc[history_index, 'name']\n",
    "    date = history_full.loc[history_index, 'date']\n",
    "    \n",
    "    # Use name to pick slate type (All, Afternoon, etc...)\n",
    "    slate = pick_slate(name)\n",
    "    \n",
    "    # Read in slates\n",
    "    roto_slates = pd.read_csv(os.path.join(baseball_path, \"11. Projections\", \"RotoWire\", \"A. Slates\", \"Slates \" + str(int(date)) + \".csv\"))\n",
    "    roto_index = roto_slates.loc[roto_slates['name'] == slate].index[0]\n",
    "    roto_slate = roto_slates.loc[roto_index, 'slateID']\n",
    "\n",
    "    roto_projections = pd.read_csv(os.path.join(baseball_path, \"11. Projections\", \"RotoWire\", \"B. Projections\", \"Slate \" + str(roto_slate) + \".csv\"), encoding='iso-8859-1')\n",
    "    \n",
    "    return roto_projections\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e9bf7334-644d-45b0-ae2e-0b6c525b0fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in history file        \n",
    "# history = pd.read_csv(os.path.join(baseball_path, \"Utilities\", \"Contests.csv\"))\n",
    "\n",
    "# # Sort by date, then draft group, then fee\n",
    "# history.sort_values(['date', 'draftGroupId', 'entryFee'], ascending=False)\n",
    "# # Keep only one observation per draft group \n",
    "# history.drop_duplicates('draftGroupId', keep='first', inplace=True)\n",
    "\n",
    "# history_full = history.copy()\n",
    "# history = history.query('result == 1').query('payout == 1').query('salary == 1')\n",
    "\n",
    "# history = history.reset_index(drop=True)\n",
    "# history['date'] = history['date'].astype('int').astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "85960bd5-4693-4bb0-9161-bf88c8ab4047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roto_projections = read_rotowire(147446392)\n",
    "# roto_projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f9633a21-5102-4e23-ac57-a46012aa14b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime, timedelta\n",
    "# import time\n",
    "\n",
    "# def get_date_range(start_date, end_date):\n",
    "#     date_format = \"%Y%m%d\"\n",
    "#     start_date_obj = datetime.strptime(start_date, date_format)\n",
    "#     end_date_obj = datetime.strptime(end_date, date_format)\n",
    "\n",
    "#     current_date = start_date_obj\n",
    "#     while current_date <= end_date_obj:\n",
    "#         yield current_date.strftime(date_format)\n",
    "#         current_date += timedelta(days=1)\n",
    "\n",
    "# # Example usage:\n",
    "# start_date = \"20221101\"\n",
    "# end_date = \"20221105\"\n",
    "# for date in get_date_range(start_date, end_date):\n",
    "#     print(date)\n",
    "#     try:\n",
    "#         scrape_slates(date)\n",
    "#         time.sleep(2)\n",
    "#     except:\n",
    "#         print(\"Nothing for this day\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e51681af-ee6a-41a8-a0c7-68d53aa93d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # All, Early, Afternoon, Night, Late Night\n",
    "# directory_path = r'C:\\Users\\james\\Documents\\MLB\\Data2\\11. Projections\\RotoWire\\A. Slates'\n",
    "\n",
    "# def process_csv_files_in_directory(directory_path):\n",
    "#     csv_files = [file for file in os.listdir(directory_path) if file.endswith('.csv')]\n",
    "\n",
    "#     for file in csv_files:\n",
    "#         file_path = os.path.join(directory_path, file)\n",
    "#         try:\n",
    "#             df = pd.read_csv(file_path)\n",
    "\n",
    "#             for index, row in df.iterrows():\n",
    "#                 if row['name'] in [\"All\", \"Early\", \"Afternoon\", \"Night\", \"Late Night\"]:\n",
    "#                     slate_id = row['slateID']\n",
    "#                     output_file = os.path.join(r'C:\\Users\\james\\Documents\\MLB\\Data2\\11. Projections\\RotoWire\\B. Projections', f'Slate {slate_id}.csv')\n",
    "\n",
    "#                     if not os.path.exists(output_file):\n",
    "#                         scrape_points(slate_id)\n",
    "\n",
    "#                         time.sleep(5)\n",
    "#         except:\n",
    "#             print(file_path)\n",
    "                    \n",
    "# # Call the function to process the CSV files in the directory\n",
    "# process_csv_files_in_directory(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f4a1ad-2972-4382-9d2a-c407996eb147",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
