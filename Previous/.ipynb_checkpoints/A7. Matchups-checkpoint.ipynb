{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daf6e3c1-eacb-4cd8-b257-ee1d0daaa502",
   "metadata": {},
   "source": [
    "# A6. Stats\n",
    "Source: DKSalaries, A5. Stats <br>\n",
    "\n",
    "This scrapes Swish Analytics for daily weather data <br>\n",
    "Historic data can be found using the stats API <br>\n",
    "\n",
    "To do: <br>\n",
    "    Clean team names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5458dce1-9790-4120-918b-6f91b43a7ca8",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "774b3e91-8e43-4932-8324-abde3eae6fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Utilities.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import xlrd\n",
    "import unidecode\n",
    "import datetime\n",
    "from datetime import date\n",
    "from pathlib import Path\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import import_ipynb\n",
    "from Utilities import *\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\")\n",
    "from distutils.dir_util import copy_tree\n",
    "\n",
    "baseball_path = r\"C:\\Users\\james\\Documents\\MLB\\Data\"\n",
    "download_path = r\"C:\\Users\\james\\Downloads\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ce78c85-0bda-4034-8a40-47c2fa3500cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230403\n"
     ]
    }
   ],
   "source": [
    "todaysdate = date.today()\n",
    "todaysdate_dash = str(todaysdate)\n",
    "todaysdate = todaysdate_dash.replace(\"-\", \"\")\n",
    "\n",
    "# todaysdate = \"20230330\"\n",
    "print(todaysdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7cf8084-518f-430c-9590-e10bd9e825c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This reads in a map of team name, codes, and the number Fangraphs uses in their URLs\n",
    "team_map = pd.read_csv(os.path.join(baseball_path, \"Utilities\", \"Team Map.csv\"))\n",
    "\n",
    "# We just need teams right now\n",
    "team_map = team_map[['DKTEAM', 'BBREFTEAM', 'SFBBTEAM']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b752fa0-d60d-41c0-b852-37da7b787ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lineups = pd.read_csv(f\"https://baseballmonster.com/Lineups.aspx?csv=1&d={todaysdate_dash}\")\n",
    "\n",
    "lineups = lineups.merge(team_map, left_on='team code', right_on='SFBBTEAM', how='inner') \n",
    "\n",
    "# Fill missings\n",
    "lineups[' mlb id'] = np.where(lineups[' player name'] == \"Masataka Yoshida\", 807799, lineups[' mlb id'])\n",
    "\n",
    "# Check missings\n",
    "lineups[' mlb id'].fillna(999999, inplace=True)\n",
    "for i in range(len(lineups)):\n",
    "    if lineups[' mlb id'][i] == 999999:\n",
    "        print(lineups[' player name'][i])\n",
    "        \n",
    "lineups = lineups[[' mlb id', ' batting order', 'BBREFTEAM']]\n",
    "lineups.rename(columns={' mlb id': 'key_mlbam', ' batting order':'batting_order_fill'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be599c30-5e0d-4a23-8164-f797b7bcf904",
   "metadata": {},
   "source": [
    "# DK Salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b815914e-7f0d-422e-b68e-1fc320900ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Position                   Name + ID             Name        ID  \\\n",
      "0          SP     Carlos Rodon (27305242)     Carlos Rodon  27305242   \n",
      "1          SP      Gerrit Cole (27305243)      Gerrit Cole  27305243   \n",
      "2          SP  Clayton Kershaw (27305244)  Clayton Kershaw  27305244   \n",
      "3          SP     Zack Wheeler (27305245)     Zack Wheeler  27305245   \n",
      "4          SP   Framber Valdez (27305246)   Framber Valdez  27305246   \n",
      "...       ...                         ...              ...       ...   \n",
      "1453    3B/SS   Matthew Batten (27305177)   Matthew Batten  27305177   \n",
      "1454    2B/SS     Eguy Rosario (27305180)     Eguy Rosario  27305180   \n",
      "1455       OF    Luis Liberato (27305195)    Luis Liberato  27305195   \n",
      "1456    2B/3B      Yairo Munoz (27305200)      Yairo Munoz  27305200   \n",
      "1457    2B/3B       Jake Hager (27305235)       Jake Hager  27305235   \n",
      "\n",
      "     Roster Position  Salary                      Game Info TeamAbbrev  \\\n",
      "0                  P   10000  PHI@NYY 04/03/2023 07:05PM ET        NYY   \n",
      "1                  P    9900  PHI@NYY 04/03/2023 07:05PM ET        NYY   \n",
      "2                  P    9900  COL@LAD 04/03/2023 10:10PM ET        LAD   \n",
      "3                  P    9800  PHI@NYY 04/03/2023 07:05PM ET        PHI   \n",
      "4                  P    9800  DET@HOU 04/03/2023 08:10PM ET        HOU   \n",
      "...              ...     ...                            ...        ...   \n",
      "1453           3B/SS    2000   ARI@SD 04/03/2023 09:40PM ET         SD   \n",
      "1454           2B/SS    2000   ARI@SD 04/03/2023 09:40PM ET         SD   \n",
      "1455              OF    2000   ARI@SD 04/03/2023 09:40PM ET         SD   \n",
      "1456           2B/3B    2000   ARI@SD 04/03/2023 09:40PM ET        ARI   \n",
      "1457           2B/3B    2000   ARI@SD 04/03/2023 09:40PM ET        ARI   \n",
      "\n",
      "      AvgPointsPerGame  \n",
      "0                22.82  \n",
      "1                22.46  \n",
      "2                21.01  \n",
      "3                19.78  \n",
      "4                21.69  \n",
      "...                ...  \n",
      "1453              1.07  \n",
      "1454              0.71  \n",
      "1455              0.00  \n",
      "1456              3.45  \n",
      "1457              2.50  \n",
      "\n",
      "[1458 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# This reads in the most recently downloaded salary file and saves it \n",
    "def create_dk_salaries():\n",
    "    # Find all DK downloads\n",
    "    dk_files = glob.glob(os.path.join(download_path, 'DKSalaries*.csv'))\n",
    "    dk_files.sort(key=os.path.getmtime)\n",
    "\n",
    "    latest = dk_files[-1]\n",
    "\n",
    "\n",
    "    dk_name = \"DKSalaries_\" + todaysdate + \".csv\"\n",
    "\n",
    "    # Clean DK salaries for merge\n",
    "    dk_salaries = pd.read_csv(os.path.join(download_path, latest))\n",
    "    \n",
    "    print(dk_salaries)\n",
    "    dk_salaries = dk_salaries[dk_salaries['Name'] != \"Caleb Smith\"] # There are two Ca Smiths on Pit. Kept Canaan\n",
    "    \n",
    "    \n",
    "    dk_salaries.to_csv(os.path.join(baseball_path, \"A7. Matchups - 1. Salaries\", dk_name))\n",
    "    \n",
    "create_dk_salaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "800fa9d9-0b7f-4b15-b01f-5ec339967b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This reads in saves salary files and keeps relevant variables. It also creates a list of games.\n",
    "def clean_dk_salaries(date=todaysdate):\n",
    "    # Read in DK Salaries\n",
    "    dk_name = \"DKSalaries_\" + date + \".csv\"\n",
    "    # Clean DK salaries for merge\n",
    "    dk_salaries = pd.read_csv(os.path.join(baseball_path, \"A7. Matchups - 1. Salaries\", dk_name))\n",
    "    \n",
    "    # Clean game info\n",
    "    # For scraped, we already fix the names - make this better universally\n",
    "    dk_salaries['Game Info'] = dk_salaries['Game Info'].replace({\"CWS\":\"CHW\", \"KC\": \"KCR\", \"SD\": \"SDP\", \"SF\":\"SFG\", \"TB\":\"TBR\", \"WAS\":\"WSN\", \"@\": \"_\", \":\": \"\", \"/\": \"\"}, regex=True)\n",
    "    dk_salaries['Game Info'] = dk_salaries['Game Info'].replace({\"@\": \"_\", \":\": \"\", \"/\": \"\"}, regex=True)\n",
    "    # Merge with team map to get baseball reference names\n",
    "    dk_salaries = dk_salaries.merge(team_map, left_on='TeamAbbrev', right_on='DKTEAM', how='left')\n",
    "\n",
    "    # Convert to Baseball Reference team code\n",
    "    dk_salaries['TeamAbbrev'] = dk_salaries['BBREFTEAM']\n",
    "\n",
    "    # Change Ohtani's number\n",
    "    dk_salaries['ID'] = np.where((dk_salaries['Name'] == \"Shohei Ohtani\"), 134045, dk_salaries['ID'])\n",
    "   \n",
    "    # Clean names\n",
    "    dk_salaries = name_clean(dk_salaries)\n",
    "\n",
    "    # This is all we need to merge. \n",
    "    dk_salaries_cut = dk_salaries[['First2', 'Last5', 'BBREFTEAM', 'Salary', 'ID']]\n",
    "\n",
    "\n",
    "    # We also want a separate game info df with teams, time, who's home, date\n",
    "    game_info = dk_salaries[['Game Info']]\n",
    "\n",
    "    # This is the list of all matchups\n",
    "    matchups = game_info['Game Info'].unique()\n",
    "    matchups = matchups.tolist()\n",
    "    \n",
    "    try:\n",
    "        matchups.remove('Postponed')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        matchups.remove('Cancelled')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return dk_salaries_cut, matchups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ff1677-645b-4baa-b366-534c16e439e1",
   "metadata": {},
   "source": [
    "# FanGraphs Replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df91b3af-9b47-43b8-8d12-2397d5556bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fg_batter_replace(df):\n",
    "    # Replace with FanGraphs imputations if sample is small \n",
    "    stat_list = ['so', 'b1', 'b2', 'b3', 'hr', 'bb', 'hbp', 'lo', 'po', 'go', 'fo', 'woba', 'obp', 'slg']\n",
    "    \n",
    "    # Replace small sample size stats with FanGraphs imputations\n",
    "    # Left\n",
    "    df['pa_b_l'].fillna(0, inplace=True)\n",
    "    for stat in stat_list:\n",
    "        short = stat + \"_b_l\"\n",
    "        long = stat + \"_b_long_l\"\n",
    "        fangraphs = stat + \"_l\"\n",
    "        df[short] = np.where(df['pa_b_l'] < 40, df[fangraphs], df[short])\n",
    "        df[long] = np.where(df['pa_b_l'] < 40, df[fangraphs], df[long])\n",
    "\n",
    "    # Right\n",
    "    df['pa_b_r'].fillna(0, inplace=True)\n",
    "    for stat in stat_list:\n",
    "        short = stat + \"_b_r\"\n",
    "        long = stat + \"_b_long_r\"\n",
    "        fangraphs = stat + \"_r\"\n",
    "        df[short] = np.where(df['pa_b_r'] < 40, df[fangraphs], df[short])\n",
    "        df[long] = np.where(df['pa_b_r'] < 40, df[fangraphs], df[long])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c341c644-a2fb-44b6-a2a7-d594f977d3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fg_pitcher_replace(df):\n",
    "    # Replace with FanGraphs imputations if sample is small \n",
    "    stat_list = ['so', 'b1', 'b2', 'b3', 'hr', 'bb', 'hbp', 'lo', 'po', 'go', 'fo', 'woba', 'obp', 'slg']\n",
    "    \n",
    "    # Replace small sample size stats with FanGraphs imputations\n",
    "    # Left\n",
    "    df['pa_p_l'].fillna(0, inplace=True)\n",
    "    for stat in stat_list:\n",
    "        short = stat + \"_p_l\"\n",
    "        long = stat + \"_p_long_l\"\n",
    "        fangraphs = stat + \"_l\"\n",
    "        df[short] = np.where(df['pa_p_l'] < 40, df[fangraphs], df[short])\n",
    "        df[long] = np.where(df['pa_p_l'] < 40, df[fangraphs], df[long])\n",
    "\n",
    "    # Right\n",
    "    df['pa_p_r'].fillna(0, inplace=True)\n",
    "    for stat in stat_list:\n",
    "        short = stat + \"_p_r\"\n",
    "        long = stat + \"_p_long_r\"\n",
    "        fangraphs = stat + \"_r\"\n",
    "        df[short] = np.where(df['pa_p_r'] < 40, df[fangraphs], df[short])\n",
    "        df[long] = np.where(df['pa_p_r'] < 40, df[fangraphs], df[long])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ab9792e-2bfa-425d-9477-8913b08527d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_ins(df):\n",
    "    # Take first two characters of first name\n",
    "    df['First2_fill'] = df['firstName'].str.slice(0,2)\n",
    "    # And first 5 characters of last name\n",
    "    df['Last5_fill'] = df['lastName'].str.slice(0,5)\n",
    "\n",
    "    # Make lower case\n",
    "    df['First2_fill'] = df['First2_fill'].str.lower()\n",
    "    df['Last5_fill'] = df['Last5_fill'].str.lower()\n",
    "\n",
    "    # Make string (this makes the f_remove_accents function work properly\n",
    "    df['First2_fill'] = df['First2_fill'].astype(str) # this one is necessary\n",
    "    df['Last5_fill'] = df['Last5_fill'].astype(str) # this one is not\n",
    "\n",
    "    # Remove accents\n",
    "    df['First2_fill'] = df.apply(lambda x: remove_accents(x['First2_fill']), axis=1)  # remove accents\n",
    "    df['Last5_fill'] = df.apply(lambda x: remove_accents(x['Last5_fill']), axis=1)  # remove accents\n",
    "\n",
    "    # Remove abnormal characters\n",
    "    df['First2_fill'] = df['First2_fill'].str.replace('[^a-zA-Z0-9 ]', '')\n",
    "    df['Last5_fill'] = df['Last5_fill'].str.replace('[^a-zA-Z0-9 ]', '')\n",
    "    \n",
    "    df['First2'].fillna(df['First2_fill'],inplace=True)\n",
    "    df['Last5'].fillna(df['Last5_fill'],inplace=True)\n",
    "    \n",
    "    try:\n",
    "        df['outs'].fillna(9, inplace=True)\n",
    "        df['avgFaced'].fillna(15, inplace=True)\n",
    "        df['starter_api'].fillna(1, inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    df.drop(columns=['First2_fill', 'Last5_fill'], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e680a9-a608-4036-a920-7df859b79c94",
   "metadata": {},
   "source": [
    "# Matchup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d1d9745-5499-413e-b650-407466653a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_matchups(df):\n",
    "    # Add RP leverage to starting pitcher leverage (1 if starter)\n",
    "    df['Leverage'] = np.where(df['starter'] == 1, 1, df['Leverage'])\n",
    "    \n",
    "    # Determine batting order\n",
    "    df['batting_order'] = np.nan\n",
    "    for i in range(9):\n",
    "        df['batting_order'] = np.where(df['order'] == (i+1)*100, i+1, df['batting_order'])\n",
    "    \n",
    "    # Imputed flag\n",
    "    try:\n",
    "        df['imp'] = np.where(df['pa_b_long_r'] < 40, 1, 0)\n",
    "    except:\n",
    "        df['imp'] = np.where(df['pa_p_long_r'] < 40, 1, 0)\n",
    "        \n",
    "    # Delete unnamed columns\n",
    "    df = df.loc[:,~df.columns.str.startswith('Unnamed')]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "596f72f6-1ffa-492a-835a-2ce47904c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matchups(date=todaysdate):\n",
    "    # Read in DK Salaries data\n",
    "    dk_salaries_cut, matchups = clean_dk_salaries(date)\n",
    "    # print(dk_salaries_cut[['First2', 'Last5']])\n",
    "    \n",
    "    daily_folder = \"Daily\" + date\n",
    "    for matchup in matchups:\n",
    "        \n",
    "        # Create new folder with daily rosters\n",
    "        matchup_folder = \"Matchups\" + date\n",
    "        try:\n",
    "            os.mkdir(os.path.join(baseball_path, \"A7. Matchups - 2. Matchups\", matchup_folder))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        away = matchup[0:3]\n",
    "        home = matchup[4:7]\n",
    "        \n",
    "        away_file = away + date + \".xlsx\"\n",
    "        home_file = home + date + \".xlsx\"\n",
    "        \n",
    "        # Read in away data\n",
    "        away_batters = pd.read_excel(os.path.join(baseball_path, \"A5. Stats - 2. Teams\", daily_folder, away_file), sheet_name='Batters')\n",
    "        away_pitchers = pd.read_excel(os.path.join(baseball_path, \"A5. Stats - 2. Teams\", daily_folder, away_file), sheet_name='Pitchers')\n",
    "        \n",
    "        # Read in home data\n",
    "        home_batters = pd.read_excel(os.path.join(baseball_path, \"A5. Stats - 2. Teams\", daily_folder, home_file), sheet_name='Batters')\n",
    "        home_pitchers = pd.read_excel(os.path.join(baseball_path, \"A5. Stats - 2. Teams\", daily_folder, home_file), sheet_name='Pitchers')\n",
    "            \n",
    "        # Replace stats with FG stats if there are too few PAs\n",
    "        away_batters = fg_batter_replace(away_batters)\n",
    "        away_pitchers = fg_pitcher_replace(away_pitchers)\n",
    "        home_batters = fg_batter_replace(home_batters)\n",
    "        home_pitchers = fg_pitcher_replace(home_pitchers)\n",
    "        \n",
    "        # Fill in missings\n",
    "        away_batters = fill_ins(away_batters)\n",
    "        away_pitchers = fill_ins(away_pitchers)\n",
    "        home_batters = fill_ins(home_batters)\n",
    "        home_pitchers = fill_ins(home_pitchers)\n",
    "    \n",
    "        # Merge with DK Salaries\n",
    "        away_batters = away_batters.merge(dk_salaries_cut, on=['First2', 'Last5', 'BBREFTEAM'], how='left')\n",
    "        away_pitchers = away_pitchers.merge(dk_salaries_cut, on=['First2', 'Last5', 'BBREFTEAM'], how='left')\n",
    "        \n",
    "        home_batters = home_batters.merge(dk_salaries_cut, on=['First2', 'Last5', 'BBREFTEAM'], how='left')\n",
    "        home_pitchers = home_pitchers.merge(dk_salaries_cut, on=['First2', 'Last5', 'BBREFTEAM'], how='left')\n",
    "        \n",
    "        # Create name variable so Sims reads in right objects\n",
    "        away_batters['Name'] = away_batters['fullName']\n",
    "        away_pitchers['Name'] = away_pitchers['fullName']\n",
    "        home_batters['Name'] = home_batters['fullName']\n",
    "        home_pitchers['Name'] = home_pitchers['fullName']\n",
    "             \n",
    "        # Clean\n",
    "        away_batters = clean_matchups(away_batters)\n",
    "        away_pitchers = clean_matchups(away_pitchers)\n",
    "        \n",
    "        home_batters = clean_matchups(home_batters)\n",
    "        home_pitchers = clean_matchups(home_pitchers)   \n",
    "        \n",
    "        # Since they're getting fixed, we can make imp all 0, eventually get rid of it\n",
    "        away_batters['imp'] = 0\n",
    "        away_pitchers['imp'] = 0\n",
    "        home_batters['imp'] = 0\n",
    "        home_pitchers['imp'] = 0\n",
    "        \n",
    "        \n",
    "        # Add lineups\n",
    "        away_batters = away_batters.merge(lineups, on=['key_mlbam', 'BBREFTEAM'], how='left')\n",
    "        home_batters = home_batters.merge(lineups, on=['key_mlbam', 'BBREFTEAM'], how='left')\n",
    "        away_pitchers = away_pitchers.merge(lineups, on=['key_mlbam', 'BBREFTEAM'], how='left')\n",
    "        home_pitchers = home_pitchers.merge(lineups, on=['key_mlbam', 'BBREFTEAM'], how='left')\n",
    "              \n",
    "        # Don't need this if backtesting\n",
    "        # Fill in batting orders\n",
    "        away_batters['batting_order_fill'].fillna(\"-1\", inplace=True)\n",
    "        away_batters['batting_order'] = away_batters['batting_order_fill'].astype('int')\n",
    "        away_batters['batting_order'] = np.where(away_batters['batting_order'] == -1, np.nan, away_batters['batting_order'])\n",
    "        away_batters.drop(columns={'batting_order_fill'}, inplace=True)\n",
    "        \n",
    "        home_batters['batting_order_fill'].fillna(\"-1\", inplace=True)\n",
    "        home_batters['batting_order'] = home_batters['batting_order_fill'].astype('int')\n",
    "        home_batters['batting_order'] = np.where(home_batters['batting_order'] == -1, np.nan, home_batters['batting_order'])\n",
    "        home_batters.drop(columns={'batting_order_fill'}, inplace=True)\n",
    "        \n",
    "        away_pitchers['batting_order'] = away_pitchers['batting_order_fill']\n",
    "        away_pitchers['starter'] = np.where(away_pitchers['batting_order'] == \"SP\", 1, 0)\n",
    "        away_pitchers['Leverage'] = np.where(away_pitchers['batting_order'] == \"SP\", 1, away_pitchers['Leverage'])\n",
    "        away_pitchers.drop(columns={'batting_order_fill'}, inplace=True)\n",
    "        \n",
    "        home_pitchers['batting_order'] = home_pitchers['batting_order_fill']\n",
    "        home_pitchers['starter'] = np.where(home_pitchers['batting_order'] == \"SP\", 1, 0)\n",
    "        home_pitchers['Leverage'] = np.where(home_pitchers['batting_order'] == \"SP\", 1, home_pitchers['Leverage'])\n",
    "        home_pitchers.drop(columns={'batting_order_fill'}, inplace=True)\n",
    "        \n",
    "        \n",
    "        away_batters_list = list(away_pitchers.columns)\n",
    "        \n",
    "        batter_list = ['fullName', 'firstName', 'lastName', 'Salary', 'batting_order', 'starter', 'Leverage', 'batSide', 'pitchHand', \n",
    "         'position', 'BBREFTEAM', \n",
    "         'ID', 'id', 'key_mlbam', 'key_fangraphs', 'key_bbref_minors', 'key_bbref', \n",
    "         'name_first', 'name_last', 'First2', 'Last5', 'Name', 'order',        \n",
    "         'status', 'venue_id', 'game_date', 'game_type', 'game_num', 'summary', \n",
    "         'weather', 'wind', 'missing', \n",
    "         'batSide_l', 'so_b_l', 'b1_b_l', 'b2_b_l', 'b3_b_l', 'hr_b_l', 'bb_b_l', 'hbp_b_l', 'lo_b_l', \n",
    "         'po_b_l', 'go_b_l', 'fo_b_l', 'pa_b_l', 'ab_b_l', 'woba_b_l', 'slg_b_l', 'obp_b_l', 'so_b_long_l',\n",
    "         'b1_b_long_l', 'b2_b_long_l', 'b3_b_long_l', 'hr_b_long_l', 'bb_b_long_l', 'hbp_b_long_l', 'lo_b_long_l', \n",
    "         'po_b_long_l', 'go_b_long_l', 'fo_b_long_l', 'pa_b_long_l', 'ab_b_long_l', 'woba_b_long_l', 'slg_b_long_l', 'obp_b_long_l', \n",
    "         'batSide_r', 'so_b_r', 'b1_b_r', 'b2_b_r', 'b3_b_r', 'hr_b_r', 'bb_b_r', 'hbp_b_r', 'lo_b_r',\n",
    "         'po_b_r', 'go_b_r', 'fo_b_r', 'pa_b_r', 'ab_b_r', 'woba_b_r', 'slg_b_r', 'obp_b_r', 'so_b_long_r', 'b1_b_long_r', \n",
    "         'b2_b_long_r', 'b3_b_long_r', 'hr_b_long_r', 'bb_b_long_r', 'hbp_b_long_r', 'lo_b_long_r', 'po_b_long_r', 'go_b_long_r', \n",
    "         'fo_b_long_r', 'pa_b_long_r', 'ab_b_long_r', 'woba_b_long_r', 'slg_b_long_r', 'obp_b_long_r', \n",
    "         'b_L', 'sba_imp', 'sbr', 'obp', 'slg', 'woba', 'b1_rate', 'b2_rate', 'b3_rate', 'hr_rate', 'bb_rate', 'hbp_rate', 'so_rate',\n",
    "         'sba_2b', 'sba_3b', 'sb_2b', 'sb_3b', \n",
    "         'b1_l', 'b2_l', 'b3_l', 'bb_l', 'fo_l', 'go_l', 'hbp_l', 'hr_l', 'lo_l', 'po_l', 'so_l', 'woba_l', 'obp_l', 'slg_l', \n",
    "         'b1_r', 'b2_r', 'b3_r', 'bb_r', 'fo_r', 'go_r', 'hbp_r', 'hr_r', 'lo_r', 'po_r', 'so_r', 'woba_r', 'obp_r', 'slg_r', \n",
    "         'imp']\n",
    "        \n",
    "        pitcher_list = ['fullName', 'firstName', 'lastName', 'Salary', 'batting_order', 'starter', 'Leverage', 'batSide', 'pitchHand', \n",
    "         'position', 'BBREFTEAM', \n",
    "         'ID', 'id', 'key_mlbam', 'key_fangraphs', 'key_bbref_minors', 'key_bbref',  \n",
    "         'name_first', 'name_last', 'First2', 'Last5', 'Name', 'order',               \n",
    "         'status', 'venue_id', 'game_date', 'game_type', 'game_num', 'summary', \n",
    "         'weather', 'wind', 'missing',  \n",
    "         'pitchHand_l', 'so_p_l', 'b1_p_l', 'b2_p_l', 'b3_p_l', 'hr_p_l', 'bb_p_l', 'hbp_p_l', 'lo_p_l', \n",
    "         'po_p_l', 'go_p_l', 'fo_p_l', 'pa_p_l', 'ab_p_l', 'woba_p_l', 'slg_p_l', 'obp_p_l', 'so_p_long_l', \n",
    "         'b1_p_long_l', 'b2_p_long_l', 'b3_p_long_l', 'hr_p_long_l', 'bb_p_long_l', 'hbp_p_long_l', 'lo_p_long_l', \n",
    "         'po_p_long_l', 'go_p_long_l', 'fo_p_long_l', 'pa_p_long_l', 'ab_p_long_l', 'woba_p_long_l', 'slg_p_long_l', 'obp_p_long_l', \n",
    "         'pitchHand_r', 'so_p_r', 'b1_p_r', 'b2_p_r', 'b3_p_r', 'hr_p_r', 'bb_p_r', 'hbp_p_r', 'lo_p_r', \n",
    "         'po_p_r', 'go_p_r', 'fo_p_r', 'pa_p_r', 'ab_p_r', 'woba_p_r', 'slg_p_r', 'obp_p_r', \n",
    "         'so_p_long_r', 'b1_p_long_r', 'b2_p_long_r', 'b3_p_long_r', 'hr_p_long_r', 'bb_p_long_r', 'hbp_p_long_r', 'lo_p_long_r', \n",
    "         'po_p_long_r', 'go_p_long_r', 'fo_p_long_r', 'pa_p_long_r', 'ab_p_long_r', 'woba_p_long_r', 'slg_p_long_r', 'obp_p_long_r', \n",
    "         'p_L', 'outs', 'avgFaced',\n",
    "         'H/9', 'HR/9', 'K/9', 'BB/9', \n",
    "         'b1_l', 'b2_l', 'b3_l', 'bb_l', 'fo_l', 'go_l', 'hbp_l', 'hr_l', 'lo_l', 'po_l', 'so_l', 'woba_l', 'obp_l', 'slg_l', \n",
    "         'b1_r', 'b2_r', 'b3_r', 'bb_r', 'fo_r', 'go_r', 'hbp_r', 'hr_r', 'lo_r', 'po_r', 'so_r', 'woba_r', 'obp_r', 'slg_r', \n",
    "         'imp']\n",
    "        \n",
    "        away_batters = away_batters[batter_list]\n",
    "        home_batters = home_batters[batter_list]\n",
    "        away_pitchers = away_pitchers[pitcher_list]\n",
    "        home_pitchers = home_pitchers[pitcher_list]\n",
    "        \n",
    "        away_batters.sort_values('batting_order', inplace=True)\n",
    "        home_batters.sort_values('batting_order', inplace=True)\n",
    "        away_pitchers.sort_values('Leverage', inplace=True)\n",
    "        home_pitchers.sort_values('Leverage', inplace=True)\n",
    "        \n",
    "        print(matchup)\n",
    "        if away_batters['batting_order'].sum() != 45:\n",
    "            print(\"The sum of the away team's batting order is {}.\".format(away_batters['batting_order'].sum()))\n",
    "        if home_batters['batting_order'].sum() != 45:\n",
    "            print(\"The sum of the home team's batting order is {}.\".format(home_batters['batting_order'].sum()))\n",
    "        if 1 not in list(away_pitchers['Leverage']):\n",
    "            print(\"The away team is missing a starting pitcher.\")\n",
    "        if 4 not in list(away_pitchers['Leverage']):\n",
    "            print(\"The away team is missing a closer.\")\n",
    "        if 1 not in list(home_pitchers['Leverage']):\n",
    "            print(\"The home team is missing a starting pitcher.\")\n",
    "        if 4 not in list(home_pitchers['Leverage']):\n",
    "            print(\"The home team is missing a closer.\")\n",
    "        \n",
    "        # Create file named after matchup\n",
    "        matchup_file = matchup + \".xlsx\"\n",
    "        \n",
    "        # Write to Excel\n",
    "        away_batters.to_excel(os.path.join(baseball_path, \"A7. Matchups - 2. Matchups\", matchup_folder, matchup_file), sheet_name=\"AwayBatters\", engine='openpyxl')\n",
    "\n",
    "        with pd.ExcelWriter(os.path.join(baseball_path, \"A7. Matchups - 2. Matchups\", matchup_folder, matchup_file), mode='a', engine='openpyxl') as writer:  \n",
    "            away_pitchers.to_excel(writer, sheet_name='AwayPitchers')\n",
    "\n",
    "        with pd.ExcelWriter(os.path.join(baseball_path, \"A7. Matchups - 2. Matchups\", matchup_folder, matchup_file), mode='a', engine='openpyxl') as writer:  \n",
    "            home_batters.to_excel(writer, sheet_name='HomeBatters')\n",
    "\n",
    "        with pd.ExcelWriter(os.path.join(baseball_path, \"A7. Matchups - 2. Matchups\", matchup_folder, matchup_file), mode='a', engine='openpyxl') as writer:  \n",
    "            home_pitchers.to_excel(writer, sheet_name='HomePitchers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76624d87-463e-4a4a-958c-227404a58fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHI_NYY 04032023 0705PM ET\n",
      "COL_LAD 04032023 1010PM ET\n",
      "DET_HOU 04032023 0810PM ET\n",
      "ATL_STL 04032023 0745PM ET\n",
      "TOR_KCR 04032023 0740PM ET\n",
      "BAL_TEX 04032023 0805PM ET\n",
      "LAA_SEA 04032023 0940PM ET\n",
      "CLE_OAK 04032023 0940PM ET\n",
      "ARI_SDP 04032023 0940PM ET\n",
      "TBR_WSN 04032023 0705PM ET\n",
      "The sum of the home team's batting order is 42.0.\n",
      "PIT_BOS 04032023 0710PM ET\n"
     ]
    }
   ],
   "source": [
    "create_matchups(todaysdate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e26ba02-7530-42d5-9d30-3951563219f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Run All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "932e6318-9080-4b22-b506-21ba92d5fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loop over dates that we have fangraphs projections for\n",
    "# for filename in os.listdir(r\"C:\\Users\\james\\Documents\\MLB\\Data\\Salaries Scraped\"):\n",
    "#     date = filename[11:19]\n",
    "#     print(date)\n",
    "#     try:\n",
    "#         create_matchups(date)\n",
    "#     except:\n",
    "#         print(\"Can't do\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13be8047-5a5b-48d9-889c-104e082564b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_matchups(\"20220408\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5abf8b66-fdc6-4d31-aaa9-f3d6f59b4ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code was last run on: 2023-04-03 at 09:04:16.\n"
     ]
    }
   ],
   "source": [
    "print(\"Code was last run on: {} at {}.\".format(datetime.date.today(), datetime.datetime.now().strftime(\"%H:%M:%S\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
