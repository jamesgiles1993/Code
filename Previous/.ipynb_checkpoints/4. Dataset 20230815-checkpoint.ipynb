{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5527c04d-632c-4c1a-a1bc-14b1064d47bc",
   "metadata": {},
   "source": [
    "# 4. Dataset\n",
    "Source: <br>\n",
    "1. '4. MLB API <br>\n",
    "\n",
    "Description: This creates usable datasets from the MLB API data <br>\n",
    "Main outputs include batter and pitcher model inputs, neural network PA inputs, and a complete dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3133f248-3dfa-42e4-92e4-dc77346b2a17",
   "metadata": {},
   "source": [
    "### Wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fb7cc7f-df83-4ffd-a8f6-6be7b8791d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate wind vectors\n",
    "# Note: 2 is to centerfield, 6 is from centerfield, clockwise\n",
    "# Note: y vector is positive to centerfield, negative from centerfield\n",
    "# Note: x vector is positive from left to right, negatives from right to left\n",
    "# Assumption is wind is blowing in 8 cardinal directions, so we can use simple right isosceles triangles\n",
    "def y_vect(df):\n",
    "    wind_speed = df['windSpeed']\n",
    "    angled = df['windSpeed'] / 2 * math.sqrt(2)\n",
    "    \n",
    "    if df['windDirection'] == \"Out To CF\": \n",
    "        y_vect = wind_speed\n",
    "    elif df['windDirection'] == \"Out To RF\": \n",
    "        y_vect = angled\n",
    "    elif df['windDirection'] == \"L To R\": \n",
    "        y_vect = 0\n",
    "    elif df['windDirection'] == \"In From LF\": \n",
    "        y_vect = angled * -1\n",
    "    elif df['windDirection'] == \"In From CF\": \n",
    "        y_vect = wind_speed * - 1\n",
    "    elif df['windDirection'] == \"In From RF\": \n",
    "        y_vect = angled * -1\n",
    "    elif df['windDirection'] == \"R To L\": \n",
    "        y_vect = 0\n",
    "    elif df['windDirection'] == \"Out To LF\": \n",
    "        y_vect = angled\n",
    "    else:\n",
    "        y_vect = 0\n",
    "        \n",
    "    return y_vect\n",
    "\n",
    "def x_vect(df):\n",
    "    wind_speed = df['windSpeed']\n",
    "    angled = df['windSpeed'] / 2 * math.sqrt(2)\n",
    "    \n",
    "    if df['windDirection'] == \"L To R\": \n",
    "        x_vect = wind_speed\n",
    "    elif df['windDirection'] == \"In From LF\": \n",
    "        x_vect = angled\n",
    "    elif df['windDirection'] == \"In From CF\": \n",
    "        x_vect = 0\n",
    "    elif df['windDirection'] == \"In From RF\": \n",
    "        x_vect = angled * -1\n",
    "    elif df['windDirection'] == \"R To L\": \n",
    "        x_vect = wind_speed * - 1\n",
    "    elif df['windDirection'] == \"Out To LF\": \n",
    "        x_vect = angled * -1\n",
    "    elif df['windDirection'] == \"Out To CF\": \n",
    "        x_vect = 0\n",
    "    elif df['windDirection'] == \"Out To RF\": \n",
    "        x_vect = angled\n",
    "    else:\n",
    "        x_vect = 0\n",
    "        \n",
    "    return x_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0ad0c6-70e2-4b0c-b337-6da96c19c7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52bdc969-2557-46e7-a82d-16285b3b2900",
   "metadata": {},
   "source": [
    "### Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad560891-c573-4b54-a69c-c6655df0910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_weather(df):\n",
    "    # Separate weather into temperature and weather type\n",
    "    df[['temperature', 'weather']] = df['weather'].str.split(\", \", expand=True)\n",
    "    df['temperature'] = df['temperature'].str.replace(\" degrees\", \"\").astype('int')\n",
    "    # Separate wind into speed and direction\n",
    "    df[['windSpeed', 'windDirection']] = df['wind'].str.split(\", \", expand=True)\n",
    "    df['windSpeed'].fillna(\"0 mph\", inplace=True)\n",
    "    df['windSpeed'] = df['windSpeed'].str.replace(\" mph\", \"\")\n",
    "    df['windSpeed'] = pd.to_numeric(df['windSpeed'], errors='coerce')\n",
    "    df['windSpeed'].fillna(0, inplace=True)\n",
    "    df['windDirection'].fillna('L to R', inplace=True)\n",
    "    df['windSpeed'].unique()\n",
    "    df['windDirection'] = df['windDirection'].str.replace(\".\", \"\")\n",
    "    # Calculate vectors\n",
    "    df['x_vect'] = df.apply(x_vect, axis=1)\n",
    "    df['y_vect'] = df.apply(y_vect, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d65ff0-e3c7-411d-a496-f4c253d38017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa644436-584e-475a-b02b-c1ee57c12599",
   "metadata": {},
   "source": [
    "### Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9ad4be9-bd9a-49e1-bc97-c8a22069919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_events(df):\n",
    "    event_mapping = {\n",
    "        'Strikeout': 'so',\n",
    "        'Strikeout Double Play': 'so',\n",
    "        'Groundout': 'go',\n",
    "        'Fielders Choice': 'go',\n",
    "        'Double Play': 'go',\n",
    "        'Grounded Into DP': 'go',\n",
    "        'Triple Play': 'go',\n",
    "        'Field Error': 'go',\n",
    "        'Forceout': 'go',\n",
    "        'Lineout': 'lo',\n",
    "        'Bunt Lineout': 'lo',\n",
    "        'Flyout': 'fo',\n",
    "        'Sac Fly': 'fo',\n",
    "        'Sac Fly Double Play': 'fo',\n",
    "        'Pop Out': 'po',\n",
    "        'Bunt Pop Out': 'po',\n",
    "        'Hit By Pitch': 'hbp',\n",
    "        'Walk': 'bb',\n",
    "        'Intent Walk': 'bb',\n",
    "        'Single': 'b1',\n",
    "        'Double': 'b2',\n",
    "        'Triple': 'b3',\n",
    "        'Home Run': 'hr'\n",
    "    }\n",
    "\n",
    "    df['eventsModel'] = df['event'].map(event_mapping).fillna('Cut')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8d6f73-8bd8-4e80-8650-eabc1641c874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a69ff98f-fa1f-46c0-b411-a164afcf1383",
   "metadata": {},
   "source": [
    "### Base Running\n",
    "(Perhaps move elsewhere)\n",
    "Calculate SBA2B%, SBA3B%, SB2B%, SB3B%\n",
    "Calculate SB and CS totals\n",
    "Derive new stats: \n",
    "    SBrate = SB / (SB + CS)\n",
    "    SBArate = (SB + CS) / (BB + HBP + 1B)\n",
    "\n",
    "Use actual data for these derived stats (from API) to project the four base running stats\n",
    "    Observations should be player-seasons, but only use full seasons\n",
    "Calculate derived stats in fangraphs projections\n",
    "Use model to predict four base running stats in the fangraphs projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36401d18-9e4d-414b-9269-0ec413a0e9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This turns several variables, including events, venues, hands, and bases into dummies\n",
    "def create_dummies(df):\n",
    "    # Events\n",
    "    event_dummies = pd.get_dummies(df['eventsModel'])\n",
    "    # Venues\n",
    "    venue_dummies = pd.get_dummies(df['venue_id'], prefix='venue')\n",
    "    # Hands\n",
    "    pitcher_dummies = pd.get_dummies(df['pitchHand'], prefix='p')\n",
    "    batter_dummies = pd.get_dummies(df['batSide'], prefix='b')\n",
    "    # Years\n",
    "    year_dummies = pd.get_dummies(df['year'], prefix='year')\n",
    "    \n",
    "    # Create lists of dummies\n",
    "    venue_list = venue_dummies.columns.tolist()\n",
    "    year_list = year_dummies.columns.tolist()\n",
    "    dummy_list = venue_list + year_list\n",
    "    \n",
    "    # Add dummies to dataframe\n",
    "    df = pd.concat([df, event_dummies, venue_dummies, pitcher_dummies, batter_dummies, year_dummies], axis=1)\n",
    "    \n",
    "    # Create dummy for runners on base\n",
    "    df['preOnFirst'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnFirst'].shift(1)\n",
    "    df['preOnSecond'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnSecond'].shift(1)\n",
    "    df['preOnThird'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnThird'].shift(1)\n",
    "    \n",
    "    df['onFirst'] = df['preOnFirst'].notnull().astype('int')\n",
    "    df['onSecond'] = df['preOnSecond'].notnull().astype('int')\n",
    "    df['onThird'] = df['preOnThird'].notnull().astype('int')\n",
    "    \n",
    "    # Top of the inning dummy\n",
    "    df['top'] = np.where(df['halfInning'] == \"top\", 1, 0)\n",
    "    \n",
    "    # Calculate PAs and ABs\n",
    "    df['pa'] = np.where(df['eventsModel'] != \"Cut\", 1, 0)\n",
    "    df['ab'] = df['pa'] - df['hbp'] - df['bb']\n",
    "    \n",
    "    return df, dummy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c75993-5eaf-48c6-8a48-1bb188df6ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2dc99212-b89e-4178-b69d-ac3f8837bfd9",
   "metadata": {},
   "source": [
    "### Rolling Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd06dade-8189-45bd-bf84-fd2032f01cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return a dataframe that can eventually be used as the model input. Has pitcher vs hitter stats, specific to hand\n",
    "def rolling_pas(df, pa_num):\n",
    "    # Stats to calculate rolling averages/maximums\n",
    "    stat_list = ['so', 'b1', 'b2', 'b3', 'hr', 'bb', 'hbp', 'lo', 'po', 'go', 'fo', \n",
    "                 'hard_hit', 'to_left', 'to_middle', 'to_right', 'pa', 'ab']\n",
    "    max_list = ['totalDistance', 'maxSpeed', 'maxSpin', 'launchSpeed']\n",
    "                \n",
    "    # \n",
    "    df['pa_num'] = df.index\n",
    "    \n",
    "    batter_stats = []\n",
    "    pitcher_stats = []\n",
    "    batter_stats2 = []\n",
    "    pitcher_stats2 = []\n",
    "\n",
    "    for stat in stat_list:\n",
    "        batter_stat = stat + \"_b\"\n",
    "        pitcher_stat = stat + \"_p\"\n",
    "        batter_stats.append(batter_stat)\n",
    "        pitcher_stats.append(pitcher_stat)\n",
    "\n",
    "    for stat in max_list:\n",
    "        batter_stat = stat + \"_b\"\n",
    "        pitcher_stat = stat + \"_p\"\n",
    "        batter_stats2.append(batter_stat)\n",
    "        pitcher_stats2.append(pitcher_stat)\n",
    "        \n",
    "    df[batter_stats] = df.groupby(['batter', 'pitchHand'])[stat_list].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).sum())\n",
    "    df[batter_stats2] = df.groupby(['batter', 'pitchHand'])[max_list].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).max())\n",
    "                \n",
    "    df[pitcher_stats] = df.groupby(['pitcher', 'batSide'])[stat_list].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).sum())\n",
    "    df[pitcher_stats2] = df.groupby(['pitcher', 'batSide'])[max_list].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).max())\n",
    "                \n",
    "    df.sort_values(['pa_num'], axis=0, ascending=True, inplace=True)\n",
    "\n",
    "    # wOBA - using 2022 values throughout\n",
    "    df['woba_b'] = (0.690 * df['bb_b']) + (0.721 * df['hbp_b']) + (0.885 * df['b1_b']) + (1.262 * df['b2_b']) + (1.601 * df['b3_b']) + (2.070 * df['hr_b'])\n",
    "    df['woba_p'] = (0.690 * df['bb_p']) + (0.721 * df['hbp_p']) + (0.885 * df['b1_p']) + (1.262 * df['b2_p']) + (1.601 * df['b3_p']) + (2.070 * df['hr_p'])\n",
    "    \n",
    "    # Slugging\n",
    "    df['slg_b'] = (1 * df['b1_b']) + (2 * df['b2_b']) + (3 * df['b3_b']) + (4 * df['hr_b'])\n",
    "    df['slg_b'] = df['slg_b'] / df['ab_b']\n",
    "    df['slg_p'] = (1 * df['b1_p']) + (2 * df['b2_p']) + (3 * df['b3_p']) + (4 * df['hr_p'])\n",
    "    df['slg_p'] = df['slg_p'] / df['ab_p']\n",
    "\n",
    "    # OBP    \n",
    "    df['obp_b'] = df[['b1_b', 'b2_b', 'b3_b', 'hr_b', 'bb_b', 'hbp_b']].sum(axis=1)\n",
    "    df['obp_p'] = df[['b1_p', 'b2_p', 'b3_p', 'hr_p', 'bb_p', 'hbp_p']].sum(axis=1)\n",
    "    \n",
    "    # ISO\n",
    "    df['iso_b'] = df['b2_b'] * 1 + df['b3_b'] * 2 + df['hr_b'] * 3\n",
    "    df['iso_p'] = df['b2_p'] * 1 + df['b3_p'] * 2 + df['hr_p'] * 3\n",
    "\n",
    "    \n",
    "    \n",
    "    # Calculate rates\n",
    "    stat_short = ['so', 'b1', 'b2', 'b3', 'hr', 'bb', 'hbp', 'lo', 'po', 'go', 'fo', 'woba', 'obp', 'iso', 'hard_hit', 'to_left', 'to_middle', 'to_right']\n",
    "    for stat in stat_short:\n",
    "        batter_stat = stat + \"_b\"\n",
    "        pitcher_stat = stat + \"_p\"  \n",
    "        df[batter_stat] = df[batter_stat] / df['pa_b']\n",
    "        df[pitcher_stat] = df[pitcher_stat] / df['pa_p']\n",
    "        \n",
    "    df.sort_values('pa_num', inplace=True)\n",
    "    \n",
    "    batter_stats = batter_stats + batter_stats2\n",
    "    pitcher_stats = pitcher_stats + pitcher_stats2\n",
    "                \n",
    "    return df, batter_stats, pitcher_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3156d38-d585-41c8-98dd-d6fce4e8f76a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e285989-cdf0-4eae-a27c-0ddee3d81bd1",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b135b741-f94a-4270-abd7-f3885734d723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This reads in raw API data\n",
    "def import_data(start_year, end_year):\n",
    "    year_df_list = []\n",
    "    while start_year <= end_year:\n",
    "        # Choose file\n",
    "        filename = \"Play\" + str(start_year) + \".csv\"\n",
    "        \n",
    "        # Read in dataframe\n",
    "        year_df = pd.read_csv(os.path.join(baseball_path, \"3. MLB API\", filename))\n",
    "        \n",
    "        # Only keep one observation per PA (don't keep each runner)\n",
    "        year_df.drop_duplicates(['gamePk', 'atBatIndex'], keep='first', inplace=True, ignore_index=True)\n",
    "\n",
    "        # Create year variable \n",
    "        year_df['year'] = start_year\n",
    "        \n",
    "        # Add it to list of dataframes\n",
    "        year_df_list.append(year_df)\n",
    "                \n",
    "        start_year += 1\n",
    "        \n",
    "    df = pd.concat(year_df_list, axis=0)\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    df = df[df['game_type'] == \"R\"]\n",
    "    df.reset_index(inplace=True)\n",
    "    df.drop(columns={'level_0', 'index'}, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47f4dc0-45e6-4ec2-8ffd-4c40d0a378c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "febc92f5-0d52-4b06-ba02-b24dad9378eb",
   "metadata": {},
   "source": [
    "### Model Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "473defad-26e4-4749-9651-6d80944ecd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statcast(df):\n",
    "    statcast = df.copy()\n",
    "    # Hard hit dummy\n",
    "    statcast['hard_hit'] = (statcast['hardness'].str.contains('hard')).astype('int')\n",
    "    \n",
    "    def find_max(lst):\n",
    "        if lst:\n",
    "            return max(lst)\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    # Max pitch speed\n",
    "    statcast['startSpeeds'] = statcast['startSpeeds'].apply(lambda x: ast.literal_eval(x))\n",
    "    statcast['maxSpeed'] = statcast['startSpeeds'].apply(find_max)\n",
    "    # Have to drop, can't take lists\n",
    "    statcast.drop(columns={'startSpeeds'}, inplace=True)\n",
    "    \n",
    "    # Max spin rate\n",
    "    statcast['spinRates'] = statcast['spinRates'].apply(lambda x: ast.literal_eval(x))\n",
    "    statcast['maxSpin'] = statcast['spinRates'].apply(find_max)\n",
    "    # Have to drop, can't take lists\n",
    "    statcast.drop(columns={'spinRates'}, inplace=True)\n",
    "    \n",
    "    # Launch speeds\n",
    "    statcast['launchSpeeds'] = statcast['launchSpeeds'].str.replace(\"[\", \"\")\n",
    "    statcast['launchSpeeds'] = statcast['launchSpeeds'].str.replace(\"]\", \"\")\n",
    "    statcast['launchSpeed'] = (statcast['launchSpeeds']).astype('float', errors='ignore')\n",
    "    statcast['launchSpeed'] = pd.to_numeric(statcast['launchSpeed'])\n",
    "    \n",
    "    # Launch angle\n",
    "    statcast['launchAngles'] = statcast['launchAngles'].str.replace(\"[\", \"\")\n",
    "    statcast['launchAngles'] = statcast['launchAngles'].str.replace(\"]\", \"\")\n",
    "    statcast['launchAngle'] = (statcast['launchAngles']).astype('float', errors='ignore')\n",
    "    statcast['launchAngle'] = pd.to_numeric(statcast['launchAngle'])\n",
    "        \n",
    "    # Total distances\n",
    "    statcast['totalDistances'] = statcast['totalDistances'].str.replace(\"[\", \"\")\n",
    "    statcast['totalDistances'] = statcast['totalDistances'].str.replace(\"]\", \"\")\n",
    "    statcast['totalDistance'] = (statcast['totalDistances']).astype('float', errors='ignore')\n",
    "    statcast['totalDistance'] = pd.to_numeric(statcast['totalDistance'])\n",
    "    \n",
    "    # Coordinates of batted ball\n",
    "    statcast['coord'] = statcast['coord'].str.replace(\"[\", \"\")\n",
    "    statcast['coord'] = statcast['coord'].str.replace(\"]\", \"\")    \n",
    "    statcast[['x', 'y']] = statcast['coord'].str.split(\",\", expand=True)\n",
    "    statcast['x'] = pd.to_numeric(statcast['x'])\n",
    "    statcast['y'] = pd.to_numeric(statcast['y'])\n",
    "    \n",
    "    statcast['spray_angle'] = np.arctan((statcast['x']-125.42)/(198.27-statcast['y'])) * 180/np.pi * 0.75\n",
    "    statcast['to_left'] = (statcast['spray_angle'] < -15).astype('int')\n",
    "    statcast['to_middle'] = ((statcast['spray_angle'] >= -15) & (statcast['spray_angle'] <= 15)).astype('int')\n",
    "    statcast['to_right'] = (statcast['spray_angle'] > 15).astype('int')\n",
    "\n",
    "    \n",
    "    return statcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dcf06a95-8372-4830-8ae4-1a197a31e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This converts raw data to clean model input\n",
    "def create_model_input(df, date):\n",
    "    keep_list = ['so_b', 'b1_b', 'b2_b', 'b3_b', 'hr_b', 'bb_b', 'hbp_b', 'lo_b', 'po_b', 'go_b', 'fo_b', 'pa_b', 'ab_b', \n",
    "                 'woba_b', 'slg_b', 'obp_b', 'iso_b', 'hard_hit_b', 'to_left_b', 'to_middle_b', 'to_right_b', \n",
    "                 'totalDistance_b', 'maxSpeed_b', 'maxSpin_b', 'launchSpeed_b',\n",
    "                 'so_p', 'b1_p', 'b2_p', 'b3_p', 'hr_p', 'bb_p', 'hbp_p', 'lo_p', 'po_p', 'go_p', 'fo_p', 'pa_p', 'ab_p', \n",
    "                 'woba_p', 'slg_p', 'obp_p', 'iso_p', 'hard_hit_p', 'to_left_p', 'to_middle_p', 'to_right_p', \n",
    "                 'totalDistance_p', 'maxSpeed_p', 'maxSpin_p', 'launchSpeed_p']\n",
    "    \n",
    "    # Clean weather variables\n",
    "    df2 = clean_weather(df)\n",
    "    # Create events\n",
    "    df3 = create_events(df2)\n",
    "    # Make dummies\n",
    "    df4, dummy_list = create_dummies(df3)\n",
    "    # Create Statcast stats\n",
    "    df5 = statcast(df4)\n",
    "    \n",
    "    # Restrict on data\n",
    "    date = datetime.datetime.strptime(date, \"%Y%m%d\")\n",
    "    df5 = df5[df5['date'] < date]\n",
    "    \n",
    "    # Determine score before PA\n",
    "    df5['preAwayScore'] = df5.groupby(['gamePk', 'inning', 'halfInning'])['awayScore'].shift(1)\n",
    "    df5['preHomeScore'] = df5.groupby(['gamePk', 'inning', 'halfInning'])['homeScore'].shift(1)\n",
    "    \n",
    "    df5['preAwayScore'].fillna(df5['awayScore'], inplace=True)\n",
    "    df5['preHomeScore'].fillna(df5['homeScore'], inplace=True)\n",
    "    \n",
    "    # Calculate score differential\n",
    "    df5['score_diff'] = np.where(df5['top'] == 1, df5['preAwayScore'] - df5['preHomeScore'], df5['preHomeScore'] - df5['preAwayScore'])\n",
    "    \n",
    "    # Cut if event isn't one we care about (usually these are weird base running things)\n",
    "    df5 = df5[df5['Cut'] != 1]\n",
    "\n",
    "    # Calculate short time frame rolling stats (100 PAs for now)\n",
    "    dfshort, batter_stats, pitcher_stats = rolling_pas(df5, 100)\n",
    "    dfmain = dfshort.copy()\n",
    "    # Calculate long time frame rolling stats (300 PAs for now)\n",
    "    dflong, batter_stats, pitcher_stats = rolling_pas(df5, 300)\n",
    "    dflong = dflong[keep_list]\n",
    "    dflong = dflong.add_suffix(\"_long\")\n",
    "    # Concatenate them together\n",
    "    sample = pd.concat([dfmain, dflong], axis=1)\n",
    "            \n",
    "    # Delete intermediate DFs\n",
    "    del dfmain, dfshort, dflong, df, df2, df3, df4, df5\n",
    "    \n",
    "    \n",
    "    \n",
    "    return sample, batter_stats, pitcher_stats, dummy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09238787-dd96-4e89-b4cb-dff3deb5e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batter inputs\n",
    "def create_batter_df(df, date):\n",
    "    # Stats of interest\n",
    "    batter_list = ['batter',  'batterName', 'batSide', 'p_L',\n",
    "     'so_b', 'b1_b', 'b2_b', 'b3_b', 'hr_b', 'bb_b', 'hbp_b', 'lo_b', 'po_b', 'go_b', 'fo_b', \n",
    "     'pa_b', 'ab_b', 'woba_b', 'slg_b', 'obp_b', 'iso_b', 'hard_hit_b', 'to_left_b', 'to_middle_b', 'to_right_b', \n",
    "     'totalDistance_b', 'maxSpeed_b', 'maxSpin_b', 'launchSpeed_b', \n",
    "     'so_b_long', 'b1_b_long', 'b2_b_long', 'b3_b_long', 'hr_b_long', 'bb_b_long', 'hbp_b_long', 'lo_b_long', 'po_b_long', 'go_b_long', 'fo_b_long', \n",
    "     'pa_b_long', 'ab_b_long', 'woba_b_long', 'slg_b_long', 'obp_b_long', 'iso_b_long', 'hard_hit_b_long', 'to_left_b_long', 'to_middle_b_long', 'to_right_b_long', \n",
    "     'totalDistance_b_long', 'maxSpeed_b_long', 'maxSpin_b_long', 'launchSpeed_b_long']\n",
    "\n",
    "    # Only keep relevant stats\n",
    "    batters = df[batter_list]\n",
    "    # Only care about most recent stats of each batter before PA\n",
    "    batters.drop_duplicates(subset=['batter', 'p_L'], keep='last', inplace=True)\n",
    "\n",
    "    # Create separate dataframes for vs RHP and LHP\n",
    "    vs_r = batters.query('p_L == 0')\n",
    "    vs_l = batters.query('p_L == 1')\n",
    "\n",
    "    # Merge them together\n",
    "    batters = vs_l.merge(vs_r, on='batter', how='outer', suffixes=('_l', '_r'))\n",
    "\n",
    "    # Drop duplicate columns\n",
    "    batters.drop(columns={'batterName_r', 'p_L_l', 'p_L_r'}, inplace=True)\n",
    "    # Only need this once\n",
    "    batters.rename(columns={'batterName_l': 'batterName'}, inplace=True)\n",
    "    \n",
    "    \n",
    "    # Merge with Chadwick\n",
    "    batters = batters.merge(chadwick, left_on='batter', right_on='key_mlbam', how='left')\n",
    "    \n",
    "    \n",
    "    # Export\n",
    "    batters.to_csv(os.path.join(baseball_path, \"4. Dataset\", \"Batters\", \"Batters\" + date + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca2446d6-a402-4488-ab96-795baf4c72d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pitcher inputs\n",
    "def create_pitcher_df(df, date):\n",
    "    # Stats of interest\n",
    "    pitcher_list =  ['pitcher',  'pitcherName', 'pitchHand', 'b_L',\n",
    "                     'b1_p', 'b2_p', 'b3_p', 'hr_p', 'bb_p', 'hbp_p', \n",
    "                     'so_p', 'lo_p', 'po_p', 'go_p', 'fo_p', \n",
    "                     'woba_p', 'slg_p', 'obp_p', 'iso_p',\n",
    "                     'to_left_p', 'to_middle_p', 'to_right_p', \n",
    "                     'hard_hit_p', 'maxSpeed_p', 'maxSpin_p', 'totalDistance_p', 'launchSpeed_p',\n",
    "                     'pa_p', 'ab_p',\n",
    "                     \n",
    "                     'b1_p_long', 'b2_p_long', 'b3_p_long', 'hr_p_long', 'bb_p_long', 'hbp_p_long', \n",
    "                     'so_p_long', 'lo_p_long', 'po_p_long', 'go_p_long', 'fo_p_long', \n",
    "                     'woba_p_long', 'slg_p_long', 'obp_p_long', 'iso_p_long', \n",
    "                     'to_left_p_long', 'to_middle_p_long', 'to_right_p_long',\n",
    "                     'hard_hit_p_long', 'maxSpeed_p_long', 'maxSpin_p_long', 'totalDistance_p_long', 'launchSpeed_p_long',\n",
    "                     'pa_p_long', 'ab_p_long', \n",
    "\n",
    "                     'inning', 'outs', 'gamePk', 'eventsModel', 'game_date']\n",
    "    \n",
    "    # Only keep relevant stats\n",
    "    pitchers = df[pitcher_list]\n",
    "    \n",
    "    # Calculate average outs\n",
    "    # Create a copy of the dataframe\n",
    "    pitchers_cut = pitchers.copy()\n",
    "    # Only look at PAs since 2019\n",
    "    pitchers_cut = pitchers_cut[pitchers_cut['game_date'] > '2019-04-01']\n",
    "    pitchers_cut.drop_duplicates(subset=['pitcher', 'gamePk', 'inning'], keep='last', inplace=True)\n",
    "    # Identify if they're a starter\n",
    "    pitchers_cut['starter'] = (pitchers_cut['inning'] == 1).astype('int')\n",
    "    # Add up starts\n",
    "    pitchers_cut = pitchers_cut.groupby(['pitcher', 'gamePk'])['outs', 'starter'].sum().reset_index()\n",
    "    # Calculate mean outs and sum of starts\n",
    "    pitchers_cut = pitchers_cut.groupby('pitcher').agg({'outs': np.mean, 'starter': np.sum}).reset_index()\n",
    "\n",
    "    # Only care about most recent stats of each pitcher before PA\n",
    "    pitchers.drop_duplicates(subset=['pitcher', 'b_L'], keep='last', inplace=True)\n",
    "    \n",
    "    # Create separate dataframes for vs RHB and LBH\n",
    "    vs_r = pitchers.query('b_L == 0')\n",
    "    vs_l = pitchers.query('b_L == 1')\n",
    "\n",
    "    # Merge them together\n",
    "    pitchers = vs_l.merge(vs_r, on='pitcher', how='outer', suffixes=('_l', '_r'))\n",
    "    # And add outs/starts\n",
    "    pitchers = pitchers.merge(pitchers_cut, on='pitcher', how='left')\n",
    "    \n",
    "    # Drop duplicate columns\n",
    "    pitchers.drop(columns={'pitcherName_r', 'b_L_l', 'b_L_r', 'inning_r', 'outs_r', 'gamePk_r', 'eventsModel_r', 'game_date_r',  'inning_l',\n",
    "                           'outs_l', 'gamePk_l', 'eventsModel_l', 'game_date_l'}, inplace=True)\n",
    "    # Only need this once\n",
    "    pitchers.rename(columns={'pitcherName_l': 'pitcherName'}, inplace=True)\n",
    "    \n",
    "    # Merge with Chadwick\n",
    "    pitchers = pitchers.merge(chadwick, left_on='pitcher', right_on='key_mlbam', how='left')\n",
    "    \n",
    "    # Take average number of batters faced\n",
    "    faced = df.copy()\n",
    "    faced['faced'] = 1\n",
    "    games = faced.groupby(['pitcher', 'gamePk'])['faced'].sum().reset_index()\n",
    "    games['avgFaced'] = games.groupby('pitcher')['faced'].rolling(30, min_periods=1).mean().shift().reset_index(level=0, drop=True)\n",
    "    games.drop_duplicates(subset=['pitcher'], keep='last', inplace=True)\n",
    "    games = games[['pitcher', 'avgFaced']]\n",
    "    \n",
    "    pitchers = pitchers.merge(games, on='pitcher', how='inner')\n",
    "    \n",
    "    # Export    \n",
    "    pitchers.to_csv(os.path.join(baseball_path, \"4. Dataset\", \"Pitchers\", \"Pitchers\" + date + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2340bb43-c6d4-4973-ac7e-c2c2922281c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates inputs on a given date\n",
    "def create_datasets(df, date):\n",
    "    # Create data for model and data for model inputs \n",
    "    sample, batter_stats, pitcher_stats, dummy_list = create_model_input(df, date)\n",
    "    # Create batter and pitcher csvfiles\n",
    "    create_batter_df(sample, date)\n",
    "    create_pitcher_df(sample, date)\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7f6be5-d899-46ee-a850-8d289b909f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6f5f39f-291d-4d4c-a3fe-d502e6088a4e",
   "metadata": {},
   "source": [
    "### Run One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de0f5665-49d2-49cd-b79d-f78f7748e58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets2(df, date):\n",
    "    df_copy = df.copy()\n",
    "    sample = create_datasets(df_copy, date)\n",
    "    del df_copy\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4863bb8-2937-4534-a875-05d3418bb5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = import_data(2019, 2023) # Changed to 2019 - keep full 2015- for training set below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "118c3447-d02f-4cd6-b7b6-4c57a8418d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # todaysdate = \"20220422\"\n",
    "# sample = create_datasets(df, todaysdate)\n",
    "\n",
    "# # sample.to_csv(os.path.join(baseball_path, \"Inputs\", \"Sample100_unstandardized.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1f5a4e-1104-4804-a71e-1dc66da5f8b3",
   "metadata": {},
   "source": [
    "### Run All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a7654d5-8906-4c15-a7ac-519e955b635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_datasets2(df, todaysdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f9fac01-181e-42a5-8cf3-b7ebefed42cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Haven't tested this yet. \n",
    "# date_list = []\n",
    "# for filename in os.listdir(r\"C:\\Users\\james\\Documents\\MLB\\Data2\\4. Dataset\\Batters\"): \n",
    "#     # Pull out date\n",
    "#     date = filename[7:15]\n",
    "#     date_list.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "248c91f4-a521-4313-a4ba-8dd87a7f08af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for filename in os.listdir(r\"C:\\Users\\james\\Documents\\MLB\\Data2\\4. Dataset\\Batters\"): \n",
    "#     # 2023 \n",
    "#     if filename.endswith(\".csv\"):\n",
    "#         # Pull out date\n",
    "#         date = filename[7:15]\n",
    "#         print(date)\n",
    "#         df = import_data(2019, 2023) # Changed to 2020 - keep full 2015- for training set below\n",
    "#         sample = create_datasets(df, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4d95e9c-3929-4c36-ba27-12bfb0fce3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel(n_jobs=-2, verbose=5)(delayed(create_datasets2)(df, date) for date in date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6643aa8a-2efa-40a2-b048-41892b193afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this using contests.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2051d45b-284a-4d98-aeac-47321b0784e8",
   "metadata": {},
   "source": [
    "### Create Inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01ea7f2f-c11a-4316-ae69-15a389dacdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sample used for training PA model (import_date from 2015 onward)\n",
    "# sample.to_csv(os.path.join(baseball_path, \"Inputs\", \"Sample100_unstandardized.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "857fc768-0a49-4bd9-a088-4aa987be27a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Can we get rid of this?\n",
    "# # You probably don't need to run it again until a new park is created, but it does need to exist\n",
    "# # Park list (all park dummies)\n",
    "# parks = df[['home_name', 'venue_id']]\n",
    "# parks = parks.drop_duplicates().sort_values('home_name')\n",
    "# parks.to_csv(os.path.join(baseball_path, \"Inputs\", \"All Parks.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c283236c-c224-4707-a819-001e6c4db76a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
