{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fc63541-ac5e-4646-87ca-1134c4c1180d",
   "metadata": {},
   "source": [
    "# A5. Stats\n",
    "Source: FanGraphs API <br>\n",
    "\n",
    "This imports stats from Fangraphs <br>\n",
    "This calculates stats that aren't used in the models but help us get there <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d92f9c1-c5d9-4a6a-a837-a564c2bafa9c",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7d4366b7-70bd-48b7-b3a9-79e86c041902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import statsmodels.formula.api as smf\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import datetime\n",
    "from datetime import date\n",
    "import time\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\james\\Documents\\MLB\\Code\")\n",
    "from Utilities import *\n",
    "\n",
    "# import import_ipynb\n",
    "# from Utilities import *\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "model_path = r\"C:\\Users\\james\\Documents\\MLB\\Code\\Models\"\n",
    "baseball_path = r\"C:\\Users\\james\\Documents\\MLB\\Data2\"\n",
    "download_path = r\"C:\\Users\\james\\Downloads\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b22d6a6f-c729-4cf6-9449-4e69d99215cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Today's Date\n",
    "# YYYY-MM-DD (datetime)\n",
    "todaysdate_dt = datetime.date.today()\n",
    "\n",
    "# YYYY-MM-DD (string)\n",
    "todaysdate_dash = str(todaysdate_dt)\n",
    "\n",
    "# MM/DD/YYYY\n",
    "todaysdate_slash = todaysdate_dash.split(\"-\")\n",
    "todaysdate_slash = todaysdate_slash[1] + \"/\" + todaysdate_slash[2] + \"/\" + todaysdate_slash[0]\n",
    "\n",
    "# YYYYMMDD\n",
    "todaysdate = todaysdate_dash.replace(\"-\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a32d76b1-8a07-4ff9-945b-1b63f3428bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    " # This reads in Chadwick register with player codes.\n",
    "keep_list = ['key_mlbam', 'key_fangraphs', 'name_first', 'name_last']\n",
    "chadwick = read_chadwick(keep_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "31b9b566-8422-4f4a-bdcb-68e48c57ba1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "crosswalk = pd.read_csv(os.path.join(baseball_path, \"Utilities\", \"Crosswalk.csv\"), encoding='iso-8859-1') \n",
    "crosswalk = crosswalk[['mlbamid', 'steamerid']]\n",
    "crosswalk.rename(columns={'mlbamid':'mlbamid_fill'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44283ed-806a-457a-837a-28a10ea9999e",
   "metadata": {},
   "source": [
    "### Scrape FanGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9b86dfa1-82b2-4738-80d9-4e1f4bad0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fangraphs API\n",
    "def scrape_batters():\n",
    "    # Read in API json\n",
    "    batters_lb = pd.read_json('https://www.fangraphs.com/api/projections?type=steamer&stats=bat&pos=all&team=0&players=0&lg=all')\n",
    "\n",
    "    # Name is currently some weird thing with a bunch of data. We don't need all that\n",
    "    batters_lb['Name'] = batters_lb['PlayerName']\n",
    "    # Rename to match steam. Note that steamerid = key_fangraphs\n",
    "    batters_lb.rename(columns={'playerids':'steamerid'}, inplace=True)\n",
    "    # Convert to string\n",
    "    chadwick['key_fangraphs'] = (chadwick['key_fangraphs']).astype('str')\n",
    "    # Remove trailing .0\n",
    "    chadwick['key_fangraphs'] = chadwick['key_fangraphs'].str.replace(r'\\.\\d', \"\", regex=True)\n",
    "    \n",
    "    # Merge with chadwick for mlbamid\n",
    "    batters_lb = batters_lb.merge(chadwick, left_on='steamerid', right_on='key_fangraphs', how='left')\n",
    "    batters_lb = batters_lb.merge(crosswalk, on='steamerid', how='left')\n",
    "    \n",
    "    \n",
    "    # Create missing columns to match what's provided by steamer \n",
    "    batters_lb['proj_date'] = todaysdate\n",
    "    batters_lb['mlbamid'] = batters_lb['key_mlbam']\n",
    "    batters_lb['bats'] = \"MI\" # Not included in FanGraphs data\n",
    "    batters_lb['playerid'] = batters_lb['steamerid']\n",
    "    batters_lb['NIBB'] = batters_lb['BB'] - batters_lb['IBB']\n",
    "    batters_lb.rename(columns={'name_first':'firstname', 'name_last':'lastname', 'minpos':'position'}, inplace=True)\n",
    "\n",
    "    batters_lb['mlbamid'].fillna(batters_lb['mlbamid_fill'], inplace=True)\n",
    "    \n",
    "    # Keep relevant variables and in order\n",
    "    batters_lb = batters_lb[['proj_date', 'mlbamid', 'steamerid', 'firstname', 'lastname', 'Team', 'position', 'bats', \n",
    "                             'PA', 'IBB', 'NIBB', 'BB', 'SO', 'HBP', 'H', '2B', '3B', 'HR', 'OBP', 'SLG', 'wOBA', 'SB', 'CS', 'playerid', 'Name']]\n",
    "\n",
    "    # Export to CSV\n",
    "    batters_lb.to_csv(os.path.join(baseball_path, \"7. Stats\", \"A. Raw FanGraphs\", \"Batters\", \"Batters_FG_\" + todaysdate + \".csv\"), encoding='iso-8859-1')\n",
    "    \n",
    "scrape_batters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e5b19f24-4170-43ae-9b0c-ac7830c6c699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fangraphs API\n",
    "def scrape_pitchers():\n",
    "    # Read in API json\n",
    "    pitchers_lb = pd.read_json('https://www.fangraphs.com/api/projections?type=steamer&stats=pit&pos=all&team=0&players=0&lg=all')\n",
    "\n",
    "    # Name is currently some weird thing with a bunch of data. We don't need all that\n",
    "    pitchers_lb['Name'] = pitchers_lb['PlayerName']\n",
    "    # Rename to match steam. Note that steamerid = key_fangraphs\n",
    "    pitchers_lb.rename(columns={'playerids':'steamerid'}, inplace=True)\n",
    "    # Convert to string\n",
    "    chadwick['key_fangraphs'] = (chadwick['key_fangraphs']).astype('str')\n",
    "    # Remove trailing .0\n",
    "    chadwick['key_fangraphs'] = chadwick['key_fangraphs'].str.replace(r'\\.\\d', \"\", regex=True)\n",
    "    \n",
    "    # Merge with chadwick for mlbamid\n",
    "    pitchers_lb = pitchers_lb.merge(chadwick, left_on='steamerid', right_on='key_fangraphs', how='left')\n",
    "    pitchers_lb = pitchers_lb.merge(crosswalk, on='steamerid', how='left')\n",
    "\n",
    "\n",
    "    # Create missing columns to match what's provided by steamer \n",
    "    pitchers_lb['proj_date'] = todaysdate\n",
    "    pitchers_lb['mlbamid'] = pitchers_lb['key_mlbam']\n",
    "    pitchers_lb['Throws'] = \"MI\" # Not included in FanGraphs data\n",
    "    pitchers_lb['playerid'] = pitchers_lb['steamerid']\n",
    "    pitchers_lb.rename(columns={'name_first':'firstname', 'name_last':'lastname', 'minpos':'position'}, inplace=True)\n",
    "\n",
    "    pitchers_lb['mlbamid'].fillna(pitchers_lb['mlbamid_fill'], inplace=True)\n",
    "\n",
    "    \n",
    "    # Keep relevant variables and in order\n",
    "    pitchers_lb = pitchers_lb[['proj_date', 'mlbamid', 'steamerid', 'firstname', 'lastname', 'Throws', \n",
    "                               'IP', 'G', 'GS', 'K/9', 'BB/9', 'H', 'HR', 'playerid', 'Name']]\n",
    "    \n",
    "    # Export to CSV\n",
    "    pitchers_lb.to_csv(os.path.join(baseball_path, \"7. Stats\", \"A. Raw FanGraphs\", \"Pitchers\", \"Pitchers_FG_\" + todaysdate + \".csv\"), encoding='iso-8859-1')\n",
    "    \n",
    "scrape_pitchers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90668205-2c3b-426c-b936-cd4c93a0a2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c888a735-c96c-4f51-ad3d-a5f3c6914aaf",
   "metadata": {},
   "source": [
    "### Create Useful Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "609b2398-43ad-45a5-b9d8-3084d9ff0f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_intermediate_batters(date):\n",
    "    # Read in file\n",
    "    filename = \"Batters_FG_\" + date + \".csv\"\n",
    "    df = pd.read_csv(os.path.join(baseball_path, \"7. Stats\", \"A. Raw FanGraphs\", \"Batters\", filename), encoding='iso-8859-1')\n",
    "    # Create singles\n",
    "    df['1B'] = df['H'] - df['2B'] - df['3B'] - df['HR']\n",
    "    \n",
    "    # Basic stats\n",
    "    hit_list = ['1B', '2B', '3B', 'HR', 'BB', 'HBP', 'SO']\n",
    "\n",
    "    # Advance stats\n",
    "    rate_list = ['OBP', 'SLG', 'wOBA']\n",
    "    for stat in hit_list:\n",
    "        rate = stat + \"_rate\"\n",
    "        rate_list.append(rate)\n",
    "        df[rate] = df[stat] / df['PA']\n",
    "\n",
    "    df['SBA'] = df['SB'] + df['CS']\n",
    "    df['SBO'] = df['1B'] + df['BB'] + df['HBP']\n",
    "    df['sba_imp'] = df['SBA'] / df['SBO']\n",
    "\n",
    "    # Cap imputed SBA \n",
    "    df['sba_imp'] = np.where(df['sba_imp'] > 0.15, 0.15, df['sba_imp'])\n",
    "\n",
    "    # Determine stolen base success rate\n",
    "    df['sbr'] = df['SB'] / df['SBA']\n",
    "    \n",
    "    keep_list = ['Name', 'mlbamid', 'playerid', 'sba_imp', 'sbr'] + rate_list\n",
    "    df = df[keep_list]\n",
    "    \n",
    "    df['sbr'].fillna(0.6, inplace=True) # assume 25th percentile \n",
    "    df['sba_imp'].fillna(0.05, inplace=True) # assume low prob\n",
    "    \n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.rename(columns={'1b_rate': 'b1_rate', '2b_rate': 'b2_rate', '3b_rate': 'b3_rate'}, inplace=True)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    sba_2b_reg = pickle.load(open(os.path.join(model_path, 'sba_2b_20220901.sav'), 'rb'))\n",
    "    df['sba_2b'] = sba_2b_reg.predict(df[['sba_imp']])\n",
    "\n",
    "    sba_3b_reg = pickle.load(open(os.path.join(model_path, 'sba_3b_20220901.sav'), 'rb'))\n",
    "    df['sba_3b'] = sba_3b_reg.predict(df[['sba_imp']])\n",
    "\n",
    "    sb_2b_reg = pickle.load(open(os.path.join(model_path, 'sb_2b_20220901.sav'), 'rb'))\n",
    "    df['sb_2b'] = sb_2b_reg.predict(df[['sbr']])\n",
    "\n",
    "    sb_3b_reg = pickle.load(open(os.path.join(model_path, 'sb_3b_20220901.sav'), 'rb'))\n",
    "    df['sb_3b'] = sb_3b_reg.predict(df[['sbr']])\n",
    "       \n",
    "    # Merge with chadwick to fix certain fangraphs ids \n",
    "    df = df.merge(chadwick, left_on='mlbamid', right_on='key_mlbam', how='left')\n",
    "    # df['key_fangraphs'] = df['key_fangraphs'].astype('int', errors='ignore')\n",
    "    df['playerid'] = np.where(df['playerid'].str.startswith(\"sa\") & ~df['key_fangraphs'].isna(), df['key_fangraphs'], df['playerid'])\n",
    "    df['playerid'] = df['playerid'].astype('string')\n",
    "    df['playerid'] = df['playerid'].str.replace(r'\\.0', '', regex=True)\n",
    "        \n",
    "    df.drop(columns={'index', 'key_fangraphs', 'key_mlbam', 'name_first', 'name_last'}, inplace=True)\n",
    "    \n",
    "    # Write intermediate FanGraphs data to csv\n",
    "    df.to_csv(os.path.join(baseball_path, \"7. Stats\", \"B. Clean FanGraphs\", \"Batters\", \"Batters_FG2_\" + date + \".csv\"), encoding='iso-8859-1')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "caaace8c-a39a-48b3-9247-4a6926396a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_intermediate_pitchers(date):\n",
    "    # Read in file\n",
    "    filename = \"Pitchers_FG_\" + date + \".csv\"\n",
    "    df = pd.read_csv(os.path.join(baseball_path, \"7. Stats\", \"A. Raw FanGraphs\", \"Pitchers\", filename), encoding='iso-8859-1')\n",
    "    \n",
    "    df['H9'] = df['H'] / df['IP'] * 9\n",
    "    df['HR9'] = df['HR'] / df['IP'] * 9\n",
    "    \n",
    "    df.rename(columns={'K/9':'K9', 'BB/9':'BB9'}, inplace=True)\n",
    "    \n",
    "    keep_list = ['playerid', 'mlbamid', 'H9', 'HR9', 'K9', 'BB9'] \n",
    "    df = df[keep_list]\n",
    "    \n",
    "    # Merge with chadwick to fix certain fangraphs ids \n",
    "    df = df.merge(chadwick, left_on='mlbamid', right_on='key_mlbam', how='left')\n",
    "    # df['key_fangraphs'] = df['key_fangraphs'].astype('int', errors='ignore')\n",
    "    df['playerid'] = np.where(df['playerid'].str.startswith(\"sa\") & ~df['key_fangraphs'].isna(), df['key_fangraphs'], df['playerid'])\n",
    "    df['playerid'] = df['playerid'].astype('string')\n",
    "    df['playerid'] = df['playerid'].str.replace(r'\\.0', '', regex=True)\n",
    "    \n",
    "    df.drop(columns={'index', 'key_fangraphs', 'key_mlbam', 'name_first', 'name_last'}, inplace=True)\n",
    "    \n",
    "    \n",
    "    # Write intermediate FanGraphs data to csv\n",
    "    df.to_csv(os.path.join(baseball_path, \"7. Stats\", \"B. Clean FanGraphs\", \"Pitchers\", \"Pitchers_FG2_\" + date + \".csv\"), encoding='iso-8859-1')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bb13783e-2be3-4035-ba94-26666f21802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batter_merge(date):\n",
    "    # Read in batter stats from API\n",
    "    batter_filename = \"Batters\" + date + \".csv\"\n",
    "    batters_api = pd.read_csv(os.path.join(baseball_path, \"4. Dataset\", \"Batters\", batter_filename), encoding='iso-8859-1')\n",
    "    \n",
    "    # Make string, remove trailing .0\n",
    "    batters_api = fix_fangraphs(batters_api)\n",
    "    \n",
    "    # Read in batter projections from FanGraphs\n",
    "    batters_fg = create_intermediate_batters(date)\n",
    "    batters_fg['key_fangraphs'] = batters_fg['playerid']\n",
    "    \n",
    "    \n",
    "    # Merge API data with FG data\n",
    "    batters_df = batters_api.merge(batters_fg, left_on='key_mlbam', right_on='mlbamid', how='outer')\n",
    "    \n",
    "    return batters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ed28c3e2-bfd0-483a-96a6-a392cf99e327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitcher_merge(date):\n",
    "    # Read in pitcher stats from API\n",
    "    pitcher_filename = \"Pitchers\" + date + \".csv\"\n",
    "    pitchers_api = pd.read_csv(os.path.join(baseball_path, \"4. Dataset\", \"Pitchers\", pitcher_filename), encoding='iso-8859-1')\n",
    "    \n",
    "    # Make string, remove trailing .0\n",
    "    pitchers_api = fix_fangraphs(pitchers_api)\n",
    "    \n",
    "    # Read in pitcher projections from FanGraphs\n",
    "    pitchers_fg = create_intermediate_pitchers(date)\n",
    "    pitchers_fg['key_fangraphs'] = pitchers_fg['playerid']\n",
    "\n",
    "    # Merge API data with FG data\n",
    "    pitchers_df = pitchers_api.merge(pitchers_fg, left_on='key_mlbam', right_on='mlbamid', how='outer')\n",
    "\n",
    "    \n",
    "    return pitchers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d58c57b-9dcc-417a-895f-f66f82b2080f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e4a8143-8d14-44db-a4fc-ee5357038449",
   "metadata": {},
   "source": [
    "### Create Rosters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "77fc9b82-1b1c-45b7-9f60-fb371e28a479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_team_rosters(date=todaysdate):\n",
    "    # Create new folder with daily rosters\n",
    "    team_folder = \"Daily\" + date\n",
    "    try:\n",
    "        os.mkdir(os.path.join(baseball_path, \"7. Stats\", \"C. Teams\", team_folder))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Locate daily rosters\n",
    "    rosters_folder = \"Rosters\" + date\n",
    "    rosters_path = os.path.join(baseball_path, \"6. Rosters\", rosters_folder)\n",
    "    \n",
    "    \n",
    "    # Merge API and FG data\n",
    "    batters_df = batter_merge(date)\n",
    "    pitchers_df = pitcher_merge(date)\n",
    "    \n",
    "\n",
    "    \n",
    "    for filename in os.listdir(rosters_path):\n",
    "        print(filename)\n",
    "        # Read in roster\n",
    "        df = pd.read_csv(os.path.join(rosters_path, filename), encoding='iso-8859-1')\n",
    "\n",
    "        # Destination     \n",
    "        excel_file = filename.replace(\".csv\", \"\")\n",
    "        excel_file = excel_file + \".xlsx\"\n",
    "        file_name = os.path.join(baseball_path, \"7. Stats\", \"C. Teams\", team_folder, excel_file)\n",
    "\n",
    "\n",
    "        ### Batters\n",
    "        batters_merged = df.merge(batters_df, left_on='id', right_on='batter', how='left', suffixes=(\"\", \"_api\"))\n",
    "        \n",
    "        # Only keep batters\n",
    "        batters_merged = batters_merged.query('position != \"P\"')\n",
    "        \n",
    "        # Create dummy variable for if they're a lefty. This is necessary to project. (maybe move this)\n",
    "        batters_merged['b_L'] = np.where(batters_merged['batSide'] == \"L\", 1, 0)\n",
    "        \n",
    "        # Save as Excel\n",
    "        batters_merged.to_excel(file_name, sheet_name=\"Batters\", engine='openpyxl')\n",
    "        \n",
    "\n",
    "        ### Pitcher\n",
    "        pitchers_merged = df.merge(pitchers_df, left_on='id', right_on='pitcher', how='left', suffixes=(\"\", \"_api\"))\n",
    "        \n",
    "        # Only keep pitchers\n",
    "        pitchers_merged = pitchers_merged[(pitchers_merged['position'] == 'P') | (pitchers_merged['position'] == 'TWP')]\n",
    "\n",
    "        # Create dummy variable for if they're a lefty. This is necessary to project. (maybe move this)\n",
    "        pitchers_merged['p_L'] = np.where(pitchers_merged['pitchHand'] == \"L\", 1, 0)\n",
    "        \n",
    "        # Save as Excel\n",
    "        with pd.ExcelWriter(file_name, mode='a', engine='openpyxl') as writer:  \n",
    "            pitchers_merged.to_excel(writer, sheet_name='Pitchers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13667647-e708-4e8b-85c7-a7c8895440e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09d7ccc2-d52b-43d8-ae15-6b542bfb3568",
   "metadata": {},
   "source": [
    "### Run One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "932d368c-3689-4744-8547-bf96fd4fd82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI20230616.csv\n",
      "ATL20230616.csv\n",
      "BAL20230616.csv\n",
      "BOS20230616.csv\n",
      "CHC20230616.csv\n",
      "CHW20230616.csv\n",
      "CIN20230616.csv\n",
      "CLE20230616.csv\n",
      "COL20230616.csv\n",
      "DET20230616.csv\n",
      "HOU20230616.csv\n",
      "KCR20230616.csv\n",
      "LAA20230616.csv\n",
      "LAD20230616.csv\n",
      "MIA20230616.csv\n",
      "MIL20230616.csv\n",
      "MIN20230616.csv\n",
      "NYM20230616.csv\n",
      "NYY20230616.csv\n",
      "OAK20230616.csv\n",
      "PHI20230616.csv\n",
      "PIT20230616.csv\n",
      "SDP20230616.csv\n",
      "SEA20230616.csv\n",
      "SFG20230616.csv\n",
      "STL20230616.csv\n",
      "TBR20230616.csv\n",
      "TEX20230616.csv\n",
      "TOR20230616.csv\n",
      "WSN20230616.csv\n"
     ]
    }
   ],
   "source": [
    "create_team_rosters(todaysdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc0d33c-a8ac-40be-92f4-32efa6b350a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34d33de0-b02d-4ea4-9322-56c061bfbd48",
   "metadata": {},
   "source": [
    "### Run All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a1e39a11-07bc-4ceb-806d-c28df9bcdf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for filename in os.listdir(r\"C:\\Users\\james\\Documents\\MLB\\Data\\A8. Sims - 1. Players\"): \n",
    "#     # 2023 \n",
    "#     if filename.endswith(\".csv\") and filename.startswith(\"Player_Sims_2023\"):\n",
    "#         # Pull out date\n",
    "#         date = filename[12:20]\n",
    "#         print(date)\n",
    "#         create_team_rosters(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "029e1b21-bcb6-451e-afd0-068b96acfc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code was last run on: 2023-06-16 at 17:01:43.\n"
     ]
    }
   ],
   "source": [
    "print(\"Code was last run on: {} at {}.\".format(datetime.date.today(), datetime.datetime.now().strftime(\"%H:%M:%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad36797-ad91-4fbd-80ce-ffd0282dc697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e25c13-691d-4075-b2a1-3ab364213797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b9a4d3-4db0-4a29-82b5-e46c1f69143f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
