{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d54e1ade-7583-4241-b152-9c3b7fee1817",
   "metadata": {},
   "source": [
    "# B01. Matchups\n",
    "- Create matchup files with batter and pitcher stats for both the home and away teams\n",
    "- Files are unimputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54cd67c4-d621-4682-8c04-f9dde54ab752",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"U1. Imports.ipynb\"\n",
    "%run \"U2. Utilities.ipynb\"\n",
    "%run \"U3. Classes.ipynb\"\n",
    "\n",
    "baseball_path = r'C:\\Users\\james\\Documents\\MLB\\Database'\n",
    "\n",
    "db_path = r'C:\\Users\\james\\Documents\\MLB\\Database\\MLBDB.db'\n",
    "engine = create_engine(f'sqlite:///{db_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b29e2fc3-97b4-42f4-aa8b-21117b06dc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"A02. MLB API.ipynb\"\n",
    "%run \"A03. Steamer.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cf8a89-2504-414a-b82a-9c497a24b46e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0103945-e973-4e46-91f0-4445781eddca",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ab58b4-d3f3-44f2-9b80-6441285d72c8",
   "metadata": {},
   "source": [
    "##### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1ddc301-f9d8-4f5d-b5cc-b83084879699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batters\n",
    "with open(os.path.join(model_path, \"batter_stats_scaler_20231027.pkl\"), \"rb\") as file:\n",
    "    batter_stats_scaler = pickle.load(file)\n",
    "# Pitchers\n",
    "with open(os.path.join(model_path, \"pitcher_stats_scaler_20231027.pkl\"), \"rb\") as file:\n",
    "    pitcher_stats_scaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4fc02c-6304-43c0-abf8-448e73fe1b1e",
   "metadata": {},
   "source": [
    "##### FanGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ee01662-f36c-4942-b3e6-b6b1f46735be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batters\n",
    "with open(os.path.join(model_path, \"batter_stats_fg_scaler_20231027.pkl\"), \"rb\") as file:\n",
    "    batter_stats_fg_scaler = pickle.load(file)\n",
    "# Pitchers\n",
    "with open(os.path.join(model_path, \"pitcher_stats_fg_scaler_20231027.pkl\"), \"rb\") as file:\n",
    "    pitcher_stats_fg_scaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc9168a-6094-4f18-9d69-ef1e7288303d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02bacfc2-4519-4a59-9fd6-9c30b13fc869",
   "metadata": {},
   "source": [
    "### Clean Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0e066b6-3d4e-4f46-b98b-3420ecc81d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean draftable players \n",
    "def clean_draftables(draftGroupId):\n",
    "    # Read in draftables\n",
    "    sql_query = f'''\n",
    "    SELECT *\n",
    "    FROM \"Draftables {draftGroupId}\"\n",
    "    '''\n",
    "\n",
    "    draftables = pd.read_sql_query(sql_query, con=engine)\n",
    "    \n",
    "    # Replace @ sign for easier splitting\n",
    "    draftables['Game Info2'] = draftables['Game Info'].str.replace(\"@\", \" \")\n",
    "    # Extract game info\n",
    "    draftables[['Away', 'Home', 'date_slash', 'time', 'zone']] = draftables['Game Info2'].str.split(' ', 4, expand=True)\n",
    "    \n",
    "    # Convert the \"time\" column to datetime\n",
    "    draftables['datetime'] = pd.to_datetime(draftables['date_slash'] + ' ' + draftables['time'], format='%m/%d/%Y %I:%M%p')\n",
    "    # Sort the DataFrame by the \"time\" column\n",
    "    draftables = draftables.sort_values(by='datetime')\n",
    "\n",
    "    # Clean name\n",
    "    draftables['Name'] = draftables['Name'].apply(lambda x: unidecode.unidecode(x))\n",
    "\n",
    "    # Extract unique \"Game Info\" values and store them in a list\n",
    "    matchups = draftables['Game Info'].unique().tolist()\n",
    "    \n",
    "    return draftables, matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e6bc8ae-dcd4-4ac2-917a-1b3e6106df81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in missing spots in batting order\n",
    "def clean_order(df):\n",
    "    df2 = df.copy()\n",
    "    \n",
    "    # Find duplicate values in batting_order column\n",
    "    duplicated_numbers = list(df2[df2['batting_order'].duplicated(keep=False)]['batting_order'].unique())\n",
    "    duplicated_numbers = [x for x in duplicated_numbers if not np.isnan(x)]\n",
    "    \n",
    "    # Print out duplicates\n",
    "    for number in duplicated_numbers:\n",
    "        print(f\"Batter {number} was duplicated.\")\n",
    "        \n",
    "    # Set duplicates to missing\n",
    "    df2.sort_values(['batting_order', 'Salary'], ascending=True, inplace=True)\n",
    "    df2.reset_index(drop=True, inplace=True)\n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            if df2['batting_order'][i] == df2['batting_order'][i-1]:\n",
    "                df2['batting_order'][i] = np.nan\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    # Find missing numbers in batting_order column\n",
    "    missing_numbers = set(range(1, 10)) - set(df['batting_order'])\n",
    "\n",
    "    # Find the row with the lowest Salary for each missing number\n",
    "    for number in missing_numbers:\n",
    "        lowest_salary_index = df2[df2['batting_order'].isna()].sort_values('Salary').index[0]\n",
    "        df2.loc[lowest_salary_index, 'batting_order'] = number\n",
    "        print(f\"Batter {number} was filled in.\")\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fc568d7-cabf-4d41-9930-d8dbdb015849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract game information such as gamePk\n",
    "def game_info(matchup, games, team_map):\n",
    "    # Determine home and away team\n",
    "    parts = matchup.split()\n",
    "    away, home = parts[0].split('@')\n",
    "    # Retrieve home team ID\n",
    "    home_id = team_map.loc[home, 'teamId']\n",
    "    # Determine date\n",
    "    date_slash = parts[1]  \n",
    "    date_dash = date_slash[6:] + \"-\" + date_slash[:2] + \"-\" + date_slash[3:5]\n",
    "    # Determine datetime \n",
    "    dt = date_dash + \" \" + parts[2] + \" \" + parts[3]\n",
    "    dt = parser.parse(dt, tzinfos={\"ET\": \"US/Eastern\"})\n",
    "    # Create a new datetime object representing 6:00 PM EST\n",
    "    est = pytz.timezone(\"US/Eastern\")\n",
    "    six_pm_est = est.localize(datetime.datetime(dt.year, dt.month, dt.day, 18, 0))\n",
    "    # Check if the parsed datetime is later than 6:00 PM EST\n",
    "    # If it is, and it's a doubleheader, it's the late game. Else, it's the early game.\n",
    "    if dt > six_pm_est:\n",
    "        late = True\n",
    "    else:\n",
    "        late = False\n",
    "    \n",
    "    gamePk = None\n",
    "    # Loop over all games\n",
    "    for game in games:   \n",
    "        # If date and home team match\n",
    "        if game['game_date'] == date_dash and game['home_id'] == home_id:\n",
    "            # And it's a doubleheader\n",
    "            if game['doubleheader'] != \"N\":\n",
    "                # If it's late in the day and it's a double header, it's game two\n",
    "                if late and game['game_num'] == 2:\n",
    "                    gamePk = game['game_id']\n",
    "                # Else, it's game 1\n",
    "                elif not late and game['game_num'] == 1:\n",
    "                    gamePk = game['game_id']\n",
    "            # If it's not a double header, there will only be one.\n",
    "            elif game['doubleheader'] == \"N\":\n",
    "                gamePk = game['game_id']\n",
    "            # Identify venue id\n",
    "            venue_id = game['venue_id']     \n",
    "            # Away starter\n",
    "            away_starter = game['away_probable_pitcher']\n",
    "            # Home starter\n",
    "            home_starter = game['home_probable_pitcher']\n",
    "            \n",
    "    if away_starter == \"\":\n",
    "        away_starter = \"Missing AwayStarter\"\n",
    "    if home_starter == \"\":\n",
    "        home_starter = \"Missing HomeStarter\"\n",
    "        \n",
    "                \n",
    "                \n",
    "    return date_slash, gamePk, venue_id, away, home, away_starter, home_starter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02e5457f-305a-4a3c-bead-cd072a7cd6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create player dataframes\n",
    "def create_matchup_file(dkteam, date_slash, gamePk, venue_id, away_starter, home_starter, draftables, team_map, complete_dataset, steamer_hitters, steamer_pitchers):\n",
    "    # Retrieve Baseball Reference team abbreviation\n",
    "    team = team_map.loc[dkteam, 'BBREFTEAM']\n",
    "        \n",
    "    # Convert date to compatible format\n",
    "    date = date_slash[6:] + date_slash[:2] + date_slash[3:5]\n",
    "    \n",
    "    ### Roster\n",
    "    sql_query = f'''\n",
    "    SELECT *\n",
    "    FROM \"Roster {team} {date}\"\n",
    "    '''\n",
    "    roster = pd.read_sql_query(sql_query, con=engine)\n",
    "    \n",
    "    \n",
    "    ### Batting order\n",
    "    sql_query = f'''\n",
    "    SELECT *\n",
    "    FROM \"Batting Order {team} {gamePk}\"\n",
    "    '''\n",
    "    order = pd.read_sql_query(sql_query, con=engine)\n",
    "    # Would want to fix order here for upcoming games without order variable\n",
    "    \n",
    "    \n",
    "    ### Bullpen\n",
    "    sql_query = f'''\n",
    "    SELECT *\n",
    "    FROM \"Bullpen {team} {date}\"\n",
    "    '''   \n",
    "    bullpen = pd.read_sql_query(sql_query, con=engine)\n",
    "    bullpen.rename(columns={'Name': 'fullName'}, inplace=True)\n",
    "\n",
    "        \n",
    "    # Merge batting order onto roster\n",
    "    team_df = pd.merge(roster, order[['id', 'fullName', 'position', 'status', 'order']], on='id', how='outer', suffixes=(\"\",\"2\"))\n",
    "    # Fill in missings\n",
    "    team_df['batSide'].fillna('Right', inplace=True)\n",
    "    team_df['pitchHand'].fillna('Right', inplace=True)\n",
    "    team_df['fullName'].fillna(team_df['fullName2'], inplace=True)\n",
    "    team_df['position'].fillna(team_df['position2'], inplace=True)\n",
    "    \n",
    "    # Merge pitcher leverage onto roster\n",
    "    team_df = pd.merge(team_df, bullpen[['fullName', 'Leverage']], on='fullName', how='left')\n",
    "    \n",
    "    # Merge draftables\n",
    "    team_df['TeamAbbrev'] = dkteam\n",
    "    team_df = pd.merge(team_df, draftables[['Name + ID', 'Name', 'ID', 'playerId', 'Position', 'Roster Position', 'Salary', 'AvgPointsPerGame', 'TeamAbbrev']], left_on=['fullName', 'TeamAbbrev'], right_on=['Name', 'TeamAbbrev'], how='left')\n",
    "    \n",
    "    # Add weather\n",
    "    box = create_box(gamePk)\n",
    "    team_df['weather'] = box[0]\n",
    "    team_df['wind'] = box[1]\n",
    "    team_df['park'] = box[2]\n",
    "    team_df = clean_weather(team_df)\n",
    "    \n",
    "    # Add venue\n",
    "    team_df['venue_id'] = venue_id\n",
    "    \n",
    "    # Add starters\n",
    "    team_df['away_starter'] = away_starter\n",
    "    team_df['home_starter'] = home_starter\n",
    "    \n",
    "    # Assign Leverage of 1 to starting pitcher\n",
    "    team_df['Leverage'] = np.where((team_df['fullName'] == team_df['away_starter']) | (team_df['fullName'] == team_df['home_starter']), 1, team_df['Leverage'])\n",
    "    \n",
    "    # Determine batting order\n",
    "    team_df['order'] = pd.to_numeric(team_df['order'], errors='coerce')\n",
    "    team_df['batting_order'] = np.nan\n",
    "    for i in range(9):\n",
    "        team_df['batting_order'] = np.where(team_df['order'] == (i+1)*100, i+1, team_df['batting_order'])\n",
    "    \n",
    "    ### Batters\n",
    "    batter_df = team_df[team_df['position'] != \"Pitcher\"]\n",
    "    \n",
    "    ## Dataset\n",
    "    # Vs. LHP\n",
    "    vs_l = complete_dataset[complete_dataset['date'] < int(date)]\n",
    "    vs_l = vs_l[vs_l['pitchHand'] == \"L\"]\n",
    "    vs_l.drop_duplicates(subset='batter', keep='last', inplace=True)\n",
    "    \n",
    "    # Merge in stats\n",
    "    batter_df = pd.merge(batter_df, vs_l[['batter'] + batter_inputs + ['imp_b', 'pa_b', 'pa_b_long']], left_on='id', right_on='batter', how='left')\n",
    "    \n",
    "    # Vs. RHP\n",
    "    vs_r = complete_dataset[complete_dataset['date'] < int(date)]\n",
    "    vs_r = vs_r[vs_r['pitchHand'] == \"R\"]\n",
    "    vs_r.drop_duplicates(subset='batter', keep='last', inplace=True)\n",
    "    \n",
    "    # Merge in stats\n",
    "    batter_df = pd.merge(batter_df, vs_r[['batter'] + batter_inputs + ['imp_b', 'pa_b', 'pa_b_long']], left_on='id', right_on='batter', how='left', suffixes=(\"_l\", \"_r\"))\n",
    "    \n",
    "    ## Steamer \n",
    "    # Keep last observation before date (may switch to <= if I find projections are up early)\n",
    "    steamer_hitters_last_df = steamer_hitters[steamer_hitters['date'] < int(date)]\n",
    "    steamer_hitters_last_df.drop_duplicates(subset='mlbamid', keep='last', inplace=True)\n",
    "\n",
    "    # Merge\n",
    "    batter_df = pd.merge(batter_df, steamer_hitters_last_df, left_on='id', right_on='mlbamid', how='left', suffixes=(\"\", \"_fg\"))\n",
    "    \n",
    "    # Remove redundant variables\n",
    "    batter_df.drop(columns={'batter_l', 'batter_r', 'firstname', 'lastname', 'mlbamid', 'fullName2', 'position2'}, inplace=True)\n",
    "    \n",
    "    # Clean\n",
    "    batter_df = clean_order(batter_df)\n",
    "    \n",
    "    # Move 'batting_order' to the desired position\n",
    "    batter_df.insert(batter_df.columns.get_loc('order') + 1, 'batting_order', batter_df.pop('batting_order'))\n",
    "\n",
    "    # Sort\n",
    "    batter_df.sort_values('batting_order', inplace=True)\n",
    "    \n",
    "    \n",
    "    ### Pitchers\n",
    "    pitcher_df = team_df[(team_df['position'] == \"Pitcher\") | (team_df['position'] == \"Two-Way Player\")]\n",
    "    \n",
    "    ## Dataset\n",
    "    # Vs. LHB\n",
    "    vs_l = complete_dataset[complete_dataset['date'] < int(date)]\n",
    "    vs_l = vs_l[vs_l['batSide'] == \"L\"]\n",
    "    vs_l.drop_duplicates(subset='pitcher', keep='last', inplace=True)\n",
    "    \n",
    "    # Merge in stats\n",
    "    pitcher_df = pd.merge(pitcher_df, vs_l[['pitcher'] + pitcher_inputs + ['imp_p', 'pa_p', 'pa_p_long']], left_on='id', right_on='pitcher', how='left')\n",
    "    \n",
    "    # Vs. RHB\n",
    "    vs_r = complete_dataset[complete_dataset['date'] < int(date)]\n",
    "    vs_r = vs_r[vs_r['batSide'] == \"R\"]\n",
    "    vs_r.drop_duplicates(subset='pitcher', keep='last', inplace=True)\n",
    "    \n",
    "    # Merge in stats\n",
    "    pitcher_df = pd.merge(pitcher_df, vs_r[['pitcher'] + pitcher_inputs + ['imp_p', 'pa_p', 'pa_p_long']], left_on='id', right_on='pitcher', how='left', suffixes=(\"_l\", \"_r\"))\n",
    "    \n",
    "    ## Steamer \n",
    "    # Keep last observation before date (may switch to <= if I find projections are up early)\n",
    "    steamer_pitchers_last_df = steamer_pitchers[steamer_pitchers['date'] < int(date)]\n",
    "    steamer_pitchers_last_df.drop_duplicates(subset='mlbamid', keep='last', inplace=True)\n",
    "\n",
    "    # Merge\n",
    "    pitcher_df = pd.merge(pitcher_df, steamer_pitchers_last_df, left_on='id', right_on='mlbamid', how='left', suffixes=(\"\", \"_fg\"))\n",
    "    \n",
    "    # Remove redundant variables\n",
    "    pitcher_df.drop(columns={'pitcher_l', 'pitcher_r', 'firstname', 'lastname', 'mlbamid', 'fullName2', 'position2'}, inplace=True)\n",
    "    \n",
    "    # Move 'batting_order' to the desired position\n",
    "    pitcher_df.insert(pitcher_df.columns.get_loc('order') + 1, 'batting_order', pitcher_df.pop('batting_order'))\n",
    "    \n",
    "    # Sort\n",
    "    pitcher_df.sort_values('Leverage', inplace=True)\n",
    "    \n",
    "    return batter_df, pitcher_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f54fee-8a78-423c-bb46-a8ad2119df01",
   "metadata": {},
   "source": [
    "### Read Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7eb81fa-17e7-4907-89b9-228bc31dfaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in API/Statcast data\n",
    "def read_dataset():\n",
    "    # Choose the last instance of each player in each game, assuming they have enough PAs\n",
    "    sql_query = f'''\n",
    "        SELECT *\n",
    "        FROM \"Dataset\"\n",
    "        WHERE date >= 20220301\n",
    "        '''\n",
    "\n",
    "    df = pd.read_sql_query(sql_query, con=engine)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e7d48ae-53ab-4f2a-b953-a880e86255bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Steamer hitter data\n",
    "def read_steamer_hitters():\n",
    "    # Choose the last instance of each player in each game, assuming they have enough PAs\n",
    "    sql_query = f'''\n",
    "        SELECT *\n",
    "        FROM \"Steamer Hitters\"\n",
    "        WHERE proj_year >= 2021\n",
    "        '''\n",
    "\n",
    "    df = pd.read_sql_query(sql_query, con=engine)\n",
    "    df2 = clean_steamer_hitters(df)\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49b78e73-5ada-4a9d-8807-6efe172f4462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in steamer pitcher data\n",
    "def read_steamer_pitchers():\n",
    "    # Choose the last instance of each player in each game, assuming they have enough PAs\n",
    "    sql_query = f'''\n",
    "        SELECT *\n",
    "        FROM \"Steamer Pitchers\"\n",
    "        WHERE proj_year >= 2021\n",
    "        '''\n",
    "\n",
    "    df = pd.read_sql_query(sql_query, con=engine)\n",
    "    df2 = clean_steamer_pitchers(df)\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a138bef-07a1-40d7-8151-b5c696380d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in team_map\n",
    "def read_team_map():\n",
    "    # Choose the last instance of each player in each game, assuming they have enough PAs\n",
    "    sql_query = f'''\n",
    "        SELECT DKTEAM, BBREFTEAM, teamId\n",
    "        FROM \"Team Map\"\n",
    "        '''\n",
    "\n",
    "    team_map = pd.read_sql_query(sql_query, con=engine)\n",
    "    team_map.set_index('DKTEAM', inplace=True)\n",
    "    \n",
    "    return team_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed0fff99-0cb0-4b00-bb57-16e6d3816059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in schedule to extract gamePKs based on teams and dates\n",
    "def read_schedule():\n",
    "    # 2022 games\n",
    "    games2022 = statsapi.schedule(start_date=\"03/04/2022\", end_date=\"11/01/2022\")\n",
    "    # 2023 games\n",
    "    games2023 = statsapi.schedule(start_date=\"03/04/2023\", end_date=todaysdate_slash)\n",
    "    # Add 'em together\n",
    "    games = games2022 + games2023\n",
    "    \n",
    "    return games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7d8226-4af2-4c53-be65-bdfdf6d62dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
