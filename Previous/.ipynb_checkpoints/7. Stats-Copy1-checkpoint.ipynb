{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fc63541-ac5e-4646-87ca-1134c4c1180d",
   "metadata": {},
   "source": [
    "# 7. Stats\n",
    "Source: <br> \n",
    "1. FanGraphs API <br>\n",
    "\n",
    "This imports stats from Fangraphs <br>\n",
    "This calculates stats that aren't used in the models but help us get there <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d92f9c1-c5d9-4a6a-a837-a564c2bafa9c",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d4366b7-70bd-48b7-b3a9-79e86c041902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import statsmodels.formula.api as smf\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import datetime\n",
    "from datetime import date\n",
    "import time\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\james\\Documents\\MLB\\Code\")\n",
    "from Utilities import *\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "model_path = r\"C:\\Users\\james\\Documents\\MLB\\Code\\Models\"\n",
    "baseball_path = r\"C:\\Users\\james\\Documents\\MLB\\Data2\"\n",
    "download_path = r\"C:\\Users\\james\\Downloads\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b22d6a6f-c729-4cf6-9449-4e69d99215cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Today's Date\n",
    "# YYYY-MM-DD (datetime)\n",
    "todaysdate_dt = datetime.date.today()\n",
    "\n",
    "# YYYY-MM-DD (string)\n",
    "todaysdate_dash = str(todaysdate_dt)\n",
    "\n",
    "# MM/DD/YYYY\n",
    "todaysdate_slash = todaysdate_dash.split(\"-\")\n",
    "todaysdate_slash = todaysdate_slash[1] + \"/\" + todaysdate_slash[2] + \"/\" + todaysdate_slash[0]\n",
    "\n",
    "# YYYYMMDD\n",
    "todaysdate = todaysdate_dash.replace(\"-\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a32d76b1-8a07-4ff9-945b-1b63f3428bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    " # This reads in Chadwick register with player codes.\n",
    "keep_list = ['key_mlbam', 'key_fangraphs', 'name_first', 'name_last']\n",
    "chadwick = read_chadwick(keep_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31b9b566-8422-4f4a-bdcb-68e48c57ba1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "crosswalk = pd.read_csv(os.path.join(baseball_path, \"Utilities\", \"Crosswalk.csv\"), encoding='iso-8859-1') \n",
    "crosswalk = crosswalk[['mlbamid', 'steamerid']]\n",
    "crosswalk.rename(columns={'mlbamid':'mlbamid_fill'}, inplace=True)\n",
    "\n",
    "crosswalk.drop_duplicates('steamerid', keep='last', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44283ed-806a-457a-837a-28a10ea9999e",
   "metadata": {},
   "source": [
    "### Scrape FanGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b86dfa1-82b2-4738-80d9-4e1f4bad0ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    proj_date   mlbamid steamerid firstname lastname Team position bats   PA  \\\n",
      "279  20230629  691023.0     27475    Jordan   Walker  STL       OF   MI  514   \n",
      "\n",
      "     IBB  ...  2B  3B  HR       OBP       SLG     wOBA  SB  CS  playerid  \\\n",
      "279    1  ...  25   2  13  0.305773  0.393533  0.30609   8   4     27475   \n",
      "\n",
      "              Name  \n",
      "279  Jordan Walker  \n",
      "\n",
      "[1 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Fangraphs API\n",
    "def scrape_batters():\n",
    "    # Read in API json\n",
    "    batters_lb = pd.read_json('https://www.fangraphs.com/api/projections?type=steamer&stats=bat&pos=all&team=0&players=0&lg=all')\n",
    "    \n",
    "    # Name is currently some weird thing with a bunch of data. We don't need all that\n",
    "    batters_lb['Name'] = batters_lb['PlayerName']\n",
    "    # Rename to match steam. Note that steamerid = key_fangraphs\n",
    "    batters_lb.rename(columns={'playerids':'steamerid'}, inplace=True)\n",
    "    # Convert to string\n",
    "    chadwick['key_fangraphs'] = (chadwick['key_fangraphs']).astype('str')\n",
    "    # Remove trailing .0\n",
    "    chadwick['key_fangraphs'] = chadwick['key_fangraphs'].str.replace(r'\\.\\d', \"\", regex=True)\n",
    "    \n",
    "    # Merge with chadwick for mlbamid\n",
    "    batters_lb = batters_lb.merge(chadwick, left_on='steamerid', right_on='key_fangraphs', how='left')\n",
    "    batters_lb = batters_lb.merge(crosswalk, on='steamerid', how='left')\n",
    "    \n",
    "    \n",
    "    # Create missing columns to match what's provided by steamer \n",
    "    batters_lb['proj_date'] = todaysdate\n",
    "    batters_lb['mlbamid'] = batters_lb['key_mlbam']\n",
    "    batters_lb['bats'] = \"MI\" # Not included in FanGraphs data\n",
    "    batters_lb['playerid'] = batters_lb['steamerid']\n",
    "    batters_lb['NIBB'] = batters_lb['BB'] - batters_lb['IBB']\n",
    "    batters_lb.rename(columns={'name_first':'firstname', 'name_last':'lastname', 'minpos':'position'}, inplace=True)\n",
    "\n",
    "    batters_lb['mlbamid'].fillna(batters_lb['mlbamid_fill'], inplace=True)\n",
    "    \n",
    "    # Keep relevant variables and in order\n",
    "    batters_lb = batters_lb[['proj_date', 'mlbamid', 'steamerid', 'firstname', 'lastname', 'Team', 'position', 'bats', \n",
    "                             'PA', 'IBB', 'NIBB', 'BB', 'SO', 'HBP', 'H', '2B', '3B', 'HR', 'OBP', 'SLG', 'wOBA', 'SB', 'CS', 'playerid', 'Name']]\n",
    "\n",
    "\n",
    "    print(batters_lb[batters_lb['Name'] == \"Jordan Walker\"])    \n",
    "\n",
    "    \n",
    "    # Export to CSV\n",
    "    batters_lb.to_csv(os.path.join(baseball_path, \"7. Stats\", \"A. Raw FanGraphs\", \"Batters\", \"Batters_FG_\" + todaysdate + \".csv\"), encoding='iso-8859-1')\n",
    "    \n",
    "scrape_batters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5b19f24-4170-43ae-9b0c-ac7830c6c699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fangraphs API\n",
    "def scrape_pitchers():\n",
    "    # Read in API json\n",
    "    pitchers_lb = pd.read_json('https://www.fangraphs.com/api/projections?type=steamer&stats=pit&pos=all&team=0&players=0&lg=all')\n",
    "\n",
    "    # Name is currently some weird thing with a bunch of data. We don't need all that\n",
    "    pitchers_lb['Name'] = pitchers_lb['PlayerName']\n",
    "    # Rename to match steam. Note that steamerid = key_fangraphs\n",
    "    pitchers_lb.rename(columns={'playerids':'steamerid'}, inplace=True)\n",
    "    # Convert to string\n",
    "    chadwick['key_fangraphs'] = (chadwick['key_fangraphs']).astype('str')\n",
    "    # Remove trailing .0\n",
    "    chadwick['key_fangraphs'] = chadwick['key_fangraphs'].str.replace(r'\\.\\d', \"\", regex=True)\n",
    "    \n",
    "    # Merge with chadwick for mlbamid\n",
    "    pitchers_lb = pitchers_lb.merge(chadwick, left_on='steamerid', right_on='key_fangraphs', how='left')\n",
    "    pitchers_lb = pitchers_lb.merge(crosswalk, on='steamerid', how='left')\n",
    "\n",
    "\n",
    "    # Create missing columns to match what's provided by steamer \n",
    "    pitchers_lb['proj_date'] = todaysdate\n",
    "    pitchers_lb['mlbamid'] = pitchers_lb['key_mlbam']\n",
    "    pitchers_lb['Throws'] = \"MI\" # Not included in FanGraphs data\n",
    "    pitchers_lb['playerid'] = pitchers_lb['steamerid']\n",
    "    pitchers_lb.rename(columns={'name_first':'firstname', 'name_last':'lastname', 'minpos':'position'}, inplace=True)\n",
    "\n",
    "    pitchers_lb['mlbamid'].fillna(pitchers_lb['mlbamid_fill'], inplace=True)\n",
    "\n",
    "    \n",
    "    # Keep relevant variables and in order\n",
    "    pitchers_lb = pitchers_lb[['proj_date', 'mlbamid', 'steamerid', 'firstname', 'lastname', 'Throws', \n",
    "                               'IP', 'G', 'GS', 'K/9', 'BB/9', 'H', 'HR', 'playerid', 'Name']]\n",
    "    \n",
    "    # Export to CSV\n",
    "    pitchers_lb.to_csv(os.path.join(baseball_path, \"7. Stats\", \"A. Raw FanGraphs\", \"Pitchers\", \"Pitchers_FG_\" + todaysdate + \".csv\"), encoding='iso-8859-1')\n",
    "    \n",
    "scrape_pitchers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90668205-2c3b-426c-b936-cd4c93a0a2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c888a735-c96c-4f51-ad3d-a5f3c6914aaf",
   "metadata": {},
   "source": [
    "### Create Useful Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "609b2398-43ad-45a5-b9d8-3084d9ff0f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_intermediate_batters(date):\n",
    "    # Read in file\n",
    "    filename = \"Batters_FG_\" + date + \".csv\"\n",
    "    df = pd.read_csv(os.path.join(baseball_path, \"7. Stats\", \"A. Raw FanGraphs\", \"Batters\", filename), encoding='iso-8859-1')\n",
    "    # Create singles\n",
    "    df['1B'] = df['H'] - df['2B'] - df['3B'] - df['HR']\n",
    "    \n",
    "    # Basic stats\n",
    "    hit_list = ['1B', '2B', '3B', 'HR', 'BB', 'HBP', 'SO']\n",
    "\n",
    "    # Advance stats\n",
    "    rate_list = ['OBP', 'SLG', 'wOBA']\n",
    "    for stat in hit_list:\n",
    "        rate = stat + \"_rate\"\n",
    "        rate_list.append(rate)\n",
    "        df[rate] = df[stat] / df['PA']\n",
    "\n",
    "    df['SBA'] = df['SB'] + df['CS']\n",
    "    df['SBO'] = df['1B'] + df['BB'] + df['HBP']\n",
    "    df['sba_imp'] = df['SBA'] / df['SBO']\n",
    "\n",
    "    # Cap imputed SBA \n",
    "    df['sba_imp'] = np.where(df['sba_imp'] > 0.15, 0.15, df['sba_imp'])\n",
    "\n",
    "    # Determine stolen base success rate\n",
    "    df['sbr'] = df['SB'] / df['SBA']\n",
    "    \n",
    "    keep_list = ['Name', 'mlbamid', 'playerid', 'sba_imp', 'sbr'] + rate_list\n",
    "    df = df[keep_list]\n",
    "    \n",
    "    df['sbr'].fillna(0.6, inplace=True) # assume 25th percentile \n",
    "    df['sba_imp'].fillna(0.05, inplace=True) # assume low prob\n",
    "    \n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.rename(columns={'1b_rate': 'b1_rate', '2b_rate': 'b2_rate', '3b_rate': 'b3_rate'}, inplace=True)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    sba_2b_reg = pickle.load(open(os.path.join(model_path, 'sba_2b_20220901.sav'), 'rb'))\n",
    "    df['sba_2b'] = sba_2b_reg.predict(df[['sba_imp']])\n",
    "\n",
    "    sba_3b_reg = pickle.load(open(os.path.join(model_path, 'sba_3b_20220901.sav'), 'rb'))\n",
    "    df['sba_3b'] = sba_3b_reg.predict(df[['sba_imp']])\n",
    "\n",
    "    sb_2b_reg = pickle.load(open(os.path.join(model_path, 'sb_2b_20220901.sav'), 'rb'))\n",
    "    df['sb_2b'] = sb_2b_reg.predict(df[['sbr']])\n",
    "\n",
    "    sb_3b_reg = pickle.load(open(os.path.join(model_path, 'sb_3b_20220901.sav'), 'rb'))\n",
    "    df['sb_3b'] = sb_3b_reg.predict(df[['sbr']])\n",
    "       \n",
    "    # Merge with chadwick to fix certain fangraphs ids \n",
    "    df = df.merge(chadwick, left_on='mlbamid', right_on='key_mlbam', how='left')\n",
    "    # df['key_fangraphs'] = df['key_fangraphs'].astype('int', errors='ignore')\n",
    "    df['playerid'] = np.where(df['playerid'].str.startswith(\"sa\") & ~df['key_fangraphs'].isna(), df['key_fangraphs'], df['playerid'])\n",
    "    df['playerid'] = df['playerid'].astype('string')\n",
    "    df['playerid'] = df['playerid'].str.replace(r'\\.0', '', regex=True)\n",
    "        \n",
    "    df.drop(columns={'index', 'key_fangraphs', 'key_mlbam', 'name_first', 'name_last'}, inplace=True)\n",
    "    \n",
    "    # Write intermediate FanGraphs data to csv\n",
    "    df.to_csv(os.path.join(baseball_path, \"7. Stats\", \"B. Clean FanGraphs\", \"Batters\", \"Batters_FG2_\" + date + \".csv\"), encoding='iso-8859-1')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caaace8c-a39a-48b3-9247-4a6926396a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_intermediate_pitchers(date):\n",
    "    # Read in file\n",
    "    filename = \"Pitchers_FG_\" + date + \".csv\"\n",
    "    df = pd.read_csv(os.path.join(baseball_path, \"7. Stats\", \"A. Raw FanGraphs\", \"Pitchers\", filename), encoding='iso-8859-1')\n",
    "    \n",
    "    df['H9'] = df['H'] / df['IP'] * 9\n",
    "    df['HR9'] = df['HR'] / df['IP'] * 9\n",
    "    \n",
    "    df.rename(columns={'K/9':'K9', 'BB/9':'BB9'}, inplace=True)\n",
    "    \n",
    "    keep_list = ['playerid', 'mlbamid', 'H9', 'HR9', 'K9', 'BB9'] \n",
    "    df = df[keep_list]\n",
    "    \n",
    "    # Merge with chadwick to fix certain fangraphs ids \n",
    "    df = df.merge(chadwick, left_on='mlbamid', right_on='key_mlbam', how='left')\n",
    "    # df['key_fangraphs'] = df['key_fangraphs'].astype('int', errors='ignore')\n",
    "    df['playerid'] = np.where(df['playerid'].str.startswith(\"sa\") & ~df['key_fangraphs'].isna(), df['key_fangraphs'], df['playerid'])\n",
    "    df['playerid'] = df['playerid'].astype('string')\n",
    "    df['playerid'] = df['playerid'].str.replace(r'\\.0', '', regex=True)\n",
    "    \n",
    "    df.drop(columns={'index', 'key_fangraphs', 'key_mlbam', 'name_first', 'name_last'}, inplace=True)\n",
    "    \n",
    "    \n",
    "    # Write intermediate FanGraphs data to csv\n",
    "    df.to_csv(os.path.join(baseball_path, \"7. Stats\", \"B. Clean FanGraphs\", \"Pitchers\", \"Pitchers_FG2_\" + date + \".csv\"), encoding='iso-8859-1')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb13783e-2be3-4035-ba94-26666f21802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batter_merge(date):\n",
    "    # Read in batter stats from API\n",
    "    batter_filename = \"Batters\" + date + \".csv\"\n",
    "    batters_api = pd.read_csv(os.path.join(baseball_path, \"4. Dataset\", \"Batters\", batter_filename), encoding='iso-8859-1')\n",
    "    \n",
    "    # Make string, remove trailing .0\n",
    "    batters_api = fix_fangraphs(batters_api)\n",
    "    \n",
    "    # Read in batter projections from FanGraphs\n",
    "    batters_fg = create_intermediate_batters(date)\n",
    "    batters_fg['key_fangraphs'] = batters_fg['playerid']\n",
    "    \n",
    "    \n",
    "    # Merge API data with FG data\n",
    "    batters_df = batters_api.merge(batters_fg, left_on='key_mlbam', right_on='mlbamid', how='outer')\n",
    "    \n",
    "    return batters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed28c3e2-bfd0-483a-96a6-a392cf99e327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitcher_merge(date):\n",
    "    # Read in pitcher stats from API\n",
    "    pitcher_filename = \"Pitchers\" + date + \".csv\"\n",
    "    pitchers_api = pd.read_csv(os.path.join(baseball_path, \"4. Dataset\", \"Pitchers\", pitcher_filename), encoding='iso-8859-1')\n",
    "    \n",
    "    # Make string, remove trailing .0\n",
    "    pitchers_api = fix_fangraphs(pitchers_api)\n",
    "    \n",
    "    # Read in pitcher projections from FanGraphs\n",
    "    pitchers_fg = create_intermediate_pitchers(date)\n",
    "    pitchers_fg['key_fangraphs'] = pitchers_fg['playerid']\n",
    "\n",
    "    # Merge API data with FG data\n",
    "    pitchers_df = pitchers_api.merge(pitchers_fg, left_on='key_mlbam', right_on='mlbamid', how='outer')\n",
    "\n",
    "    \n",
    "    return pitchers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d58c57b-9dcc-417a-895f-f66f82b2080f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\james\\Documents\\MLB\\Code\\Models\")\n",
    "\n",
    "kmeans_model_filename = \"model_batter_cluster.pkl\"\n",
    "with open(kmeans_model_filename, \"rb\") as file:\n",
    "    batter_kmeans = pickle.load(file)\n",
    "    \n",
    "batter_stats_fg = ['b1_rate','b2_rate','b3_rate','hr_rate','bb_rate','hbp_rate','so_rate', 'woba', 'slg', 'obp']\n",
    "\n",
    "kmeans_model_filename = \"model_pitcher_cluster.pkl\"\n",
    "with open(kmeans_model_filename, \"rb\") as file:\n",
    "    pitcher_kmeans = pickle.load(file)\n",
    "    \n",
    "pitcher_stats_fg = ['H9','HR9','K9','BB9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "595d619c-d7aa-4769-a1ed-d899f807b0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data using StandardScaler\n",
    "scaler_filename = \"batter_stats_fg_scaler.pkl\"\n",
    "with open(scaler_filename, \"rb\") as file:\n",
    "    batter_scaler = pickle.load(file)\n",
    "    \n",
    "scaler_filename = \"pitcher_stats_fg_scaler.pkl\"\n",
    "with open(scaler_filename, \"rb\") as file:\n",
    "    pitcher_scaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "736e15a6-eebe-419c-8401-21625ec214d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batter_clusters = pd.read_csv(os.path.join(baseball_path, \"Inputs\", \"Batter Clusters.csv\"))\n",
    "pitcher_clusters = pd.read_csv(os.path.join(baseball_path, \"Inputs\", \"Pitcher Clusters.csv\"))# Inputs\n",
    "batter_stats_short = ['b1_b','b2_b','b3_b','hr_b','bb_b','hbp_b',\n",
    "                'so_b','fo_b','go_b','lo_b','po_b',\n",
    "                'iso_b','slg_b','obp_b','woba_b',\n",
    "                'to_left_b','to_middle_b','to_right_b',\n",
    "                'hard_hit_b','totalDistance_b','launchSpeed_b','maxSpeed_b','maxSpin_b',\n",
    "                'ab_b','pa_b']\n",
    "\n",
    "batter_stats_long =  ['b1_b_long','b2_b_long','b3_b_long','hr_b_long','bb_b_long','hbp_b_long',\n",
    "                'so_b_long','fo_b_long','go_b_long','lo_b_long','po_b_long',\n",
    "                'iso_b_long','slg_b_long','obp_b_long','woba_b_long',\n",
    "                'to_left_b_long','to_middle_b_long','to_right_b_long',\n",
    "                'hard_hit_b_long','totalDistance_b_long','launchSpeed_b_long','maxSpeed_b_long','maxSpin_b_long',\n",
    "                'ab_b_long','pa_b_long']\n",
    "\n",
    "pitcher_stats_short = ['b1_p','b2_p','b3_p','hr_p','bb_p','hbp_p',\n",
    "                 'so_p','fo_p','go_p','lo_p','po_p',\n",
    "                 'iso_p','slg_p','obp_p','woba_p',\n",
    "                 'to_left_p','to_middle_p','to_right_p',\n",
    "                 'hard_hit_p','totalDistance_p','launchSpeed_p','maxSpeed_p','maxSpin_p',\n",
    "                 'ab_p','pa_p']\n",
    "\n",
    "pitcher_stats_long = ['b1_p_long','b2_p_long','b3_p_long','hr_p_long','bb_p_long','hbp_p_long',\n",
    "                 'so_p_long','fo_p_long','go_p_long','lo_p_long','po_p_long',\n",
    "                 'iso_p_long','slg_p_long','obp_p_long','woba_p_long',\n",
    "                 'to_left_p_long','to_middle_p_long','to_right_p_long',\n",
    "                 'hard_hit_p_long','totalDistance_p_long','launchSpeed_p_long','maxSpeed_p_long','maxSpin_p_long',\n",
    "                 'ab_p_long','pa_p_long']\n",
    "\n",
    "batter_stats_fg = ['b1_rate','b2_rate','b3_rate','hr_rate','bb_rate','hbp_rate','so_rate', 'woba', 'slg', 'obp']\n",
    "\n",
    "pitcher_stats_fg = ['H/9','HR/9','K/9','BB/9']\n",
    "\n",
    "\n",
    "venues = ['venue_1', 'venue_2', 'venue_3', 'venue_4', 'venue_5', 'venue_7', 'venue_10', 'venue_12', \n",
    "          'venue_13', 'venue_14', 'venue_15', 'venue_16', 'venue_17', 'venue_19', 'venue_22', 'venue_31', \n",
    "          'venue_32', 'venue_680', 'venue_2392', 'venue_2394', 'venue_2395', 'venue_2535', 'venue_2536', \n",
    "          'venue_2602', 'venue_2680', 'venue_2681', 'venue_2701', 'venue_2735', 'venue_2756', 'venue_2889', \n",
    "          'venue_3289', 'venue_3309', 'venue_3312', 'venue_3313', 'venue_4169', 'venue_4705', 'venue_5010', \n",
    "          'venue_5325', 'venue_5365', 'venue_5381', 'venue_5445']\n",
    "\n",
    "years = ['year_2015', 'year_2016', 'year_2017', 'year_2018', 'year_2019', 'year_2020', 'year_2021', 'year_2022', 'year_2023']\n",
    "\n",
    "other_list = ['p_L','b_L','x_vect','y_vect','temperature','onFirst','onSecond','onThird','inning','top','score_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f17b4095-ed8e-48a8-813c-b9e1c3725baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove items that do not apply to batters or pitchers\n",
    "batter_stats_short.remove(\"maxSpeed_b\")\n",
    "batter_stats_short.remove(\"maxSpin_b\")\n",
    "batter_stats_long.remove(\"maxSpeed_b_long\")\n",
    "batter_stats_long.remove(\"maxSpin_b_long\")\n",
    "\n",
    "pitcher_stats_short.remove(\"totalDistance_p\")\n",
    "pitcher_stats_long.remove(\"totalDistance_p_long\")\n",
    "pitcher_stats_short.remove(\"launchSpeed_p\")\n",
    "pitcher_stats_long.remove(\"launchSpeed_p_long\")\n",
    "\n",
    "\n",
    "# # Not sure why but these are weird\n",
    "# batter_stats.remove(\"launchSpeed_b\")\n",
    "# batter_stats.remove(\"totalDistance_b\")\n",
    "# batter_stats.remove(\"launchSpeed_b_long\")\n",
    "# batter_stats.remove(\"totalDistance_b_long\")\n",
    "\n",
    "# pitcher_stats.remove(\"maxSpeed_p\")\n",
    "# pitcher_stats.remove(\"maxSpin_p\")\n",
    "# pitcher_stats.remove(\"maxSpeed_p_long\")\n",
    "# pitcher_stats.remove(\"maxSpin_p_long\")\n",
    "\n",
    "\n",
    "# Testing removing these\n",
    "batter_stats_short.remove('ab_b')\n",
    "batter_stats_short.remove('pa_b')\n",
    "batter_stats_long.remove('ab_b_long')\n",
    "batter_stats_long.remove('pa_b_long')\n",
    "\n",
    "pitcher_stats_short.remove('ab_p')\n",
    "pitcher_stats_short.remove('pa_p')\n",
    "pitcher_stats_long.remove('ab_p_long')\n",
    "pitcher_stats_long.remove('pa_p_long')\n",
    "\n",
    "batter_stats = batter_stats_short + batter_stats_long\n",
    "pitcher_stats = pitcher_stats_short + pitcher_stats_long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4a8143-8d14-44db-a4fc-ee5357038449",
   "metadata": {},
   "source": [
    "### Create Rosters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "77fc9b82-1b1c-45b7-9f60-fb371e28a479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_team_rosters(date=todaysdate):\n",
    "    # Create new folder with daily rosters\n",
    "    team_folder = \"Daily\" + date\n",
    "    try:\n",
    "        os.mkdir(os.path.join(baseball_path, \"7. Stats\", \"C. Teams\", team_folder))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Locate daily rosters\n",
    "    rosters_folder = \"Rosters\" + date\n",
    "    rosters_path = os.path.join(baseball_path, \"6. Rosters\", rosters_folder)\n",
    "    \n",
    "    \n",
    "    # Merge API and FG data\n",
    "    batters_df = batter_merge(date)\n",
    "    pitchers_df = pitcher_merge(date)\n",
    "    \n",
    "\n",
    "    \n",
    "    for filename in os.listdir(rosters_path):\n",
    "        print(filename)\n",
    "        # Read in roster\n",
    "        df = pd.read_csv(os.path.join(rosters_path, filename), encoding='iso-8859-1')\n",
    "\n",
    "        # Destination     \n",
    "        excel_file = filename.replace(\".csv\", \"\")\n",
    "        excel_file = excel_file + \".xlsx\"\n",
    "        file_name = os.path.join(baseball_path, \"7. Stats\", \"C. Teams\", team_folder, excel_file)\n",
    "\n",
    "\n",
    "        ### Batters\n",
    "        batters_merged = df.merge(batters_df, left_on='id', right_on='batter', how='left', suffixes=(\"\", \"_api\"))\n",
    "        \n",
    "        # Only keep batters\n",
    "        batters_merged = batters_merged.query('position != \"P\"')\n",
    "        \n",
    "        # Create dummy variable for if they're a lefty. This is necessary to project. (maybe move this)\n",
    "        batters_merged['b_L'] = np.where(batters_merged['batSide'] == \"Left\", 1, 0)\n",
    "        \n",
    "        \n",
    "        # Standardize data \n",
    "        batter_stats_fg = ['b1_rate','b2_rate','b3_rate','hr_rate','bb_rate','hbp_rate','so_rate', 'woba', 'slg', 'obp']\n",
    "        batters_merged[batter_stats_fg] = batter_scaler.transform(batters_merged[batter_stats_fg])\n",
    "\n",
    "        for stat in batter_stats_fg:\n",
    "            batters_merged[stat].fillna(0, inplace=True)\n",
    "        \n",
    "        # Determine cluster\n",
    "        batters_merged['Cluster'] = np.nan\n",
    "        for i, row in batters_merged.iterrows():\n",
    "            try:\n",
    "                prediction = batter_kmeans.predict([row[['b1_rate','b2_rate','b3_rate','hr_rate','bb_rate','hbp_rate','so_rate', 'woba', 'slg', 'obp', 'b_L']]])\n",
    "                # print(f\"Prediction: {prediction}\")\n",
    "                batters_merged.loc[i, 'Cluster'] = prediction[0]\n",
    "            except KeyError as err:\n",
    "                print(f\"KeyError: {err}\")\n",
    "                batters_merged.loc[i, 'Cluster'] = 1\n",
    "                \n",
    "        # Merge with clusters\n",
    "        batters_merged = pd.merge(batters_merged, batter_clusters, on='Cluster', suffixes=(\"\", \"_cl\"))\n",
    "        \n",
    "        # Fill in small sample \n",
    "        for stat in batter_stats:\n",
    "            # CLUSTERS SHOULD BE BY PITCHER HAND THIS IS BAD AND WRONG!\n",
    "            batters_merged[f'{stat}_l'] = np.where(batters_merged['pa_b_l'] < 40, batters_merged[f'{stat}'], batters_merged[f'{stat}_l'])\n",
    "            batters_merged[f'{stat}_r'] = np.where(batters_merged['pa_b_r'] < 40, batters_merged[f'{stat}'], batters_merged[f'{stat}_r'])\n",
    "            \n",
    "        # Drop \n",
    "        # Standardize\n",
    "        \n",
    "        \n",
    "        # Save as Excel\n",
    "        batters_merged.to_excel(file_name, sheet_name=\"Batters\", engine='openpyxl')\n",
    "        \n",
    "\n",
    "        ### Pitcher\n",
    "        pitchers_merged = df.merge(pitchers_df, left_on='id', right_on='pitcher', how='left', suffixes=(\"\", \"_api\"))\n",
    "        \n",
    "        # Only keep pitchers\n",
    "        pitchers_merged = pitchers_merged[(pitchers_merged['position'] == 'P') | (pitchers_merged['position'] == 'TWP')]\n",
    "\n",
    "        # Create dummy variable for if they're a lefty. This is necessary to project. (maybe move this)\n",
    "        pitchers_merged['p_L'] = np.where(pitchers_merged['pitchHand'] == \"L\", 1, 0)\n",
    "        \n",
    "        \n",
    "        pitchers_merged.rename(columns={'H9':'H/9', 'HR9':'HR/9','K9':'K/9','BB9':'BB/9'}, inplace=True)\n",
    "        pitcher_stats_fg = ['H/9', 'HR/9','K/9', 'BB/9']\n",
    "        pitchers_merged[pitcher_stats_fg] = pitcher_scaler.transform(pitchers_merged[pitcher_stats_fg])\n",
    "\n",
    "        \n",
    "        # Determine clusters \n",
    "        pitcher_stats_fg = pitcher_stats_fg.append('p_L')\n",
    "        pitchers_merged['Cluster'] = np.nan\n",
    "        for i, row in pitchers_merged.iterrows():\n",
    "            try:\n",
    "                prediction = pitcher_kmeans.predict([row[['H/9', 'HR/9','K/9', 'BB/9', 'p_L']]])\n",
    "                pitchers_merged.loc[i, 'Cluster'] = prediction[0]\n",
    "            except:\n",
    "                pitchers_merged.loc[i, 'Cluster'] = 1\n",
    "        \n",
    "        # Merge with clusters\n",
    "        \n",
    "        \n",
    "        # Save as Excel\n",
    "        with pd.ExcelWriter(file_name, mode='a', engine='openpyxl') as writer:  \n",
    "            pitchers_merged.to_excel(writer, sheet_name='Pitchers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13667647-e708-4e8b-85c7-a7c8895440e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09d7ccc2-d52b-43d8-ae15-6b542bfb3568",
   "metadata": {},
   "source": [
    "### Run One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "932d368c-3689-4744-8547-bf96fd4fd82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI20230629.csv\n",
      "b1_b\n",
      "b2_b\n",
      "b3_b\n",
      "hr_b\n",
      "bb_b\n",
      "hbp_b\n",
      "so_b\n",
      "fo_b\n",
      "go_b\n",
      "lo_b\n",
      "po_b\n",
      "iso_b\n",
      "slg_b\n",
      "obp_b\n",
      "woba_b\n",
      "to_left_b\n",
      "to_middle_b\n",
      "to_right_b\n",
      "hard_hit_b\n",
      "totalDistance_b\n",
      "launchSpeed_b\n",
      "b1_b_long\n",
      "b2_b_long\n",
      "b3_b_long\n",
      "hr_b_long\n",
      "bb_b_long\n",
      "hbp_b_long\n",
      "so_b_long\n",
      "fo_b_long\n",
      "go_b_long\n",
      "lo_b_long\n",
      "po_b_long\n",
      "iso_b_long\n",
      "slg_b_long\n",
      "obp_b_long\n",
      "woba_b_long\n",
      "to_left_b_long\n",
      "to_middle_b_long\n",
      "to_right_b_long\n",
      "hard_hit_b_long\n",
      "totalDistance_b_long\n",
      "launchSpeed_b_long\n",
      "BOS20230629.csv\n",
      "b1_b\n",
      "b2_b\n",
      "b3_b\n",
      "hr_b\n",
      "bb_b\n",
      "hbp_b\n",
      "so_b\n",
      "fo_b\n",
      "go_b\n",
      "lo_b\n",
      "po_b\n",
      "iso_b\n",
      "slg_b\n",
      "obp_b\n",
      "woba_b\n",
      "to_left_b\n",
      "to_middle_b\n",
      "to_right_b\n",
      "hard_hit_b\n",
      "totalDistance_b\n",
      "launchSpeed_b\n",
      "b1_b_long\n",
      "b2_b_long\n",
      "b3_b_long\n",
      "hr_b_long\n",
      "bb_b_long\n",
      "hbp_b_long\n",
      "so_b_long\n",
      "fo_b_long\n",
      "go_b_long\n",
      "lo_b_long\n",
      "po_b_long\n",
      "iso_b_long\n",
      "slg_b_long\n",
      "obp_b_long\n",
      "woba_b_long\n",
      "to_left_b_long\n",
      "to_middle_b_long\n",
      "to_right_b_long\n",
      "hard_hit_b_long\n",
      "totalDistance_b_long\n",
      "launchSpeed_b_long\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\james\\\\Documents\\\\MLB\\\\Data2\\\\7. Stats\\\\C. Teams\\\\Daily20230629\\\\BOS20230629.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcreate_team_rosters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtodaysdate\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[108], line 72\u001b[0m, in \u001b[0;36mcreate_team_rosters\u001b[1;34m(date)\u001b[0m\n\u001b[0;32m     65\u001b[0m     batters_merged[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_l\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(batters_merged[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpa_b_r\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m40\u001b[39m, batters_merged[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m], batters_merged[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_l\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Drop \u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Standardize\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \n\u001b[0;32m     70\u001b[0m \n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Save as Excel\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m \u001b[43mbatters_merged\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBatters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopenpyxl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m### Pitcher\u001b[39;00m\n\u001b[0;32m     76\u001b[0m pitchers_merged \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mmerge(pitchers_df, left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpitcher\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, suffixes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_api\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2345\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes, storage_options)\u001b[0m\n\u001b[0;32m   2332\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2334\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2335\u001b[0m     df,\n\u001b[0;32m   2336\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2343\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2344\u001b[0m )\n\u001b[1;32m-> 2345\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2347\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2353\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\excel.py:888\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001b[0m\n\u001b[0;32m    884\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m# error: Cannot instantiate abstract class 'ExcelWriter' with abstract\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;66;03m# attributes 'engine', 'save', 'supported_extensions' and 'write_cells'\u001b[39;00m\n\u001b[1;32m--> 888\u001b[0m     writer \u001b[38;5;241m=\u001b[39m \u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[abstract]\u001b[39;49;00m\n\u001b[0;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:53\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[0;32m     51\u001b[0m engine_kwargs \u001b[38;5;241m=\u001b[39m combine_kwargs(engine_kwargs, kwargs)\n\u001b[1;32m---> 53\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_sheet_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_sheet_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# ExcelWriter replaced \"a\" by \"r+\" to allow us to first read the excel file from\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# the file and later write to it\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode:  \u001b[38;5;66;03m# Load from existing workbook\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1106\u001b[0m, in \u001b[0;36mExcelWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m IOHandles(\n\u001b[0;32m   1103\u001b[0m     cast(IO[\u001b[38;5;28mbytes\u001b[39m], path), compression\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m   1104\u001b[0m )\n\u001b[0;32m   1105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, ExcelWriter):\n\u001b[1;32m-> 1106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msheets: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcur_sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:798\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    790\u001b[0m             handle,\n\u001b[0;32m    791\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    794\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    799\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\james\\\\Documents\\\\MLB\\\\Data2\\\\7. Stats\\\\C. Teams\\\\Daily20230629\\\\BOS20230629.xlsx'"
     ]
    }
   ],
   "source": [
    "create_team_rosters(todaysdate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d33de0-b02d-4ea4-9322-56c061bfbd48",
   "metadata": {},
   "source": [
    "### Run All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e39a11-07bc-4ceb-806d-c28df9bcdf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loop over the folders in the directory\n",
    "# directory = r\"C:\\Users\\james\\Documents\\MLB\\Data2\\6. Rosters\"\n",
    "# for folder_name in os.listdir(directory):\n",
    "#     # Construct the full path of the folder\n",
    "#     folder_path = os.path.join(directory, folder_name)\n",
    "    \n",
    "#     # Check if the path is a directory\n",
    "#     if os.path.isdir(folder_path):\n",
    "#         # Print the folder name\n",
    "#         date = folder_name[7:15]\n",
    "        \n",
    "#         try:\n",
    "#             create_team_rosters(date)\n",
    "#         except:\n",
    "#             print(\"Missing for {}.\".format(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029e1b21-bcb6-451e-afd0-068b96acfc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Code was last run on: {} at {}.\".format(datetime.date.today(), datetime.datetime.now().strftime(\"%H:%M:%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edccf788-4cef-480f-9b5f-16cae29b985e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
