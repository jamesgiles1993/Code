{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a67c59d-8013-4b08-860b-f2b40e53261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do: integrate stats list from Imports to clean things up a little"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29ac501-33ac-4e27-95c9-0e6cd8f74e57",
   "metadata": {},
   "source": [
    "# 04. Rosters\n",
    "Source: <br>\n",
    "1. MLB Stats API <br>\n",
    "2. Statcast\n",
    "\n",
    "Description: This cleans raw data and creates master sample (for training models) and batter and pitcher datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2be61e-eeb5-492e-bc74-82a36c42a63c",
   "metadata": {},
   "source": [
    "### Read Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62818352-cc48-4e74-a0dd-865666f24f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in API data (Stats API or Statcast, it works for both)\n",
    "def read_api(directory):\n",
    "    # Specify the directory path\n",
    "    directory_path = r'C:\\Users\\james\\Documents\\MLB\\Data2\\3. MLB API\\\\' + directory\n",
    "\n",
    "    # Initialize an empty list to store DataFrames\n",
    "    dataframes = []\n",
    "\n",
    "    # Append all years together\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            df = pd.read_csv(file_path)  \n",
    "            dataframes.append(df)  \n",
    "\n",
    "    # Concatenate all DataFrames in the list into a single DataFrame\n",
    "    df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Keep only regular season games\n",
    "    df = df[df['game_type'] == \"R\"]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edebeaef-1c5d-4243-a746-80ef8450a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset of raw data, merging Stats API and Statcast\n",
    "def raw_dataset():\n",
    "    # Read in Stats API data\n",
    "    statsapi = read_api('Stats API')\n",
    "    # Read in Statcast data\n",
    "    statcast = read_api('Statcast')\n",
    "    \n",
    "    # Merge Stats API and Statcast data\n",
    "    df = pd.merge(statsapi, statcast, on=['gamePk', 'atBatIndex'], how='left', indicator=True)    \n",
    "    \n",
    "    # Sort\n",
    "    df.sort_values(['game_date', 'gamePk', 'atBatIndex'], inplace=True)\n",
    "    \n",
    "    # Only keep one observation per at bat\n",
    "    df.drop_duplicates(['gamePk', 'atBatIndex'], keep='last', inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39153600-98cd-4827-bd3f-40cde225bde3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77bea979-44d2-4b18-b232-e2ea517ce8fb",
   "metadata": {},
   "source": [
    "### Wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15dea7c3-4432-4af4-aa1a-5bff61b2810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive to centerfield, negative from centerfield\n",
    "def y_vect(df):\n",
    "    wind_speed = df['windSpeed']\n",
    "    angled = df['windSpeed'] / 2 * math.sqrt(2)\n",
    "    \n",
    "    if df['windDirection'] == \"Out To CF\": \n",
    "        y_vect = wind_speed\n",
    "    elif df['windDirection'] == \"Out To RF\": \n",
    "        y_vect = angled\n",
    "    elif df['windDirection'] == \"L To R\": \n",
    "        y_vect = 0\n",
    "    elif df['windDirection'] == \"In From LF\": \n",
    "        y_vect = angled * -1\n",
    "    elif df['windDirection'] == \"In From CF\": \n",
    "        y_vect = wind_speed * - 1\n",
    "    elif df['windDirection'] == \"In From RF\": \n",
    "        y_vect = angled * -1\n",
    "    elif df['windDirection'] == \"R To L\": \n",
    "        y_vect = 0\n",
    "    elif df['windDirection'] == \"Out To LF\": \n",
    "        y_vect = angled\n",
    "    else:\n",
    "        y_vect = 0\n",
    "        \n",
    "    return y_vect\n",
    "\n",
    "# Positive from left to right, negative from right to left\n",
    "def x_vect(df):\n",
    "    wind_speed = df['windSpeed']\n",
    "    angled = df['windSpeed'] / 2 * math.sqrt(2)\n",
    "    \n",
    "    if df['windDirection'] == \"L To R\": \n",
    "        x_vect = wind_speed\n",
    "    elif df['windDirection'] == \"In From LF\": \n",
    "        x_vect = angled\n",
    "    elif df['windDirection'] == \"In From CF\": \n",
    "        x_vect = 0\n",
    "    elif df['windDirection'] == \"In From RF\": \n",
    "        x_vect = angled * -1\n",
    "    elif df['windDirection'] == \"R To L\": \n",
    "        x_vect = wind_speed * - 1\n",
    "    elif df['windDirection'] == \"Out To LF\": \n",
    "        x_vect = angled * -1\n",
    "    elif df['windDirection'] == \"Out To CF\": \n",
    "        x_vect = 0\n",
    "    elif df['windDirection'] == \"Out To RF\": \n",
    "        x_vect = angled\n",
    "    else:\n",
    "        x_vect = 0\n",
    "        \n",
    "    return x_vect\n",
    "\n",
    "# 2 is to centerfield, 6 is from centerfield, clockwise\n",
    "# Assumption is wind is blowing in 8 cardinal directions, so we can use simple right isosceles triangles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4c3257-7a30-43ec-946c-2e7af6a2714d",
   "metadata": {},
   "source": [
    "### Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2187436c-bce8-4cbe-8b65-3d7e6b71b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_weather(df):\n",
    "    # Separate weather into temperature and weather type\n",
    "    df[['temperature', 'weather']] = df['weather'].str.split(\", \", expand=True)\n",
    "    df['temperature'] = df['temperature'].str.replace(\" degrees\", \"\").astype('int')\n",
    "    # Separate wind into speed and direction\n",
    "    df[['windSpeed', 'windDirection']] = df['wind'].str.split(\", \", expand=True)\n",
    "    df['windSpeed'].fillna(\"0 mph\", inplace=True)\n",
    "    df['windSpeed'] = df['windSpeed'].str.replace(\" mph\", \"\")\n",
    "    df['windSpeed'] = pd.to_numeric(df['windSpeed'], errors='coerce')\n",
    "    df['windSpeed'].fillna(0, inplace=True)\n",
    "    df['windDirection'].fillna('L to R', inplace=True)\n",
    "    df['windSpeed'].unique()\n",
    "    df['windDirection'] = df['windDirection'].str.replace(\".\", \"\")\n",
    "    # Calculate vectors\n",
    "    df['x_vect'] = df.apply(x_vect, axis=1)\n",
    "    df['y_vect'] = df.apply(y_vect, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9b3b4d-7c60-4d18-95dd-f69f160488f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c48551c7-2a46-4211-b800-9f848a1e8c2a",
   "metadata": {},
   "source": [
    "### Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f7d1ba1-f465-41b5-95e4-f0a22cb7c57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_events(df):\n",
    "    event_mapping = {\n",
    "        'Strikeout': 'so',\n",
    "        'Strikeout Double Play': 'so',\n",
    "        'Groundout': 'go',\n",
    "        'Fielders Choice': 'go',\n",
    "        'Double Play': 'go',\n",
    "        'Grounded Into DP': 'go',\n",
    "        'Triple Play': 'go',\n",
    "        'Field Error': 'go',\n",
    "        'Forceout': 'go',\n",
    "        'Lineout': 'lo',\n",
    "        'Bunt Lineout': 'lo',\n",
    "        'Flyout': 'fo',\n",
    "        'Sac Fly': 'fo',\n",
    "        'Sac Fly Double Play': 'fo',\n",
    "        'Pop Out': 'po',\n",
    "        'Bunt Pop Out': 'po',\n",
    "        'Hit By Pitch': 'hbp',\n",
    "        'Walk': 'bb',\n",
    "        'Intent Walk': 'bb',\n",
    "        'Single': 'b1',\n",
    "        'Double': 'b2',\n",
    "        'Triple': 'b3',\n",
    "        'Home Run': 'hr'\n",
    "    }\n",
    "\n",
    "    df['eventsModel'] = df['event'].map(event_mapping).fillna('Cut')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad871b35-6890-484d-8f8e-7a78c2236ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22db79f3-3807-4488-8047-a4d8f7dc9d9b",
   "metadata": {},
   "source": [
    "### Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcf6523a-6f08-4275-aece-97657a2657ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This turns several variables, including events, venues, hands, and bases into dummies\n",
    "def create_dummies(df):\n",
    "    \n",
    "    # Events\n",
    "    event_dummies = pd.get_dummies(df['eventsModel'])\n",
    "    # Venues\n",
    "    venue_dummies = pd.get_dummies(df['venue_id'], prefix='venue')\n",
    "    # Hands\n",
    "    pitcher_dummies = pd.get_dummies(df['pitchHand'], prefix='p')\n",
    "    batter_dummies = pd.get_dummies(df['batSide'], prefix='b')\n",
    "    # Years\n",
    "    df['year'] = df['game_date'].str[:4]\n",
    "    year_dummies = pd.get_dummies(df['year'], prefix='year')\n",
    "    \n",
    "    # Create lists of dummies\n",
    "    venue_list = venue_dummies.columns.tolist()\n",
    "    year_list = year_dummies.columns.tolist()\n",
    "    dummy_list = venue_list + year_list\n",
    "    \n",
    "    # Add dummies to dataframe\n",
    "    df = pd.concat([df, event_dummies, venue_dummies, pitcher_dummies, batter_dummies, year_dummies], axis=1)\n",
    "    \n",
    "    # Create dummy for runners on base\n",
    "    df['preOnFirst'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnFirst'].shift(1)\n",
    "    df['preOnSecond'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnSecond'].shift(1)\n",
    "    df['preOnThird'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnThird'].shift(1)\n",
    "    \n",
    "    df['onFirst'] = df['preOnFirst'].notnull().astype('int')\n",
    "    df['onSecond'] = df['preOnSecond'].notnull().astype('int')\n",
    "    df['onThird'] = df['preOnThird'].notnull().astype('int')\n",
    "    \n",
    "    # Top of the inning dummy\n",
    "    df['top'] = np.where(df['halfInning'] == \"top\", 1, 0)\n",
    "    \n",
    "    # Calculate PAs and ABs\n",
    "    df['pa'] = np.where(df['eventsModel'] != \"Cut\", 1, 0)\n",
    "    df['ab'] = df['pa'] - df['hbp'] - df['bb']\n",
    "    \n",
    "    return df, dummy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4c6e6f-2a1a-4591-a773-d8ba4ff91bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ddaffff-e19e-4df1-ab26-302ab8585500",
   "metadata": {},
   "source": [
    "### Clean Statcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fcba04c-28ab-42ba-b2bd-e64e378c6976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max(lst):\n",
    "    return max(lst) if lst else 0\n",
    "\n",
    "def clean_statcast(df):\n",
    "    # Hard hit dummy\n",
    "    df['hard_hit'] = (df['launch_speed'] >= 95).astype('int')\n",
    "    \n",
    "    # Barrel dummy\n",
    "    df['barrel'] = (df['launch_speed_angle'] == 6).astype('int')\n",
    "\n",
    "    # Spray \n",
    "    df['spray_angle'] = np.arctan((df['hc_x'] - 125.42) / (198.27 - df['hc_y'])) * 180 / np.pi * 0.75\n",
    "    df['to_left'] = (df['spray_angle'] < -15).astype('int')\n",
    "    df['to_middle'] = ((df['spray_angle'] >= -15) & (df['spray_angle'] <= 15)).astype('int')\n",
    "    df['to_right'] = (df['spray_angle'] > 15).astype('int')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe115f48-6a50-4358-b31c-d30427073b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6da4befe-74e0-42b7-9e5e-45d78eadc6bb",
   "metadata": {},
   "source": [
    "### Park Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d216f84e-79d8-4e94-a6ae-9a437d7636ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_park_factors(team_map):\n",
    "    # Read in park factors\n",
    "    park_factors_l = pd.read_excel(r\"C:\\Users\\james\\Documents\\MLB\\Data2\\Utilities\\Statcast Park Factors.xlsx\", sheet_name='L')\n",
    "    park_factors_l['batSide'] = \"L\"\n",
    "    park_factors_r = pd.read_excel(r\"C:\\Users\\james\\Documents\\MLB\\Data2\\Utilities\\Statcast Park Factors.xlsx\", sheet_name='R')\n",
    "    park_factors_r['batSide'] = \"R\"\n",
    "\n",
    "    # Append \n",
    "    park_factors = pd.concat([park_factors_l, park_factors_r], axis=0)\n",
    "    # Clean\n",
    "    park_factors['Team'] = park_factors['Team'].str.strip()\n",
    "  \n",
    "    # Merge with team map to get venue ID\n",
    "    park_factors = park_factors.merge(team_map[['FANGRAPHSTEAM', 'VENUE_ID']], left_on='Team', right_on='FANGRAPHSTEAM', how='inner')\n",
    "    park_factors.rename(columns={'VENUE_ID':'venue_id'}, inplace=True)\n",
    "    \n",
    "    # Keep relevant variables\n",
    "    park_factors = park_factors[['venue_id', 'batSide', 'Park Factor', '1B', '2B', '3B', 'HR', 'BB', 'SO']]\n",
    "    \n",
    "    # Convert to mean of 1, not 100\n",
    "    factor_list = ['Park Factor', '1B', '2B', '3B', 'HR', 'BB', 'SO']\n",
    "    for factor in factor_list:\n",
    "        park_factors[factor] = park_factors[factor] / 100\n",
    "    \n",
    "    return park_factors\n",
    "\n",
    "park_factors = read_park_factors(team_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae4f7ebe-8ffe-4c3c-af8b-120d3c69f158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def park_adjustments(df, park_factors):\n",
    "    # Merge with park factors\n",
    "    df = df.merge(park_factors, on=['venue_id', 'batSide'], how='left')\n",
    "    \n",
    "    # Old/other parks get all 1s\n",
    "    df['Park Factor'].fillna(1, inplace=True)\n",
    "    df['1B'].fillna(1, inplace=True)\n",
    "    df['2B'].fillna(1, inplace=True)\n",
    "    df['3B'].fillna(1, inplace=True)\n",
    "    df['HR'].fillna(1, inplace=True)\n",
    "    df['BB'].fillna(1, inplace=True)\n",
    "    df['SO'].fillna(1, inplace=True)\n",
    "    \n",
    "    # Adjust stats by park factor\n",
    "    df['b1'] = df['b1'] / df['1B']\n",
    "    df['b2'] = df['b2'] / df['2B']\n",
    "    df['b3'] = df['b3'] / df['3B']\n",
    "    df['hr'] = df['hr'] / df['HR']\n",
    "    df['bb'] = df['bb'] / df['BB']\n",
    "    df['so'] = df['so'] / df['SO']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d579b3f8-ff4c-4be9-95bc-696eb6751e05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4059ca59-f8ba-43d3-b36f-fc65818ae402",
   "metadata": {},
   "source": [
    "### Rolling Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4a05515-a0be-468f-b393-45c522ef754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return a dataframe that can eventually be used as the model input. Has pitcher vs hitter stats, specific to hand\n",
    "def rolling_pas(df, pa_num):\n",
    "    # Rename for compatibility purposes\n",
    "    df.rename(columns={'hit_distance_sc':'totalDistance', 'launch_speed':'launchSpeed'}, inplace=True)\n",
    "    \n",
    "    # Stats to calculate rolling averages/maximums\n",
    "    stat_list = ['so', 'b1', 'b2', 'b3', 'hr', 'bb', 'hbp', 'lo', 'po', 'go', 'fo', \n",
    "                 'hard_hit', 'barrel', 'to_left', 'to_middle', 'to_right', \n",
    "                 'estimated_woba_using_speedangle',\n",
    "                 'pa', 'ab']\n",
    "    \n",
    "    max_list = ['totalDistance', 'maxSpeed', 'maxSpin', 'launchSpeed']\n",
    "\n",
    "                \n",
    "    # \n",
    "    df['pa_num'] = df.index\n",
    "    \n",
    "    batter_stats = []\n",
    "    pitcher_stats = []\n",
    "    batter_stats2 = []\n",
    "    pitcher_stats2 = []\n",
    "\n",
    "    for stat in stat_list:\n",
    "        batter_stat = stat + \"_b\"\n",
    "        pitcher_stat = stat + \"_p\"\n",
    "        batter_stats.append(batter_stat)\n",
    "        pitcher_stats.append(pitcher_stat)\n",
    "\n",
    "    for stat in max_list:\n",
    "        batter_stat = stat + \"_b\"\n",
    "        pitcher_stat = stat + \"_p\"\n",
    "        batter_stats2.append(batter_stat)\n",
    "        pitcher_stats2.append(pitcher_stat)\n",
    "        \n",
    "    df[batter_stats] = df.groupby(['batter', 'pitchHand'])[stat_list].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).sum())\n",
    "    df[batter_stats2] = df.groupby(['batter', 'pitchHand'])[max_list].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).max())\n",
    "                \n",
    "    df[pitcher_stats] = df.groupby(['pitcher', 'batSide'])[stat_list].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).sum())\n",
    "    df[pitcher_stats2] = df.groupby(['pitcher', 'batSide'])[max_list].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).max())\n",
    "                \n",
    "    df.sort_values(['pa_num'], axis=0, ascending=True, inplace=True)\n",
    "\n",
    "    # wOBA - using 2022 values throughout\n",
    "    df['woba_b'] = (0.690 * df['bb_b']) + (0.721 * df['hbp_b']) + (0.885 * df['b1_b']) + (1.262 * df['b2_b']) + (1.601 * df['b3_b']) + (2.070 * df['hr_b'])\n",
    "    df['woba_p'] = (0.690 * df['bb_p']) + (0.721 * df['hbp_p']) + (0.885 * df['b1_p']) + (1.262 * df['b2_p']) + (1.601 * df['b3_p']) + (2.070 * df['hr_p'])\n",
    "    \n",
    "    # Slugging\n",
    "    df['slg_b'] = (1 * df['b1_b']) + (2 * df['b2_b']) + (3 * df['b3_b']) + (4 * df['hr_b'])\n",
    "    df['slg_b'] = df['slg_b'] / df['ab_b']\n",
    "    df['slg_p'] = (1 * df['b1_p']) + (2 * df['b2_p']) + (3 * df['b3_p']) + (4 * df['hr_p'])\n",
    "    df['slg_p'] = df['slg_p'] / df['ab_p']\n",
    "\n",
    "    # OBP    \n",
    "    df['obp_b'] = df[['b1_b', 'b2_b', 'b3_b', 'hr_b', 'bb_b', 'hbp_b']].sum(axis=1)\n",
    "    df['obp_p'] = df[['b1_p', 'b2_p', 'b3_p', 'hr_p', 'bb_p', 'hbp_p']].sum(axis=1)\n",
    "    \n",
    "    # ISO\n",
    "    df['iso_b'] = df['b2_b'] * 1 + df['b3_b'] * 2 + df['hr_b'] * 3\n",
    "    df['iso_p'] = df['b2_p'] * 1 + df['b3_p'] * 2 + df['hr_p'] * 3\n",
    "\n",
    "    \n",
    "    \n",
    "    # Calculate rates\n",
    "    stat_short = ['so', 'b1', 'b2', 'b3', 'hr', 'bb', 'hbp', 'lo', 'po', 'go', 'fo', \n",
    "                  'estimated_woba_using_speedangle', 'woba', 'obp', 'iso', 'hard_hit', 'barrel', \n",
    "                  'to_left', 'to_middle', 'to_right']\n",
    "    \n",
    "    for stat in stat_short:\n",
    "        batter_stat = stat + \"_b\"\n",
    "        pitcher_stat = stat + \"_p\"  \n",
    "        df[batter_stat] = df[batter_stat] / df['pa_b']\n",
    "        df[pitcher_stat] = df[pitcher_stat] / df['pa_p']\n",
    "        \n",
    "    df.sort_values('pa_num', inplace=True)\n",
    "    \n",
    "    batter_stats = batter_stats + batter_stats2\n",
    "    pitcher_stats = pitcher_stats + pitcher_stats2\n",
    "                \n",
    "        \n",
    "    return df, batter_stats, pitcher_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0b30462-8853-44a5-8bb7-2fac11549d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8103af8f-b93b-4d49-91e5-880cc1edde3f",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bfaaaa-5b29-433f-9666-5abf0da47f1e",
   "metadata": {},
   "source": [
    "##### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c208e2de-ca70-4ab4-951e-3b4c95da4a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This converts raw data to clean model input\n",
    "def create_model_input(date):\n",
    "    keep_list = ['so_b', 'b1_b', 'b2_b', 'b3_b', 'hr_b', 'bb_b', 'hbp_b', 'lo_b', 'po_b', 'go_b', 'fo_b', 'pa_b', 'ab_b', \n",
    "                 'estimated_woba_using_speedangle_b', 'woba_b', 'slg_b', 'obp_b', 'iso_b', 'hard_hit_b', 'barrel_b', \n",
    "                 'to_left_b', 'to_middle_b', 'to_right_b', \n",
    "                 'totalDistance_b', 'maxSpeed_b', 'maxSpin_b', 'launchSpeed_b',\n",
    "                 'so_p', 'b1_p', 'b2_p', 'b3_p', 'hr_p', 'bb_p', 'hbp_p', 'lo_p', 'po_p', 'go_p', 'fo_p', 'pa_p', 'ab_p', \n",
    "                 'estimated_woba_using_speedangle_p', 'woba_p', 'slg_p', 'obp_p', 'iso_p', 'hard_hit_p', 'barrel_p', \n",
    "                 'to_left_p', 'to_middle_p', 'to_right_p', \n",
    "                 'totalDistance_p', 'maxSpeed_p', 'maxSpin_p', 'launchSpeed_p']\n",
    "    \n",
    "    # Read in raw data\n",
    "    df = raw_dataset()    \n",
    "    # Clean weather variables\n",
    "    df2 = clean_weather(df)\n",
    "    # Create events\n",
    "    df3 = create_events(df2)\n",
    "    # Make dummies\n",
    "    df4, dummy_list = create_dummies(df3)\n",
    "    # Create Statcast stats\n",
    "    df5 = clean_statcast(df4)\n",
    "    # Make park adjustments\n",
    "    df6 = park_adjustments(df5, park_factors)\n",
    "    \n",
    "    # Restrict on data\n",
    "    # date = datetime.datetime.strptime(date, \"%Y%m%d\")\n",
    "    df6['date'] = df6['game_date'].str.replace(\"-\", \"\")\n",
    "    df6 = df6[df6['date'] < date]\n",
    "    # Cut if event isn't one we care about (usually these are weird base running things)\n",
    "    df6 = df6[df6['Cut'] != 1]\n",
    "\n",
    "    # Calculate short time frame rolling stats (100 PAs for now)\n",
    "    dfshort, batter_stats, pitcher_stats = rolling_pas(df6, 100)\n",
    "    dfmain = dfshort.copy()\n",
    "    # Calculate long time frame rolling stats (300 PAs for now)\n",
    "    dflong, batter_stats, pitcher_stats = rolling_pas(df6, 300)\n",
    "    dflong = dflong[keep_list]\n",
    "    dflong = dflong.add_suffix(\"_long\")\n",
    "    # Concatenate them together\n",
    "    sample = pd.concat([dfmain, dflong], axis=1)\n",
    "            \n",
    "    # Delete intermediate DFs\n",
    "    del dfmain, dfshort, dflong, df, df2, df3, df4, df5, df6    \n",
    "    \n",
    "    \n",
    "    # Determine score before PA\n",
    "    sample['preAwayScore'] = sample.groupby(['gamePk', 'inning', 'halfInning'])['awayScore'].shift(1)\n",
    "    sample['preHomeScore'] = sample.groupby(['gamePk', 'inning', 'halfInning'])['homeScore'].shift(1)\n",
    "    \n",
    "    sample['preAwayScore'].fillna(sample['awayScore'], inplace=True)\n",
    "    sample['preHomeScore'].fillna(sample['homeScore'], inplace=True)\n",
    "    \n",
    "    # Calculate score differential\n",
    "    sample['score_diff'] = np.where(sample['top'] == 1, sample['preAwayScore'] - sample['preHomeScore'], sample['preHomeScore'] - sample['preAwayScore'])\n",
    "    \n",
    "    \n",
    "    # Start dummy (=1 for first batter for each starter)\n",
    "    sample['start'] = 0\n",
    "\n",
    "    # Group by 'gamePk' and 'halfInning', then find the index of the first occurrence\n",
    "    top_first_idx = sample[sample['halfInning'] == 'top'].groupby('gamePk').head(1).index\n",
    "    bottom_first_idx = sample[sample['halfInning'] == 'bottom'].groupby('gamePk').head(1).index\n",
    "\n",
    "    # Update 'start' column based on the first occurrences\n",
    "    sample.loc[top_first_idx, 'start'] = 1\n",
    "    sample.loc[bottom_first_idx, 'start'] = 1\n",
    "    \n",
    "    # Add them up\n",
    "    sample['starts'] = sample[sample['date'] > \"20190330\"].groupby(['pitcher'])['start'].cumsum()\n",
    "    \n",
    "    \n",
    "    # Group by 'gamePk' and 'pitcher', then identify the index of the last observation\n",
    "    last_observation_idx = sample.groupby(['gamePk', 'pitcher']).tail(1).index   \n",
    "    \n",
    "    # Pulled dummy (=1 for last batter for each pitcher)\n",
    "    sample['pulled'] = 0\n",
    "\n",
    "    # Update 'pulled' column for the last observations\n",
    "    sample.loc[last_observation_idx, 'pulled'] = 1\n",
    "    \n",
    "    \n",
    "    # Batters faced\n",
    "    sample['faced'] = 1\n",
    "    games = sample.groupby(['pitcher', 'gamePk'])['faced'].sum().reset_index()\n",
    "    # Average of last n games, rolling, shifted\n",
    "    games['avgFaced'] = games.groupby('pitcher')['faced'].rolling(30, min_periods=1).mean().shift().reset_index(level=0, drop=True)\n",
    "    \n",
    "    # Merge to get avgFaced back\n",
    "    sample = sample.merge(games, on=['pitcher', 'gamePk'], how='left')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19076578-e9f6-460a-ab37-7c4e07b8e9fd",
   "metadata": {},
   "source": [
    "##### Batters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36148a3a-bd41-45e4-974d-ec92ce91ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batter inputs\n",
    "def create_batter_df(df, date):\n",
    "    # Stats of interest\n",
    "    batter_list = ['batter',  'batterName', 'batSide', 'p_L',\n",
    "     'so_b', 'b1_b', 'b2_b', 'b3_b', 'hr_b', 'bb_b', 'hbp_b', 'lo_b', 'po_b', 'go_b', 'fo_b', \n",
    "     'pa_b', 'ab_b', 'estimated_woba_using_speedangle_b', 'woba_b', 'slg_b', 'obp_b', 'iso_b', \n",
    "     'hard_hit_b', 'barrel_b', 'to_left_b', 'to_middle_b', 'to_right_b', \n",
    "     'totalDistance_b', 'maxSpeed_b', 'maxSpin_b', 'launchSpeed_b', \n",
    "     'so_b_long', 'b1_b_long', 'b2_b_long', 'b3_b_long', 'hr_b_long', 'bb_b_long', 'hbp_b_long', 'lo_b_long', 'po_b_long', 'go_b_long', 'fo_b_long', \n",
    "     'pa_b_long', 'ab_b_long', 'estimated_woba_using_speedangle_b_long', 'woba_b_long', 'slg_b_long', 'obp_b_long', 'iso_b_long', \n",
    "     'hard_hit_b_long', 'barrel_b_long', 'to_left_b_long', 'to_middle_b_long', 'to_right_b_long', \n",
    "     'totalDistance_b_long', 'maxSpeed_b_long', 'maxSpin_b_long', 'launchSpeed_b_long']\n",
    "\n",
    "    # Only keep relevant stats\n",
    "    batters = df[batter_list]\n",
    "    # Only care about most recent stats of each batter before PA\n",
    "    batters.drop_duplicates(subset=['batter', 'p_L'], keep='last', inplace=True)\n",
    "\n",
    "    # Create separate dataframes for vs RHP and LHP\n",
    "    vs_r = batters.query('p_L == 0')\n",
    "    vs_l = batters.query('p_L == 1')\n",
    "\n",
    "    # Merge them together\n",
    "    batters = vs_l.merge(vs_r, on='batter', how='outer', suffixes=('_l', '_r'))\n",
    "\n",
    "    # Drop duplicate columns\n",
    "    batters.drop(columns={'batterName_r', 'p_L_l', 'p_L_r'}, inplace=True)\n",
    "    # Only need this once\n",
    "    batters.rename(columns={'batterName_l': 'batterName'}, inplace=True)\n",
    "    \n",
    "    \n",
    "    # Merge with Chadwick\n",
    "    batters = batters.merge(chadwick, left_on='batter', right_on='key_mlbam', how='left')\n",
    "    \n",
    "    \n",
    "    # Export\n",
    "    batters.to_csv(os.path.join(baseball_path, \"4. Dataset\", \"Batters\", f\"Batters{date}.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46af4b3f-235e-4694-b7df-2368ca6f3d6e",
   "metadata": {},
   "source": [
    "##### Pitchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fff4ce1-5c52-4048-864e-15ff8534013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pitcher inputs\n",
    "def create_pitcher_df(df, date):\n",
    "    # Stats of interest\n",
    "    pitcher_list =  ['pitcher',  'pitcherName', 'pitchHand', 'b_L',\n",
    "                     'b1_p', 'b2_p', 'b3_p', 'hr_p', 'bb_p', 'hbp_p', \n",
    "                     'so_p', 'lo_p', 'po_p', 'go_p', 'fo_p', \n",
    "                     'estimated_woba_using_speedangle_p', 'woba_p', 'slg_p', 'obp_p', 'iso_p',\n",
    "                     'to_left_p', 'to_middle_p', 'to_right_p', \n",
    "                     'hard_hit_p', 'barrel_p', 'maxSpeed_p', 'maxSpin_p', 'totalDistance_p', 'launchSpeed_p',\n",
    "                     'pa_p', 'ab_p',\n",
    "                     \n",
    "                     'b1_p_long', 'b2_p_long', 'b3_p_long', 'hr_p_long', 'bb_p_long', 'hbp_p_long', \n",
    "                     'so_p_long', 'lo_p_long', 'po_p_long', 'go_p_long', 'fo_p_long', \n",
    "                     'estimated_woba_using_speedangle_p_long', 'woba_p_long', 'slg_p_long', 'obp_p_long', 'iso_p_long', \n",
    "                     'to_left_p_long', 'to_middle_p_long', 'to_right_p_long',\n",
    "                     'hard_hit_p_long', 'barrel_p_long', 'maxSpeed_p_long', 'maxSpin_p_long', 'totalDistance_p_long', 'launchSpeed_p_long',\n",
    "                     'pa_p_long', 'ab_p_long', \n",
    "                     'avgFaced', 'starts',\n",
    "                     'inning', 'outs', 'gamePk', 'eventsModel', 'game_date']\n",
    "    \n",
    "    # Only keep relevant stats\n",
    "    pitchers = df[pitcher_list]\n",
    "    \n",
    "    # Calculate average outs\n",
    "    # Create a copy of the dataframe\n",
    "    pitchers_cut = pitchers.copy()\n",
    "    # Only look at PAs since 2019\n",
    "    pitchers_cut = pitchers_cut[pitchers_cut['game_date'] > '2019-04-01']\n",
    "    pitchers_cut.drop_duplicates(subset=['pitcher', 'gamePk', 'inning'], keep='last', inplace=True)\n",
    "    # Identify if they're a starter\n",
    "    pitchers_cut['starter'] = (pitchers_cut['inning'] == 1).astype('int')\n",
    "    # Add up starts\n",
    "    pitchers_cut = pitchers_cut.groupby(['pitcher', 'gamePk'])['outs', 'starter'].sum().reset_index()\n",
    "    # Calculate mean outs and sum of starts\n",
    "    pitchers_cut = pitchers_cut.groupby('pitcher').agg({'outs': np.mean, 'starter': np.sum}).reset_index()\n",
    "\n",
    "    # Only care about most recent stats of each pitcher before PA\n",
    "    pitchers.drop_duplicates(subset=['pitcher', 'b_L'], keep='last', inplace=True)\n",
    "    \n",
    "    # Create separate dataframes for vs RHB and LHB\n",
    "    vs_r = pitchers.query('b_L == 0')\n",
    "    vs_l = pitchers.query('b_L == 1')\n",
    "\n",
    "    # Merge them together\n",
    "    pitchers = vs_l.merge(vs_r, on='pitcher', how='outer', suffixes=('_l', '_r'))\n",
    "    # And add outs/starts\n",
    "    pitchers = pitchers.merge(pitchers_cut, on='pitcher', how='left')\n",
    "    \n",
    "    # Drop duplicate columns\n",
    "    pitchers.drop(columns={'pitcherName_r', 'b_L_l', 'b_L_r', 'inning_r', 'outs_r', 'gamePk_r', 'eventsModel_r', 'game_date_r',  'inning_l',\n",
    "                           'outs_l', 'gamePk_l', 'eventsModel_l', 'game_date_l', 'starts_l', 'avgFaced_l'}, inplace=True)\n",
    "    # Only need this once\n",
    "    pitchers.rename(columns={'pitcherName_l': 'pitcherName', 'starts_r': 'start', 'avgFaced_r':'avgFaced'}, inplace=True)\n",
    "    \n",
    "    # Merge with Chadwick\n",
    "    pitchers = pitchers.merge(chadwick, left_on='pitcher', right_on='key_mlbam', how='left')\n",
    "    \n",
    "    \n",
    "    # Export    \n",
    "    pitchers.to_csv(os.path.join(baseball_path, \"4. Dataset\", \"Pitchers\", f\"Pitchers{date}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d97bd1d-cac6-4ddb-8788-6010def60984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates inputs on a given date\n",
    "def create_datasets(date):\n",
    "    # Create data for model and data for model inputs \n",
    "    sample = create_model_input(date)\n",
    "    # Create batter and pitcher csvfiles\n",
    "    create_batter_df(sample, date)\n",
    "    create_pitcher_df(sample, date)\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26280840-dbe1-454b-ae14-2d0e02a9684b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e3f4aa-a055-47ed-a897-0161d97ed7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b02e2c-c7fc-4a0a-b3f8-dae6373a962e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecc4669-ddae-483d-91e9-fa971f2d95d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
