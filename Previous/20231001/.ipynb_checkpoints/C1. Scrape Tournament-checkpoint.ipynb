{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a6abfd9-2035-444e-a5bc-eeb19756799b",
   "metadata": {},
   "source": [
    "# Scrape Fantasy Labs\n",
    "This scrapes www.fantasylabs.com <br>\n",
    "This website contains information on contest results that can be used to replicate DraftKings' salary and result files <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc43df9f-1368-4908-b4f6-c1993635e2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\")\n",
    "\n",
    "baseball_path = r\"C:\\Users\\james\\Documents\\MLB\\Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9b0c2d5a-5545-4061-bd0a-2d0bb68e9c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This reads in a map of team name, codes, and the number Fangraphs uses in their URLs\n",
    "team_map = pd.read_csv(os.path.join(baseball_path, \"Utilities\", \"Team Map.csv\"))\n",
    "# We just need teams right now\n",
    "team_map = team_map[['FULLNAME', 'FANPROSTEAM', 'BBREFTEAM', 'ROTOWIRETEAM']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "038d2e75-bd2e-4c77-a028-3182fe4a75a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This scrapes the Fantasy Labs website to recreate DK salaries and results\n",
    "def scrape_fantasylabs(dateStr):\n",
    "    # Create date string\n",
    "    dateStr_alpha = datetime.datetime.strptime(dateStr, '%Y-%M-%d').strftime('%Y%M%d')\n",
    "\n",
    "    # Use date to find URL\n",
    "    url = f'https://service.fantasylabs.com/contest-sources/?sport_id=3&date={dateStr}'\n",
    "    # Use url to request json data\n",
    "    jsonData = requests.get(url).json()\n",
    "    # Gather groupId variable\n",
    "    groupId = jsonData['contest-sources'][0]['draft_groups'][0]['id']\n",
    "    print(jsonData)\n",
    "   \n",
    "    # Use that in this URL\n",
    "    url = f'https://service.fantasylabs.com/live-contests/?sport=MLB&contest_group_id={groupId}'\n",
    "    headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36'}\n",
    "    jsonData = requests.get(url, headers=headers).json()\n",
    "    \n",
    "    # Extract contestIds\n",
    "    contestIds = {}\n",
    "    for each in jsonData['live_contests']:\n",
    "        contestIds[each['contest_name']] = each['contest_id']\n",
    "\n",
    "    # Gather standings\n",
    "    rows = []\n",
    "    for contestName, contestId in contestIds.items():\n",
    "        url = f'https://dh5nxc6yx3kwy.cloudfront.net/contests/mlb/{dateStr_alpha}/{contestId}/lineups/'\n",
    "        jsonData = requests.get(url, headers=headers).json()\n",
    "\n",
    "        lineups = jsonData['lineups']\n",
    "        for k, v in lineups.items():\n",
    "            v.update({'contestName':contestName})\n",
    "            rows.append(v)\n",
    "\n",
    "        standings = pd.DataFrame(rows)\n",
    "    \n",
    "    # Grab url again (probably could do this cleaner but I don't really know what I'm doing)\n",
    "    url = f'https://service.fantasylabs.com/live-contests/?sport=MLB&contest_group_id={groupId}'\n",
    "    headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36'}\n",
    "    jsonData = requests.get(url, headers=headers).json()\n",
    "    print(groupId)\n",
    "    # Choose largest contest\n",
    "    largest_contest = \"\"\n",
    "    largest_size = 0\n",
    "    entry_cost = 0\n",
    "    largest_name = \"\"\n",
    "    for each in jsonData['live_contests']:\n",
    "        if (each['contest_size'] > largest_size) and (each['entry_cost'] > 0): \n",
    "            largest_contest = each['contest_id'] \n",
    "            largest_size = each['contest_size']\n",
    "            entry_cost = each['entry_cost']\n",
    "            largest_name = each['contest_name']\n",
    "            \n",
    "    # Create dataframes for largest contest\n",
    "    tables = {}\n",
    "    for each in jsonData['live_contests']:\n",
    "        if each['contest_id'] == largest_contest:\n",
    "            contestId = each['contest_id']\n",
    "            if each['contest_name'] not in tables.keys():\n",
    "                tables[each['contest_name']] = {}\n",
    "\n",
    "            url = f'https://dh5nxc6yx3kwy.cloudfront.net/contests/mlb/{dateStr_alpha}/{contestId}/data/'\n",
    "            jsonData = requests.get(url).json()\n",
    "            \n",
    "            contestUsers = pd.DataFrame(jsonData['users']).T.reset_index(drop=True)\n",
    "            tables[each['contest_name']]['users'] = contestUsers\n",
    "\n",
    "            fieldExposures = pd.DataFrame(jsonData['players']).T\n",
    "\n",
    "            for k, v in jsonData['exposures'].items():\n",
    "                exposureDf = pd.DataFrame(v['exposureCounts']).T\n",
    "                exposureDf.columns = [x + f'_top_{k}%' for x in exposureDf.columns]\n",
    "                fieldExposures = pd.merge(fieldExposures, exposureDf, how='left', left_index=True, right_index=True )\n",
    "\n",
    "            fieldExposures = fieldExposures.fillna(0).reset_index(drop=True)\n",
    "            tables[each['contest_name']]['exposures'] = fieldExposures\n",
    "\n",
    "            # Exclude those without a team\n",
    "            fieldExposures = fieldExposures[fieldExposures[\"currentTeam\"] != \"\"]\n",
    "        \n",
    "        # print('****** ' + each['contest_name'] + ' ******')\n",
    "        # print(contestUsers,fieldExposures )\n",
    "        \n",
    "    # Add entry cost and name to standings\n",
    "    standings['entry_cost'] = entry_cost\n",
    "    standings['largest_name'] = largest_name\n",
    "    \n",
    "    # Only keep largest contest\n",
    "    standings = standings[standings['largest_name'] == standings['contestName']]\n",
    "        \n",
    "    return fieldExposures, contestUsers, standings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "a15aa1e9-3337-4be4-ba17-84e53f1aa2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://www.fantasylabs.com/api/contest-ownership/1/10_12_2022/4/75377/0/'\n",
    "url = 'https://www.fantasylabs.com/api/contest-ownership/3/04_07_2022/4/66314/0/'\n",
    "headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36'}\n",
    "jsonData = requests.get(url, headers=headers).json()\n",
    "# print(jsonData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "df5246c1-c852-4f15-9f91-46f721ddb532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contest-sources': [{'id': 4, 'source_name': 'draftkings.com', 'is_primary': False, 'orphan_count': 0, 'ui_display_order': 1, 'display_name': 'DraftKings', 'min_salary': 0, 'max_salary': 0, 'is_active': True, 'short_name': 'dk', 'draft_groups': [{'id': 73806, 'contest_start_date': '2022-04-07T16:05:00', 'contest_end_date': '2022-04-07T21:40:00', 'contest_suffix': '', 'draft_group_id': 66314, 'game_count': 7, 'sport': {'id': 3}, 'source': {'id': 4}}]}, {'id': 11, 'source_name': 'yahoo.com', 'is_primary': False, 'orphan_count': 0, 'ui_display_order': 8, 'display_name': 'Yahoo', 'min_salary': 0, 'max_salary': 0, 'is_active': True, 'short_name': 'yahoo', 'draft_groups': [{'id': 73926, 'contest_start_date': '2022-04-07T13:05:00', 'contest_end_date': '0001-01-01T00:00:00', 'contest_suffix': '', 'draft_group_id': 15381, 'game_count': 9, 'sport': {'id': 3}, 'source': {'id': 11}}]}]}\n",
      "73806\n"
     ]
    }
   ],
   "source": [
    "fieldExposures, contestUsers, standings = scrape_fantasylabs(\"2022-04-07\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "fb37c62b-2972-459c-8c2a-904e0c95513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This data is sloppy and some dates have to be fixed\n",
    "def manual_clean(df):\n",
    "    df = df[~((df['eventId'] == 5292910) & (df['currentTeam'] == 'SEA'))]\n",
    "    df = df[~((df['eventId'] == 5292910) & (df['currentTeam'] == 'DET'))]\n",
    "    # 8/19/2022\n",
    "    df = df[~((df['eventId'] == 5374000) & (df['currentTeam'] == 'CHW'))]\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "d871fcb6-555d-482c-ac28-b5807c5a2e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates basic Game Info to mimic DK Salaries away@home (ignoring date and time)\n",
    "def create_gameinfo(df):\n",
    "    df = df.groupby(['currentTeam', 'homeVisitor'])['eventId'].agg(pd.Series.mode).reset_index()\n",
    "    \n",
    "    df = df.merge(team_map, left_on='currentTeam', right_on='FANPROSTEAM', how='left')\n",
    "    df['currentTeam'] = df['BBREFTEAM']\n",
    "    \n",
    "    df = manual_clean(df)\n",
    "    \n",
    "    # Create home and away dataframes\n",
    "    home = df.query('homeVisitor == \"Home\"')\n",
    "    visitor = df.query('homeVisitor == \"Visitor\"')\n",
    "    # print(home[['currentTeam', 'eventId']])\n",
    "    # print(visitor[['currentTeam', 'eventId']])\n",
    "    # Merge them together\n",
    "    merged = visitor.merge(home, on='eventId', how='inner')\n",
    "    # Create Game Info variable\n",
    "    merged['Game Info'] = merged['currentTeam_x'] + \"@\" + merged['currentTeam_y']\n",
    "    merged.drop_duplicates(subset=['currentTeam_x'], inplace=True)\n",
    "    merged.drop_duplicates(subset=['currentTeam_y'], inplace=True)\n",
    "    \n",
    "    # Just keep that and a game code to merge on\n",
    "    merged = merged[['eventId', 'Game Info']]\n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f54db13c-dfce-4540-8981-bd3883fa8bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates:\n",
    "\n",
    "def create_dfs(standings, fieldExposures):\n",
    "    # Split lineupHash to make each its own variable\n",
    "    standings[['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']] = standings['lineupHash'].str.split(\":\", expand=True)\n",
    "    \n",
    "    # Fill missings with a string\n",
    "    standings.fillna(\"999909\", inplace=True)\n",
    "    \n",
    "    # Gather player info\n",
    "    # players = fieldExposures[['playerId', 'fullName', 'actualPoints', 'salary', 'position', 'rosterPosition', 'ownership']]\n",
    "    players = fieldExposures.copy()\n",
    "    players['playerId'] = players['playerId'].astype('str')\n",
    "    players_cut = players[['playerId', 'position', 'fullName', 'actualPoints']]\n",
    "\n",
    "    \n",
    "    \n",
    "    for i in range(1, 11):\n",
    "        position = str(i)\n",
    "        standings = standings.merge(players_cut, left_on=position, right_on='playerId', how='left', suffixes=(\"\", position))\n",
    "\n",
    "    standings.fillna(\"MI\", inplace=True)\n",
    "        \n",
    "    standings['Lineup'] = \"\"\n",
    "    for col in standings.columns:\n",
    "        if col.startswith('position'):\n",
    "            standings['Lineup'] = standings['Lineup'] + standings[col] + \" \" \n",
    "        if col.startswith('fullName'):\n",
    "            standings['Lineup'] = standings['Lineup'] + standings[col] + \" \" \n",
    "\n",
    "    standings = standings.reset_index()\n",
    "\n",
    "    # Duplicate lineups, one for each instance of that lineup\n",
    "    standings = standings.loc[standings.index.repeat(standings.lineupCt)]\n",
    "    \n",
    "    standings['entryId'] = standings['index']\n",
    "    standings['TimeRemaining'] = 0\n",
    "    \n",
    "    standings.rename(columns={'lineupRank':'Rank', 'entryId':'EntryId', 'entryNameList':'EntryName', 'points':'Points'}, inplace=True)\n",
    "    \n",
    "    results = standings[['Rank', 'EntryId', 'EntryName', 'TimeRemaining', 'Points', 'Lineup']]\n",
    "    payout = standings[['Rank', 'EntryId', 'EntryName', 'TimeRemaining', 'Points', 'Lineup', 'payout', 'entry_cost']]\n",
    "    \n",
    "    \n",
    "    \n",
    "    players.rename(columns={'fullName':'Player', 'actualPoints':'FPTS', 'ownership':'%Drafted', 'rosterPosition': 'Roster Position', 'position':'Position', 'playerId':'ID'}, inplace=True)\n",
    "    player_results = players[['Player', 'Roster Position', '%Drafted', 'FPTS']]\n",
    "    players.rename(columns={'Player':'Name', 'FPTS':'AvgPointsPerGame', 'salary':'Salary'}, inplace=True)\n",
    "    # print(players)\n",
    "    players['Name + ID'] = players['Name'] + \" (\" + players['ID'].astype('str') + \")\"\n",
    "    \n",
    "    # Create Game Info variable\n",
    "    game_df = create_gameinfo(players)\n",
    "    # Merge Game Info onto salaries\n",
    "    merged = players.merge(game_df, on='eventId', how='left')\n",
    "    merged.rename(columns={'currentTeam':'TeamAbbrev'}, inplace=True)\n",
    "    # Keep relevant variables\n",
    "    merged = merged[['Position', 'Name + ID', 'Name', 'ID', 'Roster Position', 'Salary', 'Game Info', 'TeamAbbrev', 'AvgPointsPerGame']]\n",
    "    salaries = merged[['Position', 'Name + ID', 'Name', 'ID', 'Roster Position', 'Salary', 'Game Info', 'TeamAbbrev', 'AvgPointsPerGame']]\n",
    "    \n",
    "    player_results.sort_values(by=['FPTS'], ascending=False, inplace=True)\n",
    "    salaries.sort_values(by=['Salary'], ascending=False, inplace=True)\n",
    "    return results, payout, player_results, salaries\n",
    "\n",
    "\n",
    "# results, payout, player_results, salaries = create_dfs(standings, fieldExposures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "71c00bb1-52c6-4dc7-b6e9-63cda2ee6824",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This creates the Salaries and Results csvs\n",
    "def create_excels(dateStr):\n",
    "    # Scrape fantasylabs for fieldExposures (which has salary info) and contestUsers (has lineups)\n",
    "    fieldExposures, contestUsers, standings = scrape_fantasylabs(dateStr)\n",
    "    \n",
    "    # Create field lineup results and salaries\n",
    "    results, payout, player_results, salaries = create_dfs(standings, fieldExposures)\n",
    "        \n",
    "    # Results (similar to DK results)\n",
    "    date_short = dateStr.replace(\"-\", \"\")\n",
    "    filename = \"Results \" + date_short + \".xlsx\"\n",
    "    \n",
    "    # Write as Excel \n",
    "    # We really want a CSV, but we have two DFs and I'm not sure how to write them correctly to a csv\n",
    "    writer = pd.ExcelWriter(os.path.join(baseball_path, \"Results Scraped\", filename), engine='openpyxl')\n",
    "    \n",
    "    results.to_excel(writer, sheet_name='Sheet1', header=True, index=False)\n",
    "    player_results.to_excel(writer, sheet_name='Sheet1', header=True, index=False,\n",
    "                 startcol=7,startrow=0)\n",
    "    \n",
    "    writer.save()\n",
    "    \n",
    "    # Convert it to CSV\n",
    "    results = pd.read_excel(os.path.join(baseball_path, \"Results Scraped\", filename))\n",
    "    csvname = filename = \"Results \" + date_short + \".csv\"\n",
    "    results.to_csv(os.path.join(baseball_path, \"Results Scraped\", csvname))\n",
    "    \n",
    "    # Salaries (similar to DK salaries)\n",
    "    filename2 = \"DKSalaries_\" + date_short + \".csv\"\n",
    "    salaries.to_csv(os.path.join(baseball_path, \"Salaries Scraped\", filename2))\n",
    "\n",
    "    # Payouts\n",
    "    filename3 = \"Payouts_\" + date_short + \".csv\"\n",
    "    payout.to_csv(os.path.join(baseball_path, \"Payouts Scraped\", filename3))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "08758830-d1d7-4937-b30c-051b10a167db",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_excels(\"2022-05-23\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "da642aba-2a5c-4fe2-8984-0dbbda66fb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20220401\n",
      "Didn't work\n",
      "20220402\n",
      "Didn't work\n",
      "20220403\n",
      "Didn't work\n",
      "20220404\n",
      "Didn't work\n",
      "20220405\n",
      "Didn't work\n",
      "20220406\n",
      "Didn't work\n",
      "20220407\n",
      "20220408\n",
      "20220409\n",
      "20220410\n",
      "20220411\n",
      "20220412\n",
      "20220413\n",
      "20220414\n",
      "20220415\n",
      "20220416\n",
      "20220417\n",
      "20220418\n",
      "20220419\n",
      "20220420\n",
      "20220421\n",
      "20220422\n",
      "20220423\n",
      "20220424\n",
      "20220425\n",
      "20220426\n",
      "20220427\n",
      "20220428\n",
      "20220429\n",
      "20220430\n",
      "20220501\n",
      "20220502\n",
      "20220503\n",
      "20220504\n",
      "20220505\n",
      "20220506\n",
      "20220507\n",
      "20220508\n",
      "20220509\n",
      "20220510\n",
      "20220511\n",
      "20220512\n",
      "20220513\n",
      "20220514\n",
      "20220515\n",
      "20220516\n",
      "20220517\n",
      "20220518\n",
      "20220519\n",
      "20220520\n",
      "20220521\n",
      "20220522\n",
      "20220523\n",
      "20220524\n",
      "20220525\n",
      "20220526\n",
      "20220527\n",
      "Didn't work\n",
      "20220528\n",
      "Didn't work\n",
      "20220529\n",
      "20220530\n",
      "20220531\n",
      "20220601\n",
      "20220602\n",
      "20220603\n",
      "20220604\n",
      "20220605\n",
      "20220606\n",
      "20220607\n",
      "20220608\n",
      "20220609\n",
      "20220610\n",
      "20220611\n",
      "20220612\n",
      "20220613\n",
      "20220614\n",
      "20220615\n",
      "20220616\n",
      "20220617\n",
      "20220618\n",
      "20220619\n",
      "20220620\n",
      "20220621\n",
      "20220622\n",
      "20220623\n",
      "20220624\n",
      "Didn't work\n",
      "20220625\n",
      "20220626\n",
      "20220627\n",
      "20220628\n",
      "20220629\n",
      "20220630\n",
      "20220701\n",
      "20220702\n",
      "20220703\n",
      "20220704\n",
      "20220705\n",
      "20220706\n",
      "20220707\n",
      "20220708\n",
      "20220709\n",
      "20220710\n",
      "20220711\n",
      "20220712\n",
      "20220713\n",
      "20220714\n",
      "20220715\n",
      "20220716\n",
      "20220717\n",
      "20220718\n",
      "Didn't work\n",
      "20220719\n",
      "Didn't work\n",
      "20220720\n",
      "Didn't work\n",
      "20220721\n",
      "20220722\n",
      "20220723\n",
      "20220724\n",
      "20220725\n",
      "20220726\n",
      "20220727\n",
      "20220728\n",
      "20220729\n",
      "20220730\n",
      "20220731\n",
      "20220801\n",
      "Didn't work\n",
      "20220802\n",
      "20220803\n",
      "20220804\n",
      "20220805\n",
      "20220806\n",
      "20220807\n",
      "20220808\n",
      "20220809\n",
      "20220810\n",
      "20220811\n",
      "20220812\n",
      "20220813\n",
      "20220814\n",
      "20220815\n",
      "20220816\n",
      "20220817\n",
      "20220818\n",
      "20220819\n",
      "20220820\n",
      "20220821\n",
      "20220822\n",
      "20220823\n",
      "20220824\n",
      "20220825\n",
      "20220826\n",
      "20220827\n",
      "20220828\n",
      "20220829\n",
      "20220830\n",
      "20220831\n",
      "20220901\n",
      "20220902\n",
      "20220903\n",
      "20220904\n",
      "20220905\n",
      "20220906\n",
      "20220907\n",
      "20220908\n",
      "20220909\n",
      "Didn't work\n",
      "20220910\n",
      "20220911\n",
      "Didn't work\n",
      "20220912\n",
      "20220913\n",
      "20220914\n",
      "20220915\n",
      "20220916\n",
      "20220917\n",
      "20220918\n",
      "Didn't work\n",
      "20220919\n",
      "20220920\n",
      "20220921\n",
      "20220922\n",
      "20220923\n",
      "20220924\n",
      "20220925\n",
      "Didn't work\n",
      "20220926\n",
      "20220927\n",
      "20220928\n",
      "20220929\n",
      "20220930\n",
      "20221001\n",
      "20221002\n",
      "Didn't work\n",
      "20221003\n",
      "20221004\n",
      "20221005\n",
      "20221006\n",
      "Didn't work\n",
      "20221007\n",
      "20221008\n",
      "20221009\n",
      "Didn't work\n",
      "20221010\n",
      "Didn't work\n",
      "20221011\n",
      "20221012\n",
      "20221013\n",
      "Didn't work\n",
      "20221014\n",
      "20221015\n",
      "20221016\n",
      "Didn't work\n",
      "20221017\n",
      "Didn't work\n",
      "20221018\n",
      "Didn't work\n",
      "20221019\n",
      "20221020\n",
      "Didn't work\n",
      "20221021\n",
      "Didn't work\n",
      "20221022\n",
      "Didn't work\n",
      "20221023\n",
      "Didn't work\n",
      "20221024\n",
      "Didn't work\n",
      "20221025\n",
      "Didn't work\n",
      "20221026\n",
      "Didn't work\n"
     ]
    }
   ],
   "source": [
    "# Loop over dates that we have fangraphs projections for\n",
    "for filename in os.listdir(r\"C:\\Users\\james\\Documents\\MLB\\Data\\Rosters\\Depth\"):\n",
    "    date = filename[5:13]\n",
    "    print(date)\n",
    "    \n",
    "    dateStr = date[0:4] + \"-\" + date[4:6] + \"-\" + date[6:8]\n",
    "    \n",
    "    try:\n",
    "        create_excels(dateStr)\n",
    "    except:\n",
    "        print(\"Didn't work\")\n",
    "    \n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "83292082-8f09-415a-a5e1-a1a3e5fee2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import bs4\n",
    "# from bs4 import BeautifulSoup\n",
    "# from selenium import webdriver\n",
    "\n",
    "# chromedriver_path= r\"C:\\Users\\james\\Documents\\MLB\\chromedriver.exe\"\n",
    "# driver = webdriver.Chrome(chromedriver_path)\n",
    "# url = \"https://www.fantasylabs.com/mlb/contest-ownership/?date=04072022\"\n",
    "# driver.get(url)\n",
    "# time.sleep(6) #if you want to wait 3 seconds for the page to load\n",
    "# page_source = driver.page_source\n",
    "# soup = bs4.BeautifulSoup(page_source, 'lxml')\n",
    "# for tag in soup.find_all(\"div\", id=\"ownershipGrid\"):\n",
    "#     print(tag.get_text(separator=\" \"))\n",
    "    \n",
    "# driver.close()\n",
    "# # soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "963a0ffd-4573-41d0-98a4-30761febbc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.rotowire.com/daily/tables/optimizer-mlb.php'\n",
    "# url = 'https://www.rotowire.com/daily/mlb/optimizer.php?projections=RotoWire&rst=UFCollective&slateID=8730'\n",
    "# url = 'https://www.rotowire.com/daily/mlb/player-roster-percent.php'\n",
    "payload = {\n",
    "'siteID': '1',\n",
    "'slateID': '7115',\n",
    "'projSource': 'RotoWire',\n",
    "'rst': 'RotoWire'}\n",
    "\n",
    "jsonData = requests.get(url, params=payload).json()\n",
    "df = pd.DataFrame(jsonData)\n",
    "# df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4303f3d3-270a-427b-acef-7fbc6131f290",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['id', 'rotoPlayerID', 'player', 'ownership', 'proj_points', 'team',\\n       'game_location'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [162]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     df \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrotoPlayerID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mownership\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproj_points\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteam\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgame_location\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(df)\n\u001b[1;32m---> 18\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mplayer_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8727\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m df\n",
      "Input \u001b[1;32mIn [162]\u001b[0m, in \u001b[0;36mplayer_data\u001b[1;34m(slateID)\u001b[0m\n\u001b[0;32m     10\u001b[0m jsonData \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url, params\u001b[38;5;241m=\u001b[39mpayload)\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m     11\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(jsonData)\n\u001b[1;32m---> 13\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrotoPlayerID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mplayer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mownership\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mproj_points\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mteam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgame_location\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m(df)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3510\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3511\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3513\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5784\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5786\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5842\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5841\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 5842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5844\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   5845\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['id', 'rotoPlayerID', 'player', 'ownership', 'proj_points', 'team',\\n       'game_location'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "def player_data(slateID):\n",
    "    slateID = str(slateID)\n",
    "    url = 'https://www.rotowire.com/daily/tables/optimizer-mlb.php'\n",
    "    payload = {\n",
    "    'siteID': '1',\n",
    "    'slateID': slateID,\n",
    "    'projSource': 'RotoWire',\n",
    "    'rst': 'RotoWire'\n",
    "    }\n",
    "    jsonData = requests.get(url, params=payload).json()\n",
    "    df = pd.DataFrame(jsonData)\n",
    "    \n",
    "    df = df[['id', 'rotoPlayerID', 'player', 'ownership', 'proj_points', 'team', 'game_location']]\n",
    "    \n",
    "    \n",
    "    return(df)\n",
    "\n",
    "df = player_data(8727)\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8da5ef80-f428-4d99-ae8a-9cda7d3986b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['date', 'visit_team', 'home_team'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [161]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     df \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvisit_team\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhome_team\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m---> 11\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mmatchup_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8727\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m df\n",
      "Input \u001b[1;32mIn [161]\u001b[0m, in \u001b[0;36mmatchup_data\u001b[1;34m(slateID)\u001b[0m\n\u001b[0;32m      3\u001b[0m jsonData \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(jsonData)\n\u001b[1;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisit_team\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhome_team\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3510\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3511\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3513\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5784\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5786\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5842\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5841\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 5842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5844\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   5845\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['date', 'visit_team', 'home_team'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "def matchup_data(slateID):\n",
    "    url = f'https://www.rotowire.com/daily/tables/mlb/schedule.php?&siteID=1&slateID={slateID}'\n",
    "    jsonData = requests.get(url).json()\n",
    "    df = pd.DataFrame(jsonData)\n",
    "    \n",
    "    df = df[['date', 'visit_team', 'home_team']]\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = matchup_data(8727)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "304c4988-7c38-431b-b746-35b94fcd3f2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['id', 'rotoPlayerID', 'player', 'ownership', 'proj_points', 'team',\\n       'game_location'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [160]\u001b[0m, in \u001b[0;36m<cell line: 33>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mslateID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m slateID\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m---> 33\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_rotowire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8727\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m df\n",
      "Input \u001b[1;32mIn [160]\u001b[0m, in \u001b[0;36mscrape_rotowire\u001b[1;34m(slateID)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscrape_rotowire\u001b[39m(slateID):\n\u001b[1;32m----> 2\u001b[0m     player_df \u001b[38;5;241m=\u001b[39m \u001b[43mplayer_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslateID\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     matchup_df \u001b[38;5;241m=\u001b[39m matchup_data(slateID)\n\u001b[0;32m      5\u001b[0m     df \u001b[38;5;241m=\u001b[39m player_df\u001b[38;5;241m.\u001b[39mmerge(matchup_df, left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteam\u001b[39m\u001b[38;5;124m'\u001b[39m, right_on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvisit_team\u001b[39m\u001b[38;5;124m'\u001b[39m], how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, suffixes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maway\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "Input \u001b[1;32mIn [95]\u001b[0m, in \u001b[0;36mplayer_data\u001b[1;34m(slateID)\u001b[0m\n\u001b[0;32m     10\u001b[0m jsonData \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url, params\u001b[38;5;241m=\u001b[39mpayload)\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m     11\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(jsonData)\n\u001b[1;32m---> 13\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrotoPlayerID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mplayer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mownership\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mproj_points\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mteam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgame_location\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m(df)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3510\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3511\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3513\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5784\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5786\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5842\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5841\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 5842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5844\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   5845\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['id', 'rotoPlayerID', 'player', 'ownership', 'proj_points', 'team',\\n       'game_location'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "def scrape_rotowire(slateID):\n",
    "    player_df = player_data(slateID)\n",
    "    matchup_df = matchup_data(slateID)\n",
    "    \n",
    "    df = player_df.merge(matchup_df, left_on='team', right_on=['visit_team'], how='left', suffixes=(\"\", \"away\"))\n",
    "    df = df.merge(matchup_df, left_on='team', right_on=['home_team'], how='left', suffixes=(\"\", \"home\"))\n",
    "    \n",
    "    df['date'].fillna(df['datehome'],inplace=True)\n",
    "    df['visit_team'].fillna(df['visit_teamhome'],inplace=True)\n",
    "    df['home_team'].fillna(df['home_teamhome'],inplace=True)\n",
    "    \n",
    "    #Merge with team map\n",
    "    df = df.merge(team_map, left_on='visit_team', right_on='ROTOWIRETEAM', how='left',suffixes=(\"\", \"away\"))\n",
    "    df = df.merge(team_map, left_on='home_team', right_on='ROTOWIRETEAM', how='left',suffixes=(\"\", \"home\"))\n",
    "    \n",
    "    df['Game Info'] = df['ROTOWIRETEAM'] + \"@\" + df['ROTOWIRETEAMhome']\n",
    "                          \n",
    "    df['day'] = df['date'].str.slice(0,3)\n",
    "    df['num_matchups'] = len(matchup_df)\n",
    "        \n",
    "    df = df[['id', 'player', 'Game Info', 'date', 'day', 'proj_points', 'ownership', 'num_matchups']]\n",
    "    \n",
    "    df['proj_points'] = pd.to_numeric(df['proj_points'])\n",
    "    df['ownership'] = pd.to_numeric(df['ownership'])\n",
    "    \n",
    "    df['has_ownership'] = ((df['ownership'].mean()) > 0)\n",
    "    df['has_ownership'] = df['has_ownership'].astype('int')\n",
    "    \n",
    "    df['slateID'] = slateID\n",
    "        \n",
    "    return df\n",
    "\n",
    "df = scrape_rotowire(8727)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff24a3c-7dc8-4400-84fc-2eefb0609e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6721 is 8/24 (use pitcher, day)\n",
    "# Not all will have ownership - maybe this is useful - might just project main slate (wrong)\n",
    "# Run a bunch, put all together\n",
    "# Read in player sims, add var for num_matchups, merge on player, num_matchups (once we know date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3064a7c5-0907-4157-a761-90770d681729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8500\n",
      "8499\n",
      "8498\n",
      "8497\n",
      "8496\n",
      "8495\n",
      "8494\n",
      "8493\n",
      "8492\n",
      "8491\n",
      "8490\n",
      "8489\n",
      "8488\n",
      "8487\n",
      "8486\n",
      "8485\n",
      "8484\n",
      "8483\n",
      "8482\n",
      "8481\n",
      "8480\n",
      "8479\n",
      "8478\n",
      "8477\n",
      "8476\n",
      "8475\n",
      "8474\n",
      "8473\n",
      "8472\n",
      "8471\n",
      "8470\n",
      "8469\n",
      "8468\n",
      "8467\n",
      "8466\n",
      "8465\n",
      "8464\n",
      "8463\n",
      "8462\n",
      "8461\n",
      "8460\n",
      "8459\n",
      "8458\n",
      "8457\n",
      "8456\n",
      "8455\n",
      "8454\n",
      "8453\n",
      "8452\n",
      "8451\n",
      "8450\n",
      "8449\n",
      "8448\n",
      "8447\n",
      "8446\n",
      "8445\n",
      "8444\n",
      "8443\n",
      "8442\n",
      "Doesn't work\n",
      "8441\n",
      "8440\n",
      "8439\n",
      "8438\n",
      "Doesn't work\n",
      "8437\n",
      "8436\n",
      "Doesn't work\n",
      "8435\n",
      "Doesn't work\n",
      "8434\n",
      "8433\n",
      "8432\n",
      "8431\n",
      "8430\n",
      "8429\n",
      "8428\n",
      "8427\n",
      "8426\n",
      "8425\n",
      "8424\n",
      "8423\n",
      "8422\n",
      "8421\n",
      "8420\n",
      "8419\n",
      "8418\n",
      "8417\n",
      "8416\n",
      "8415\n",
      "8414\n",
      "8413\n",
      "8412\n",
      "8411\n",
      "8410\n",
      "8409\n",
      "8408\n",
      "8407\n",
      "8406\n",
      "8405\n",
      "8404\n",
      "8403\n",
      "8402\n",
      "8401\n",
      "8400\n",
      "8399\n",
      "8398\n",
      "8397\n",
      "8396\n",
      "8395\n",
      "8394\n",
      "8393\n",
      "8392\n",
      "8391\n",
      "8390\n",
      "8389\n",
      "8388\n",
      "8387\n",
      "8386\n",
      "8385\n",
      "8384\n",
      "8383\n",
      "Doesn't work\n",
      "8382\n",
      "8381\n",
      "8380\n",
      "8379\n",
      "8378\n",
      "8377\n",
      "8376\n",
      "8375\n",
      "8374\n",
      "8373\n",
      "8372\n",
      "8371\n",
      "8370\n",
      "8369\n",
      "8368\n",
      "8367\n",
      "8366\n",
      "8365\n",
      "8364\n",
      "8363\n",
      "8362\n",
      "8361\n",
      "8360\n",
      "8359\n",
      "8358\n",
      "8357\n",
      "8356\n",
      "8355\n",
      "8354\n",
      "8353\n",
      "8352\n",
      "8351\n",
      "8350\n",
      "8349\n",
      "8348\n",
      "8347\n",
      "8346\n",
      "8345\n",
      "8344\n",
      "8343\n",
      "8342\n",
      "8341\n",
      "8340\n",
      "8339\n",
      "8338\n",
      "8337\n",
      "8336\n",
      "8335\n",
      "8334\n",
      "8333\n",
      "8332\n",
      "8331\n",
      "8330\n",
      "8329\n",
      "8328\n",
      "8327\n",
      "8326\n",
      "8325\n",
      "8324\n",
      "8323\n",
      "8322\n",
      "8321\n",
      "8320\n",
      "8319\n",
      "8318\n",
      "8317\n",
      "8316\n",
      "8315\n",
      "8314\n",
      "8313\n",
      "8312\n",
      "8311\n",
      "8310\n",
      "8309\n",
      "8308\n",
      "8307\n",
      "8306\n",
      "8305\n",
      "8304\n",
      "8303\n",
      "8302\n",
      "8301\n"
     ]
    }
   ],
   "source": [
    "for i in range(8500, 8300, -1):\n",
    "    print(i)\n",
    "    filename = \"slateID\" + str(i) + \".csv\"\n",
    "    \n",
    "    try:\n",
    "        df = scrape_rotowire(i)\n",
    "        df.to_csv(os.path.join(baseball_path, \"RotoWire\", filename))\n",
    "        time.sleep(5)\n",
    "    except:\n",
    "        print(\"Doesn't work\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7e5c6614-795f-4067-af64-c347afd49fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THU'"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create weekday dictionary to match with RotoWire's unhelpful date variable, which I converted to an also unhelpful day\n",
    "weekday = {0:\"SUN\", 1:\"MON\", 2:\"TUE\", 3:\"WED\", 4:\"THU\", 5:\"FRI\", 6:\"SAT\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "37a31ae4-affc-4615-bf10-79468d43789b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 'SUN')"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in player sims, try to figure out day\n",
    "date = \"20220410\"\n",
    "filename = \"Player_Sims_\" + date + \".csv\"\n",
    "sims = pd.read_csv(os.path.join(baseball_path, \"Player Sims\", filename))\n",
    "\n",
    "team_list = (list(sims['Game Info'].unique()))\n",
    "team_list.sort()\n",
    "\n",
    "num_matchups = len(team_list)\n",
    "dow = weekday[datetime.datetime.strptime(date, '%Y%M%d').weekday()]\n",
    "num_matchups, dow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bd1654-9cbf-4cb5-97c7-7d42ea0c03e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ownership(date):\n",
    "    # Read in player sims, try to figure out day\n",
    "    filename = \"Player_Sims_\" + date + \".csv\"\n",
    "    sims = pd.read_csv(os.path.join(baseball_path, \"Player Sims\", filename))\n",
    "\n",
    "    # Game list could be used to merge, but idk\n",
    "    team_list = (list(sims['Game Info'].unique()))\n",
    "    team_list.sort()\n",
    "\n",
    "    # Number of matchups\n",
    "    num_matchups = len(team_list)\n",
    "    # Day of week\n",
    "    day = weekday[datetime.datetime.strptime(date, '%Y%M%d').weekday()]\n",
    "    \n",
    "    sims['num_matchups'] = num_matchups\n",
    "    sims['day'] = day\n",
    "    \n",
    "    \n",
    "    # Merge with giant list of ownership dataframes here\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "c5afdc3a-c3be-4b71-923b-05d755930909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     slate  day  has_ownership  num_matchups  \\\n",
      "0     8301  FRI              1             2   \n",
      "1     8302  FRI              1             1   \n",
      "2     8303  FRI              1             2   \n",
      "3     8304  FRI              1             1   \n",
      "4     8305  FRI              1             4   \n",
      "..     ...  ...            ...           ...   \n",
      "381   8725  TUE              0             3   \n",
      "382   8726  TUE              0            18   \n",
      "383   8728  TUE              0            20   \n",
      "384   8729  WED              0             1   \n",
      "385   8730  WED              0             4   \n",
      "\n",
      "                                             team_list  \n",
      "0                                   [PHI@STL, SEA@TOR]  \n",
      "1                                            [SEA@TOR]  \n",
      "2                                    [SD@NYM, SEA@TOR]  \n",
      "3                                             [SD@NYM]  \n",
      "4                   [PHI@STL, SD@NYM, SEA@TOR, TB@CLE]  \n",
      "..                                                 ...  \n",
      "381                        [BOS@BAL, MIA@HOU, PHI@PIT]  \n",
      "382  [ARI@CWS, BAL@PHI, CHC@KC, CLE@TEX, COL@SD, DE...  \n",
      "383  [ATL@DET, BAL@TOR, BOS@BAL, CHC@KC, COL@SD, CW...  \n",
      "384                                          [BAL@TOR]  \n",
      "385               [ATL@DET, BAL@TOR, HOU@NYM, NYY@WAS]  \n",
      "\n",
      "[386 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "def slate_guide():\n",
    "    slate_stats_all = []\n",
    "    for file in os.listdir(os.path.join(baseball_path, \"RotoWire\")):\n",
    "        df = pd.read_csv(os.path.join(baseball_path, \"RotoWire\", file))\n",
    "        \n",
    "        slateID = df['slateID'][0]\n",
    "        day = df['day'][0]\n",
    "        has_ownership = df['has_ownership'][0]\n",
    "        \n",
    "        \n",
    "        team_list = (list(df['Game Info'].unique()))\n",
    "        team_list.sort()\n",
    "        \n",
    "        num_matchups = len(team_list)\n",
    "        \n",
    "        slate_stats = [slateID, day, has_ownership, num_matchups, team_list]\n",
    "        slate_stats_all.append(slate_stats)\n",
    "    slate_df = pd.DataFrame(slate_stats_all, columns=['slate', 'day', 'has_ownership', 'num_matchups', 'team_list'])\n",
    "    print(slate_df)\n",
    "slate_guide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "91d8a20d-d0f8-4358-9e1f-31498df93f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slateID8301.csv\n",
      "slateID8302.csv\n",
      "slateID8303.csv\n",
      "slateID8304.csv\n",
      "slateID8305.csv\n",
      "slateID8306.csv\n",
      "slateID8307.csv\n",
      "slateID8308.csv\n",
      "slateID8309.csv\n",
      "slateID8310.csv\n",
      "slateID8311.csv\n",
      "slateID8312.csv\n",
      "slateID8313.csv\n",
      "slateID8314.csv\n",
      "slateID8315.csv\n",
      "slateID8316.csv\n",
      "slateID8317.csv\n",
      "slateID8318.csv\n",
      "slateID8319.csv\n",
      "slateID8320.csv\n",
      "slateID8321.csv\n",
      "slateID8322.csv\n",
      "slateID8323.csv\n",
      "slateID8324.csv\n",
      "slateID8325.csv\n",
      "slateID8326.csv\n",
      "slateID8327.csv\n",
      "slateID8328.csv\n",
      "slateID8329.csv\n",
      "slateID8330.csv\n",
      "slateID8331.csv\n",
      "slateID8332.csv\n",
      "slateID8333.csv\n",
      "slateID8334.csv\n",
      "slateID8335.csv\n",
      "slateID8336.csv\n",
      "slateID8337.csv\n",
      "slateID8338.csv\n",
      "slateID8339.csv\n",
      "slateID8340.csv\n",
      "slateID8341.csv\n",
      "slateID8342.csv\n",
      "slateID8343.csv\n",
      "slateID8344.csv\n",
      "slateID8345.csv\n",
      "slateID8346.csv\n",
      "slateID8347.csv\n",
      "slateID8348.csv\n",
      "slateID8349.csv\n",
      "slateID8350.csv\n",
      "slateID8351.csv\n",
      "slateID8352.csv\n",
      "slateID8353.csv\n",
      "slateID8354.csv\n",
      "slateID8355.csv\n",
      "slateID8356.csv\n",
      "slateID8357.csv\n",
      "slateID8358.csv\n",
      "slateID8359.csv\n",
      "slateID8360.csv\n",
      "slateID8361.csv\n",
      "slateID8362.csv\n",
      "slateID8363.csv\n",
      "slateID8364.csv\n",
      "slateID8365.csv\n",
      "slateID8366.csv\n",
      "slateID8367.csv\n",
      "slateID8368.csv\n",
      "slateID8369.csv\n",
      "slateID8370.csv\n",
      "slateID8371.csv\n",
      "slateID8372.csv\n",
      "slateID8373.csv\n",
      "slateID8374.csv\n",
      "slateID8375.csv\n",
      "slateID8376.csv\n",
      "slateID8377.csv\n",
      "slateID8378.csv\n",
      "slateID8379.csv\n",
      "slateID8380.csv\n",
      "slateID8381.csv\n",
      "slateID8382.csv\n",
      "slateID8384.csv\n",
      "slateID8385.csv\n",
      "slateID8386.csv\n",
      "slateID8387.csv\n",
      "slateID8388.csv\n",
      "slateID8389.csv\n",
      "slateID8390.csv\n",
      "slateID8391.csv\n",
      "slateID8392.csv\n",
      "slateID8393.csv\n",
      "slateID8394.csv\n",
      "slateID8395.csv\n",
      "slateID8396.csv\n",
      "slateID8397.csv\n",
      "slateID8398.csv\n",
      "slateID8399.csv\n",
      "slateID8400.csv\n",
      "slateID8401.csv\n",
      "slateID8402.csv\n",
      "slateID8403.csv\n",
      "slateID8404.csv\n",
      "slateID8405.csv\n",
      "slateID8406.csv\n",
      "slateID8407.csv\n",
      "slateID8408.csv\n",
      "slateID8409.csv\n",
      "slateID8410.csv\n",
      "slateID8411.csv\n",
      "slateID8412.csv\n",
      "slateID8413.csv\n",
      "slateID8414.csv\n",
      "slateID8415.csv\n",
      "slateID8416.csv\n",
      "slateID8417.csv\n",
      "slateID8418.csv\n",
      "slateID8419.csv\n",
      "slateID8420.csv\n",
      "slateID8421.csv\n",
      "slateID8422.csv\n",
      "slateID8423.csv\n",
      "slateID8424.csv\n",
      "slateID8425.csv\n",
      "slateID8426.csv\n",
      "slateID8427.csv\n",
      "slateID8428.csv\n",
      "slateID8429.csv\n",
      "slateID8430.csv\n",
      "slateID8431.csv\n",
      "slateID8432.csv\n",
      "slateID8433.csv\n",
      "slateID8434.csv\n",
      "slateID8437.csv\n",
      "slateID8439.csv\n",
      "slateID8440.csv\n",
      "slateID8441.csv\n",
      "slateID8443.csv\n",
      "slateID8444.csv\n",
      "slateID8445.csv\n",
      "slateID8446.csv\n",
      "slateID8447.csv\n",
      "slateID8448.csv\n",
      "slateID8449.csv\n",
      "slateID8450.csv\n",
      "slateID8451.csv\n",
      "slateID8452.csv\n",
      "slateID8453.csv\n",
      "slateID8454.csv\n",
      "slateID8455.csv\n",
      "slateID8456.csv\n",
      "slateID8457.csv\n",
      "slateID8458.csv\n",
      "slateID8459.csv\n",
      "slateID8460.csv\n",
      "slateID8461.csv\n",
      "slateID8462.csv\n",
      "slateID8463.csv\n",
      "slateID8464.csv\n",
      "slateID8465.csv\n",
      "slateID8466.csv\n",
      "slateID8467.csv\n",
      "slateID8468.csv\n",
      "slateID8469.csv\n",
      "slateID8470.csv\n",
      "slateID8471.csv\n",
      "slateID8472.csv\n",
      "slateID8473.csv\n",
      "slateID8474.csv\n",
      "slateID8475.csv\n",
      "slateID8476.csv\n",
      "slateID8477.csv\n",
      "slateID8478.csv\n",
      "slateID8479.csv\n",
      "slateID8480.csv\n",
      "slateID8481.csv\n",
      "slateID8482.csv\n",
      "slateID8483.csv\n",
      "slateID8484.csv\n",
      "slateID8485.csv\n",
      "slateID8486.csv\n",
      "slateID8487.csv\n",
      "slateID8488.csv\n",
      "slateID8489.csv\n",
      "slateID8490.csv\n",
      "slateID8491.csv\n",
      "slateID8492.csv\n",
      "slateID8493.csv\n",
      "slateID8494.csv\n",
      "slateID8495.csv\n",
      "slateID8496.csv\n",
      "slateID8497.csv\n",
      "slateID8498.csv\n",
      "slateID8499.csv\n",
      "slateID8500.csv\n",
      "slateID8501.csv\n",
      "slateID8502.csv\n",
      "slateID8503.csv\n",
      "slateID8504.csv\n",
      "slateID8505.csv\n",
      "slateID8506.csv\n",
      "slateID8507.csv\n",
      "slateID8508.csv\n",
      "slateID8509.csv\n",
      "slateID8510.csv\n",
      "slateID8511.csv\n",
      "slateID8512.csv\n",
      "slateID8513.csv\n",
      "slateID8514.csv\n",
      "slateID8515.csv\n",
      "slateID8516.csv\n",
      "slateID8517.csv\n",
      "slateID8518.csv\n",
      "slateID8519.csv\n",
      "slateID8520.csv\n",
      "slateID8521.csv\n",
      "slateID8522.csv\n",
      "slateID8523.csv\n",
      "slateID8524.csv\n",
      "slateID8525.csv\n",
      "slateID8526.csv\n",
      "slateID8527.csv\n",
      "slateID8528.csv\n",
      "slateID8533.csv\n",
      "slateID8534.csv\n",
      "slateID8535.csv\n",
      "slateID8536.csv\n",
      "slateID8537.csv\n",
      "slateID8538.csv\n",
      "slateID8539.csv\n",
      "slateID8540.csv\n",
      "slateID8541.csv\n",
      "slateID8542.csv\n",
      "slateID8543.csv\n",
      "slateID8544.csv\n",
      "slateID8545.csv\n",
      "slateID8546.csv\n",
      "slateID8547.csv\n",
      "slateID8548.csv\n",
      "slateID8549.csv\n",
      "slateID8550.csv\n",
      "slateID8551.csv\n",
      "slateID8552.csv\n",
      "slateID8553.csv\n",
      "slateID8554.csv\n",
      "slateID8555.csv\n",
      "slateID8556.csv\n",
      "slateID8557.csv\n",
      "slateID8560.csv\n",
      "slateID8561.csv\n",
      "slateID8562.csv\n",
      "slateID8563.csv\n",
      "slateID8564.csv\n",
      "slateID8566.csv\n",
      "slateID8567.csv\n",
      "slateID8568.csv\n",
      "slateID8569.csv\n",
      "slateID8570.csv\n",
      "slateID8571.csv\n",
      "slateID8572.csv\n",
      "slateID8573.csv\n",
      "slateID8574.csv\n",
      "slateID8575.csv\n",
      "slateID8576.csv\n",
      "slateID8577.csv\n",
      "slateID8578.csv\n",
      "slateID8579.csv\n",
      "slateID8580.csv\n",
      "slateID8581.csv\n",
      "slateID8582.csv\n",
      "slateID8587.csv\n",
      "slateID8588.csv\n",
      "slateID8589.csv\n",
      "slateID8590.csv\n",
      "slateID8591.csv\n",
      "slateID8592.csv\n",
      "slateID8593.csv\n",
      "slateID8594.csv\n",
      "slateID8595.csv\n",
      "slateID8596.csv\n",
      "slateID8597.csv\n",
      "slateID8598.csv\n",
      "slateID8599.csv\n",
      "slateID8600.csv\n",
      "slateID8601.csv\n",
      "slateID8602.csv\n",
      "slateID8603.csv\n",
      "slateID8604.csv\n",
      "slateID8605.csv\n",
      "slateID8606.csv\n",
      "slateID8607.csv\n",
      "slateID8608.csv\n",
      "slateID8609.csv\n",
      "slateID8610.csv\n",
      "slateID8611.csv\n",
      "slateID8612.csv\n",
      "slateID8613.csv\n",
      "slateID8614.csv\n",
      "slateID8615.csv\n",
      "slateID8616.csv\n",
      "slateID8617.csv\n",
      "slateID8618.csv\n",
      "slateID8619.csv\n",
      "slateID8620.csv\n",
      "slateID8621.csv\n",
      "slateID8622.csv\n",
      "slateID8623.csv\n",
      "slateID8624.csv\n",
      "slateID8625.csv\n",
      "slateID8626.csv\n",
      "slateID8627.csv\n",
      "slateID8628.csv\n",
      "slateID8629.csv\n",
      "slateID8631.csv\n",
      "slateID8632.csv\n",
      "slateID8633.csv\n",
      "slateID8634.csv\n",
      "slateID8635.csv\n",
      "slateID8636.csv\n",
      "slateID8637.csv\n",
      "slateID8638.csv\n",
      "slateID8641.csv\n",
      "slateID8642.csv\n",
      "slateID8643.csv\n",
      "slateID8644.csv\n",
      "slateID8646.csv\n",
      "slateID8648.csv\n",
      "slateID8649.csv\n",
      "slateID8650.csv\n",
      "slateID8651.csv\n",
      "slateID8653.csv\n",
      "slateID8654.csv\n",
      "slateID8656.csv\n",
      "slateID8657.csv\n",
      "slateID8658.csv\n",
      "slateID8659.csv\n",
      "slateID8660.csv\n",
      "slateID8662.csv\n",
      "slateID8663.csv\n",
      "slateID8664.csv\n",
      "slateID8665.csv\n",
      "slateID8669.csv\n",
      "slateID8672.csv\n",
      "slateID8676.csv\n",
      "slateID8677.csv\n",
      "slateID8678.csv\n",
      "slateID8681.csv\n",
      "slateID8682.csv\n",
      "slateID8683.csv\n",
      "slateID8684.csv\n",
      "slateID8685.csv\n",
      "slateID8686.csv\n",
      "slateID8689.csv\n",
      "slateID8691.csv\n",
      "slateID8692.csv\n",
      "slateID8693.csv\n",
      "slateID8695.csv\n",
      "slateID8696.csv\n",
      "slateID8697.csv\n",
      "slateID8699.csv\n",
      "slateID8700.csv\n",
      "slateID8701.csv\n",
      "slateID8702.csv\n",
      "slateID8703.csv\n",
      "slateID8704.csv\n",
      "slateID8706.csv\n",
      "slateID8707.csv\n",
      "slateID8708.csv\n",
      "slateID8710.csv\n",
      "slateID8711.csv\n",
      "slateID8712.csv\n",
      "slateID8713.csv\n",
      "slateID8714.csv\n",
      "slateID8715.csv\n",
      "slateID8716.csv\n",
      "slateID8717.csv\n",
      "slateID8718.csv\n",
      "slateID8719.csv\n",
      "slateID8720.csv\n",
      "slateID8723.csv\n",
      "slateID8724.csv\n",
      "slateID8725.csv\n",
      "slateID8726.csv\n",
      "slateID8728.csv\n",
      "slateID8729.csv\n",
      "slateID8730.csv\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(os.path.join(baseball_path, \"RotoWire\")):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facb1392-0341-45a2-bdf0-09e803751b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
