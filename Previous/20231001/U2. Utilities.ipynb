{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcdd389f-17f6-489f-b015-f012060f521a",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aed130f2-3405-42d3-b6c8-2b003236a14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import os\n",
    "\n",
    "# import warnings\n",
    "# warnings.simplefilter(action=\"ignore\")\n",
    "\n",
    "# baseball_path = r\"C:\\Users\\james\\Documents\\MLB\\Data2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e502d9b4-e3f2-485d-9ed5-1ad7b3cba55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean names\n",
    "def remove_accents(old):\n",
    "    new = re.sub(r'[àáâãäå]', 'a', old)\n",
    "    new = re.sub(r'[èéêë]', 'e', new)\n",
    "    new = re.sub(r'[ìíîï]', 'i', new)\n",
    "    new = re.sub(r'[òóôõö]', 'o', new)\n",
    "    new = re.sub(r'[ùúûü]', 'u', new)\n",
    "    new = re.sub(r'[ñ]', 'n', new)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4274cdff-0d58-463e-8b23-51d7b96c2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean names for consistency\n",
    "# This is really only used now to clean DK Salaries\n",
    "# You should add players to this if they're not merging on salary information\n",
    "def name_clean(df):\n",
    "    df['Name'] = np.where(df['Name'] == \"Kike Hernandez\", \"Enrique Hernandez\", df['Name'])\n",
    "    df['Name'] = np.where(df['Name'] == \"Michael A. Taylor\", \"Michael Taylor\", df['Name'])\n",
    "    # Note: to get all the de la Cruz's of the world right as last names, we need to manually add the Ji Mans to be one word so they're the first name\n",
    "    df['Name'] = np.where(df['Name'] == \"Ji Man Choi\", \"Ji-Man Choi\", df['Name'])\n",
    "    df['Name'] = np.where(df['Name'] == \"Ji Hwan Bae\", \"Ji-Hwan Bae\", df['Name']) # he technically has no dash, but we need it so it treats last name properly\n",
    "    df['Name'] = np.where(df['Name'] == \"Hyun Jin Ryu\", \"Hyun-Jin Ryu\", df['Name'])\n",
    "    \n",
    "    \n",
    "    df['Name_Adjusted'] = df.apply(lambda x: remove_accents(x['Name']), axis=1)  # remove accents\n",
    "    df['Name_Adjusted'] = df['Name_Adjusted'].str.replace(r'[^a-zA-Z0-9 ]', '')\n",
    "    df['Name_Adjusted'] = df['Name_Adjusted'].str.replace(\"Jr\", \"\")\n",
    "    df['Name_Adjusted'] = df['Name_Adjusted'].str.replace(\"Sr\", \"\")\n",
    "    df['Name_Adjusted'] = df['Name_Adjusted'].str.replace(\"II\", \"\")\n",
    "    df['Name_Adjusted'] = df['Name_Adjusted'].str.replace(\"III\", \"\")\n",
    "    \n",
    "    # Separate first and last names\n",
    "    df[['First','Last']] = df['Name_Adjusted'].str.split(\" \", n=1, expand=True) \n",
    "    df['First'] = df['First'].str.lower()\n",
    "    df['First'] = df['First'].str.replace(r'[ ]', '')\n",
    "    df['Last'] = df['Last'].str.lower()\n",
    "    df['Last'] = df['Last'].str.replace(r'[ ]', '')\n",
    "    \n",
    "    # Take first 2 letters of first name and first 5 of last as a sort of merge code\n",
    "    df['First2'] = df['First'].str.slice(0,2)\n",
    "    df['Last5'] = df['Last'].str.slice(0,5)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c40716f9-8fc0-4c4a-94de-1c469741eb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean FanGraphs ID\n",
    "# Once had individual manual replacements, now could probably be done without\n",
    "def fix_fangraphs(chadwick):  \n",
    "    \n",
    "    chadwick['key_fangraphs'] = chadwick['key_fangraphs'].astype('str')\n",
    "    chadwick['key_fangraphs'] = chadwick['key_fangraphs'].str.replace(r'\\.\\d', \"\", regex=True)\n",
    "\n",
    "    return chadwick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfd4472e-77fb-424c-8f0f-4cc196048035",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>key_uuid</th>\n",
       "      <th>key_person</th>\n",
       "      <th>key_retro</th>\n",
       "      <th>key_mlbam</th>\n",
       "      <th>key_bbref</th>\n",
       "      <th>key_fangraphs</th>\n",
       "      <th>name_last</th>\n",
       "      <th>name_first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>000007d9-a2b6-47fd-bc61-e582f190e74a</td>\n",
       "      <td>000007d9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>472542.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>Adolfito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000018b8-a25e-45b8-b060-5c4877cb84cc</td>\n",
       "      <td>000018b8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>572962.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>Kaupang</td>\n",
       "      <td>Stephen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>0001534a-3266-4c2f-9fdd-76d2a5094ad2</td>\n",
       "      <td>0001534a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>664660.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>Ramirez</td>\n",
       "      <td>Dagin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>000207da-aeaa-4ac4-ab4d-834407e1df1d</td>\n",
       "      <td>000207da</td>\n",
       "      <td>NaN</td>\n",
       "      <td>670448.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>Dexter</td>\n",
       "      <td>Sam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>00022ebb-4e9a-4106-9ffa-6dacdf73e34e</td>\n",
       "      <td>00022ebb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>808910.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>Webb</td>\n",
       "      <td>Bryan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                              key_uuid key_person key_retro  \\\n",
       "0      0  000007d9-a2b6-47fd-bc61-e582f190e74a   000007d9       NaN   \n",
       "1      1  000018b8-a25e-45b8-b060-5c4877cb84cc   000018b8       NaN   \n",
       "2     12  0001534a-3266-4c2f-9fdd-76d2a5094ad2   0001534a       NaN   \n",
       "3     19  000207da-aeaa-4ac4-ab4d-834407e1df1d   000207da       NaN   \n",
       "4     22  00022ebb-4e9a-4106-9ffa-6dacdf73e34e   00022ebb       NaN   \n",
       "\n",
       "   key_mlbam key_bbref key_fangraphs name_last name_first  \n",
       "0   472542.0       NaN           nan    Garcia   Adolfito  \n",
       "1   572962.0       NaN           nan   Kaupang    Stephen  \n",
       "2   664660.0       NaN           nan   Ramirez      Dagin  \n",
       "3   670448.0       NaN           nan    Dexter        Sam  \n",
       "4   808910.0       NaN           nan      Webb      Bryan  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reads in select variables from the Chadwick Register\n",
    "# You should add keys to this if they're not merging with FanGraphs data\n",
    "def read_chadwick(keep_list):\n",
    "    # Separated across these suffixes\n",
    "    chadwick_list = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\"]\n",
    "    # Create a list with a dataframe for each suffix\n",
    "    dataframe_list = []\n",
    "    # Loop over suffix\n",
    "    for char in chadwick_list:\n",
    "        # Read in that csv, keeping relevant variables\n",
    "        df = pd.read_csv(\"https://raw.githubusercontent.com/chadwickbureau/register/master/data/people-{}.csv\".format(char), low_memory=False, encoding='utf-8')[keep_list]\n",
    "        # Drop if missing key_mlbam\n",
    "        df.dropna(subset=['key_mlbam'], axis=0, inplace=True)\n",
    "        # Add to dataframe list\n",
    "        dataframe_list.append(df)\n",
    "    # Append all dataframes together\n",
    "    chadwick = pd.concat(dataframe_list, axis=0).reset_index()\n",
    "    \n",
    "    # Edit missing fangraphs IDs (if all else fails)\n",
    "    chadwick = fix_fangraphs(chadwick)\n",
    "    \n",
    "    \n",
    "    chadwick['name_last'].fillna(\"Missing\", inplace=True)\n",
    "    chadwick['name_first'].fillna(\"Mr\", inplace=True)\n",
    "    \n",
    "    chadwick['name_first'] = chadwick['name_first'].str.replace(\" \", \"\")\n",
    "    chadwick['name_first'] = chadwick['name_first'].str.replace(\".\", \"\")\n",
    "    chadwick['name_last'] = chadwick['name_last'].str.replace(\" \", \"\")\n",
    "    chadwick['name_last'] = chadwick['name_last'].str.replace(\".\", \"\")\n",
    "    \n",
    "    # Remove accents\n",
    "    chadwick['name_last'] = chadwick.apply(lambda x: remove_accents(x['name_last']), axis=1)  # remove accents\n",
    "    chadwick['name_first'] = chadwick.apply(lambda x: remove_accents(x['name_first']), axis=1)  # remove accents\n",
    "\n",
    "    # Remove non-alpha numeric characters\n",
    "    chadwick['name_first'] = chadwick['name_first'].apply(lambda x: re.sub(r\"[^a-zA-Z0-9]+\", \"\", x))\n",
    "    chadwick['name_last'] = chadwick['name_last'].apply(lambda x: re.sub(r\"[^a-zA-Z0-9]+\", \"\", x))\n",
    "    \n",
    "    # Return big dataframe\n",
    "    return chadwick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ea85038-1fe8-460b-be74-8085ec33b70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searches for player IDs\n",
    "def new_ids(player, team, website):\n",
    "    # Google player plus fangraphs\n",
    "    search = player + ' ' + team + ' player page ' + website\n",
    "    url = 'https://www.google.com/search'\n",
    "\n",
    "    headers = {\n",
    "        'Accept' : '*/*',\n",
    "        'Accept-Language': 'en-US,en;q=0.5',\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.82',\n",
    "    }\n",
    "    parameters = {'q': search}\n",
    "\n",
    "    \n",
    "    # Get info from URL\n",
    "    content = requests.get(url, headers=headers, params=parameters).text\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    text = soup.find(id = 'search')\n",
    "    first_link = text.find('a')\n",
    "    \n",
    "    # FanGraph's ID is found a little differently\n",
    "    if website == \"fangraphs\":\n",
    "        website_id = first_link['href'].split(\"/\")[5]\n",
    "\n",
    "    # This should work for RotoWire and MLB.com\n",
    "    else:\n",
    "        website_id = first_link['href'].split(\"-\")[-1]  \n",
    "    \n",
    "    # If it's a minor leaguer code, add quotes\n",
    "    if website_id.startswith(\"sa\"):\n",
    "        website_id = \"'\" + website_id + \"'\"\n",
    "        \n",
    "    \n",
    "    return website_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0cefef4-564a-472e-97ee-d6145ec7baf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads in contest history\n",
    "def contest_history(entry_min=8, date_min=\"20220301\", date_max=\"20991231\"):\n",
    "    history = pd.read_csv(os.path.join(baseball_path, \"Utilities\", \"draftkings-contest-entry-history.csv\"))\n",
    "    history = history[history['Sport'] == \"MLB\"]\n",
    "    history = history[history['Contest_Entries'] >= entry_min]\n",
    "    history.drop_duplicates('Contest_Key', inplace=True)\n",
    "    \n",
    "    history['date'] = pd.to_datetime(history['Contest_Date_EST']).dt.strftime('%Y%m%d')\n",
    "    history = history[history['date'] > date_min]\n",
    "    history = history[history['date'] < date_max]\n",
    "\n",
    "    history = history.reset_index(drop=True)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c9c159-af02-49ea-98d1-083be9c556c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pause_code(start_time='2023-08-09T07:24:30'):\n",
    "    pause_until = datetime.datetime.fromisoformat(start_time) # or whatever timestamp you gonna need\n",
    "    print((pause_until - datetime.datetime.now()).total_seconds())\n",
    "    time.sleep((pause_until - datetime.datetime.now()).total_seconds())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
