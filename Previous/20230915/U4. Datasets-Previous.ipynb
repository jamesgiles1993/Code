{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e5d0f6-3979-4a21-a770-fbc7209992ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in boxscore for weather\n",
    "def create_box(gamePk):\n",
    "    # Read in boxscore as json\n",
    "    box = pd.json_normalize(statsapi.boxscore_data(gamePk, timecode=None), record_path='gameBoxInfo')\n",
    "    \n",
    "    # Define default values\n",
    "    default_weather = \"75 degrees, Clear.\"\n",
    "    default_wind = \"0 mph, L To R.\"\n",
    "    default_venue = \"Missing Park.\"\n",
    "    default_date = \"November 30, 1993\"\n",
    "    \n",
    "    # Extract weather, wind, venue, and date\n",
    "    weather = box.loc[box['label'] == \"Weather\", \"value\"].item() if 'Weather' in box['label'].values else default_weather\n",
    "    wind = box.loc[box['label'] == \"Wind\", \"value\"].item() if 'Wind' in box['label'].values else default_wind\n",
    "    venue = box.loc[box['label'] == \"Venue\", \"value\"].item() if 'Venue' in box['label'].values else default_venue\n",
    "    \n",
    "    try:\n",
    "        date = box.iloc[-1, box.columns.get_loc('label')]\n",
    "    except:\n",
    "        date = default_date\n",
    "\n",
    "    if \"Weather\" not in list(box['label']):\n",
    "        missing_weather = True\n",
    "    else:\n",
    "        missing_weather = False\n",
    "        \n",
    "    \n",
    "    \n",
    "    return weather, wind, venue, date, missing_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315d5b07-b494-4bfc-a154-90d60018de12",
   "metadata": {},
   "source": [
    "##### Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe770413-e196-4f24-81e4-af1d677f765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive to centerfield, negative from centerfield\n",
    "def y_vect(df):\n",
    "    wind_speed = df['windSpeed']\n",
    "    angled = df['windSpeed'] / 2 * math.sqrt(2)\n",
    "    \n",
    "    if df['windDirection'] == \"Out To CF\": \n",
    "        y_vect = wind_speed\n",
    "    elif df['windDirection'] == \"Out To RF\": \n",
    "        y_vect = angled\n",
    "    elif df['windDirection'] == \"L To R\": \n",
    "        y_vect = 0\n",
    "    elif df['windDirection'] == \"In From LF\": \n",
    "        y_vect = angled * -1\n",
    "    elif df['windDirection'] == \"In From CF\": \n",
    "        y_vect = wind_speed * - 1\n",
    "    elif df['windDirection'] == \"In From RF\": \n",
    "        y_vect = angled * -1\n",
    "    elif df['windDirection'] == \"R To L\": \n",
    "        y_vect = 0\n",
    "    elif df['windDirection'] == \"Out To LF\": \n",
    "        y_vect = angled\n",
    "    else:\n",
    "        y_vect = 0\n",
    "\n",
    "    \n",
    "    return y_vect\n",
    "\n",
    "# Positive from left to right, negative from right to left\n",
    "def x_vect(df):\n",
    "    wind_speed = df['windSpeed']\n",
    "    angled = df['windSpeed'] / 2 * math.sqrt(2)\n",
    "    \n",
    "    if df['windDirection'] == \"L To R\": \n",
    "        x_vect = wind_speed\n",
    "    elif df['windDirection'] == \"In From LF\": \n",
    "        x_vect = angled\n",
    "    elif df['windDirection'] == \"In From CF\": \n",
    "        x_vect = 0\n",
    "    elif df['windDirection'] == \"In From RF\": \n",
    "        x_vect = angled * -1\n",
    "    elif df['windDirection'] == \"R To L\": \n",
    "        x_vect = wind_speed * - 1\n",
    "    elif df['windDirection'] == \"Out To LF\": \n",
    "        x_vect = angled * -1\n",
    "    elif df['windDirection'] == \"Out To CF\": \n",
    "        x_vect = 0\n",
    "    elif df['windDirection'] == \"Out To RF\": \n",
    "        x_vect = angled\n",
    "    else:\n",
    "        x_vect = 0\n",
    "\n",
    "    \n",
    "    return x_vect\n",
    "\n",
    "# 2 is to centerfield, 6 is from centerfield, clockwise\n",
    "# Assumption is wind is blowing in 8 cardinal directions, so we can use simple right isosceles triangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fd07eb1-f8ea-490a-9116-288b54e6f5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_weather(df):   \n",
    "    # Separate weather into temperature and weather type\n",
    "    df[['temperature', 'weather']] = df['weather'].str.split(\", \", expand=True)\n",
    "    df['temperature'] = df['temperature'].str.replace(\" degrees\", \"\").astype('int')\n",
    "    # Separate wind into speed and direction\n",
    "    df[['windSpeed', 'windDirection']] = df['wind'].str.split(\", \", expand=True)\n",
    "    df['windSpeed'].fillna(\"0 mph\", inplace=True)\n",
    "    df['windSpeed'] = df['windSpeed'].str.replace(\" mph\", \"\")\n",
    "    df['windSpeed'] = pd.to_numeric(df['windSpeed'], errors='coerce')\n",
    "    df['windSpeed'].fillna(0, inplace=True)\n",
    "    df['windDirection'].fillna('L to R', inplace=True)\n",
    "    df['windSpeed'].unique()\n",
    "    df['windDirection'] = df['windDirection'].str.replace(\".\", \"\")\n",
    "    # Calculate vectors\n",
    "    df['x_vect'] = df.apply(x_vect, axis=1)\n",
    "    df['y_vect'] = df.apply(y_vect, axis=1)\n",
    "\n",
    "    ### TESTING:\n",
    "    # Set temperature to 70 degrees if it's a dome or the roof is close\n",
    "    df['temperature'] = df.apply(lambda row: 70 if 'Roof' in row['weather'] or 'Dome' in row['weather'] else row['temperature'], axis=1)\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00b1894-a0fe-4b7f-acf6-6a61b1cf0378",
   "metadata": {},
   "source": [
    "##### Model Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0c0bed1-43d5-4976-8bbc-3d3743518e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign play categories to full descriptions\n",
    "def create_events(df):\n",
    "    event_mapping = {\n",
    "        'Strikeout': 'so',\n",
    "        'Strikeout Double Play': 'so',\n",
    "        'Groundout': 'go',\n",
    "        'Fielders Choice': 'go',\n",
    "        'Fielders Choice Out': 'go',\n",
    "        'Double Play': 'go',\n",
    "        'Grounded Into DP': 'go',\n",
    "        'Triple Play': 'go',\n",
    "        'Field Error': 'go',\n",
    "        'Forceout': 'go',\n",
    "        'Sac Bunt': 'go',\n",
    "        'Sac Bunt Double Play': 'go', \n",
    "        'Bunt Groundout': 'go',\n",
    "        'Lineout': 'lo',\n",
    "        'Bunt Lineout': 'lo',\n",
    "        'Flyout': 'fo',\n",
    "        'Sac Fly': 'fo',\n",
    "        'Sac Fly Double Play': 'fo',\n",
    "        'Pop Out': 'po',\n",
    "        'Bunt Pop Out': 'po',\n",
    "        'Hit By Pitch': 'hbp',\n",
    "        'Walk': 'bb',\n",
    "        'Intent Walk': 'bb',\n",
    "        'Single': 'b1',\n",
    "        'Double': 'b2',\n",
    "        'Triple': 'b3',\n",
    "        'Home Run': 'hr'\n",
    "    }\n",
    "\n",
    "    df['eventsModel'] = df['event'].map(event_mapping).fillna('Cut')\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b97c232-0f40-4761-93a9-6e9b7bf93f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This turns several variables, including events, venues, hands, and bases into dummies\n",
    "def create_dummies(df):    \n",
    "    # Events\n",
    "    event_dummies = pd.get_dummies(df['eventsModel'])\n",
    "    # Venues\n",
    "    df['venue_id'] = df['venue_id'].astype('str')\n",
    "    venue_dummies = pd.get_dummies(df['venue_id'], prefix='venue')\n",
    "    # Hands\n",
    "    pitcher_dummies = pd.get_dummies(df['pitchHand'], prefix='p')\n",
    "    batter_dummies = pd.get_dummies(df['batSide'], prefix='b')\n",
    "    # Years\n",
    "    df['year'] = df['game_date'].str[:4]\n",
    "    year_dummies = pd.get_dummies(df['year'], prefix='year')\n",
    "    \n",
    "    # # Create lists of dummies\n",
    "    # venue_list = venue_dummies.columns.tolist()\n",
    "    # year_list = year_dummies.columns.tolist()\n",
    "    \n",
    "    # Add dummies to dataframe\n",
    "    df = pd.concat([df, event_dummies, venue_dummies, pitcher_dummies, batter_dummies, year_dummies], axis=1)\n",
    "\n",
    "    # Identify starting pitcher\n",
    "    df['startingPitcher'] = df.groupby(['gamePk', 'halfInning'])['pitcherName'].transform('first')\n",
    "    df['starter'] = (df['startingPitcher'] == df['pitcherName']).astype('int')\n",
    "    \n",
    "    # Create compatible date variable\n",
    "    df['date'] = df['game_date'].str.replace('-', '')\n",
    "    \n",
    "    # Convert to numeric for sorting\n",
    "    df['date'] = df['date'].astype('int')\n",
    "    df['gamePk'] = df['gamePk'].astype('int')\n",
    "    df['atBatIndex'] = df['atBatIndex'].astype('int')\n",
    "    \n",
    "    # Sort\n",
    "    df.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "    \n",
    "    # Create dummy for runners on base\n",
    "    df['preOnFirst'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnFirst'].shift(1)\n",
    "    df['preOnSecond'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnSecond'].shift(1)\n",
    "    df['preOnThird'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnThird'].shift(1)\n",
    "    \n",
    "    df['onFirst'] = df['preOnFirst'].apply(lambda x: 1 if isinstance(x, str) and 'id' in x else 0)\n",
    "    df['onSecond'] = df['preOnSecond'].apply(lambda x: 1 if isinstance(x, str) and 'id' in x else 0)\n",
    "    df['onThird'] = df['preOnThird'].apply(lambda x: 1 if isinstance(x, str) and 'id' in x else 0)\n",
    "    \n",
    "    # Top of the inning dummy\n",
    "    df['top'] = np.where(df['halfInning'] == \"top\", 1, 0)\n",
    "    \n",
    "    # Convert to numeric\n",
    "    df['awayScore'] = df['awayScore'].astype('int')\n",
    "    df['homeScore'] = df['homeScore'].astype('int')\n",
    "    \n",
    "    # Determine score before PA\n",
    "    df['preAwayScore'] = df.groupby(['gamePk'])['awayScore'].shift(1)\n",
    "    df['preHomeScore'] = df.groupby(['gamePk'])['homeScore'].shift(1)\n",
    "    \n",
    "    # If it's the first PA, it'll be missing. \n",
    "    df['preAwayScore'] = df['preAwayScore'].fillna(0)\n",
    "    df['preHomeScore'] = df['preHomeScore'].fillna(0)\n",
    "    \n",
    "    # Calculate differential\n",
    "    df['score_diff'] = np.where(df['top'] == 1, df['preAwayScore'] - df['preHomeScore'], df['preHomeScore'] - df['preAwayScore'])\n",
    "    \n",
    "    # Determine hitter and pitcher scores\n",
    "    df['batterScore'] = np.where(df['halfInning'] == 'top', df['awayScore'], df['homeScore'])\n",
    "    df['pitcherScore'] = np.where(df['halfInning'] == 'top', df['homeScore'], df['awayScore'])\n",
    "    \n",
    "    # Calculate PAs and ABs\n",
    "    df['pa'] = np.where(df['eventsModel'] != \"Cut\", 1, 0)\n",
    "    df['ab'] = df['pa'] - df['hbp'] - df['bb']           \n",
    "            \n",
    "    # Sort\n",
    "    df.sort_values(['date', 'gamePk', 'atBatIndex'], inplace=True)\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab59322d-abb2-4081-bd7b-7a81e3244210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This turns several variables, including events, venues, hands, and bases into dummies\n",
    "def create_dummies(df):    \n",
    "    # Events\n",
    "    event_dummies = pd.get_dummies(df['eventsModel'])\n",
    "    # Venues\n",
    "    df['venue_id'] = df['venue_id'].astype('str')\n",
    "    # venue_dummies = pd.get_dummies(df['venue_id'], prefix='venue')\n",
    "    # Hands\n",
    "    pitcher_dummies = pd.get_dummies(df['pitchHand'], prefix='p')\n",
    "    batter_dummies = pd.get_dummies(df['batSide'], prefix='b')\n",
    "    # Years\n",
    "    df['year'] = df['game_date'].str[:4]\n",
    "    # year_dummies = pd.get_dummies(df['year'], prefix='year')\n",
    "    \n",
    "    # Add dummies to dataframe\n",
    "    # df = pd.concat([df, event_dummies, venue_dummies, pitcher_dummies, batter_dummies, year_dummies], axis=1)\n",
    "    df = pd.concat([df, event_dummies, pitcher_dummies, batter_dummies], axis=1)\n",
    "\n",
    "    # Identify starting pitcher\n",
    "    df['startingPitcher'] = df.groupby(['gamePk', 'halfInning'])['pitcherName'].transform('first')\n",
    "    df['starter'] = (df['startingPitcher'] == df['pitcherName']).astype('int')\n",
    "    \n",
    "    # Create compatible date variable\n",
    "    df['date'] = df['game_date'].str.replace('-', '')\n",
    "    \n",
    "    # Convert to numeric for sorting\n",
    "    df['date'] = df['date'].astype('int')\n",
    "    df['gamePk'] = df['gamePk'].astype('int')\n",
    "    df['atBatIndex'] = df['atBatIndex'].astype('int')\n",
    "    \n",
    "    # Sort\n",
    "    df.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "    \n",
    "    # Create dummy for runners on base\n",
    "    df['preOnFirst'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnFirst'].shift(1)\n",
    "    df['preOnSecond'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnSecond'].shift(1)\n",
    "    df['preOnThird'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnThird'].shift(1)\n",
    "    \n",
    "    df['onFirst'] = df['preOnFirst'].apply(lambda x: 1 if isinstance(x, str) and 'id' in x else 0)\n",
    "    df['onSecond'] = df['preOnSecond'].apply(lambda x: 1 if isinstance(x, str) and 'id' in x else 0)\n",
    "    df['onThird'] = df['preOnThird'].apply(lambda x: 1 if isinstance(x, str) and 'id' in x else 0)\n",
    "    \n",
    "    # Top of the inning dummy\n",
    "    df['top'] = np.where(df['halfInning'] == \"top\", 1, 0)\n",
    "    \n",
    "    # Convert to numeric\n",
    "    df['awayScore'] = df['awayScore'].astype('int')\n",
    "    df['homeScore'] = df['homeScore'].astype('int')\n",
    "    \n",
    "    # Determine score before PA\n",
    "    df['preAwayScore'] = df.groupby(['gamePk'])['awayScore'].shift(1)\n",
    "    df['preHomeScore'] = df.groupby(['gamePk'])['homeScore'].shift(1)\n",
    "    \n",
    "    # If it's the first PA, it'll be missing. \n",
    "    df['preAwayScore'] = df['preAwayScore'].fillna(0)\n",
    "    df['preHomeScore'] = df['preHomeScore'].fillna(0)\n",
    "    \n",
    "    # Calculate differential\n",
    "    df['score_diff'] = np.where(df['top'] == 1, df['preAwayScore'] - df['preHomeScore'], df['preHomeScore'] - df['preAwayScore'])\n",
    "    \n",
    "    # Determine hitter and pitcher scores\n",
    "    df['batterScore'] = np.where(df['halfInning'] == 'top', df['awayScore'], df['homeScore'])\n",
    "    df['pitcherScore'] = np.where(df['halfInning'] == 'top', df['homeScore'], df['awayScore'])\n",
    "    \n",
    "    # Determine score before PA\n",
    "    df['preBatterScore'] = np.where(df['halfInning'] == 'top', df['preAwayScore'], df['preHomeScore'])\n",
    "    df['prePitcherScore'] = np.where(df['halfInning'] == 'top', df['preHomeScore'], df['preAwayScore'])\n",
    "    \n",
    "    # Calculate PAs and ABs\n",
    "    df['pa'] = np.where(df['eventsModel'] != \"Cut\", 1, 0)\n",
    "    df['ab'] = df['pa'] - df['hbp'] - df['bb']           \n",
    "            \n",
    "    # Sort\n",
    "    df.sort_values(['date', 'gamePk', 'atBatIndex'], inplace=True)\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9086db7e-516c-4a12-9103-cb8658e9ebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create useful Statcast variables\n",
    "def clean_statcast(df):\n",
    "    # Convert variables to numeric\n",
    "    df['launch_speed'] = pd.to_numeric(df['launch_speed'], errors='coerce')\n",
    "    df['launch_speed_angle'] = pd.to_numeric(df['launch_speed_angle'], errors='coerce')\n",
    "    df['hc_x'] = pd.to_numeric(df['hc_x'], errors='coerce')\n",
    "    df['hc_y'] = pd.to_numeric(df['hc_y'], errors='coerce')\n",
    "    \n",
    "    # Hard hit dummy\n",
    "    df['hard_hit'] = (df['launch_speed'] >= 95).astype('int')\n",
    "    \n",
    "    # Barrel dummy\n",
    "    df['barrel'] = (df['launch_speed_angle'] == 6).astype('int')\n",
    "\n",
    "    # Spray \n",
    "    df['spray_angle'] = np.arctan((df['hc_x'] - 125.42) / (198.27 - df['hc_y'])) * 180 / np.pi * 0.75\n",
    "    df['to_left'] = (df['spray_angle'] < -15).astype('int')\n",
    "    df['to_middle'] = ((df['spray_angle'] >= -15) & (df['spray_angle'] <= 15)).astype('int')\n",
    "    df['to_right'] = (df['spray_angle'] > 15).astype('int')\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aeff47-2e6f-46a4-9c8c-1e37435ee004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust for park factors\n",
    "def park_adjustments(df):   \n",
    "    # Read in park factors\n",
    "    multiplier_df = pd.read_csv(os.path.join(baseball_path, \"Multiplier Dataset.csv\"))\n",
    "\n",
    "    # Convert to numeric for merging\n",
    "    multiplier_df['gamePk'] = multiplier_df['gamePk'].astype(int)\n",
    "    df['gamePk'] = df['gamePk'].astype('int')\n",
    "    \n",
    "    # Merge with park factors\n",
    "    multiplier_columns = [column for column in multiplier_df.columns if \"mult\" in column]\n",
    "    league_avg_columns = [column for column in multiplier_df.columns if \"league\" in column]\n",
    "    df = df.merge(multiplier_df[[\"gamePk\"] + multiplier_columns + league_avg_columns], on=['gamePk'], how='left', indicator=True)\n",
    "    \n",
    "    # Missings (old parks, other parks)\n",
    "    # Multipliers of 1 \n",
    "    df[multiplier_columns] = df[multiplier_columns].fillna(1)\n",
    "    # Most recent league_averages\n",
    "    df[league_avg_columns] = df[league_avg_columns].ffill()\n",
    "\n",
    "\n",
    "    # Loop over events\n",
    "    for event in events_list:\n",
    "        # Adjust based on calculated multiplier\n",
    "        df[event] = np.where(df['batSide'] == \"L\", df[event].astype(float) / df[f'{event}_mult_l'].astype(float), df[event].astype(float) / df[f'{event}_mult_r'].astype(float))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2f862055-9a96-49e2-8844-6fde8b4bb5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return a dataframe that can eventually be used as the model input. Has pitcher vs hitter stats, specific to hand\n",
    "def rolling_pas(df, pa_num):\n",
    "    # Copy dataframe\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Note: batter_avg_short will work even when pa_num refers to the \"long\" period. Suffix will be added in post.\n",
    "    # Rename for compatibility purposes\n",
    "    df_copy.rename(columns={'hit_distance_sc':'totalDistance', 'launch_speed':'launchSpeed'}, inplace=True)          \n",
    "            \n",
    "    # Convert to numeric and fill with 0s\n",
    "    combined_list = avg_list + max_list\n",
    "    for col in combined_list:\n",
    "        # Check if the column is not numeric\n",
    "        if not pd.api.types.is_numeric_dtype(df_copy[col]):\n",
    "            # Convert the non-numeric column to numeric and fill missing values with 0\n",
    "            df_copy[col] = pd.to_numeric(df_copy[col], errors='coerce')\n",
    "            df_copy[col] = df_copy[col].fillna(0)\n",
    "\n",
    "    # Sort\n",
    "    df_copy.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "            \n",
    "    # Data types may vary. This makes grouping impossible. \n",
    "    df_copy['batter'] = df_copy['batter'].astype('int')\n",
    "    df_copy['pitcher'] = df_copy['pitcher'].astype('int')\n",
    "        \n",
    "    ### Batter stats \n",
    "    # Stats for which you want the average \n",
    "    df_copy[batter_avg_short] = df_copy.groupby(['batter', 'pitchHand'])[avg_list].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).mean())\n",
    "    # Stats for which you want the maximum\n",
    "    df_copy[batter_max_short] = df_copy.groupby(['batter', 'pitchHand'])[max_list].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).max())\n",
    "    # Stats for which you just want the sum \n",
    "    df_copy[['ab_b', 'pa_b']] = df_copy.groupby(['batter', 'pitchHand'])[['ab', 'pa']].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).sum())\n",
    "                \n",
    "    ### Pitcher stats\n",
    "    # Stats for which you want the average\n",
    "    df_copy[pitcher_avg_short] = df_copy.groupby(['pitcher', 'batSide'])[avg_list].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).mean())\n",
    "    # Stats for which you want the maximum\n",
    "    df_copy[pitcher_max_short] = df_copy.groupby(['pitcher', 'batSide'])[max_list].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).max())\n",
    "    # Stats for which you just want the sum \n",
    "    df_copy[['ab_p', 'pa_p']] = df_copy.groupby(['pitcher', 'batSide'])[['ab', 'pa']].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).sum())\n",
    "                \n",
    "    # Create imputation flags (these observations will have imputed inputs)\n",
    "    df_copy['imp_b'] = (df_copy['pa_b'] < 40).astype('int')\n",
    "    df_copy['imp_p'] = (df_copy['pa_p'] < 40).astype('int')\n",
    "\n",
    "    # Create compatible date variable\n",
    "    df_copy['date'] = df_copy['game_date'].str.replace('-', '')\n",
    "    \n",
    "    # Convert to numeric for sorting\n",
    "    df_copy['date'] = df_copy['date'].astype('int')\n",
    "    df_copy['gamePk'] = df_copy['gamePk'].astype('int')\n",
    "    df_copy['atBatIndex'] = df_copy['atBatIndex'].astype('int')\n",
    "    df_copy['batter'] = df_copy['batter'].astype('int')\n",
    "    df_copy['pitcher'] = df_copy['pitcher'].astype('int')\n",
    "    \n",
    "    # Sort\n",
    "    df_copy.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "\n",
    "    ### Advanced stats\n",
    "    # wOBA - using 2022 values throughout\n",
    "    df_copy['woba_b'] = (0.690 * df_copy['bb_b']) + (0.721 * df_copy['hbp_b']) + (0.885 * df_copy['b1_b']) + (1.262 * df_copy['b2_b']) + (1.601 * df_copy['b3_b']) + (2.070 * df_copy['hr_b'])\n",
    "    df_copy['woba_p'] = (0.690 * df_copy['bb_p']) + (0.721 * df_copy['hbp_p']) + (0.885 * df_copy['b1_p']) + (1.262 * df_copy['b2_p']) + (1.601 * df_copy['b3_p']) + (2.070 * df_copy['hr_p'])\n",
    "    \n",
    "    # Slugging\n",
    "    df_copy['slg_b'] = ((1 * df_copy['b1_b']) + (2 * df_copy['b2_b']) + (3 * df_copy['b3_b']) + (4 * df_copy['hr_b'])) * (1 / (1-(df_copy['bb_b'] + df_copy['hbp_b'])))\n",
    "    df_copy['slg_p'] = ((1 * df_copy['b1_p']) + (2 * df_copy['b2_p']) + (3 * df_copy['b3_p']) + (4 * df_copy['hr_p'])) * (1 / (1-(df_copy['bb_p'] + df_copy['hbp_p'])))\n",
    "    # OBP    \n",
    "    df_copy['obp_b'] = df_copy[['b1_b', 'b2_b', 'b3_b', 'hr_b', 'bb_b', 'hbp_b']].sum(axis=1)\n",
    "    df_copy['obp_p'] = df_copy[['b1_p', 'b2_p', 'b3_p', 'hr_p', 'bb_p', 'hbp_p']].sum(axis=1)\n",
    "    \n",
    "    # ISO\n",
    "    df_copy['iso_b'] = (df_copy['b2_b'] * 1 + df_copy['b3_b'] * 2 + df_copy['hr_b'] * 3) * (1 / (1-(df_copy['bb_b'] + df_copy['hbp_b'])))\n",
    "    df_copy['iso_p'] = (df_copy['b2_p'] * 1 + df_copy['b3_p'] * 2 + df_copy['hr_p'] * 3) * (1 / (1-(df_copy['bb_p'] + df_copy['hbp_p'])))\n",
    "\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cec745-caa0-4285-9959-0b95c0f16713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates information about starts for use in pulling pitchers\n",
    "def start_data(df):\n",
    "    # Calculate the sum for each group\n",
    "    df['br'] = df[['b1', 'b2', 'b3', 'hr', 'bb', 'hbp']].astype('float').sum(axis=1)\n",
    "\n",
    "    # Calculate the cumulative sum within each group\n",
    "    df['br_inning'] = df.groupby(['gamePk', 'inning', 'halfInning'])['br'].cumsum()\n",
    "    \n",
    "    # Convert to numeric\n",
    "    df['inning'] = pd.to_numeric(df['inning'])\n",
    "    df['outs'] = pd.to_numeric(df['outs'])\n",
    "    df['rbi'] = df['rbi'].astype('int')\n",
    "    \n",
    "    # Number of batters faced (will be used to calculate rolling sum)\n",
    "    df['faced'] = 1\n",
    "    \n",
    "    # Cumulative counts\n",
    "    # Stats to sum\n",
    "    sums_list = ['gamePk', 'pitcher'] + events_list + ['rbi', 'faced']\n",
    "    # Calculate\n",
    "    sums = df[sums_list].groupby(['gamePk', 'pitcher']).cumsum()\n",
    "    # Add suffix\n",
    "    sums = sums.add_suffix(\"_sum\")\n",
    "    \n",
    "    # Add rolling sums\n",
    "    df = pd.concat([df, sums], axis=1)\n",
    "    \n",
    "    # Identify if it's the bottom of the inning (a little more helpful than \"top\" as it's sortable)\n",
    "    df['bottom'] = (df['top'] == 0).astype('int')\n",
    "    \n",
    "    # Sort to identify starting pitchers\n",
    "    df = df.sort_values(by=['date', 'gamePk', 'bottom', 'atBatIndex'])\n",
    "    \n",
    "    # The starter has the lowest atBatIndex\n",
    "    df['atBatIndex_min'] = df.groupby(['gamePk', 'bottom'])['atBatIndex'].transform('min')\n",
    "    df['start'] = (df['atBatIndex'] == df['atBatIndex_min']).astype('int')\n",
    "        \n",
    "    # Identify starter throughout\n",
    "    df['starter'] = df.groupby(['pitcher', 'gamePk'])['start'].cumsum()\n",
    "    \n",
    "    # Keep only starters\n",
    "    df = df.query('starter == 1')\n",
    "    \n",
    "    # The starter is pulled at their highest atBatIndex\n",
    "    df['atBatIndex_max'] = df.groupby(['gamePk', 'bottom'])['atBatIndex'].transform('max')\n",
    "    df['pulled'] = (df['atBatIndex'] == df['atBatIndex_max']).astype('int')\n",
    "    \n",
    "    # Batters faced that inning\n",
    "    df['faced_inning'] = df.groupby(['gamePk', 'inning', 'bottom']).cumcount()+1\n",
    "    df['faced_inning'] = np.where(df['outs'] == 3, 0, df['faced_inning'])\n",
    "    \n",
    "    # Rolling sums stats (post-rolling sum)\n",
    "    rolled_sums_list = [f'{stat}_sum' for stat in events_list] + ['rbi_sum', 'faced_sum']\n",
    "    \n",
    "    # Outs recorded by starting pitcher \n",
    "    df['OUT'] = ((df['inning'] - 1) * 3) + df['outs']\n",
    "    \n",
    "    # This adjusts timing to better reflect when pitchers are pulled\n",
    "    # If a pitcher is pulled after 6 innings in the data, that's the same as pulling at the top of the 7th, which more closely reflects how the sim works\n",
    "    df['inning_adj'] = df['inning'] + (df['outs'] == 3).astype('int')\n",
    "    df['outs_adj'] = np.where(df['outs'] == 3, 0, df['outs'])\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3199c843-6a0a-4a80-a404-337953c74319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates information about starts for use in pulling pitchers\n",
    "def start_data(df):\n",
    "    # Calculate the sum for each group\n",
    "    df['br'] = df[['b1', 'b2', 'b3', 'hr', 'bb', 'hbp']].astype('float').sum(axis=1)\n",
    "\n",
    "    # Calculate the cumulative sum within each group\n",
    "    df['br_inning'] = df.groupby(['gamePk', 'inning', 'halfInning'])['br'].cumsum()\n",
    "    \n",
    "    # Convert to numeric\n",
    "    df['inning'] = pd.to_numeric(df['inning'])\n",
    "    df['outs'] = pd.to_numeric(df['outs'])\n",
    "    df['rbi'] = df['rbi'].astype('int')\n",
    "    \n",
    "    # Number of batters faced (will be used to calculate rolling sum)\n",
    "    df['faced'] = 1\n",
    "    \n",
    "    # Cumulative counts\n",
    "    # Stats to sum\n",
    "    sums_list = ['gamePk', 'pitcher'] + events_list + ['rbi', 'faced']\n",
    "    # Calculate\n",
    "    sums = df[sums_list].groupby(['gamePk', 'pitcher']).cumsum()\n",
    "    # Add suffix\n",
    "    sums = sums.add_suffix(\"_sum\")\n",
    "    \n",
    "    # Add rolling sums\n",
    "    df = pd.concat([df, sums], axis=1)\n",
    "    \n",
    "    # Identify if it's the bottom of the inning (a little more helpful than \"top\" as it's sortable)\n",
    "    df['bottom'] = (df['top'] == 0).astype('int')\n",
    "    \n",
    "    # Sort to identify starting pitchers\n",
    "    df = df.sort_values(by=['date', 'gamePk', 'bottom', 'atBatIndex'])\n",
    "    \n",
    "    # The starter has the lowest atBatIndex\n",
    "    df['atBatIndex_min'] = df.groupby(['gamePk', 'bottom'])['atBatIndex'].transform('min')\n",
    "    df['start'] = (df['atBatIndex'] == df['atBatIndex_min']).astype('int')\n",
    "        \n",
    "    # Identify starter throughout\n",
    "    df['starter'] = df.groupby(['pitcher', 'gamePk'])['start'].cumsum()\n",
    "    \n",
    "    # # Keep only starters\n",
    "    # df = df.query('starter == 1')\n",
    "    \n",
    "    # The starter is pulled at their highest atBatIndex\n",
    "    df['atBatIndex_max'] = df.groupby(['gamePk', 'bottom'])['atBatIndex'].transform('max')\n",
    "    df['pulled'] = (df['atBatIndex'] == df['atBatIndex_max']).astype('int')\n",
    "    \n",
    "    # Batters faced that inning\n",
    "    df['faced_inning'] = df.groupby(['gamePk', 'inning', 'bottom']).cumcount()+1\n",
    "    df['faced_inning'] = np.where(df['outs'] == 3, 0, df['faced_inning'])\n",
    "    \n",
    "    # Rolling sums stats (post-rolling sum)\n",
    "    rolled_sums_list = [f'{stat}_sum' for stat in events_list] + ['rbi_sum', 'faced_sum']\n",
    "    \n",
    "    # Outs recorded by starting pitcher \n",
    "    df['OUT'] = ((df['inning'] - 1) * 3) + df['outs']\n",
    "    \n",
    "    # This adjusts timing to better reflect when pitchers are pulled\n",
    "    # If a pitcher is pulled after 6 innings in the data, that's the same as pulling at the top of the 7th, which more closely reflects how the sim works\n",
    "    df['inning_adj'] = df['inning'] + (df['outs'] == 3).astype('int')\n",
    "    df['outs_adj'] = np.where(df['outs'] == 3, 0, df['outs'])\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5901b5-1e03-425b-b77d-374b66a5b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_datasets(start_year=2015, end_year=2024):\n",
    "    # List of merged datasets\n",
    "    df_list = []\n",
    "    # Read in datasets\n",
    "    for year in range(start_year, end_year+1):\n",
    "        statsapi_df = pd.read_csv(os.path.join(baseball_path, \"A02. MLB API\", \"1. Stats API\", f\"Stats API {year}.csv\"), encoding='iso-8859-1')\n",
    "        statcast_df = pd.read_csv(os.path.join(baseball_path, \"A02. MLB API\", \"2. Statcast\", f\"Statcast {year}.csv\"), encoding='iso-8859-1')\n",
    "        \n",
    "        # Merge them together\n",
    "        merged_df = pd.merge(statsapi_df, statcast_df, on=['gamePk', 'atBatIndex'], how='left')\n",
    "\n",
    "        # Drop duplicate observations\n",
    "        merged_df.drop_duplicates(['gamePk', 'atBatIndex'], keep='first', inplace=True)\n",
    "        \n",
    "        # Add them to a list\n",
    "        df_list.append(merged_df)\n",
    "    \n",
    "    # Create raw dataset\n",
    "    df = pd.concat(df_list, axis=0)   \n",
    "    \n",
    "    # Create data variable (without dashes)\n",
    "    df['date'] = df['game_date'].str.replace('-', '')\n",
    "\n",
    "    # Convert to numeric for sorting\n",
    "    df['date'] = df['date'].astype('int')\n",
    "    df['gamePk'] = df['gamePk'].astype('int')\n",
    "    df['atBatIndex'] = df['atBatIndex'].astype('int')\n",
    "\n",
    "    # Sort\n",
    "    df.sort_values(['game_date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "\n",
    "    # Only keep one observation per at bat\n",
    "    df.drop_duplicates(['gamePk', 'atBatIndex'], keep='first', inplace=True)\n",
    "\n",
    "    # Determine outs coming into PA\n",
    "    df['outs_pre'] = df.groupby(['gamePk', 'inning', 'halfInning'])['outs'].shift(fill_value=0)\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a20426-de2f-48ad-9be7-850783298494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates model inputs\n",
    "def create_pa_inputs(park_factors, team_map, start_year, end_year, short=50, long=300, adjust=True):\n",
    "    # Merge together raw Stats API and Statcast data\n",
    "    df = merge_datasets(start_year, end_year)\n",
    "    # Clean weather\n",
    "    df2 = clean_weather(df)\n",
    "    # Create PA events \n",
    "    df3 = create_events(df2)\n",
    "    # Create dummy variables \n",
    "    df4 = create_dummies(df3)\n",
    "    # Create Statcast variables\n",
    "    df5 = clean_statcast(df4)   \n",
    "    # Adjust for park factors\n",
    "    if adjust == True:\n",
    "        df6 = park_adjustments(df5)\n",
    "        df6.drop(columns={'_merge'}, inplace=True)\n",
    "    else:\n",
    "        df6 = df5.copy()\n",
    "    ### TESTING\n",
    "    # Add start data\n",
    "    df6 = start_data(df6)\n",
    "    # ### TESTING\n",
    "    # df6 = df6.query('eventsModel != \"Cut\"')\n",
    "    # Clean up\n",
    "    df6.fillna(0, inplace=True)\n",
    "    \n",
    "    ### Rolling stats\n",
    "    # Short\n",
    "    df_short = rolling_pas(df6, short)\n",
    "    # Long\n",
    "    df_long = rolling_pas(df6, long)\n",
    "    df_long = df_long.add_suffix(\"_long\")\n",
    "        \n",
    "    # We only need the rolling stats \n",
    "    long_stats = batter_stats_long + pitcher_stats_long\n",
    "    df_long = df_long[long_stats]\n",
    "    \n",
    "    # Dataset\n",
    "    complete_dataset = pd.concat([df_short, df_long], axis=1)\n",
    "\n",
    "    # Fix Guardians name to make uniform\n",
    "    complete_dataset['away_name'] = np.where(complete_dataset['away_name'] == \"Cleveland Indians\", \"Cleveland Guardians\", complete_dataset['away_name'])\n",
    "    complete_dataset['home_name'] = np.where(complete_dataset['home_name'] == \"Cleveland Indians\", \"Cleveland Guardians\", complete_dataset['home_name'])\n",
    "\n",
    "    # Only keep regular season\n",
    "    complete_dataset = complete_dataset[complete_dataset['game_type_x'] == \"R\"]\n",
    "\n",
    "    # Reset index\n",
    "    complete_dataset.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Sort\n",
    "    complete_dataset.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "    \n",
    "    \n",
    "    return complete_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a9ac1b-3a32-4b55-b75f-cfd734c97f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates model inputs\n",
    "def create_pull_inputs(park_factors, team_map, start_year, end_year, short=50, long=300, adjust=True):\n",
    "    # Merge together raw Stats API and Statcast data\n",
    "    df = merge_datasets(start_year, end_year)\n",
    "    # Clean weather\n",
    "    df2 = clean_weather(df)\n",
    "    # Create PA events \n",
    "    df3 = create_events(df2)\n",
    "    # Create dummy variables \n",
    "    df4 = create_dummies(df3)\n",
    "    # Create Statcast variables\n",
    "    df5 = clean_statcast(df4)   \n",
    "    # Adjust for park factors\n",
    "    if adjust == True:\n",
    "        df6 = park_adjustments(df5)\n",
    "        df6.drop(columns={'_merge'}, inplace=True)\n",
    "    else:\n",
    "        df6 = df5.copy()\n",
    "    # Add start data\n",
    "    complete_dataset = start_data(df6)\n",
    "    \n",
    "    # Clean up\n",
    "    # complete_dataset.drop(columns={'_merge'}, inplace=True)\n",
    "    complete_dataset.fillna(0, inplace=True)\n",
    "    \n",
    "    # Sort\n",
    "    complete_dataset.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "\n",
    "    \n",
    "    return complete_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03f651d-4f3c-45ab-b7f8-c4c8ee985d78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1506c1fc-dd11-47ce-87e9-1d5f5f58cd98",
   "metadata": {},
   "source": [
    "### Steamer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06c0a65-8fa9-4fd1-9b72-d501c3361a7a",
   "metadata": {},
   "source": [
    "##### 1. Hitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2053516-8f29-4c3c-87e1-49f5fbc91361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_steamer_hitters(df):\n",
    "    ### Hitting\n",
    "    # Basic stats\n",
    "    hit_list = ['1B', '2B', '3B', 'HR', 'BB', 'HBP', 'K']\n",
    "\n",
    "    # Advance stats\n",
    "    rate_list = ['OBP', 'SLG', 'wOBA']\n",
    "    for stat in hit_list:\n",
    "        rate = stat + \"_rate\"\n",
    "        rate_list.append(rate)\n",
    "        df[rate] = df[stat] / df['PA']\n",
    "\n",
    "    ### Base running\n",
    "    # Stolen base attempts\n",
    "    df['SBA'] = df['SB'] + df['CS']\n",
    "    # Stolen base opportunities (times on first)\n",
    "    df['SBO'] = df['1B'] + df['BB'] + df['HBP']\n",
    "    # Implied stolen base attempt rate\n",
    "    df['sba_imp'] = df['SBA'] / df['SBO']\n",
    "\n",
    "    # Cap implied stolen base attempt rate\n",
    "    df['sba_imp'] = np.where(df['sba_imp'] > 0.15, 0.15, df['sba_imp'])\n",
    "    \n",
    "    # Determine stolen base success rate\n",
    "    df['sbr'] = df['SB'] / df['SBA']\n",
    "    \n",
    "    # Fill in missings\n",
    "    df['sbr'].fillna(0.6, inplace=True) # assume 25th percentile \n",
    "    df['sba_imp'].fillna(0.05, inplace=True) # assume low probability\n",
    "    \n",
    "    # Date\n",
    "    df['date'] = df['proj_date'].str.replace(\"-\", \"\")\n",
    "    df['date'] = df['date'].astype('int')\n",
    "    \n",
    "    # Keep relevant variables\n",
    "    keep_list = ['date', 'firstname', 'lastname', 'mlbamid', 'steamerid', 'sba_imp', 'sbr'] + rate_list\n",
    "    df = df[keep_list]\n",
    "    \n",
    "    # Clean up\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.rename(columns={'1b_rate': 'b1_rate', '2b_rate': 'b2_rate', '3b_rate': 'b3_rate', 'k_rate':'so_rate'}, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Drop duplicates\n",
    "    df.drop_duplicates(subset=['steamerid', 'date'], inplace=True)\n",
    "    \n",
    "    # Calculate stolen base attempt and success rates by base\n",
    "    sba_2b_reg = pickle.load(open(os.path.join(model_path, 'sba_2b_20220901.sav'), 'rb'))\n",
    "    df['sba_2b'] = sba_2b_reg.predict(df[['sba_imp']])\n",
    "\n",
    "    sba_3b_reg = pickle.load(open(os.path.join(model_path, 'sba_3b_20220901.sav'), 'rb'))\n",
    "    df['sba_3b'] = sba_3b_reg.predict(df[['sba_imp']])\n",
    "\n",
    "    sb_2b_reg = pickle.load(open(os.path.join(model_path, 'sb_2b_20220901.sav'), 'rb'))\n",
    "    df['sb_2b'] = sb_2b_reg.predict(df[['sbr']])\n",
    "\n",
    "    sb_3b_reg = pickle.load(open(os.path.join(model_path, 'sb_3b_20220901.sav'), 'rb'))\n",
    "    df['sb_3b'] = sb_3b_reg.predict(df[['sbr']])\n",
    "\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc95785-c051-452e-aa5a-f8b9fbdd6c4a",
   "metadata": {},
   "source": [
    "##### 2. Pitchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3876f6da-1d0d-461f-8ab3-b002df855e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_steamer_pitchers(df):\n",
    "    # Hits per 9 innings\n",
    "    df['H9'] = df['H'] / df['IP'] * 9\n",
    "    \n",
    "    # Calculate average innings per game started\n",
    "    df['IP_start'] = df['start_IP'] / df['GS']\n",
    "    df['IP_start'].fillna(0, inplace=True)\n",
    "    # Replace infinites\n",
    "    df['IP_start'].replace([np.inf, -np.inf], 3, inplace=True)\n",
    "\n",
    "    # Date\n",
    "    df['date'] = df['proj_date'].str.replace(\"-\", \"\")\n",
    "    df['date'] = df['date'].astype('int')\n",
    "    \n",
    "    # Keep relevant variables\n",
    "    keep_list = ['date', 'firstname', 'lastname', 'mlbamid', 'steamerid'] + pitcher_stats_fg2 \n",
    "    df = df[keep_list]\n",
    "    \n",
    "    # Drop duplicates\n",
    "    df.drop_duplicates(subset=['steamerid', 'date'], inplace=True)\n",
    "\n",
    "    \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
