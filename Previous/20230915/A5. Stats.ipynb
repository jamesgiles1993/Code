{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fc63541-ac5e-4646-87ca-1134c4c1180d",
   "metadata": {},
   "source": [
    "# A5. Stats\n",
    "Source: FanGraphs API <br>\n",
    "\n",
    "This imports stats from Fangraphs <br>\n",
    "This calculates stats that aren't used in the models but help us get there <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d92f9c1-c5d9-4a6a-a837-a564c2bafa9c",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d4366b7-70bd-48b7-b3a9-79e86c041902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Utilities.ipynb\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import statsmodels.formula.api as smf\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import datetime\n",
    "from datetime import date\n",
    "import time\n",
    "import re\n",
    "import import_ipynb\n",
    "from Utilities import *\n",
    "import pickle\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "model_path = r\"C:\\Users\\james\\Documents\\MLB\\Code\\Models\"\n",
    "baseball_path = r\"C:\\Users\\james\\Documents\\MLB\\Data\"\n",
    "download_path = r\"C:\\Users\\james\\Downloads\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a32d76b1-8a07-4ff9-945b-1b63f3428bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This reads in Chadwick register with player codes.\n",
    "keep_list = ['key_mlbam', 'key_fangraphs', 'name_first', 'name_last']\n",
    "chadwick = read_chadwick(keep_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7fda4c6-b347-410c-b57e-bcfc6c6e459e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20230426'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set today's date\n",
    "todaysdate = date.today()\n",
    "todaysdate_dash = str(todaysdate)\n",
    "todaysdate = todaysdate_dash.replace(\"-\", \"\")\n",
    "todaysdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22f794ac-7329-4fad-a55e-e5b2a46e89eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of stats\n",
    "simple_list = ['so', 'b1', 'b2', 'b3', 'hr', 'bb', 'hbp', 'lo', 'po', 'go', 'fo']\n",
    "\n",
    "# Read in models\n",
    "woba_reg = pickle.load(open(os.path.join(model_path, 'woba_20220908.sav'), 'rb'))\n",
    "obp_reg = pickle.load(open(os.path.join(model_path, 'obp_20220908.sav'), 'rb'))\n",
    "slg_reg = pickle.load(open(os.path.join(model_path, 'slg_20220908.sav'), 'rb'))\n",
    "\n",
    "fg_vs_lhp = pickle.load(open(os.path.join(model_path, 'fg_vs_lhp_20220905.sav'), 'rb'))\n",
    "fg_vs_rhp = pickle.load(open(os.path.join(model_path, 'fg_vs_rhp_20220905.sav'), 'rb'))\n",
    "fg_vs_lhb = pickle.load(open(os.path.join(model_path, 'fg_vs_lhb_20220905.sav'), 'rb'))\n",
    "fg_vs_rhb = pickle.load(open(os.path.join(model_path, 'fg_vs_rhb_20220905.sav'), 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44283ed-806a-457a-837a-28a10ea9999e",
   "metadata": {},
   "source": [
    "# Scrape FanGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b86dfa1-82b2-4738-80d9-4e1f4bad0ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    proj_date   mlbamid steamerid firstname lastname Team position bats   PA  \\\n",
      "268  20230426  668930.0     22186     Brice   Turang  MIL       2B   MI  390   \n",
      "\n",
      "     IBB  ...  2B  3B  HR       OBP       SLG      wOBA  SB  CS  playerid  \\\n",
      "268    0  ...  16   1   6  0.307942  0.345596  0.290903  11   3     22186   \n",
      "\n",
      "             Name  \n",
      "268  Brice Turang  \n",
      "\n",
      "[1 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Fangraphs API\n",
    "def scrape_batters():\n",
    "    # Read in API json\n",
    "    batters_lb = pd.read_json('https://www.fangraphs.com/api/projections?type=steamer&stats=bat&pos=all&team=0&players=0&lg=all')\n",
    "\n",
    "    # Name is currently some weird thing with a bunch of data. We don't need all that\n",
    "    batters_lb['Name'] = batters_lb['PlayerName']\n",
    "    # Rename to match steam. Note that steamerid = key_fangraphs\n",
    "    batters_lb.rename(columns={'playerids':'steamerid'}, inplace=True)\n",
    "    # Convert to string\n",
    "    chadwick['key_fangraphs'] = (chadwick['key_fangraphs']).astype('str')\n",
    "    # Remove trailing .0\n",
    "    chadwick['key_fangraphs'] = chadwick['key_fangraphs'].str.replace(r'\\.\\d', \"\", regex=True)\n",
    "    \n",
    "    # Merge with chadwick for mlbamid\n",
    "    batters_lb = batters_lb.merge(chadwick, left_on='steamerid', right_on='key_fangraphs', how='left')\n",
    "\n",
    "    # Create missing columns to match what's provided by steamer \n",
    "    batters_lb['proj_date'] = todaysdate\n",
    "    batters_lb['mlbamid'] = batters_lb['key_mlbam']\n",
    "    batters_lb['bats'] = \"MI\" # Not included in FanGraphs data\n",
    "    batters_lb['playerid'] = batters_lb['steamerid']\n",
    "    batters_lb['NIBB'] = batters_lb['BB'] - batters_lb['IBB']\n",
    "    batters_lb.rename(columns={'name_first':'firstname', 'name_last':'lastname', 'minpos':'position'}, inplace=True)\n",
    "\n",
    "    # Keep relevant variables and in order\n",
    "    batters_lb = batters_lb[['proj_date', 'mlbamid', 'steamerid', 'firstname', 'lastname', 'Team', 'position', 'bats', 'PA', 'IBB', 'NIBB', \n",
    "                             'BB', 'SO', 'HBP', 'H', '2B', '3B', 'HR', 'OBP', 'SLG', 'wOBA', 'SB', 'CS', 'playerid', 'Name']]\n",
    "\n",
    "    # Export to CSV\n",
    "    filename = \"Batters_FG_\" + todaysdate + \".csv\"\n",
    "    batters_lb.to_csv(os.path.join(baseball_path, \"A5. Stats - 1. FanGraphs\", \"Batters\", filename), encoding='iso-8859-1')\n",
    "    \n",
    "    print(batters_lb.query('Name == \"Brice Turang\"'))\n",
    "    \n",
    "    \n",
    "scrape_batters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5b19f24-4170-43ae-9b0c-ac7830c6c699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    proj_date   mlbamid steamerid firstname lastname Throws   IP   G  GS  \\\n",
      "161  20230426  694363.0     27472     Jared  Shuster     MI  111  19  19   \n",
      "\n",
      "         K/9     BB/9    H  HR playerid           Name  \n",
      "161  7.29813  2.83048  116  16    27472  Jared Shuster  \n"
     ]
    }
   ],
   "source": [
    "# Fangraphs API\n",
    "def scrape_pitchers():\n",
    "    # Read in API json\n",
    "    pitchers_lb = pd.read_json('https://www.fangraphs.com/api/projections?type=steamer&stats=pit&pos=all&team=0&players=0&lg=all')\n",
    "\n",
    "    # Name is currently some weird thing with a bunch of data. We don't need all that\n",
    "    pitchers_lb['Name'] = pitchers_lb['PlayerName']\n",
    "    # Rename to match steam. Note that steamerid = key_fangraphs\n",
    "    pitchers_lb.rename(columns={'playerids':'steamerid'}, inplace=True)\n",
    "    # Convert to string\n",
    "    chadwick['key_fangraphs'] = (chadwick['key_fangraphs']).astype('str')\n",
    "    # Remove trailing .0\n",
    "    chadwick['key_fangraphs'] = chadwick['key_fangraphs'].str.replace(r'\\.\\d', \"\", regex=True)\n",
    "    \n",
    "    # Merge with chadwick for mlbamid\n",
    "    pitchers_lb = pitchers_lb.merge(chadwick, left_on='steamerid', right_on='key_fangraphs', how='left')\n",
    "\n",
    "    # Create missing columns to match what's provided by steamer \n",
    "    pitchers_lb['proj_date'] = todaysdate\n",
    "    pitchers_lb['mlbamid'] = pitchers_lb['key_mlbam']\n",
    "    pitchers_lb['Throws'] = \"MI\" # Not included in FanGraphs data\n",
    "    pitchers_lb['playerid'] = pitchers_lb['steamerid']\n",
    "    pitchers_lb.rename(columns={'name_first':'firstname', 'name_last':'lastname', 'minpos':'position'}, inplace=True)\n",
    "\n",
    "    # Keep relevant variables and in order\n",
    "    pitchers_lb = pitchers_lb[['proj_date', 'mlbamid', 'steamerid', 'firstname', 'lastname', 'Throws', 'IP', 'G', 'GS', 'K/9',\n",
    "                             'BB/9', 'H', 'HR', 'playerid', 'Name']]\n",
    "\n",
    "    print(pitchers_lb.query('Name == \"Jared Shuster\"'))\n",
    "\n",
    "    \n",
    "    # Export to CSV\n",
    "    filename = \"Pitchers_FG_\" + todaysdate + \".csv\"\n",
    "    pitchers_lb.to_csv(os.path.join(baseball_path, \"A5. Stats - 1. FanGraphs\", \"Pitchers\", filename), encoding='iso-8859-1')\n",
    "    \n",
    "scrape_pitchers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c888a735-c96c-4f51-ad3d-a5f3c6914aaf",
   "metadata": {},
   "source": [
    "# Create Useful Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "609b2398-43ad-45a5-b9d8-3084d9ff0f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_intermediate_batters(date):\n",
    "    # Read in file\n",
    "    filename = \"Batters_FG_\" + date + \".csv\"\n",
    "    df = pd.read_csv(os.path.join(baseball_path, \"A5. Stats - 1. FanGraphs\", \"Batters\", filename), encoding='iso-8859-1')\n",
    "    # Create singles\n",
    "    df['1B'] = df['H'] - df['2B'] - df['3B'] - df['HR']\n",
    "    \n",
    "    # Basic stats\n",
    "    hit_list = ['1B', '2B', '3B', 'HR', 'BB', 'HBP', 'SO']\n",
    "\n",
    "    # Advance stats\n",
    "    rate_list = ['OBP', 'SLG', 'wOBA']\n",
    "    for stat in hit_list:\n",
    "        rate = stat + \"_rate\"\n",
    "        rate_list.append(rate)\n",
    "        df[rate] = df[stat] / df['PA']\n",
    "\n",
    "    df['SBA'] = df['SB'] + df['CS']\n",
    "    df['SBO'] = df['1B'] + df['BB'] + df['HBP']\n",
    "    df['sba_imp'] = df['SBA'] / df['SBO']\n",
    "\n",
    "    # Cap imputed SBA \n",
    "    df['sba_imp'] = np.where(df['sba_imp'] > 0.15, 0.15, df['sba_imp'])\n",
    "\n",
    "    # Determine stolen base success rate\n",
    "    df['sbr'] = df['SB'] / df['SBA']\n",
    "    \n",
    "    keep_list = ['Name', 'mlbamid', 'playerid', 'sba_imp', 'sbr'] + rate_list\n",
    "    df = df[keep_list]\n",
    "    \n",
    "    df['sbr'].fillna(0.6, inplace=True) # assume 25th percentile \n",
    "    df['sba_imp'].fillna(0.05, inplace=True) # assume imputed\n",
    "    \n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.rename(columns={'1b_rate': 'b1_rate', '2b_rate': 'b2_rate', '3b_rate': 'b3_rate'}, inplace=True)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    sba_2b_reg = pickle.load(open(os.path.join(model_path, 'sba_2b_20220901.sav'), 'rb'))\n",
    "    df['sba_2b'] = sba_2b_reg.predict(df[['sba_imp']])\n",
    "\n",
    "    sba_3b_reg = pickle.load(open(os.path.join(model_path, 'sba_3b_20220901.sav'), 'rb'))\n",
    "    df['sba_3b'] = sba_3b_reg.predict(df[['sba_imp']])\n",
    "\n",
    "    sb_2b_reg = pickle.load(open(os.path.join(model_path, 'sb_2b_20220901.sav'), 'rb'))\n",
    "    df['sb_2b'] = sb_2b_reg.predict(df[['sbr']])\n",
    "\n",
    "    sb_3b_reg = pickle.load(open(os.path.join(model_path, 'sb_3b_20220901.sav'), 'rb'))\n",
    "    df['sb_3b'] = sb_3b_reg.predict(df[['sbr']])\n",
    "       \n",
    "    # Merge with chadwick to fix certain fangraphs ids \n",
    "    df = df.merge(chadwick, left_on='mlbamid', right_on='key_mlbam', how='left')\n",
    "    # df['key_fangraphs'] = df['key_fangraphs'].astype('int', errors='ignore')\n",
    "    df['playerid'] = np.where(df['playerid'].str.startswith(\"sa\") & ~df['key_fangraphs'].isna(), df['key_fangraphs'], df['playerid'])\n",
    "    df['playerid'] = df['playerid'].astype('string')\n",
    "    df['playerid'] = df['playerid'].str.replace(r'\\.0', '', regex=True)\n",
    "        \n",
    "    df.drop(columns={'index', 'key_fangraphs', 'key_mlbam', 'name_first', 'name_last'}, inplace=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caaace8c-a39a-48b3-9247-4a6926396a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_intermediate_pitchers(date):\n",
    "    # Read in file\n",
    "    filename = \"Pitchers_FG_\" + date + \".csv\"\n",
    "    df = pd.read_csv(os.path.join(baseball_path, \"A5. Stats - 1. FanGraphs\", \"Pitchers\", filename), encoding='iso-8859-1')\n",
    "    \n",
    "    df['H/9'] = df['H'] / df['IP'] * 9\n",
    "    df['HR/9'] = df['HR'] / df['IP'] * 9\n",
    "\n",
    "    # This is for manual changes to playerids. This occurred because Drey Jameson has a \"real\" playerid when looking back but doesn't have one in FG data from that day\n",
    "    df['playerid'] = np.where(df['Name'] == \"Drey Jameson\", \"26260\", df['playerid'])\n",
    "    \n",
    "    \n",
    "    keep_list = ['playerid', 'mlbamid', 'H/9', 'HR/9', 'K/9', 'BB/9'] \n",
    "    df = df[keep_list]\n",
    "    \n",
    "    # Merge with chadwick to fix certain fangraphs ids \n",
    "    df = df.merge(chadwick, left_on='mlbamid', right_on='key_mlbam', how='left')\n",
    "    # df['key_fangraphs'] = df['key_fangraphs'].astype('int', errors='ignore')\n",
    "    df['playerid'] = np.where(df['playerid'].str.startswith(\"sa\") & ~df['key_fangraphs'].isna(), df['key_fangraphs'], df['playerid'])\n",
    "    df['playerid'] = df['playerid'].astype('string')\n",
    "    df['playerid'] = df['playerid'].str.replace(r'\\.0', '', regex=True)\n",
    "    \n",
    "    df.drop(columns={'index', 'key_fangraphs', 'key_mlbam', 'name_first', 'name_last'}, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4a8143-8d14-44db-a4fc-ee5357038449",
   "metadata": {},
   "source": [
    "# Create Rosters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77fc9b82-1b1c-45b7-9f60-fb371e28a479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_team_rosters(date=todaysdate):\n",
    "    # Create new folder with daily rosters\n",
    "    team_folder = \"Daily\" + date\n",
    "    try:\n",
    "        os.mkdir(os.path.join(baseball_path, \"A5. Stats - 2. Teams\", team_folder))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Locate daily rosters\n",
    "    rosters_folder = \"Rosters\" + date\n",
    "    rosters_path = os.path.join(baseball_path, \"A2. Rosters\", rosters_folder)\n",
    "    \n",
    "    # Read in batter stats from API\n",
    "    batter_filename = \"Batters\" + date + \".csv\"\n",
    "    batters_api = pd.read_csv(os.path.join(baseball_path, \"A4. Dataset\", \"Batters\", batter_filename), encoding='iso-8859-1')\n",
    "\n",
    "    # And from FG\n",
    "    batters = create_intermediate_batters(date)\n",
    "    \n",
    "    # Read in pitcher stats from API\n",
    "    pitcher_filename = \"Pitchers\" + date + \".csv\"\n",
    "    pitchers_api = pd.read_csv(os.path.join(baseball_path, \"A4. Dataset\", \"Pitchers\", pitcher_filename), encoding='iso-8859-1')\n",
    "\n",
    "    # And from FG\n",
    "    pitchers = create_intermediate_pitchers(date)\n",
    "    \n",
    "    for filename in os.listdir(rosters_path):\n",
    "        print(filename)\n",
    "        # Read in roster\n",
    "        df = pd.read_csv(os.path.join(rosters_path, filename), encoding='iso-8859-1')\n",
    "\n",
    "        # Destination     \n",
    "        excel_file = filename.replace(\".csv\", \"\")\n",
    "        excel_file = excel_file + \".xlsx\"\n",
    "        file_name = os.path.join(baseball_path, \"A5. Stats - 2. Teams\", team_folder, excel_file)\n",
    "\n",
    "\n",
    "        ### Batters\n",
    "        # Merge with stats from MLB API\n",
    "        # We want a left merge because players in first game won't be in API data\n",
    "        batter_df = df.merge(batters_api, left_on='id', right_on='batter', how='left', suffixes=(\"\", \"_api\"))\n",
    "\n",
    "        # Convert fangraphs ID to string \n",
    "        batter_df = batter_df[~batter_df['key_fangraphs'].isna()].reset_index(drop=True)\n",
    "        batter_df['key_fangraphs'] = batter_df['key_fangraphs'].astype('string')\n",
    "        batter_df['key_fangraphs'] = batter_df['key_fangraphs'].str.replace(r'\\.\\d', \"\", regex=True) # This shouldn't be necessary but is right now\n",
    "        # Create dummy variable for if they're a lefty. This is necessary to project.\n",
    "        batter_df['b_L'] = np.where(batter_df['batSide'] == \"L\", 1, 0)\n",
    "        # Get fangraphs projections\n",
    "        # We want an inner merge because everyone should be in fangraphs data (or we don't care about them anyway!) - changed to left\n",
    "        batters_merged = batter_df.merge(batters, left_on='key_fangraphs', right_on='playerid', how='inner')\n",
    "\n",
    "\n",
    "        # Predict stats\n",
    "        # Vs. left-handed pitchers\n",
    "        # print(batters_merged)\n",
    "        # print(batters_merged)\n",
    "        vs_lhp_preds = fg_vs_lhp.predict_proba(batters_merged[['b_L', 'b1_rate', 'b2_rate', 'b3_rate', 'hr_rate', 'bb_rate', 'hbp_rate', 'so_rate']])\n",
    "        vs_lhp_df = pd.DataFrame(vs_lhp_preds, columns=fg_vs_lhp.classes_)\n",
    "\n",
    "        vs_lhp_df['woba'] = woba_reg.predict(vs_lhp_df[simple_list])\n",
    "        vs_lhp_df['obp'] = obp_reg.predict(vs_lhp_df[simple_list])\n",
    "        vs_lhp_df['slg'] = slg_reg.predict(vs_lhp_df[simple_list])\n",
    "\n",
    "        vs_lhp_df = vs_lhp_df.add_suffix(\"_l\")\n",
    "\n",
    "        # Vs. right-handed pitchers\n",
    "        vs_rhp_preds = fg_vs_rhp.predict_proba(batters_merged[['b_L', 'b1_rate', 'b2_rate', 'b3_rate', 'hr_rate', 'bb_rate', 'hbp_rate', 'so_rate']])\n",
    "        vs_rhp_df = pd.DataFrame(vs_rhp_preds, columns=fg_vs_rhp.classes_)\n",
    "\n",
    "        vs_rhp_df['woba'] = woba_reg.predict(vs_rhp_df[simple_list])\n",
    "        vs_rhp_df['obp'] = obp_reg.predict(vs_rhp_df[simple_list])\n",
    "        vs_rhp_df['slg'] = slg_reg.predict(vs_rhp_df[simple_list])\n",
    "\n",
    "        vs_rhp_df = vs_rhp_df.add_suffix(\"_r\")\n",
    "\n",
    "        batters_df = pd.concat([batters_merged, vs_lhp_df, vs_rhp_df], axis=1)\n",
    "\n",
    "        # Save as Excel\n",
    "        batters_df.to_excel(file_name, sheet_name=\"Batters\", engine='openpyxl')\n",
    "\n",
    "\n",
    "        ### Pitchers\n",
    "        # Merge with stats from MLB API\n",
    "        # We want a left merge because players in first game won't be in API data\n",
    "        pitcher_df = df.merge(pitchers_api, left_on='id', right_on='pitcher', how='left', suffixes=(\"\", \"_api\"))\n",
    "\n",
    "        # Convert fangraphs ID to string \n",
    "        pitcher_df = pitcher_df[~pitcher_df['key_fangraphs'].isna()].reset_index(drop=True)\n",
    "        pitcher_df['key_fangraphs'] = pitcher_df['key_fangraphs'].astype('string')\n",
    "        pitcher_df['key_fangraphs'] = pitcher_df['key_fangraphs'].str.replace(r'\\.\\d', \"\", regex=True) # This shouldn't be necessary but is right now\n",
    "\n",
    "        # Create dummy variable for if they're a lefty. This is necessary to project.\n",
    "        pitcher_df['p_L'] = np.where(pitcher_df['pitchHand'] == \"L\", 1, 0)\n",
    "\n",
    "        # Get fangraphs projections\n",
    "        # We want an inner merge because everyone should be in fangraphs data (or we don't care about them anyway!) - changed to left\n",
    "        pitchers_merged = pitcher_df.merge(pitchers, left_on='key_fangraphs', right_on='playerid', how='inner')\n",
    "\n",
    "        # Predict stats\n",
    "        # Vs. left-handed pitchers\n",
    "        vs_lhb_preds = fg_vs_lhb.predict_proba(pitchers_merged[['p_L', 'H/9', 'HR/9', 'K/9', 'BB/9']])\n",
    "        vs_lhb_df = pd.DataFrame(vs_lhb_preds, columns=fg_vs_lhb.classes_)\n",
    "\n",
    "        vs_lhb_df['woba'] = woba_reg.predict(vs_lhb_df[simple_list])\n",
    "        vs_lhb_df['obp'] = obp_reg.predict(vs_lhb_df[simple_list])\n",
    "        vs_lhb_df['slg'] = slg_reg.predict(vs_lhb_df[simple_list])\n",
    "\n",
    "        vs_lhb_df = vs_lhb_df.add_suffix(\"_l\")\n",
    "\n",
    "        # Vs. right-handed pitchers\n",
    "        vs_rhb_preds = fg_vs_rhb.predict_proba(pitchers_merged[['p_L', 'H/9', 'HR/9', 'K/9', 'BB/9']])\n",
    "        vs_rhb_df = pd.DataFrame(vs_rhb_preds, columns=fg_vs_rhb.classes_)\n",
    "\n",
    "        vs_rhb_df['woba'] = woba_reg.predict(vs_rhb_df[simple_list])\n",
    "        vs_rhb_df['obp'] = obp_reg.predict(vs_rhb_df[simple_list])\n",
    "        vs_rhb_df['slg'] = slg_reg.predict(vs_rhb_df[simple_list])\n",
    "\n",
    "        vs_rhb_df = vs_rhb_df.add_suffix(\"_r\")\n",
    "\n",
    "        pitchers_df = pd.concat([pitchers_merged, vs_lhb_df, vs_rhb_df], axis=1)\n",
    "\n",
    "        with pd.ExcelWriter(file_name, mode='a', engine='openpyxl') as writer:  \n",
    "            pitchers_df.to_excel(writer, sheet_name='Pitchers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1e39a11-07bc-4ceb-806d-c28df9bcdf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI20230426.csv\n",
      "ATL20230426.csv\n",
      "BAL20230426.csv\n",
      "BOS20230426.csv\n",
      "CHC20230426.csv\n",
      "CHW20230426.csv\n",
      "CIN20230426.csv\n",
      "CLE20230426.csv\n",
      "COL20230426.csv\n",
      "DET20230426.csv\n",
      "HOU20230426.csv\n",
      "KCR20230426.csv\n",
      "LAA20230426.csv\n",
      "LAD20230426.csv\n",
      "MIA20230426.csv\n",
      "MIL20230426.csv\n",
      "MIN20230426.csv\n",
      "NYM20230426.csv\n",
      "NYY20230426.csv\n",
      "OAK20230426.csv\n",
      "PHI20230426.csv\n",
      "PIT20230426.csv\n",
      "SDP20230426.csv\n",
      "SEA20230426.csv\n",
      "SFG20230426.csv\n",
      "STL20230426.csv\n",
      "TBR20230426.csv\n",
      "TEX20230426.csv\n",
      "TOR20230426.csv\n",
      "WSN20230426.csv\n"
     ]
    }
   ],
   "source": [
    "create_team_rosters(todaysdate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caa61d6-1e98-44ea-ad15-5ba7548fcd74",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Run All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef8d0a84-b779-423f-8589-1a01c4a5b059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loop over dates that we have fangraphs projections for\n",
    "# for filename in os.listdir(r\"C:\\Users\\james\\Documents\\MLB\\Data\\FanGraphs\\Batters\"):\n",
    "#     date = filename[11:19]\n",
    "#     print(date)\n",
    "#     try:\n",
    "#         create_team_rosters(date)\n",
    "#     except:\n",
    "#         print(\"it didn't work\")\n",
    "#     # create_team_rosters(date) \n",
    "    \n",
    "# # Breaks at 1003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "029e1b21-bcb6-451e-afd0-068b96acfc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code was last run on: 2023-04-26 at 18:10:23.\n"
     ]
    }
   ],
   "source": [
    "print(\"Code was last run on: {} at {}.\".format(datetime.date.today(), datetime.datetime.now().strftime(\"%H:%M:%S\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
