{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5527c04d-632c-4c1a-a1bc-14b1064d47bc",
   "metadata": {},
   "source": [
    "# 4. Dataset\n",
    "Source: <br>\n",
    "1. '4. MLB API <br>\n",
    "\n",
    "Description: This creates usable datasets from the MLB API data <br>\n",
    "Main outputs include batter and pitcher model inputs, neural network PA inputs, and a complete dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3454c60a-b710-4a19-afd3-018f0be8cd25",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a7be679-7090-48c9-b149-8a2adfff590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import warnings\n",
    "import re\n",
    "import datetime\n",
    "import ast\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\james\\Documents\\MLB\\Code\")\n",
    "from Utilities import *\n",
    "\n",
    "# import import_ipynb\n",
    "# from Utilities import *\n",
    "\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "baseball_path = r\"C:\\Users\\james\\Documents\\MLB\\Data2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4de962a-8387-4519-ad38-0e22c6fe3346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Today's Date\n",
    "# YYYY-MM-DD (datetime)\n",
    "todaysdate_dt = datetime.date.today()\n",
    "\n",
    "# YYYY-MM-DD (string)\n",
    "todaysdate_dash = str(todaysdate_dt)\n",
    "\n",
    "# MM/DD/YYYY\n",
    "todaysdate_slash = todaysdate_dash.split(\"-\")\n",
    "todaysdate_slash = todaysdate_slash[1] + \"/\" + todaysdate_slash[2] + \"/\" + todaysdate_slash[0]\n",
    "\n",
    "# YYYYMMDD\n",
    "todaysdate = todaysdate_dash.replace(\"-\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "365b12b2-a7c2-45cf-9502-5e1e3089cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This reads in Chadwick register with player codes.\n",
    "# Let's move this to Utilities and either make compatible with name_clean or make a separate one (mostly done in chadwick now)\n",
    "keep_list = ['key_mlbam', 'key_fangraphs', 'name_first', 'name_last']\n",
    "chadwick = read_chadwick(keep_list)\n",
    "\n",
    "# Take first two characters of first name\n",
    "chadwick['First2'] = chadwick['name_first'].str.slice(0,2)\n",
    "# And first 5 characters of last name\n",
    "chadwick['Last5'] = chadwick['name_last'].str.slice(0,5)\n",
    "\n",
    "# Make lower case\n",
    "chadwick['First2'] = chadwick['First2'].str.lower()\n",
    "chadwick['Last5'] = chadwick['Last5'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17b37b4-91ed-4846-8b3b-a54887ac667d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3133f248-3dfa-42e4-92e4-dc77346b2a17",
   "metadata": {},
   "source": [
    "### Wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fb7cc7f-df83-4ffd-a8f6-6be7b8791d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate wind vectors\n",
    "# Note: 2 is to centerfield, 6 is from centerfield, clockwise\n",
    "# Note: y vector is positive to centerfield, negative from centerfield\n",
    "# Note: x vector is positive from left to right, negatives from right to left\n",
    "# Assumption is wind is blowing in 8 cardinal directions, so we can use simple right isosceles triangles\n",
    "def y_vect(df):\n",
    "    wind_speed = df['windSpeed']\n",
    "    angled = df['windSpeed'] / 2 * math.sqrt(2)\n",
    "    \n",
    "    if df['windDirection'] == \"Out To CF\": \n",
    "        y_vect = wind_speed\n",
    "    elif df['windDirection'] == \"Out To RF\": \n",
    "        y_vect = angled\n",
    "    elif df['windDirection'] == \"L To R\": \n",
    "        y_vect = 0\n",
    "    elif df['windDirection'] == \"In From LF\": \n",
    "        y_vect = angled * -1\n",
    "    elif df['windDirection'] == \"In From CF\": \n",
    "        y_vect = wind_speed * - 1\n",
    "    elif df['windDirection'] == \"In From RF\": \n",
    "        y_vect = angled * -1\n",
    "    elif df['windDirection'] == \"R To L\": \n",
    "        y_vect = 0\n",
    "    elif df['windDirection'] == \"Out To LF\": \n",
    "        y_vect = angled\n",
    "    else:\n",
    "        y_vect = 0\n",
    "        \n",
    "    return y_vect\n",
    "\n",
    "def x_vect(df):\n",
    "    wind_speed = df['windSpeed']\n",
    "    angled = df['windSpeed'] / 2 * math.sqrt(2)\n",
    "    \n",
    "    if df['windDirection'] == \"L To R\": \n",
    "        x_vect = wind_speed\n",
    "    elif df['windDirection'] == \"In From LF\": \n",
    "        x_vect = angled\n",
    "    elif df['windDirection'] == \"In From CF\": \n",
    "        x_vect = 0\n",
    "    elif df['windDirection'] == \"In From RF\": \n",
    "        x_vect = angled * -1\n",
    "    elif df['windDirection'] == \"R To L\": \n",
    "        x_vect = wind_speed * - 1\n",
    "    elif df['windDirection'] == \"Out To LF\": \n",
    "        x_vect = angled * -1\n",
    "    elif df['windDirection'] == \"Out To CF\": \n",
    "        x_vect = 0\n",
    "    elif df['windDirection'] == \"Out To RF\": \n",
    "        x_vect = angled\n",
    "    else:\n",
    "        x_vect = 0\n",
    "        \n",
    "    return x_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0ad0c6-70e2-4b0c-b337-6da96c19c7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52bdc969-2557-46e7-a82d-16285b3b2900",
   "metadata": {},
   "source": [
    "### Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad560891-c573-4b54-a69c-c6655df0910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_weather(df):\n",
    "    # Separate weather into temperature and weather type\n",
    "    df[['temperature', 'weather']] = df['weather'].str.split(\", \", expand=True)\n",
    "    df['temperature'] = df['temperature'].str.replace(\" degrees\", \"\").astype('int')\n",
    "    # Separate wind into speed and direction\n",
    "    df[['windSpeed', 'windDirection']] = df['wind'].str.split(\", \", expand=True)\n",
    "    df['windSpeed'].fillna(\"0 mph\", inplace=True)\n",
    "    df['windSpeed'] = df['windSpeed'].str.replace(\" mph\", \"\")\n",
    "    df['windSpeed'] = pd.to_numeric(df['windSpeed'], errors='coerce')\n",
    "    df['windSpeed'].fillna(0, inplace=True)\n",
    "    df['windDirection'].fillna('L to R', inplace=True)\n",
    "    df['windSpeed'].unique()\n",
    "    df['windDirection'] = df['windDirection'].str.replace(\".\", \"\")\n",
    "    # Calculate vectors\n",
    "    df['x_vect'] = df.apply(x_vect, axis=1)\n",
    "    df['y_vect'] = df.apply(y_vect, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d65ff0-e3c7-411d-a496-f4c253d38017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa644436-584e-475a-b02b-c1ee57c12599",
   "metadata": {},
   "source": [
    "### Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9ad4be9-bd9a-49e1-bc97-c8a22069919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_events(df):\n",
    "    df['eventsModel'] = np.where(df['event'] == 'Strikeout', \"so\", \"\")\n",
    "    df['eventsModel'] = np.where(df['event'] == 'Strikeout Double Play', \"so\", df['eventsModel'])\n",
    "\n",
    "    df['eventsModel'] = np.where(df['event'] == 'Groundout', \"go\", df['eventsModel'])\n",
    "    df['eventsModel'] = np.where(df['event'] == 'Fielders Choice', \"go\", df['eventsModel'])\n",
    "    df['eventsModel'] = np.where(df['event'] == 'Double Play', \"go\", df['eventsModel'])\n",
    "    df['eventsModel'] = np.where(df['event'] == 'Grounded Into DP', \"go\", df['eventsModel'])\n",
    "    df['eventsModel'] = np.where(df['event'] == 'Triple Play', \"go\", df['eventsModel'])\n",
    "    df['eventsModel'] = np.where(df['event'] == 'Field Error', \"go\", df['eventsModel'])\n",
    "    df['eventsModel'] = np.where(df['event'] == 'Forceout', \"go\", df['eventsModel'])\n",
    "\n",
    "\n",
    "    df['eventsModel'] = np.where(df['event'] == 'Lineout', \"lo\", df['eventsModel'])\n",
    "    df['eventsModel'] = np.where(df['event'] == 'Bunt Lineout', \"lo\", df['eventsModel'])\n",
    "\n",
    "    df['eventsModel'] = np.where(df['event'] == 'Flyout', \"fo\", df['eventsModel'])\n",
    "    df['eventsModel'] = np.where(df['event'] == 'Sac Fly', \"fo\", df['eventsModel'])\n",
    "    df['eventsModel'] = np.where(df['event'] == 'Sac Fly Double Play', \"fo\", df['eventsModel'])\n",
    "\n",
    "    df['eventsModel'] = np.where(df['event'] == 'Pop Out', \"po\", df['eventsModel'])\n",
    "    df['eventsModel'] = np.where(df['event'] == 'Bunt Pop Out', \"po\", df['eventsModel'])\n",
    "\n",
    "\n",
    "    df['eventsModel'] = np.where(df['event'] == 'Hit By Pitch', \"hbp\", df['eventsModel'])\n",
    "\n",
    "    df['eventsModel'] = np.where(df['event'] == 'Walk', \"bb\", df['eventsModel'])\n",
    "    df['eventsModel'] = np.where(df['event'] == 'Intent Walk', \"bb\", df['eventsModel'])\n",
    "\n",
    "    df['eventsModel'] = np.where(df['event'] == 'Single', \"b1\", df['eventsModel'])\n",
    "    df['eventsModel'] = np.where(df['event'] == 'Double', \"b2\", df['eventsModel'])\n",
    "    df['eventsModel'] = np.where(df['event'] == 'Triple', \"b3\", df['eventsModel'])\n",
    "    df['eventsModel'] = np.where(df['event'] == 'Home Run', \"hr\", df['eventsModel'])\n",
    "\n",
    "    df['eventsModel'] = np.where(df['eventsModel'] == \"\", \"Cut\", df['eventsModel'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8d6f73-8bd8-4e80-8650-eabc1641c874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a69ff98f-fa1f-46c0-b411-a164afcf1383",
   "metadata": {},
   "source": [
    "### Base Running\n",
    "(Perhaps move elsewhere)\n",
    "Calculate SBA2B%, SBA3B%, SB2B%, SB3B%\n",
    "Calculate SB and CS totals\n",
    "Derive new stats: \n",
    "    SBrate = SB / (SB + CS)\n",
    "    SBArate = (SB + CS) / (BB + HBP + 1B)\n",
    "\n",
    "Use actual data for these derived stats (from API) to project the four base running stats\n",
    "    Observations should be player-seasons, but only use full seasons\n",
    "Calculate derived stats in fangraphs projections\n",
    "Use model to predict four base running stats in the fangraphs projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36401d18-9e4d-414b-9269-0ec413a0e9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This turns several variables, including events, venues, hands, and bases into dummies\n",
    "def create_dummies(df):\n",
    "    event_dummies = pd.get_dummies(df['eventsModel'])\n",
    "    venue_dummies = pd.get_dummies(df['venue_id'], prefix='venue')\n",
    "    pitcher_dummies = pd.get_dummies(df['pitchHand'], prefix='p')\n",
    "    batter_dummies = pd.get_dummies(df['batSide'], prefix='b')\n",
    "    year_dummies = pd.get_dummies(df['year'], prefix='year')\n",
    "    \n",
    "    venue_list = venue_dummies.columns.tolist()\n",
    "    year_list = year_dummies.columns.tolist()\n",
    "    dummy_list = venue_list + year_list\n",
    "    \n",
    "    df = pd.concat([df, event_dummies, venue_dummies, pitcher_dummies, batter_dummies, year_dummies], axis=1)\n",
    "    \n",
    "    df['preOnFirst'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnFirst'].shift(1)\n",
    "    df['preOnSecond'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnSecond'].shift(1)\n",
    "    df['preOnThird'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnThird'].shift(1)\n",
    "    \n",
    "    df['onFirst'] = df['preOnFirst'].notnull().astype('int')\n",
    "    df['onSecond'] = df['preOnSecond'].notnull().astype('int')\n",
    "    df['onThird'] = df['preOnThird'].notnull().astype('int')\n",
    "    \n",
    "    df['top'] = np.where(df['halfInning'] == \"top\", 1, 0)\n",
    "    \n",
    "    df['pa'] = np.where(df['eventsModel'] != \"Cut\", 1, 0)\n",
    "    df['ab'] = df['pa'] - df['hbp']\n",
    "    \n",
    "    return df, dummy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c75993-5eaf-48c6-8a48-1bb188df6ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2dc99212-b89e-4178-b69d-ac3f8837bfd9",
   "metadata": {},
   "source": [
    "### Rolling Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd06dade-8189-45bd-bf84-fd2032f01cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return a dataframe that can eventually be used as the model input. Has pitcher vs hitter stats, specific to hand\n",
    "def rolling_pas(df, pa_num):\n",
    "    stat_list = ['so', 'b1', 'b2', 'b3', 'hr', 'bb', 'hbp', 'lo', 'po', 'go', 'fo', 'hard_hit', 'to_left', 'to_middle', 'to_right', 'pa', 'ab']\n",
    "    max_list = ['totalDistance', 'maxSpeed', 'maxSpin', 'launchSpeed']\n",
    "                \n",
    "    df['pa_num'] = df.index\n",
    "    \n",
    "    batter_stats = []\n",
    "    pitcher_stats = []\n",
    "    batter_stats2 = []\n",
    "    pitcher_stats2 = []\n",
    "\n",
    "    for stat in stat_list:\n",
    "        batter_stat = stat + \"_b\"\n",
    "        pitcher_stat = stat + \"_p\"\n",
    "        batter_stats.append(batter_stat)\n",
    "        pitcher_stats.append(pitcher_stat)\n",
    "\n",
    "    for stat in max_list:\n",
    "        batter_stat = stat + \"_b\"\n",
    "        pitcher_stat = stat + \"_p\"\n",
    "        batter_stats2.append(batter_stat)\n",
    "        pitcher_stats2.append(pitcher_stat)\n",
    "        \n",
    "    df[batter_stats] = df.groupby(['batter', 'pitchHand'])[stat_list].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).sum())\n",
    "    df[batter_stats2] = df.groupby(['batter', 'pitchHand'])[max_list].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).max())\n",
    "                \n",
    "    df[pitcher_stats] = df.groupby(['pitcher', 'batSide'])[stat_list].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).sum())\n",
    "    df[pitcher_stats2] = df.groupby(['pitcher', 'batSide'])[max_list].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).max())\n",
    "                \n",
    "    df.sort_values(['pa_num'], axis=0, ascending=True, inplace=True)\n",
    "\n",
    "    # wOBA - using 2022 values throughout\n",
    "    df['woba_b'] = (0.690 * df['bb_b']) + (0.721 * df['hbp_b']) + (0.885 * df['b1_b']) + (1.262 * df['b2_b']) + (1.601 * df['b3_b']) + (2.070 * df['hr_b'])\n",
    "    df['woba_p'] = (0.690 * df['bb_p']) + (0.721 * df['hbp_p']) + (0.885 * df['b1_p']) + (1.262 * df['b2_p']) + (1.601 * df['b3_p']) + (2.070 * df['hr_p'])\n",
    "    \n",
    "    # Slugging\n",
    "    df['slg_b'] = (1 * df['b1_b']) + (2 * df['b2_b']) + (3 * df['b3_b']) + (4 * df['hr_b'])\n",
    "    df['slg_b'] = df['slg_b'] / df['ab_b']\n",
    "    df['slg_p'] = (1 * df['b1_p']) + (2 * df['b2_p']) + (3 * df['b3_p']) + (4 * df['hr_p'])\n",
    "    df['slg_p'] = df['slg_p'] / df['ab_p']\n",
    "\n",
    "    # OBP    \n",
    "    df['obp_b'] = df[['b1_b', 'b2_b', 'b3_b', 'hr_b', 'bb_b', 'hbp_b']].sum(axis=1)\n",
    "    df['obp_p'] = df[['b1_p', 'b2_p', 'b3_p', 'hr_p', 'bb_p', 'hbp_p']].sum(axis=1)\n",
    "    \n",
    "    # ISO\n",
    "    df['iso_b'] = df['b2_b'] * 1 + df['b3_b'] * 2 + df['hr_b'] * 3\n",
    "    df['iso_p'] = df['b2_p'] * 1 + df['b3_p'] * 2 + df['hr_p'] * 3\n",
    "\n",
    "    \n",
    "    \n",
    "    # Calculate rates\n",
    "    stat_short = ['so', 'b1', 'b2', 'b3', 'hr', 'bb', 'hbp', 'lo', 'po', 'go', 'fo', 'woba', 'obp', 'iso', 'hard_hit', 'to_left', 'to_middle', 'to_right']\n",
    "    for stat in stat_short:\n",
    "        batter_stat = stat + \"_b\"\n",
    "        pitcher_stat = stat + \"_p\"  \n",
    "        df[batter_stat] = df[batter_stat] / df['pa_b']\n",
    "        df[pitcher_stat] = df[pitcher_stat] / df['pa_p']\n",
    "        \n",
    "    df.sort_values('pa_num', inplace=True)\n",
    "    \n",
    "    batter_stats = batter_stats + batter_stats2\n",
    "    pitcher_stats = pitcher_stats + pitcher_stats2\n",
    "                \n",
    "    return df, batter_stats, pitcher_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3156d38-d585-41c8-98dd-d6fce4e8f76a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e285989-cdf0-4eae-a27c-0ddee3d81bd1",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b135b741-f94a-4270-abd7-f3885734d723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This reads in raw API data\n",
    "def import_data(start_year, end_year):\n",
    "    year_df_list = []\n",
    "    while start_year <= end_year:\n",
    "        # Choose file\n",
    "        filename = \"Play\" + str(start_year) + \".csv\"\n",
    "        \n",
    "        # Read in dataframe\n",
    "        year_df = pd.read_csv(os.path.join(baseball_path, \"3. MLB API\", filename))\n",
    "        \n",
    "        # Only keep one observation per PA (don't keep each runner)\n",
    "        year_df.drop_duplicates(['gamePk', 'atBatIndex'], keep='first', inplace=True, ignore_index=True)\n",
    "\n",
    "        # Create year variable \n",
    "        year_df['year'] = start_year\n",
    "        \n",
    "        # Add it to list of dataframes\n",
    "        year_df_list.append(year_df)\n",
    "                \n",
    "        start_year += 1\n",
    "        \n",
    "    df = pd.concat(year_df_list, axis=0)\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    df = df[df['game_type'] == \"R\"]\n",
    "    df.reset_index(inplace=True)\n",
    "    df.drop(columns={'level_0', 'index'}, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47f4dc0-45e6-4ec2-8ffd-4c40d0a378c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "febc92f5-0d52-4b06-ba02-b24dad9378eb",
   "metadata": {},
   "source": [
    "### Model Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "473defad-26e4-4749-9651-6d80944ecd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statcast(df):\n",
    "    statcast = df.copy()\n",
    "    # Hard hit dummy\n",
    "    statcast['hard_hit'] = (statcast['hardness'].str.contains('hard')).astype('int')\n",
    "    \n",
    "    def find_max(lst):\n",
    "        if lst:\n",
    "            return max(lst)\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    # Max pitch speed\n",
    "    statcast['startSpeeds'] = statcast['startSpeeds'].apply(lambda x: ast.literal_eval(x))\n",
    "    statcast['maxSpeed'] = statcast['startSpeeds'].apply(find_max)\n",
    "    # Have to drop, can't take lists\n",
    "    statcast.drop(columns={'startSpeeds'}, inplace=True)\n",
    "    \n",
    "    # Max spin rate\n",
    "    statcast['spinRates'] = statcast['spinRates'].apply(lambda x: ast.literal_eval(x))\n",
    "    statcast['maxSpin'] = statcast['spinRates'].apply(find_max)\n",
    "    # Have to drop, can't take lists\n",
    "    statcast.drop(columns={'spinRates'}, inplace=True)\n",
    "    \n",
    "    # Launch speeds\n",
    "    statcast['launchSpeeds'] = statcast['launchSpeeds'].str.replace(\"[\", \"\")\n",
    "    statcast['launchSpeeds'] = statcast['launchSpeeds'].str.replace(\"]\", \"\")\n",
    "    statcast['launchSpeed'] = (statcast['launchSpeeds']).astype('float', errors='ignore')\n",
    "    statcast['launchSpeed'] = pd.to_numeric(statcast['launchSpeed'])\n",
    "    \n",
    "    # Launch angle\n",
    "    statcast['launchAngles'] = statcast['launchAngles'].str.replace(\"[\", \"\")\n",
    "    statcast['launchAngles'] = statcast['launchAngles'].str.replace(\"]\", \"\")\n",
    "    statcast['launchAngle'] = (statcast['launchAngles']).astype('float', errors='ignore')\n",
    "    statcast['launchAngle'] = pd.to_numeric(statcast['launchAngle'])\n",
    "        \n",
    "    # Total distances\n",
    "    statcast['totalDistances'] = statcast['totalDistances'].str.replace(\"[\", \"\")\n",
    "    statcast['totalDistances'] = statcast['totalDistances'].str.replace(\"]\", \"\")\n",
    "    statcast['totalDistance'] = (statcast['totalDistances']).astype('float', errors='ignore')\n",
    "    statcast['totalDistance'] = pd.to_numeric(statcast['totalDistance'])\n",
    "    \n",
    "    # Coordinates of batted ball\n",
    "    statcast['coord'] = statcast['coord'].str.replace(\"[\", \"\")\n",
    "    statcast['coord'] = statcast['coord'].str.replace(\"]\", \"\")    \n",
    "    statcast[['x', 'y']] = statcast['coord'].str.split(\",\", expand=True)\n",
    "    statcast['x'] = pd.to_numeric(statcast['x'])\n",
    "    statcast['y'] = pd.to_numeric(statcast['y'])\n",
    "    \n",
    "    statcast['spray_angle'] = np.arctan((statcast['x']-125.42)/(198.27-statcast['y'])) * 180/np.pi * 0.75\n",
    "    statcast['to_left'] = (statcast['spray_angle'] < -15).astype('int')\n",
    "    statcast['to_middle'] = ((statcast['spray_angle'] >= -15) & (statcast['spray_angle'] <= 15)).astype('int')\n",
    "    statcast['to_right'] = (statcast['spray_angle'] > 15).astype('int')\n",
    "\n",
    "    \n",
    "    return statcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcf06a95-8372-4830-8ae4-1a197a31e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This converts raw data to clean model input\n",
    "def create_model_input(df, date):\n",
    "    keep_list = ['so_b', 'b1_b', 'b2_b', 'b3_b', 'hr_b', 'bb_b', 'hbp_b', 'lo_b', 'po_b', 'go_b', 'fo_b', 'pa_b', 'ab_b', \n",
    "                 'woba_b', 'slg_b', 'obp_b', 'iso_b', 'hard_hit_b', 'to_left_b', 'to_middle_b', 'to_right_b', 'totalDistance_b', 'maxSpeed_b', 'maxSpin_b', 'launchSpeed_b',\n",
    "                 'so_p', 'b1_p', 'b2_p', 'b3_p', 'hr_p', 'bb_p', 'hbp_p', 'lo_p', 'po_p', 'go_p', 'fo_p', 'pa_p', 'ab_p', \n",
    "                 'woba_p', 'slg_p', 'obp_p', 'iso_p', 'hard_hit_p', 'to_left_p', 'to_middle_p', 'to_right_p', 'totalDistance_p', 'maxSpeed_p', 'maxSpin_p', 'launchSpeed_p']\n",
    "    \n",
    "    \n",
    "    # df = clean_columns(df)\n",
    "    # Clean weather\n",
    "    df = clean_weather(df)\n",
    "    # Create events\n",
    "    df = create_events(df)\n",
    "    # Make dummies\n",
    "    df, dummy_list = create_dummies(df)\n",
    "    # Statcast\n",
    "    df = statcast(df)\n",
    "    \n",
    "    # Turn date into datetime object\n",
    "    date = datetime.datetime.strptime(date, \"%Y%m%d\")\n",
    "    \n",
    "    # Only keep if date is before selected date\n",
    "    df = df[df['date'] < date]\n",
    "    \n",
    "    # Determine score before PA\n",
    "    df['preAwayScore'] = df.groupby(['gamePk', 'inning', 'halfInning'])['awayScore'].shift(1)\n",
    "    df['preHomeScore'] = df.groupby(['gamePk', 'inning', 'halfInning'])['homeScore'].shift(1)\n",
    "    \n",
    "    df['preAwayScore'].fillna(df['awayScore'], inplace=True)\n",
    "    df['preHomeScore'].fillna(df['homeScore'], inplace=True)\n",
    "    \n",
    "    # Calculate score differential\n",
    "    df['score_diff'] = np.where(df['top'] == 1, df['preAwayScore'] - df['preHomeScore'], df['preHomeScore'] - df['preAwayScore'])\n",
    "    \n",
    "    # Cut if event isn't one we care about (usually these are weird base running things)\n",
    "    df = df[df['Cut'] != 1]\n",
    "\n",
    "    # Calculate short time frame rolling stats (100 PAs for now)\n",
    "    dfshort, batter_stats, pitcher_stats = rolling_pas(df, 100)\n",
    "    dfmain = dfshort.copy()\n",
    "    # Calculate long time frame rolling stats (300 PAs for now)\n",
    "    dflong, batter_stats, pitcher_stats = rolling_pas(df, 300)\n",
    "    dflong = dflong[keep_list]\n",
    "    dflong = dflong.add_suffix(\"_long\")\n",
    "    # Concat them together\n",
    "    df = pd.concat([dfmain, dflong], axis=1)\n",
    "            \n",
    "    # Delete intermediate DFs\n",
    "    del dfmain, dfshort, dflong\n",
    "\n",
    "    # For the purpose of creating a sample to train the model, only keep those PAs with significant data\n",
    "    # sample = df[((df['pa_p'] > 40) & (df['pa_b'] > 40)) & ((df['pa_p_long'] > 40) & (df['pa_b_long'] > 40)) ]\n",
    "    # sample.reset_index(inplace=True)\n",
    "    \n",
    "    ### Maybe pickle this?/save these means/stds?\n",
    "    # Standardize variables\n",
    "    standardize_list = ['totalDistance_b', 'maxSpeed_b', 'maxSpin_b', 'launchSpeed_b',  \n",
    "                        'totalDistance_b_long', 'maxSpeed_b_long', 'maxSpin_b_long', 'launchSpeed_b_long']\n",
    "    \n",
    "    for stat in standardize_list:\n",
    "        df[stat] = (df[stat] - df[stat].mean())/df[stat].std()\n",
    "    \n",
    "    # Standardize variables\n",
    "    standardize_list = ['totalDistance_p', 'maxSpeed_p', 'maxSpin_p', 'launchSpeed_p',\n",
    "                        'totalDistance_p_long', 'maxSpeed_p_long', 'maxSpin_p_long', 'launchSpeed_p_long']\n",
    "    \n",
    "    for stat in standardize_list:\n",
    "        df[stat] = (df[stat] - df[stat].mean())/df[stat].std()\n",
    "    \n",
    "    # Clean this later, maybe only keep df\n",
    "    sample = df.copy()\n",
    "    \n",
    "    \n",
    "    return sample, df, batter_stats, pitcher_stats, dummy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09238787-dd96-4e89-b4cb-dff3deb5e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batter inputs\n",
    "def create_batter_df(df, date):\n",
    "    # Stats of interest\n",
    "    batter_list = ['batter',  'batterName', 'batSide', 'p_L',\n",
    "     'so_b', 'b1_b', 'b2_b', 'b3_b', 'hr_b', 'bb_b', 'hbp_b', 'lo_b', 'po_b', 'go_b', 'fo_b', \n",
    "     'pa_b', 'ab_b', 'woba_b', 'slg_b', 'obp_b', 'iso_b', 'hard_hit_b', 'to_left_b', 'to_middle_b', 'to_right_b', \n",
    "     'totalDistance_b', 'maxSpeed_b', 'maxSpin_b', 'launchSpeed_b', \n",
    "     'so_b_long', 'b1_b_long', 'b2_b_long', 'b3_b_long', 'hr_b_long', 'bb_b_long', 'hbp_b_long', 'lo_b_long', 'po_b_long', 'go_b_long', 'fo_b_long', \n",
    "     'pa_b_long', 'ab_b_long', 'woba_b_long', 'slg_b_long', 'obp_b_long', 'iso_b_long', 'hard_hit_b_long', 'to_left_b_long', 'to_middle_b_long', 'to_right_b_long', \n",
    "     'totalDistance_b_long', 'maxSpeed_b_long', 'maxSpin_b_long', 'launchSpeed_b_long']\n",
    "\n",
    "    # Only keep relevant stats\n",
    "    batters = df[batter_list]\n",
    "    # Only care about most recent stats of each batter before PA\n",
    "    batters.drop_duplicates(subset=['batter', 'p_L'], keep='last', inplace=True)\n",
    "\n",
    "    # Create separate dataframes for vs RHP and LHP\n",
    "    vs_r = batters.query('p_L == 0')\n",
    "    vs_l = batters.query('p_L == 1')\n",
    "\n",
    "    # Merge them together\n",
    "    batters = vs_l.merge(vs_r, on='batter', how='outer', suffixes=('_l', '_r'))\n",
    "\n",
    "    # Drop duplicate columns\n",
    "    batters.drop(columns={'batterName_r', 'p_L_l', 'p_L_r'}, inplace=True)\n",
    "    # Only need this once\n",
    "    batters.rename(columns={'batterName_l': 'batterName'}, inplace=True)\n",
    "    \n",
    "    \n",
    "    # Merge with Chadwick\n",
    "    batters = batters.merge(chadwick, left_on='batter', right_on='key_mlbam', how='left')\n",
    "    \n",
    "    \n",
    "    # Export\n",
    "    batters.to_csv(os.path.join(baseball_path, \"4. Dataset\", \"Batters\", \"Batters\" + date + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca2446d6-a402-4488-ab96-795baf4c72d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pitcher inputs\n",
    "def create_pitcher_df(df, date):\n",
    "    # Stats of interest\n",
    "    pitcher_list =  ['pitcher',  'pitcherName', 'pitchHand', 'b_L',\n",
    "                     'b1_p', 'b2_p', 'b3_p', 'hr_p', 'bb_p', 'hbp_p', \n",
    "                     'so_p', 'lo_p', 'po_p', 'go_p', 'fo_p', \n",
    "                     'woba_p', 'slg_p', 'obp_p', 'iso_p',\n",
    "                     'to_left_p', 'to_middle_p', 'to_right_p', \n",
    "                     'hard_hit_p', 'maxSpeed_p', 'maxSpin_p', 'totalDistance_p', 'launchSpeed_p',\n",
    "                     'pa_p', 'ab_p',\n",
    "                     \n",
    "                     'b1_p_long', 'b2_p_long', 'b3_p_long', 'hr_p_long', 'bb_p_long', 'hbp_p_long', \n",
    "                     'so_p_long', 'lo_p_long', 'po_p_long', 'go_p_long', 'fo_p_long', \n",
    "                     'woba_p_long', 'slg_p_long', 'obp_p_long', 'iso_p_long', \n",
    "                     'to_left_p_long', 'to_middle_p_long', 'to_right_p_long',\n",
    "                     'hard_hit_p_long', 'maxSpeed_p_long', 'maxSpin_p_long', 'totalDistance_p_long', 'launchSpeed_p_long',\n",
    "                     'pa_p_long', 'ab_p_long', \n",
    "\n",
    "                     'inning', 'outs', 'gamePk', 'eventsModel', 'game_date']\n",
    "    \n",
    "    # Only keep relevant stats\n",
    "    pitchers = df[pitcher_list]\n",
    "    \n",
    "    # Calculate average outs\n",
    "    # Create a copy of the dataframe\n",
    "    pitchers_cut = pitchers.copy()\n",
    "    # Only look at PAs since 2019\n",
    "    pitchers_cut = pitchers_cut[pitchers_cut['game_date'] > '2019-04-01']\n",
    "    pitchers_cut.drop_duplicates(subset=['pitcher', 'gamePk', 'inning'], keep='last', inplace=True)\n",
    "    # Identify if they're a starter\n",
    "    pitchers_cut['starter'] = (pitchers_cut['inning'] == 1).astype('int')\n",
    "    # Add up starts\n",
    "    pitchers_cut = pitchers_cut.groupby(['pitcher', 'gamePk'])['outs', 'starter'].sum().reset_index()\n",
    "    # Calculate mean outs and sum of starts\n",
    "    pitchers_cut = pitchers_cut.groupby('pitcher').agg({'outs': np.mean, 'starter': np.sum}).reset_index()\n",
    "\n",
    "    # Only care about most recent stats of each pitcher before PA\n",
    "    pitchers.drop_duplicates(subset=['pitcher', 'b_L'], keep='last', inplace=True)\n",
    "    \n",
    "    # Create separate dataframes for vs RHB and LBH\n",
    "    vs_r = pitchers.query('b_L == 0')\n",
    "    vs_l = pitchers.query('b_L == 1')\n",
    "\n",
    "    # Merge them together\n",
    "    pitchers = vs_l.merge(vs_r, on='pitcher', how='outer', suffixes=('_l', '_r'))\n",
    "    # And add outs/starts\n",
    "    pitchers = pitchers.merge(pitchers_cut, on='pitcher', how='left')\n",
    "    \n",
    "    # Drop duplicate columns\n",
    "    pitchers.drop(columns={'pitcherName_r', 'b_L_l', 'b_L_r', 'inning_r', 'outs_r', 'gamePk_r', 'eventsModel_r', 'game_date_r',  'inning_l',\n",
    "                           'outs_l', 'gamePk_l', 'eventsModel_l', 'game_date_l'}, inplace=True)\n",
    "    # Only need this once\n",
    "    pitchers.rename(columns={'pitcherName_l': 'pitcherName'}, inplace=True)\n",
    "    \n",
    "    # Merge with Chadwick\n",
    "    pitchers = pitchers.merge(chadwick, left_on='pitcher', right_on='key_mlbam', how='left')\n",
    "    \n",
    "    # Take average number of batters faced\n",
    "    faced = df.copy()\n",
    "    faced['faced'] = 1\n",
    "    games = faced.groupby(['pitcher', 'gamePk'])['faced'].sum().reset_index()\n",
    "    games['avgFaced'] = games.groupby('pitcher')['faced'].rolling(30, min_periods=1).mean().shift().reset_index(level=0, drop=True)\n",
    "    games.drop_duplicates(subset=['pitcher'], keep='last', inplace=True)\n",
    "    games = games[['pitcher', 'avgFaced']]\n",
    "    \n",
    "    # Standardize variables\n",
    "    standardize_list = ['totalDistance_p_l', 'maxSpeed_p_l', 'maxSpin_p_l', 'launchSpeed_p_l', \n",
    "                        'totalDistance_p_r', 'maxSpeed_p_r', 'maxSpin_p_r', 'launchSpeed_p_r', \n",
    "                        'totalDistance_p_long_l', 'maxSpeed_p_long_l', 'maxSpin_p_long_l', 'launchSpeed_p_long_l', \n",
    "                        'totalDistance_p_long_r', 'maxSpeed_p_long_r', 'maxSpin_p_long_r', 'launchSpeed_p_long_r']\n",
    "    \n",
    "    for stat in standardize_list:\n",
    "        pitchers[stat] = (pitchers[stat] - pitchers[stat].mean())/pitchers[stat].std()\n",
    "    \n",
    "    pitchers = pitchers.merge(games, on='pitcher', how='inner')\n",
    "    \n",
    "    # Export    \n",
    "    pitchers.to_csv(os.path.join(baseball_path, \"4. Dataset\", \"Pitchers\", \"Pitchers\" + date + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2340bb43-c6d4-4973-ac7e-c2c2922281c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates inputs on a given date\n",
    "def create_datasets(df, date):\n",
    "    # Create data for model and data for model inputs (once model is built, sample won't really be needed)\n",
    "    sample, inputs, batter_stats, pitcher_stats, dummy_list = create_model_input(df, date)\n",
    "    # Create batter and pitcher csvfiles\n",
    "    create_batter_df(inputs, date)\n",
    "    create_pitcher_df(inputs, date)\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7f6be5-d899-46ee-a850-8d289b909f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6f5f39f-291d-4d4c-a3fe-d502e6088a4e",
   "metadata": {},
   "source": [
    "### Run One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "118c3447-d02f-4cd6-b7b6-4c57a8418d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = import_data(2019, 2023) # Changed to 2019 - keep full 2015- for training set below\n",
    "sample = create_datasets(df, todaysdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f0e434-c107-4021-99df-8c9696ee4b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed1f5a4e-1104-4804-a71e-1dc66da5f8b3",
   "metadata": {},
   "source": [
    "### Run All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4d95e9c-3929-4c36-ba27-12bfb0fce3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for filename in os.listdir(r\"C:\\Users\\james\\Documents\\MLB\\Data\\A7. Matchups - 1. Salaries\"): \n",
    "#     # 2023 \n",
    "#     if filename.endswith(\".csv\") and filename.startswith(\"DKSalaries_2023\"):\n",
    "#         # Pull out date\n",
    "#         date = filename[11:19]\n",
    "#         print(date)\n",
    "#         df = import_data(2019, 2023) # Changed to 2020 - keep full 2015- for training set below\n",
    "#         sample = create_datasets(df, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6643aa8a-2efa-40a2-b048-41892b193afc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2051d45b-284a-4d98-aeac-47321b0784e8",
   "metadata": {},
   "source": [
    "### Create Inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01ea7f2f-c11a-4316-ae69-15a389dacdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sample used for training PA model (import_date from 2015 onward)\n",
    "# sample.to_csv(os.path.join(baseball_path, \"Inputs\", \"Sample100.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "857fc768-0a49-4bd9-a088-4aa987be27a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Can we get rid of this?\n",
    "# # You probably don't need to run it again until a new park is created, but it does need to exist\n",
    "# # Park list (all park dummies)\n",
    "# parks = df[['home_name', 'venue_id']]\n",
    "# parks = parks.drop_duplicates().sort_values('home_name')\n",
    "# parks.to_csv(os.path.join(baseball_path, \"Inputs\", \"All Parks.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0611fac0-fe56-4607-bc5e-61372ca6d89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code was last run on: 2023-06-29 at 18:17:41.\n"
     ]
    }
   ],
   "source": [
    "print(\"Code was last run on: {} at {}.\".format(datetime.date.today(), datetime.datetime.now().strftime(\"%H:%M:%S\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
