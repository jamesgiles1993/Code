{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97889d6e-5f18-43ff-8d81-a6cbbe691269",
   "metadata": {},
   "source": [
    "# A02. MLB API\n",
    "This extracts DraftKings contest data and saves results\n",
    "- Type: Data\n",
    "- Run Frequency: Once daily\n",
    "- Sources:\n",
    "    - MLB Stats API\n",
    "    - Statcast (via pybaseball package)\n",
    "- Dates:\n",
    "    - Created: 9/23/2023\n",
    "    - Updated: 4/21/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041c0b22-acb7-45df-9c73-0960a5862b09",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f380c2-8a8b-4407-b42e-90c65b43ba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"running_pipeline\" not in globals():\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U1. Imports.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U2. Utilities.ipynb\"\n",
    "    %run \"C:\\Users\\james\\Documents\\MLB\\Code\\U3. Classes.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec551f4d-1de0-434c-97e4-b4dc5f8cb001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e1797f6-c309-49a2-ac51-5001bc8eac3d",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2efcd55-1e14-456d-a0f6-f5cf5498aa2e",
   "metadata": {},
   "source": [
    "If it's not a pipeline run or a run from A06B. Park and Weather Factors, assign a value to year and actually create the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98b673bf-17d1-4fac-b74d-47e52d6b4275",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (983997220.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    if \"running_pipeline\" not in globals() and \"running_weather\" not in globals() and :\u001b[0m\n\u001b[1;37m                                                                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "if all(var not in globals() for var in [\"running_pipeline\", \"running_weather\", \"running_base_runners\", \"running_steals\"]):\n",
    "    year = 2024\n",
    "    run_datasets = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb48ecf5-5fb3-4550-af9e-2f7015bed34d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd3afbf0-0fac-4007-908e-fdba481cc65d",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88a1b14-ddf6-4824-bdb0-7f50d2de4112",
   "metadata": {},
   "source": [
    "##### 1. MLB Stats API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11e4397-b0e0-48e1-9f9c-2de0bcbc40e4",
   "metadata": {},
   "source": [
    "Extract game information from boxscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eaaab5-d577-4cb0-a23d-d81bdbd82501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_box(gamePk):\n",
    "    # Read in boxscore as json\n",
    "    box = pd.json_normalize(statsapi.boxscore_data(gamePk, timecode=None), record_path='gameBoxInfo')\n",
    "    \n",
    "    # Define default values\n",
    "    default_weather = \"75 degrees, Clear.\"\n",
    "    default_wind = \"0 mph, L To R.\"\n",
    "    default_venue = \"Missing Park.\"\n",
    "    default_date = \"November 30, 1993\"\n",
    "    \n",
    "    # Extract weather, wind, venue, and date\n",
    "    weather = box.loc[box['label'] == \"Weather\", \"value\"].item() if 'Weather' in box['label'].values else default_weather\n",
    "    wind = box.loc[box['label'] == \"Wind\", \"value\"].item() if 'Wind' in box['label'].values else default_wind\n",
    "    venue = box.loc[box['label'] == \"Venue\", \"value\"].item() if 'Venue' in box['label'].values else default_venue\n",
    "    \n",
    "    try:\n",
    "        date = box.iloc[-1, box.columns.get_loc('label')]\n",
    "    except:\n",
    "        date = default_date\n",
    "\n",
    "    if \"Weather\" not in list(box['label']):\n",
    "        missing_weather = True\n",
    "    else:\n",
    "        missing_weather = False\n",
    "    \n",
    "    \n",
    "    return weather, wind, venue, date, missing_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f4402b-b9a8-4500-87d8-d34b6c3c43a4",
   "metadata": {},
   "source": [
    "Extract relevant data or provide default (helper function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbf769d-2eb2-4393-ac68-5fb6e2dfc8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_field(data, field, default=None):\n",
    "    try:\n",
    "        return data[field]\n",
    "    except:\n",
    "        return default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc726ecb-fcfa-49b5-8fd1-c96ff14380de",
   "metadata": {},
   "source": [
    "Extract play-by-play data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a26df1-70a9-43e6-b901-c009aa7cacd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_game(gamePk):\n",
    "    game = statsapi.get('game_playByPlay', {'gamePk': gamePk})\n",
    "    \n",
    "    # Create list with relevant variables\n",
    "    game_data = []\n",
    "    for play in game['allPlays']:\n",
    "        about = play['about']\n",
    "        count = play['count']\n",
    "        result = play['result']\n",
    "        matchup = play['matchup']\n",
    "        runners = play['runners']\n",
    "        \n",
    "        atBatIndex = about['atBatIndex']\n",
    "        inning = about['inning']\n",
    "        halfInning = about['halfInning']\n",
    "        outs = count['outs']\n",
    "        \n",
    "        type = extract_field(result, 'type')\n",
    "        event = extract_field(result, 'event')\n",
    "        eventType = extract_field(result, 'eventType')\n",
    "        description = extract_field(result, 'description')\n",
    "        rbi = extract_field(result, 'rbi', 0)\n",
    "        awayScore = extract_field(result, 'awayScore', 0)\n",
    "        homeScore = extract_field(result, 'homeScore', 0)\n",
    "        \n",
    "        batter = extract_field(matchup['batter'], 'id', 999999)\n",
    "        batterName = extract_field(matchup['batter'], 'fullName', 'Missing Name')\n",
    "        batSide = extract_field(matchup['batSide'], 'code', 'R')\n",
    "        pitcher = extract_field(matchup['pitcher'], 'id', 999999)\n",
    "        pitcherName = extract_field(matchup['pitcher'], 'fullName', 'Missing Name')\n",
    "        pitchHand = extract_field(matchup['pitchHand'], 'code', 'R')\n",
    "        \n",
    "        # Baserunner on base at the end of the play\n",
    "        postOnFirst = extract_field(matchup, 'postOnFirst', None)\n",
    "        postOnSecond = extract_field(matchup, 'postOnSecond', None)\n",
    "        postOnThird = extract_field(matchup, 'postOnThird', None)\n",
    "        \n",
    "        # Extract base runner information\n",
    "        for runner in runners:\n",
    "            details = runner['details']\n",
    "            movement = runner['movement']\n",
    "            \n",
    "            runner_id = details['runner']['id']\n",
    "            start = movement['start']\n",
    "            end = movement['end']\n",
    "            movementReason = details['movementReason']\n",
    "            isScoringEvent = details['isScoringEvent']\n",
    "            earned = details['earned']\n",
    "            \n",
    "            game_data.append([atBatIndex, inning, halfInning, outs, type, runner_id, event, eventType, description, \n",
    "                              rbi, awayScore, homeScore, batter, batterName, batSide, pitcher, pitcherName, pitchHand, \n",
    "                              postOnFirst, postOnSecond, postOnThird, runner_id, start, end, movementReason, isScoringEvent, earned])\n",
    "    \n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame(game_data, columns=['atBatIndex', 'inning', 'halfInning', 'outs', 'type', 'id', 'event', 'eventType', 'description', \n",
    "                                          'rbi', 'awayScore', 'homeScore', 'batter', 'batterName', 'batSide', 'pitcher', \n",
    "                                          'pitcherName', 'pitchHand', 'postOnFirst', 'postOnSecond', 'postOnThird', 'runner_id', 'start', 'end', 'movementReason', 'isScoringEvent', 'earned'])\n",
    " \n",
    "    # Create weather variables\n",
    "    weather, wind, venue, date, missing_weather = create_box(gamePk)\n",
    "    df['gamePk'] = gamePk\n",
    "    df['weather'] = weather\n",
    "    df['wind'] = wind\n",
    "    df['venue'] = venue\n",
    "    df['date'] = date\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb7e5ab-0ff0-496a-b600-739f91fdc0ee",
   "metadata": {},
   "source": [
    "Extract API data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560bfa6a-933b-4f2a-991e-5824f736c699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plays_statsapi(start_date, end_date):\n",
    "    # Extract year\n",
    "    year = start_date[-4:]\n",
    "    \n",
    "    # Read in schedule\n",
    "    games = statsapi.schedule(start_date=start_date, end_date=end_date)\n",
    "\n",
    "    # Use a list comprehension to extract unique game_ids\n",
    "    game_ids = list(game['game_id'] for game in games)\n",
    "    away_names = list(game['away_name'] for game in games)\n",
    "    home_names = list(game['home_name'] for game in games)\n",
    "    game_dates = list(game['game_date'] for game in games)\n",
    "    game_types = list(game['game_type'] for game in games)\n",
    "    venue_ids = list(game['venue_id'] for game in games)\n",
    "\n",
    "    # Run all in parallel\n",
    "    df_list = Parallel(n_jobs=-1, verbose=0)(delayed(create_game)(gamePk=game_id) for game_id in game_ids)\n",
    "\n",
    "    # Add additional information from schedule\n",
    "    for i in range(len(df_list)):\n",
    "        df_list[i]['away_name'] = away_names[i]\n",
    "        df_list[i]['home_name'] = home_names[i]\n",
    "        df_list[i]['game_date'] = game_dates[i]\n",
    "        df_list[i]['game_type'] = game_types[i]\n",
    "        df_list[i]['venue_id'] = venue_ids[i]\n",
    "    \n",
    "    # Append all dataframes together\n",
    "    df = pd.concat(df_list, axis=0)\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5008ae7-cd0e-4017-a433-d5ee20fc1d2b",
   "metadata": {},
   "source": [
    "##### 2. Statcast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db23055-c3e7-4c02-b3cc-7ba5fa571b71",
   "metadata": {},
   "source": [
    "Extract Statcast data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b1278d-8592-4f62-adb0-157c2c91e6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plays_statcast(start_date, end_date):\n",
    "    # Extract year\n",
    "    year = start_date[:4]\n",
    "    \n",
    "    # Use pybaseball to read in Statcast data\n",
    "    data = statcast(start_date, end_date)\n",
    "    \n",
    "    # Create atBatIndex compatible with Statsapi\n",
    "    data['atBatIndex'] = data['at_bat_number'] - 1 \n",
    "    \n",
    "    # Highest level during the at bat\n",
    "    data['maxSpeed'] = data.groupby(['game_pk', 'atBatIndex'])['effective_speed'].transform(max)\n",
    "    data['maxSpin'] = data.groupby(['game_pk', 'atBatIndex'])['release_spin_rate'].transform(max)\n",
    "    \n",
    "    # Convert to numeric for sorting\n",
    "    data['game_pk'] = data['game_pk'].astype('int')\n",
    "    data['atBatIndex'] = data['atBatIndex'].astype('int')\n",
    "    data['pitch_number'] = data['pitch_number'].astype('int')\n",
    "    \n",
    "    # Only want the deciding (last) pitch\n",
    "    data.sort_values(['game_pk', 'atBatIndex', 'pitch_number'], inplace=True)\n",
    "    data.drop_duplicates(['game_pk', 'atBatIndex'], keep='last', inplace=True)\n",
    "    \n",
    "    data.rename(columns={'game_pk':'gamePk'}, inplace=True)\n",
    "    \n",
    "    # Keep relevant variables\n",
    "    keep_list = ['gamePk', 'atBatIndex', 'pitch_number', 'pitch_name', 'game_type',\n",
    "                 'hc_x', 'hc_y', 'hit_location', 'hit_distance_sc', 'launch_speed', 'launch_angle', 'launch_speed_angle',\n",
    "                 'woba_value', 'woba_denom', 'estimated_ba_using_speedangle', 'estimated_woba_using_speedangle',\n",
    "                 'iso_value', 'babip_value',\n",
    "                 'maxSpeed', 'maxSpin']\n",
    "                \n",
    "    data = data[keep_list]\n",
    "\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63434032-97a4-4a86-b204-52d962905c77",
   "metadata": {},
   "source": [
    "##### 3. Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315d5b07-b494-4bfc-a154-90d60018de12",
   "metadata": {},
   "source": [
    "##### Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8152d3b-2c6c-4960-8c34-1e4ac0256a3c",
   "metadata": {},
   "source": [
    "Note: 2 is to centerfield, 6 is from centerfield, clockwise (may not be relevant here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a265c2-adb6-43b6-8b99-8f4ba4f2bcde",
   "metadata": {},
   "source": [
    "Calculate wind vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c89b43e-be46-42d1-93bd-2ab6e6ba1673",
   "metadata": {},
   "source": [
    "y-vector: positive to centerfield, negative from centerfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe770413-e196-4f24-81e4-af1d677f765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_vect(df):\n",
    "    wind_speed = df['windSpeed']\n",
    "    angled = df['windSpeed'] / 2 * math.sqrt(2)\n",
    "    \n",
    "    if df['windDirection'] == \"Out To CF\": \n",
    "        y_vect = wind_speed\n",
    "    elif df['windDirection'] == \"Out To RF\": \n",
    "        y_vect = angled\n",
    "    elif df['windDirection'] == \"L To R\": \n",
    "        y_vect = 0\n",
    "    elif df['windDirection'] == \"In From LF\": \n",
    "        y_vect = angled * -1\n",
    "    elif df['windDirection'] == \"In From CF\": \n",
    "        y_vect = wind_speed * - 1\n",
    "    elif df['windDirection'] == \"In From RF\": \n",
    "        y_vect = angled * -1\n",
    "    elif df['windDirection'] == \"R To L\": \n",
    "        y_vect = 0\n",
    "    elif df['windDirection'] == \"Out To LF\": \n",
    "        y_vect = angled\n",
    "    else:\n",
    "        y_vect = 0\n",
    "\n",
    "    \n",
    "    return y_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd315a4c-3e4b-4fbf-8c2b-ee745a89ecb0",
   "metadata": {},
   "source": [
    "x-vector: positive to right, negative to left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9181165a-55c7-4812-9d32-f9715b12ace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive from left to right, negative from right to left\n",
    "def x_vect(df):\n",
    "    wind_speed = df['windSpeed']\n",
    "    angled = df['windSpeed'] / 2 * math.sqrt(2)\n",
    "    \n",
    "    if df['windDirection'] == \"L To R\": \n",
    "        x_vect = wind_speed\n",
    "    elif df['windDirection'] == \"In From LF\": \n",
    "        x_vect = angled\n",
    "    elif df['windDirection'] == \"In From CF\": \n",
    "        x_vect = 0\n",
    "    elif df['windDirection'] == \"In From RF\": \n",
    "        x_vect = angled * -1\n",
    "    elif df['windDirection'] == \"R To L\": \n",
    "        x_vect = wind_speed * - 1\n",
    "    elif df['windDirection'] == \"Out To LF\": \n",
    "        x_vect = angled * -1\n",
    "    elif df['windDirection'] == \"Out To CF\": \n",
    "        x_vect = 0\n",
    "    elif df['windDirection'] == \"Out To RF\": \n",
    "        x_vect = angled\n",
    "    else:\n",
    "        x_vect = 0\n",
    "\n",
    "    \n",
    "    return x_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670d7710-7595-4f4a-a79d-8d1f32b31516",
   "metadata": {},
   "source": [
    "Create clean weather dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd07eb1-f8ea-490a-9116-288b54e6f5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_weather(df):   \n",
    "    # Separate weather into temperature and weather type\n",
    "    df[['temperature', 'weather']] = df['weather'].str.split(\", \", expand=True)\n",
    "    df['temperature'] = df['temperature'].str.replace(\" degrees\", \"\").astype('int')\n",
    "    \n",
    "    # Separate wind into speed and direction\n",
    "    df[['windSpeed', 'windDirection']] = df['wind'].str.split(\", \", expand=True)\n",
    "    df['windSpeed'].fillna(\"0 mph\", inplace=True)\n",
    "    df['windSpeed'] = df['windSpeed'].str.replace(\" mph\", \"\")\n",
    "    df['windSpeed'] = pd.to_numeric(df['windSpeed'], errors='coerce')\n",
    "    df['windSpeed'].fillna(0, inplace=True)\n",
    "    df['windDirection'].fillna('L to R', inplace=True)\n",
    "    df['windSpeed'].unique()\n",
    "    df['windDirection'] = df['windDirection'].str.replace(\".\", \"\")\n",
    "    \n",
    "    # Calculate vectors\n",
    "    df['x_vect'] = df.apply(x_vect, axis=1)\n",
    "    df['y_vect'] = df.apply(y_vect, axis=1)\n",
    "\n",
    "    ### TESTING:\n",
    "    # Set temperature to 70 degrees if it's a dome or the roof is close\n",
    "    df['temperature'] = df.apply(lambda row: 70 if 'Roof' in row['weather'] or 'Dome' in row['weather'] else row['temperature'], axis=1)\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00b1894-a0fe-4b7f-acf6-6a61b1cf0378",
   "metadata": {},
   "source": [
    "##### Model Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2470c260-6f9d-449f-ad82-d793584018e4",
   "metadata": {},
   "source": [
    "Categorize API events into model events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c0bed1-43d5-4976-8bbc-3d3743518e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_events(df):\n",
    "    event_mapping_dict = {\n",
    "        # Strikeout\n",
    "        'Strikeout': 'so',\n",
    "        'Strikeout Double Play': 'so',\n",
    "        # Groundout\n",
    "        'Groundout': 'go',\n",
    "        'Fielders Choice': 'go',\n",
    "        'Fielders Choice Out': 'go',\n",
    "        'Double Play': 'go',\n",
    "        'Grounded Into DP': 'go',\n",
    "        'Triple Play': 'go',\n",
    "        'Field Error': 'go',\n",
    "        'Forceout': 'go',\n",
    "        'Sac Bunt': 'go',\n",
    "        'Sac Bunt Double Play': 'go', \n",
    "        'Bunt Groundout': 'go',\n",
    "        # Lineout\n",
    "        'Lineout': 'lo',\n",
    "        'Bunt Lineout': 'lo',\n",
    "        # Flyout\n",
    "        'Flyout': 'fo',\n",
    "        'Sac Fly': 'fo',\n",
    "        'Sac Fly Double Play': 'fo',\n",
    "        # Pop out\n",
    "        'Pop Out': 'po',\n",
    "        'Bunt Pop Out': 'po',\n",
    "        # Hit by pitch\n",
    "        'Hit By Pitch': 'hbp',\n",
    "        # Walk\n",
    "        'Walk': 'bb',\n",
    "        'Intent Walk': 'bb',\n",
    "        # Single\n",
    "        'Single': 'b1',\n",
    "        # Double\n",
    "        'Double': 'b2',\n",
    "        # Triple\n",
    "        'Triple': 'b3',\n",
    "        # Home run\n",
    "        'Home Run': 'hr'\n",
    "    }\n",
    "    # Assign, categorizing all others as fit to cut\n",
    "    df['eventsModel'] = df['event'].map(event_mapping_dict).fillna('Cut')\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b416a0e4-efea-4a22-97cf-c7dc452ad7f4",
   "metadata": {},
   "source": [
    "Create dummy variables from events, venues, handedness, and bases (also generates and cleans some other simple variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab59322d-abb2-4081-bd7b-7a81e3244210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummies(df):    \n",
    "    # Events\n",
    "    event_dummies = pd.get_dummies(df['eventsModel'])\n",
    "    \n",
    "    # Hands\n",
    "    pitcher_dummies = pd.get_dummies(df['pitchHand'], prefix='p')\n",
    "    batter_dummies = pd.get_dummies(df['batSide'], prefix='b')\n",
    "    \n",
    "    # Years\n",
    "    df['year'] = df['game_date'].str[:4].astype(int)\n",
    "    \n",
    "    # Add dummies to dataframe\n",
    "    df = pd.concat([df, event_dummies, pitcher_dummies, batter_dummies], axis=1)\n",
    "\n",
    "    # Identify starting pitcher\n",
    "    df['startingPitcher'] = df.groupby(['gamePk', 'halfInning'])['pitcherName'].transform('first')\n",
    "    df['starter'] = (df['startingPitcher'] == df['pitcherName']).astype('int')\n",
    "    \n",
    "    # Create compatible date variable\n",
    "    df['date'] = df['game_date'].str.replace('-', '')\n",
    "    \n",
    "    # Convert to numeric for sorting\n",
    "    df['date'] = df['date'].astype('int')\n",
    "    df['gamePk'] = df['gamePk'].astype('int')\n",
    "    df['atBatIndex'] = df['atBatIndex'].astype('int')\n",
    "    \n",
    "    # Sort\n",
    "    df.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "    \n",
    "    # Create dummy for runners on base\n",
    "    df['preOnFirst'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnFirst'].shift(1)\n",
    "    df['preOnSecond'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnSecond'].shift(1)\n",
    "    df['preOnThird'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnThird'].shift(1)\n",
    "    \n",
    "    df['onFirst'] = df['preOnFirst'].apply(lambda x: 1 if isinstance(x, str) and 'id' in x else 0)\n",
    "    df['onSecond'] = df['preOnSecond'].apply(lambda x: 1 if isinstance(x, str) and 'id' in x else 0)\n",
    "    df['onThird'] = df['preOnThird'].apply(lambda x: 1 if isinstance(x, str) and 'id' in x else 0)\n",
    "    \n",
    "    # Top of the inning dummy\n",
    "    df['top'] = np.where(df['halfInning'] == \"top\", 1, 0)\n",
    "    \n",
    "    # Convert to numeric\n",
    "    df['awayScore'] = df['awayScore'].astype('int')\n",
    "    df['homeScore'] = df['homeScore'].astype('int')\n",
    "    \n",
    "    # Determine score before PA\n",
    "    df['preAwayScore'] = df.groupby(['gamePk'])['awayScore'].shift(1)\n",
    "    df['preHomeScore'] = df.groupby(['gamePk'])['homeScore'].shift(1)\n",
    "    \n",
    "    # If it's the first PA, it'll be missing. \n",
    "    df['preAwayScore'] = df['preAwayScore'].fillna(0)\n",
    "    df['preHomeScore'] = df['preHomeScore'].fillna(0)\n",
    "    \n",
    "    # Calculate differential\n",
    "    df['score_diff'] = np.where(df['top'] == 1, df['preAwayScore'] - df['preHomeScore'], df['preHomeScore'] - df['preAwayScore'])\n",
    "    \n",
    "    # Determine hitter and pitcher scores\n",
    "    df['batterScore'] = np.where(df['halfInning'] == 'top', df['awayScore'], df['homeScore'])\n",
    "    df['pitcherScore'] = np.where(df['halfInning'] == 'top', df['homeScore'], df['awayScore'])\n",
    "    \n",
    "    # Determine score before PA\n",
    "    df['preBatterScore'] = np.where(df['halfInning'] == 'top', df['preAwayScore'], df['preHomeScore'])\n",
    "    df['prePitcherScore'] = np.where(df['halfInning'] == 'top', df['preHomeScore'], df['preAwayScore'])\n",
    "    \n",
    "    # Calculate PAs and ABs\n",
    "    df['pa'] = np.where(df['eventsModel'] != \"Cut\", 1, 0)\n",
    "    df['ab'] = df['pa'] - df['hbp'] - df['bb']           \n",
    "            \n",
    "    # Sort\n",
    "    df.sort_values(['date', 'gamePk', 'atBatIndex'], inplace=True)\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981d2539-30b4-402e-877f-6df8b4d1caf0",
   "metadata": {},
   "source": [
    "Create variables from Statcast data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9086db7e-516c-4a12-9103-cb8658e9ebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_statcast(df):\n",
    "    # Convert variables to numeric\n",
    "    df['launch_speed'] = pd.to_numeric(df['launch_speed'], errors='coerce')\n",
    "    df['launch_speed_angle'] = pd.to_numeric(df['launch_speed_angle'], errors='coerce')\n",
    "    df['hc_x'] = pd.to_numeric(df['hc_x'], errors='coerce')\n",
    "    df['hc_y'] = pd.to_numeric(df['hc_y'], errors='coerce')\n",
    "    \n",
    "    # Hard hit dummy\n",
    "    df['hard_hit'] = (df['launch_speed'] >= 95).astype('int')\n",
    "    \n",
    "    # Barrel dummy\n",
    "    df['barrel'] = (df['launch_speed_angle'] == 6).astype('int')\n",
    "\n",
    "    # Spray \n",
    "    df['spray_angle'] = np.arctan((df['hc_x'] - 125.42) / (198.27 - df['hc_y'])) * 180 / np.pi * 0.75\n",
    "    df['to_left'] = (df['spray_angle'] < -15).astype('int')\n",
    "    df['to_middle'] = ((df['spray_angle'] >= -15) & (df['spray_angle'] <= 15)).astype('int')\n",
    "    df['to_right'] = (df['spray_angle'] > 15).astype('int')\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03adc6c7-e3e3-4b42-9641-f9e57a2bb3e7",
   "metadata": {},
   "source": [
    "Adjust for park factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aeff47-2e6f-46a4-9c8c-1e37435ee004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def park_adjustments(df):   \n",
    "    # Read in park factors\n",
    "    multiplier_df = pd.read_csv(os.path.join(baseball_path, \"Multiplier Dataset.csv\"))\n",
    "\n",
    "    # Convert to numeric for merging\n",
    "    multiplier_df['gamePk'] = multiplier_df['gamePk'].astype(int)\n",
    "    df['gamePk'] = df['gamePk'].astype('int')\n",
    "    \n",
    "    # Merge with park factors\n",
    "    multiplier_columns = [column for column in multiplier_df.columns if \"mult\" in column]\n",
    "    league_avg_columns = [column for column in multiplier_df.columns if \"league\" in column]\n",
    "    df = df.merge(multiplier_df[[\"gamePk\"] + multiplier_columns + league_avg_columns], on=['gamePk'], how='left', indicator=True)\n",
    "    \n",
    "    # Missings (old parks, other parks)\n",
    "    # Multipliers of 1 \n",
    "    df[multiplier_columns] = df[multiplier_columns].fillna(1)\n",
    "    # Most recent league_averages\n",
    "    df[league_avg_columns] = df[league_avg_columns].ffill()\n",
    "\n",
    "\n",
    "    # Loop over events\n",
    "    for event in events_list:\n",
    "        # Adjust based on calculated multiplier\n",
    "        df[event] = np.where(df['batSide'] == \"L\", df[event].astype(float) / df[f'{event}_mult_l'].astype(float), df[event].astype(float) / df[f'{event}_mult_r'].astype(float))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ce383-a501-4e2f-a1f1-03aef47d3523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New park adjustments\n",
    "def park_adjustments(df, multiplier_df):   \n",
    "    # # Read in park factors\n",
    "    # multiplier_df = pd.read_csv(os.path.join(baseball_path, \"New Multiplier Dataset.csv\"), dtype='str')\n",
    "\n",
    "#     # Convert to numeric for merging\n",
    "#     multiplier_df['gamePk'] = multiplier_df['gamePk'].astype(int)\n",
    "#     df['gamePk'] = df['gamePk'].astype('int')\n",
    "    \n",
    "    # Merge with park factors\n",
    "    # multiplier_columns = [column for column in multiplier_df.columns if \"mult\" in column]\n",
    "    # league_avg_columns = [column for column in multiplier_df.columns if \"league\" in column]\n",
    "    pfx_columns = [col for col in multiplier_df.columns if \"pfx\" in column]\n",
    "    df = df.merge(multiplier_df[['gamePk'] + pfx_columns], on=['gamePk'], how='left')\n",
    "    \n",
    "    # Missings (old parks, other parks)\n",
    "    # Multipliers of 1 \n",
    "    # df[pfx_columns] = df[pfx_columns].fillna(1)\n",
    "    # # Most recent league_averages\n",
    "    # df[league_avg_columns] = df[league_avg_columns].ffill()\n",
    "\n",
    "    \n",
    "\n",
    "    # Loop over events\n",
    "    for event in events_list:\n",
    "        # Adjust based on calculated multiplier\n",
    "        df[event] = np.where(df['batSide'] == \"L\", df[event].astype(float) / df[f'{event}_pfx_l'].astype(float), df[event].astype(float) / df[f'{event}_pfx_r'].astype(float))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061141cc-c793-4149-9913-560c83463b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f862055-9a96-49e2-8844-6fde8b4bb5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return a dataframe that can eventually be used as the model input. Has pitcher vs hitter stats, specific to hand\n",
    "def rolling_pas(df, pa_num):\n",
    "    # Copy dataframe\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Note: batter_avg_short will work even when pa_num refers to the \"long\" period. Suffix will be added in post.\n",
    "    # Rename for compatibility purposes\n",
    "    df_copy.rename(columns={'hit_distance_sc':'totalDistance', 'launch_speed':'launchSpeed'}, inplace=True)          \n",
    "            \n",
    "    # Convert to numeric and fill with 0s\n",
    "    combined_list = avg_list + max_list\n",
    "    for col in combined_list:\n",
    "        # Check if the column is not numeric\n",
    "        if not pd.api.types.is_numeric_dtype(df_copy[col]):\n",
    "            # Convert the non-numeric column to numeric and fill missing values with 0\n",
    "            df_copy[col] = pd.to_numeric(df_copy[col], errors='coerce')\n",
    "            df_copy[col] = df_copy[col].fillna(0)\n",
    "\n",
    "    # Sort\n",
    "    df_copy.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "            \n",
    "    # Data types may vary. This makes grouping impossible. \n",
    "    df_copy['batter'] = df_copy['batter'].astype('int')\n",
    "    df_copy['pitcher'] = df_copy['pitcher'].astype('int')\n",
    "        \n",
    "    ### Batter stats \n",
    "    # Stats for which you want the average \n",
    "    df_copy[batter_avg_short] = df_copy.groupby(['batter', 'pitchHand'])[avg_list].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).mean())\n",
    "    # Stats for which you want the maximum\n",
    "    df_copy[batter_max_short] = df_copy.groupby(['batter', 'pitchHand'])[max_list].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).max())\n",
    "    # Stats for which you just want the sum \n",
    "    df_copy[['ab_b', 'pa_b']] = df_copy.groupby(['batter', 'pitchHand'])[['ab', 'pa']].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).sum())\n",
    "                \n",
    "    ### Pitcher stats\n",
    "    # Stats for which you want the average\n",
    "    df_copy[pitcher_avg_short] = df_copy.groupby(['pitcher', 'batSide'])[avg_list].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).mean())\n",
    "    # Stats for which you want the maximum\n",
    "    df_copy[pitcher_max_short] = df_copy.groupby(['pitcher', 'batSide'])[max_list].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).max())\n",
    "    # Stats for which you just want the sum \n",
    "    df_copy[['ab_p', 'pa_p']] = df_copy.groupby(['pitcher', 'batSide'])[['ab', 'pa']].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).sum())\n",
    "                \n",
    "    # Create imputation flags (these observations will have imputed inputs)\n",
    "    df_copy['imp_b'] = (df_copy['pa_b'] < 40).astype('int')\n",
    "    df_copy['imp_p'] = (df_copy['pa_p'] < 40).astype('int')\n",
    "\n",
    "    # Create compatible date variable\n",
    "    df_copy['date'] = df_copy['game_date'].str.replace('-', '')\n",
    "    \n",
    "    # Convert to numeric for sorting\n",
    "    df_copy['date'] = df_copy['date'].astype('int')\n",
    "    df_copy['gamePk'] = df_copy['gamePk'].astype('int')\n",
    "    df_copy['atBatIndex'] = df_copy['atBatIndex'].astype('int')\n",
    "    df_copy['batter'] = df_copy['batter'].astype('int')\n",
    "    df_copy['pitcher'] = df_copy['pitcher'].astype('int')\n",
    "    \n",
    "    # Sort\n",
    "    df_copy.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "\n",
    "    ### Advanced stats\n",
    "    # wOBA - using 2022 values throughout\n",
    "    df_copy['woba_b'] = (0.690 * df_copy['bb_b']) + (0.721 * df_copy['hbp_b']) + (0.885 * df_copy['b1_b']) + (1.262 * df_copy['b2_b']) + (1.601 * df_copy['b3_b']) + (2.070 * df_copy['hr_b'])\n",
    "    df_copy['woba_p'] = (0.690 * df_copy['bb_p']) + (0.721 * df_copy['hbp_p']) + (0.885 * df_copy['b1_p']) + (1.262 * df_copy['b2_p']) + (1.601 * df_copy['b3_p']) + (2.070 * df_copy['hr_p'])\n",
    "    \n",
    "    # Slugging\n",
    "    df_copy['slg_b'] = ((1 * df_copy['b1_b']) + (2 * df_copy['b2_b']) + (3 * df_copy['b3_b']) + (4 * df_copy['hr_b'])) * (1 / (1-(df_copy['bb_b'] + df_copy['hbp_b'])))\n",
    "    df_copy['slg_p'] = ((1 * df_copy['b1_p']) + (2 * df_copy['b2_p']) + (3 * df_copy['b3_p']) + (4 * df_copy['hr_p'])) * (1 / (1-(df_copy['bb_p'] + df_copy['hbp_p'])))\n",
    "    # OBP    \n",
    "    df_copy['obp_b'] = df_copy[['b1_b', 'b2_b', 'b3_b', 'hr_b', 'bb_b', 'hbp_b']].sum(axis=1)\n",
    "    df_copy['obp_p'] = df_copy[['b1_p', 'b2_p', 'b3_p', 'hr_p', 'bb_p', 'hbp_p']].sum(axis=1)\n",
    "    \n",
    "    # ISO\n",
    "    df_copy['iso_b'] = (df_copy['b2_b'] * 1 + df_copy['b3_b'] * 2 + df_copy['hr_b'] * 3) * (1 / (1-(df_copy['bb_b'] + df_copy['hbp_b'])))\n",
    "    df_copy['iso_p'] = (df_copy['b2_p'] * 1 + df_copy['b3_p'] * 2 + df_copy['hr_p'] * 3) * (1 / (1-(df_copy['bb_p'] + df_copy['hbp_p'])))\n",
    "\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cec745-caa0-4285-9959-0b95c0f16713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates information about starts for use in pulling pitchers\n",
    "def start_data(df):\n",
    "    # Calculate the sum for each group\n",
    "    df['br'] = df[['b1', 'b2', 'b3', 'hr', 'bb', 'hbp']].astype('float').sum(axis=1)\n",
    "\n",
    "    # Calculate the cumulative sum within each group\n",
    "    df['br_inning'] = df.groupby(['gamePk', 'inning', 'halfInning'])['br'].cumsum()\n",
    "    \n",
    "    # Convert to numeric\n",
    "    print(df[['inning', 'outs', 'rbi']].dtypes)\n",
    "    df['inning'] = pd.to_numeric(df['inning'])\n",
    "    df['outs'] = pd.to_numeric(df['outs'])\n",
    "    df['rbi'] = df['rbi'].astype('int')\n",
    "    \n",
    "    # Number of batters faced (will be used to calculate rolling sum)\n",
    "    df['faced'] = 1\n",
    "    \n",
    "    # Cumulative counts\n",
    "    # Stats to sum\n",
    "    sums_list = ['gamePk', 'pitcher'] + events_list + ['rbi', 'faced']\n",
    "    # Calculate\n",
    "    sums = df[sums_list].groupby(['gamePk', 'pitcher']).cumsum()\n",
    "    # Add suffix\n",
    "    sums = sums.add_suffix(\"_sum\")\n",
    "    \n",
    "    # Add rolling sums\n",
    "    df = pd.concat([df, sums], axis=1)\n",
    "    \n",
    "    # Identify if it's the bottom of the inning (a little more helpful than \"top\" as it's sortable)\n",
    "    df['bottom'] = (df['top'] == 0).astype('int')\n",
    "    \n",
    "    # Sort to identify starting pitchers\n",
    "    df = df.sort_values(by=['date', 'gamePk', 'bottom', 'atBatIndex'])\n",
    "    \n",
    "    # The starter has the lowest atBatIndex\n",
    "    df['atBatIndex_min'] = df.groupby(['gamePk', 'bottom'])['atBatIndex'].transform('min')\n",
    "    df['start'] = (df['atBatIndex'] == df['atBatIndex_min']).astype('int')\n",
    "        \n",
    "    # Identify starter throughout\n",
    "    df['starter'] = df.groupby(['pitcher', 'gamePk'])['start'].cumsum()\n",
    "    \n",
    "    # Keep only starters\n",
    "    df = df.query('starter == 1')\n",
    "    \n",
    "    # The starter is pulled at their highest atBatIndex\n",
    "    df['atBatIndex_max'] = df.groupby(['gamePk', 'bottom'])['atBatIndex'].transform('max')\n",
    "    df['pulled'] = (df['atBatIndex'] == df['atBatIndex_max']).astype('int')\n",
    "    \n",
    "    # Batters faced that inning\n",
    "    df['faced_inning'] = df.groupby(['gamePk', 'inning', 'bottom']).cumcount()+1\n",
    "    df['faced_inning'] = np.where(df['outs'] == 3, 0, df['faced_inning'])\n",
    "    \n",
    "    # Rolling sums stats (post-rolling sum)\n",
    "    rolled_sums_list = [f'{stat}_sum' for stat in events_list] + ['rbi_sum', 'faced_sum']\n",
    "    \n",
    "    # Outs recorded by starting pitcher \n",
    "    df['OUT'] = ((df['inning'] - 1) * 3) + df['outs']\n",
    "    \n",
    "    # This adjusts timing to better reflect when pitchers are pulled\n",
    "    # If a pitcher is pulled after 6 innings in the data, that's the same as pulling at the top of the 7th, which more closely reflects how the sim works\n",
    "    df['inning_adj'] = df['inning'] + (df['outs'] == 3).astype('int')\n",
    "    df['outs_adj'] = np.where(df['outs'] == 3, 0, df['outs'])\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5901b5-1e03-425b-b77d-374b66a5b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_datasets(start_year=2015, end_year=2024):\n",
    "    # List of merged datasets\n",
    "    df_list = []\n",
    "    # Read in datasets\n",
    "    for year in range(start_year, end_year+1):\n",
    "        statsapi_df = pd.read_csv(os.path.join(baseball_path, \"A02. MLB API\", \"1. Stats API\", f\"Stats API {year}.csv\"), encoding='iso-8859-1')\n",
    "        statcast_df = pd.read_csv(os.path.join(baseball_path, \"A02. MLB API\", \"2. Statcast\", f\"Statcast {year}.csv\"), encoding='iso-8859-1')\n",
    "        \n",
    "        # Merge them together\n",
    "        merged_df = pd.merge(statsapi_df, statcast_df, on=['gamePk', 'atBatIndex'], how='left')\n",
    "\n",
    "        # Drop duplicate observations\n",
    "        merged_df.drop_duplicates(['gamePk', 'atBatIndex'], keep='first', inplace=True)\n",
    "        \n",
    "        # Add them to a list\n",
    "        df_list.append(merged_df)\n",
    "    \n",
    "    # Create raw dataset\n",
    "    df = pd.concat(df_list, axis=0)   \n",
    "    \n",
    "    # Create data variable (without dashes)\n",
    "    df['date'] = df['game_date'].str.replace('-', '')\n",
    "\n",
    "    # Convert to numeric for sorting\n",
    "    df['date'] = df['date'].astype('int')\n",
    "    df['gamePk'] = df['gamePk'].astype('int')\n",
    "    df['atBatIndex'] = df['atBatIndex'].astype('int')\n",
    "\n",
    "    # Sort\n",
    "    df.sort_values(['game_date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "\n",
    "    # Only keep one observation per at bat\n",
    "    df.drop_duplicates(['gamePk', 'atBatIndex'], keep='first', inplace=True)\n",
    "\n",
    "    # Determine outs coming into PA\n",
    "    df['outs_pre'] = df.groupby(['gamePk', 'inning', 'halfInning'])['outs'].shift(fill_value=0)\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a20426-de2f-48ad-9be7-850783298494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates model inputs\n",
    "def create_pa_inputs(park_factors, team_map, start_year, end_year, short=50, long=300, adjust=True):\n",
    "    # Merge together raw Stats API and Statcast data\n",
    "    df = merge_datasets(start_year, end_year)\n",
    "    # Clean weather\n",
    "    df2 = clean_weather(df)\n",
    "    # Create PA events \n",
    "    df3 = create_events(df2)\n",
    "    # Create dummy variables \n",
    "    df4 = create_dummies(df3)\n",
    "    # Create Statcast variables\n",
    "    df5 = clean_statcast(df4)   \n",
    "    # Adjust for park factors\n",
    "    if adjust == True:\n",
    "        df6 = park_adjustments(df5)\n",
    "        df6.drop(columns={'_merge'}, inplace=True)\n",
    "    else:\n",
    "        df6 = df5.copy()\n",
    "    # Clean up\n",
    "    df6 = df6.query('eventsModel != \"Cut\"')\n",
    "    df6.fillna(0, inplace=True)\n",
    "    \n",
    "    ### Rolling stats\n",
    "    # Short\n",
    "    df_short = rolling_pas(df6, short)\n",
    "    # Long\n",
    "    df_long = rolling_pas(df6, long)\n",
    "    df_long = df_long.add_suffix(\"_long\")\n",
    "        \n",
    "    # We only need the rolling stats \n",
    "    long_stats = batter_stats_long + pitcher_stats_long\n",
    "    df_long = df_long[long_stats]\n",
    "    \n",
    "    # Dataset\n",
    "    complete_dataset = pd.concat([df_short, df_long], axis=1)\n",
    "\n",
    "    # Fix Guardians name to make uniform\n",
    "    complete_dataset['away_name'] = np.where(complete_dataset['away_name'] == \"Cleveland Indians\", \"Cleveland Guardians\", complete_dataset['away_name'])\n",
    "    complete_dataset['home_name'] = np.where(complete_dataset['home_name'] == \"Cleveland Indians\", \"Cleveland Guardians\", complete_dataset['home_name'])\n",
    "\n",
    "    # Only keep regular season\n",
    "    complete_dataset = complete_dataset[complete_dataset['game_type_x'] == \"R\"]\n",
    "\n",
    "    # Reset index\n",
    "    complete_dataset.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Sort\n",
    "    complete_dataset.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "    \n",
    "    \n",
    "    return complete_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a9ac1b-3a32-4b55-b75f-cfd734c97f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates model inputs\n",
    "def create_pull_inputs(park_factors, team_map, start_year, end_year, short=50, long=300, adjust=True):\n",
    "    # Merge together raw Stats API and Statcast data\n",
    "    df = merge_datasets(start_year, end_year)\n",
    "    # Clean weather\n",
    "    df2 = clean_weather(df)\n",
    "    # Create PA events \n",
    "    df3 = create_events(df2)\n",
    "    # Create dummy variables \n",
    "    df4 = create_dummies(df3)\n",
    "    # Create Statcast variables\n",
    "    df5 = clean_statcast(df4)   \n",
    "    # Adjust for park factors\n",
    "    if adjust == True:\n",
    "        df6 = park_adjustments(df5)\n",
    "        df6.drop(columns={'_merge'}, inplace=True)\n",
    "    else:\n",
    "        df6 = df5.copy()\n",
    "    # Add start data\n",
    "    complete_dataset = start_data(df6)\n",
    "    \n",
    "    # Clean up\n",
    "    # complete_dataset.drop(columns={'_merge'}, inplace=True)\n",
    "    complete_dataset.fillna(0, inplace=True)\n",
    "    \n",
    "    # Sort\n",
    "    complete_dataset.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "\n",
    "    \n",
    "    return complete_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0756c8e-926a-4cad-9989-26083594c7b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d56dc5ac-a857-4c3c-ba8d-0593ecb5e602",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440f5068-2d13-4fc2-9c80-61618ebea3d1",
   "metadata": {},
   "source": [
    "##### 1. Stats API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c8fec9-9e3c-4c92-b155-23054a71e46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_datasets == True:\n",
    "    statsapi_df = plays_statsapi(f\"03/20/{year}\", f\"11/15/{year}\")\n",
    "    statsapi_df.to_csv(os.path.join(baseball_path, \"A02. MLB API\", \"1. Stats API\", f\"Stats API {year}.csv\"), index=False, encoding='iso-8859-1')\n",
    "\n",
    "    del statsapi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1399c2a5-e1ba-44c9-bae5-68f58b60e8a8",
   "metadata": {},
   "source": [
    "##### 2. Statcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d230bbb-af2d-43db-999e-c0dd8e95b2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_datasets == True:\n",
    "    statcast_df = plays_statcast(f\"{year}-03-20\", f\"{year}-11-15\")\n",
    "    statcast_df.to_csv(os.path.join(baseball_path, \"A02. MLB API\", \"2. Statcast\", \"Statcast 2024.csv\"), index=False, encoding='iso-8859-1')\n",
    "\n",
    "    del statcast_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
